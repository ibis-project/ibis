name: Flink Backend

on:
  push:
    # Skip the backend suite if all changes are docs
    paths-ignore:
      - "docs/**"
      - "**/*.md"
      - "**/*.qmd"
      - "codecov.yml"
      - ".envrc"
    branches:
      - master
      - "*.x.x"
  pull_request:
    # Skip the backend suite if all changes are docs
    paths-ignore:
      - "docs/**"
      - "**/*.md"
      - "**/*.qmd"
      - "codecov.yml"
      - ".envrc"
    branches:
      - master
      - "*.x.x"
  merge_group:

permissions:
  # this allows extractions/setup-just to list releases for `just` at a higher
  # rate limit while restricting GITHUB_TOKEN permissions elsewhere
  contents: read

concurrency:
  group: ${{ github.repository }}-${{ github.head_ref || github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

env:
  FORCE_COLOR: "1"

jobs:
  test_backends:
    name: ${{ matrix.backend.title }} ${{ matrix.os }} python-${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os:
          - ubuntu-latest
        python-version:
          - "3.9"
        backend:
          - name: flink
            title: Flink
            serial: true
            extras:
              - flink
            additional_deps:
              - apache-flink
              - grpcio-status # FIXME(deepyaman)
              - pytest-split
        group:
          [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
          ]
    steps:
      - name: checkout
        uses: actions/checkout@v4

      - uses: extractions/setup-just@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: download backend data
        run: just download-data

      - name: install python
        uses: actions/setup-python@v4
        id: install_python
        with:
          python-version: ${{ matrix.python-version }}

      - uses: syphar/restore-pip-download-cache@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: ${{ steps.install_python.outputs.python-version }}

      - name: install poetry
        run: python -m pip install --upgrade pip 'poetry==1.6.1'

      - uses: syphar/restore-virtualenv@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: ${{ matrix.backend.name }}-${{ steps.install_python.outputs.python-version }}

      - name: install ibis
        run: poetry install --without dev --without docs --extras "${{ join(matrix.backend.extras, ' ') }}"

      - name: install other deps
        run: poetry run pip install ${{ join(matrix.backend.additional_deps, ' ') }}

      # FIXME(deepyaman): We reinstall pandas~=1.5 to get a version with
      #   ArrowDtype, but this step will be removed once PyFlink relaxes
      #   its overly-restrictive dependencies (specifying pandas<1.4.0).
      - name: override overly-restrictive PyFlink requirements
        run: poetry run pip install pandas~=1.5

      - name: show installed deps
        run: poetry run pip list

      - name: "run serial tests: ${{ matrix.backend.name }} (common)"
        if: matrix.group > 0
        run: just ci-check -m ${{ matrix.backend.name }} ibis/backends/tests --splits 20 --group ${{ matrix.group }} --splitting-algorithm least_duration
        env:
          IBIS_EXAMPLES_DATA: ${{ runner.temp }}/examples-${{ matrix.backend.name }}-${{ matrix.os }}-${{ steps.install_python.outputs.python-version }}
          JVM_ARGS: -XX:CompressedClassSpaceSize=3G

      # FIXME(deepyaman): If some backend-specific test, in test_ddl.py,
      #   executes before common tests, they will fail with:
      #   org.apache.flink.table.api.ValidationException: Table `default_catalog`.`default_database`.`functional_alltypes` was not found.
      #   Therefore, we quarantine backend-specific tests to avoid this.
      - name: "run serial tests: ${{ matrix.backend.name }} (backend-specific)"
        if: matrix.group == 0
        run: just ci-check -m ${{ matrix.backend.name }} ibis/backends/flink/tests
        env:
          IBIS_EXAMPLES_DATA: ${{ runner.temp }}/examples-${{ matrix.backend.name }}-${{ matrix.os }}-${{ steps.install_python.outputs.python-version }}
          JVM_ARGS: -XX:CompressedClassSpaceSize=3G

      - name: check that no untracked files were produced
        shell: bash
        run: git checkout poetry.lock pyproject.toml && ! git status --porcelain | tee /dev/stderr | grep .

      - name: upload code coverage
        uses: actions/upload-artifact@v2
        with:
          name: coverage${{ matrix.group }}
          path: .coverage

  coverage:
    needs: test_backends
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os:
          - ubuntu-latest
        python-version:
          - "3.9"
        backend:
          - name: flink
            title: Flink
            serial: true
            extras:
              - flink
            additional_deps:
              - apache-flink
              - grpcio-status # FIXME(deepyaman)
              - pytest-split
    steps:
      - name: checkout
        uses: actions/checkout@v4

      - name: install python
        uses: actions/setup-python@v4
        id: install_python
        with:
          python-version: ${{ matrix.python-version }}

      - uses: syphar/restore-pip-download-cache@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: ${{ steps.install_python.outputs.python-version }}

      - name: install poetry
        run: python -m pip install --upgrade pip 'poetry==1.6.1'

      - uses: syphar/restore-virtualenv@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: ${{ matrix.backend.name }}-${{ steps.install_python.outputs.python-version }}

      - name: install ibis
        run: poetry install --without dev --without docs --extras "${{ join(matrix.backend.extras, ' ') }}"

      - name: install other deps
        run: poetry run pip install ${{ join(matrix.backend.additional_deps, ' ') }}

      # FIXME(deepyaman): We reinstall pandas~=1.5 to get a version with
      #   ArrowDtype, but this step will be removed once PyFlink relaxes
      #   its overly-restrictive dependencies (specifying pandas<1.4.0).
      - name: override overly-restrictive PyFlink requirements
        run: poetry run pip install pandas~=1.5

      - name: show installed deps
        run: poetry run pip list

      - name: download all artifacts
        # Downloads coverage1, coverage2, etc.
        uses: actions/download-artifact@v3

      - name: run coverage
        run: |
          coverage combine coverage*/.coverage*
          coverage report
          coverage xml

      - name: upload code coverage
        if: success()
        uses: codecov/codecov-action@v3
        with:
          flags: backend,${{ matrix.backend.name }},${{ runner.os }},python-${{ steps.install_python.outputs.python-version }}
