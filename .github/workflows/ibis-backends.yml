name: Backends

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

concurrency:
  group: ${{ github.repository }}-${{ github.head_ref || github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

jobs:
  test_simple_backends:
    name: ${{ matrix.backend.title }} ${{ matrix.os }} python-${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os:
          - ubuntu-latest
          - windows-latest
        python-version:
          - "3.7"
          - "3.10"
        backend:
          - name: csv
            title: CSV
          - name: dask
            title: Dask
          - name: dask
            title: Dask Extra
            deps:
              - "dask@2021.10.0 --extras array --extras dataframe"
          - name: hdf5
            title: HDF5
          - name: pandas
            title: Pandas
          - name: parquet
            title: Parquet
          - name: sqlite
            title: SQLite
        exclude:
          - os: windows-latest
            python-version: "3.10"
            backend:
              name: hdf5
              title: HDF5
          # TODO: remove this when HDF5 becomes 3.10 compatible
          - os: ubuntu-latest
            python-version: "3.10"
            backend:
              name: hdf5
              title: HDF5
        include:
          - os: windows-latest
            python-version: "3.8"
            backend:
              name: hdf5
              title: HDF5
          # TODO: remove this when HDF5 becomes 3.10 compatible
          - os: ubuntu-latest
            python-version: "3.9"
            backend:
              name: hdf5
              title: HDF5
    steps:
      - name: checkout
        uses: actions/checkout@v2

      - name: install python
        uses: actions/setup-python@v2
        id: install_python
        with:
          python-version: ${{ matrix.python-version }}

      - uses: syphar/restore-virtualenv@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: ${{ matrix.backend.name }}-${{ matrix.backend.deps }}-${{ steps.install_python.outputs.python-version }}

      - uses: syphar/restore-pip-download-cache@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: ${{ matrix.backend.name }}-${{ matrix.backend.deps }}-${{ steps.install_python.outputs.python-version }}

      - run: python -m pip install --upgrade pip poetry

      - name: install minimum dask version
        if: ${{ matrix.backend.name == 'dask' && matrix.backend.deps != null }}
        run: poetry add --lock --optional ${{ join(matrix.backend.deps, ' ') }}

      - name: install ibis
        run: poetry install --extras ${{ matrix.backend.name }}

      - name: download backend data
        run: poetry run python ci/datamgr.py download

      - name: install backend data
        run: poetry run python ci/datamgr.py ${{ matrix.backend.name }}

      - name: run tests
        shell: bash
        env:
          PYTEST_BACKENDS: ${{ matrix.backend.name }}
        run: ./ci/run_tests.sh

      - name: publish test report
        uses: actions/upload-artifact@v2
        if: success() || failure()
        with:
          name: ${{ matrix.backend.name }}-${{ join(matrix.backend.deps, '-') }}-${{ matrix.os }}-${{ matrix.python-version }}
          path: junit.xml

  test_postgres:
    name: PostgreSQL ubuntu-latest python-${{ matrix.python-version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version:
          - "3.7"
          - "3.9"
        deps:
          - []
        include:
          - python-version: "3.7"
            deps:
              - "sqlalchemy@1.3"
              - "psycopg2@2.7.6"
              - "geoalchemy@0.6"
              - "geopandas@0.6"
              - "shapely@1.6"
    services:
      postgres:
        image: shajekpivotal/ibis-docker-postgres-9.5
        ports:
          - 5432:5432
        env:
          POSTGRES_PASSWORD: ""
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3
    steps:
      - name: checkout
        uses: actions/checkout@v2

      - name: install python
        uses: actions/setup-python@v2
        id: install_python
        with:
          python-version: ${{ matrix.python-version }}

      - name: install libgeos for shapely
        run: sudo apt-get install -qq -y build-essential libgeos-dev python-dev

      - uses: syphar/restore-virtualenv@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: postgres-geospatial-${{ join(matrix.deps, '-') }}-${{ steps.install_python.outputs.python-version }}

      - uses: syphar/restore-pip-download-cache@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: postgres-geospatial-${{ join(matrix.deps, '-') }}-${{ steps.install_python.outputs.python-version }}

      - run: python -m pip install --upgrade pip poetry

      - name: install minimum postgres dependencies
        if: ${{ toJSON(matrix.deps) != '[]' }}
        run: |
          set -euo pipefail

          deps=(${{ join(matrix.deps, ' ') }})
          args=(${deps[@]/#/--optional })
          poetry add --lock ${args[*]}

      - name: install ibis
        run: poetry install --extras postgres --extras geospatial

      - name: download backend data
        run: poetry run python ci/datamgr.py download

      - name: install backend data
        run: poetry run python ci/datamgr.py postgres

      - name: run tests
        env:
          PYTEST_BACKENDS: postgres
        run: ./ci/run_tests.sh -m "not udf"

      - name: publish test report
        uses: actions/upload-artifact@v2
        if: success() || failure()
        with:
          name: postgres-geospatial-${{ join(matrix.deps, '-') }}-${{ matrix.python-version }}
          path: junit.xml

  test_pyspark:
    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version:
          - "3.7"
          - "3.10"
        pyspark:
          - version: "2.4.3"
            jdk: "8"
            env:
              ARROW_PRE_0_15_IPC_FORMAT: 1
          - version: null
            jdk: "11"
            env:
              ARROW_PRE_0_15_IPC_FORMAT: 0
        exclude:
          - python-version: "3.10"
            pyspark:
              version: "2.4.3"
              jdk: "8"
              env:
                ARROW_PRE_0_15_IPC_FORMAT: 1
    steps:
      - name: checkout
        uses: actions/checkout@v2

      - name: install python
        uses: actions/setup-python@v2
        id: install_python
        with:
          python-version: ${{ matrix.python-version }}

      - uses: actions/setup-java@v2
        with:
          distribution: zulu
          java-version: ${{ matrix.pyspark.jdk }}

      - uses: syphar/restore-virtualenv@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: pyspark-${{ matrix.pyspark-version }}-${{ matrix.pyspark.jdk }}-${{ steps.install_python.outputs.python-version }}

      - uses: syphar/restore-pip-download-cache@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: pyspark-${{ matrix.pyspark-version }}-${{ matrix.pyspark.jdk }}-${{ steps.install_python.outputs.python-version }}

      - run: python -m pip install --upgrade pip poetry

      - name: pin pyspark
        if: ${{ matrix.pyspark.version != null }}
        run: poetry add --lock --optional "pyspark@${{ matrix.pyspark.version }}"

      - name: install ibis
        run: poetry install --extras pyspark

      - name: download backend data
        run: poetry run python ci/datamgr.py download

      - name: run tests
        env:
          PYTEST_BACKENDS: pyspark
          ARROW_PRE_0_15_IPC_FORMAT: ${{ matrix.pyspark.env.ARROW_PRE_0_15_IPC_FORMAT }}
        run: ./ci/run_tests.sh

      - name: publish test report
        uses: actions/upload-artifact@v2
        if: success() || failure()
        with:
          name: pyspark-${{ matrix.python-version }}-${{ matrix.pyspark.jdk }}-${{ matrix.pyspark.env.ARROW_PRE_0_15_IPC_FORMAT }}
          path: junit.xml

  test_impala:
    name: Impala ubuntu-latest python-${{ matrix.python-version }}
    runs-on: ubuntu-latest
    env:
      IBIS_TEST_NN_HOST: localhost
      IBIS_TEST_IMPALA_HOST: localhost
      IBIS_TEST_IMPALA_PORT: 21050
      IBIS_TEST_WEBHDFS_PORT: 50070
      IBIS_TEST_WEBHDFS_USER: hdfs
    strategy:
      fail-fast: false
      matrix:
        python-version:
          - "3.7"
          # XXX: unlikely that impala will ever support 3.10
          - "3.9"
    services:
      postgres:
        image: shajekpivotal/ibis-docker-postgres-9.5
        ports:
          - 5432:5432
        env:
          POSTGRES_PASSWORD: ""
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3
      kudu-master:
        image: ibisproject/kudu:latest
        ports:
          - 7051:7051
          - 8051:8051
        env:
          KUDU_MASTER: "true"
        options: "--network-alias=kudu --cap-add=SYS_TIME"
      kudu-tserver:
        image: ibisproject/kudu:latest
        ports:
          - 7050:7050
          - 8050:8050
        env:
          KUDU_MASTER: "false"
        options: "--cap-add=SYS_TIME"
      impala:
        image: ibisproject/impala:latest
        env:
          PGPASSWORD: postgres
        ports:
          # HDFS
          - 9020:9020
          - 50070:50070
          - 50075:50075
          - 8020:8020
          - 8042:8042
          # Hive
          - 9083:9083

          # Impala
          - 21000:21000
          - 21050:21050
          - 25000:25000
          - 25010:25010
          - 25020:25020
        options: --hostname localhost --health-cmd "nc -z 127.0.0.1 21050 && nc -z 127.0.0.1 50070" --health-interval 30s --health-timeout 10s --health-retries 20
    steps:
      - name: checkout
        uses: actions/checkout@v2

      - name: install python
        uses: actions/setup-python@v2
        id: install_python
        with:
          python-version: ${{ matrix.python-version }}

      - name: install system dependencies
        run: sudo apt-get install -qq -y build-essential cmake krb5-config python-dev libkrb5-dev libboost-all-dev

      - uses: syphar/restore-virtualenv@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: impala-${{ steps.install_python.outputs.python-version }}

      - uses: syphar/restore-pip-download-cache@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: impala-${{ steps.install_python.outputs.python-version }}

      - run: python -m pip install --upgrade pip poetry

      - name: install ibis
        run: poetry install --extras impala

      - name: download backend data
        run: poetry run python ci/datamgr.py download

      - name: install backend data
        run: poetry run python ci/impalamgr.py load --data

      - name: run tests
        env:
          PYTEST_BACKENDS: impala
        run: ./ci/run_tests.sh

      - name: publish test report
        uses: actions/upload-artifact@v2
        if: success() || failure()
        with:
          name: impala-${{ matrix.python-version }}
          path: junit.xml

  test_mysql_clickhouse:
    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version:
          - "3.7"
          - "3.10"
        backend:
          - name: mysql
            title: MySQL
          - name: clickhouse
            title: ClickHouse
    services:
      mysql:
        image: mariadb:10.4.12
        ports:
          - 3306:3306
        env:
          MYSQL_ALLOW_EMPTY_PASSWORD: true
          MYSQL_DATABASE: ibis_testing
          MYSQL_USER: ibis
          MYSQL_PASSWORD: ibis
        options: --health-cmd="mysqladmin ping" --health-interval 10s --health-timeout 5s --health-retries 3
      clickhouse:
        image: yandex/clickhouse-server:20-alpine
        ports:
          - 8123:8123
          - 9000:9000
        options: --ulimit nofile=262144:262144
    steps:
      - name: checkout
        uses: actions/checkout@v2

      - name: install python
        uses: actions/setup-python@v2
        id: install_python
        with:
          python-version: ${{ matrix.python-version }}

      - uses: syphar/restore-virtualenv@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: ${{ matrix.backend.name }}-${{ steps.install_python.outputs.python-version }}

      - uses: syphar/restore-pip-download-cache@v1
        with:
          requirement_files: poetry.lock
          custom_cache_key_element: ${{ matrix.backend.name }}-${{ steps.install_python.outputs.python-version }}

      - run: python -m pip install --upgrade pip poetry

      - name: install ibis
        run: poetry install --extras ${{ matrix.backend.name }}

      - name: download backend data
        run: poetry run python ci/datamgr.py download

      - name: install backend data
        run: poetry run python ci/datamgr.py ${{ matrix.backend.name }}

      - name: run tests
        env:
          PYTEST_BACKENDS: ${{ matrix.backend.name }}
        run: ./ci/run_tests.sh

      - name: publish test report
        uses: actions/upload-artifact@v2
        if: success() || failure()
        with:
          name: ${{ matrix.backend.name }}-${{ matrix.python-version }}
          path: junit.xml

  backends:
    # this job exists so that we can use a single job from this workflow to gate merging
    runs-on: ubuntu-latest
    needs:
      - test_impala
      - test_mysql_clickhouse
      - test_postgres
      - test_pyspark
      - test_simple_backends
    steps:
      - run: exit 0
