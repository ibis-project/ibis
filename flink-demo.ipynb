{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Kafka source connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka connector is not part of the binary distribution, so we need to download and link it for cluster execution explicitly\n",
    "!wget https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-kafka/1.17.1/flink-sql-connector-kafka-1.17.1.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example record from upstream Kafka source:\n",
    "```json\n",
    "{\n",
    "    \"createTime\": \"2023-09-20 22:19:02.224\", \n",
    "    \"orderId\": 1695248388, \n",
    "    \"payAmount\": 88694.71922270155, \n",
    "    \"payPlatform\": 0, \n",
    "    \"provinceId\": 6,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "import ibis.expr.schema as sch\n",
    "import ibis.expr.datatypes as dt\n",
    "from pyflink.table import EnvironmentSettings, TableEnvironment\n",
    "from pyflink.common import Configuration\n",
    "\n",
    "source_schema = sch.Schema(\n",
    "    {\n",
    "        \"createTime\": dt.timestamp(scale=3),\n",
    "        \"orderId\": dt.int64,\n",
    "        \"payAmount\": dt.float64,\n",
    "        \"payPlatform\": dt.int32,\n",
    "        \"provinceId\": dt.int32,\n",
    "    }\n",
    ")\n",
    "\n",
    "env_settings = EnvironmentSettings.in_streaming_mode()\n",
    "table_env = TableEnvironment.create(env_settings)\n",
    "\n",
    "table_config = table_env.get_config()\n",
    "config = Configuration()\n",
    "config.set_string(\"parallelism.default\", \"1\")\n",
    "table_config.add_configuration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = ibis.flink.connect(table_env)\n",
    "\n",
    "# add the JAR downloaded above\n",
    "connection._exec_sql(\"ADD JAR 'flink-sql-connector-kafka-1.17.1.jar'\")\n",
    "\n",
    "source_configs = {\n",
    "    \"connector\": \"kafka\",\n",
    "    \"topic\": \"payment_msg\",\n",
    "    \"properties.bootstrap.servers\": \"localhost:9092\",\n",
    "    \"properties.group.id\": \"test_3\",\n",
    "    \"scan.startup.mode\": \"earliest-offset\",\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "t = connection.create_table(\n",
    "    \"payment_msg\",\n",
    "    schema=source_schema,\n",
    "    tbl_properties=source_configs,\n",
    "    watermark=ibis.watermark(\n",
    "        time_col=\"createTime\", allowed_delay=ibis.interval(seconds=15)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Kafka sink connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_schema = sch.Schema(\n",
    "    {\n",
    "        \"province\": dt.string,\n",
    "        \"pay_amount\": dt.float64,\n",
    "    }\n",
    ")\n",
    "\n",
    "kafka_sink_configs = {\n",
    "    \"connector\": \"kafka\",\n",
    "    \"topic\": \"sink\",\n",
    "    \"properties.bootstrap.servers\": \"localhost:9092\",\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "connection.create_table(\n",
    "    \"kafka_sink\", schema=sink_schema, tbl_properties=kafka_sink_configs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define reference table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "provinces = (\n",
    "    \"Beijing\",\n",
    "    \"Shanghai\",\n",
    "    \"Hangzhou\",\n",
    "    \"Shenzhen\",\n",
    "    \"Jiangxi\",\n",
    "    \"Chongqing\",\n",
    "    \"Xizang\",\n",
    ")\n",
    "province_id_to_name_df = pd.DataFrame(\n",
    "    enumerate(provinces), columns=[\"provinceId\", \"province\"]\n",
    ")\n",
    "province_id_to_name_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Ibis expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agged = t[\n",
    "    \"provinceId\",\n",
    "    t.payAmount.sum()\n",
    "    .over(range=(-ibis.interval(seconds=10), 0), order_by=t.createTime)\n",
    "    .name(\"pay_amount\"),\n",
    "]\n",
    "joined = agged.join(province_id_to_name_df, predicates=\"provinceId\")[\n",
    "    \"province\", \"pay_amount\"\n",
    "]\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = connection.compile(joined)\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream results into Kafka sink topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.insert(\"kafka_sink\", joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(\"sink\")\n",
    "for _, msg in zip(range(10), consumer):\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, do batch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(\"payment_msg\")\n",
    "rows = []\n",
    "for _, msg in zip(range(100), consumer):\n",
    "    rows.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([json.loads(row.value) for row in rows])\n",
    "df[\"createTime\"] = pd.to_datetime(df[\"createTime\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "\n",
    "con = ibis.pandas.connect()\n",
    "t = con.create_table(\"payments\", df)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agged = t[\n",
    "    \"provinceId\",\n",
    "    t.payAmount.sum()\n",
    "    .over(range=(-ibis.interval(seconds=10), 0), order_by=t.createTime)\n",
    "    .name(\"pay_amount\"),\n",
    "]\n",
    "joined = agged.join(province_id_to_name_df, predicates=\"provinceId\")[\n",
    "    \"province\", \"pay_amount\"\n",
    "]\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
