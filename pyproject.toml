[project]
name = "ibis-framework"
version = "9.5.0"
requires-python = ">=3.10"
description = "The portable Python dataframe library"
readme = "README.md"
license = "Apache-2.0"
authors = [
  { name = "Ibis Maintainers", email = "maintainers@ibis-project.org" },
]
maintainers = [
  { name = "Ibis Maintainers", email = "maintainers@ibis-project.org" },
]
classifiers = [
  "Development Status :: 5 - Production/Stable",
  "Intended Audience :: Developers",
  "Intended Audience :: Science/Research",
  "Operating System :: OS Independent",
  "Programming Language :: Python :: 3 :: Only",
  "Programming Language :: Python :: 3",
  "Programming Language :: Python",
  "Programming Language :: SQL",
  "Topic :: Database :: Front-Ends",
  "Topic :: Scientific/Engineering",
  "Topic :: Software Development :: Code Generators",
  "Topic :: Software Development :: User Interfaces",
]
dependencies = [
  "atpublic>=2.3",
  "parsy>=2",
  "python-dateutil>=2.8.2",
  "pytz>=2022.7",
  "sqlglot>=23.4,<26.2",
  "toolz>=0.11",
  "typing-extensions>=4.3.0",
]

[project.urls]
Homepage = "https://ibis-project.org"
Repository = "https://github.com/ibis-project/ibis"
Documentation = "https://ibis-project.org"
Issues = "https://github.com/ibis-project/ibis/issues"
Chat = "https://ibis-project.zulipchat.com"

[project.optional-dependencies]
athena = [
  "PyAthena[Pandas,Arrow]>=3.11.0,<4",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
  "packaging>=21.3,<25",
  "fsspec[s3]<2024.12.1",
]
bigquery = [
  "db-dtypes>=0.3,<2",
  "google-cloud-bigquery>=3,<4",
  "google-cloud-bigquery-storage>=2,<3",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "pydata-google-auth>=1.4.0,<2",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
clickhouse = [
  "clickhouse-connect[arrow,pandas,numpy]>=0.5.23,<1",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
databricks = [
  "databricks-sql-connector-core>=4,<5",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
datafusion = [
  "datafusion>=0.6,<44",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
druid = [
  "pydruid>=0.6.7,<1",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
duckdb = [
  "duckdb>=0.10,<1.2",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
  "packaging>=21.3,<25",
]
exasol = [
  "pyexasol>=0.25.2,<1",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
flink = [
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
impala = [
  "impyla>=0.17,<1",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
mssql = [
  "pyodbc>=4.0.39,<6",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
mysql = [
  "mysqlclient>=2.2.4,<3",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
oracle = [
  "oracledb>=1.3.1,<3",
  "packaging>=21.3,<25",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
polars = [
  "polars>=1,<2",
  "packaging>=21.3,<25",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
postgres = [
  "psycopg2>=2.8.4,<3",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
pyspark = [
  "pyspark>=3.3.3,<4",
  "packaging>=21.3,<25",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
snowflake = [
  "snowflake-connector-python>=3.0.2,<4,!=3.3.0b1",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
sqlite = [
  "regex>=2021.7.6",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
risingwave = [
  "psycopg2>=2.8.4,<3",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
trino = [
  "trino>=0.321,<1",
  "pyarrow>=10.0.1",
  "pyarrow-hotfix>=0.4,<1",
  "numpy>=1.23.2,<3",
  "pandas>=1.5.3,<3",
  "rich>=12.4.4,<14",
]
# non-backend extras
visualization = ["graphviz>=0.16,<1"]
decompiler = ["black>=22.1.0,<25"]
deltalake = ["deltalake>=0.9.0,<1"]
examples = ["pins[gcs]>=0.8.3,<1"]
geospatial = [
  "geoarrow-types>=0.2,<1",
  "geopandas>=0.6,<2",
  "pyproj>=3.3.0,<4",
  "shapely>=2,<3",
]

[dependency-groups]
dev = [
  "ruff>=0.7.1",
  "codespell[hard-encoding-detection,toml]>=2.2.6,<3",
  "google-cloud-storage>=2.7.0,<3",
  "ipython>=8.7.0,<9",
  "pre-commit>=4,<5",
  "pyinstrument>=4.5.1,<6",
  "ruff>=0.1.8",
  "tqdm>=4.66.1,<5",
  "dunamai>=1.22.0",
  "aws-sso-util>=4.33,<5",
]
tests = [
  "cloudpickle",
  "filelock>=3.7.0,<4",
  "fsspec[s3]<2024.12.1",
  "hypothesis>=6.58.0,<7",
  "packaging>=21.3,<25",
  "pytest>=8.2.0,<9",
  "pytest-benchmark>=3.4.1,<6",
  "pytest-deadfixtures>=2.2.1,<3",
  "pytest-clarity>=1.0.1,<2",
  "pytest-cov>=5,<7",
  "pytest-httpserver>=1.0.5,<2",
  "pytest-mock>=3.6.1,<4",
  "pytest-randomly>=3.10.1,<4",
  "pytest-repeat>=0.9.1,<0.10",
  "pytest-snapshot>=0.9.0,<1",
  "pytest-timeout>=2.3.1,<3",
  "pytest-xdist>=2.3.0,<4",
  "requests>=2,<3",
  "tomli>=2.0.1,<3",
]
docs = [
  "altair>=5.0.1,<6",
  # pin griffe until https://github.com/ibis-project/ibis/pull/9865 is
  # addressed
  "griffe<2",
  "ipykernel>=6.25.1,<7",
  "itables>=1.6.3,<2.3",
  "nbclient>=0.8.0,<1",
  "plotly>=5.16.1,<6",
  "plotnine>=0.12.2,<1",
  "py-cpuinfo>=9,<10",
  "quartodoc>=0.6.1,<1",
  "requests>=2,<3",
  "rich>13.8.0,<14",
  "scikit-learn>=1.3,<2",
  "seaborn>=0.12.2,<1",
  "lonboard==0.10.3",
  "jupyter-cache>=1.0.0,<2",
  "jupyterlab>=4.2.5,<5",
  "jupyterlab-night>=0.4.6,<1",
  "jupyterlite-core>=0.3,<0.4",
  "jupyterlite-pyodide-kernel>=0.3,<0.4",
]

[project.entry-points."ibis.backends"]
athena = "ibis.backends.athena"
bigquery = "ibis.backends.bigquery"
clickhouse = "ibis.backends.clickhouse"
databricks = "ibis.backends.databricks"
datafusion = "ibis.backends.datafusion"
druid = "ibis.backends.druid"
duckdb = "ibis.backends.duckdb"
exasol = "ibis.backends.exasol"
flink = "ibis.backends.flink"
impala = "ibis.backends.impala"
mysql = "ibis.backends.mysql"
mssql = "ibis.backends.mssql"
oracle = "ibis.backends.oracle"
polars = "ibis.backends.polars"
postgres = "ibis.backends.postgres"
risingwave = "ibis.backends.risingwave"
pyspark = "ibis.backends.pyspark"
snowflake = "ibis.backends.snowflake"
sqlite = "ibis.backends.sqlite"
trino = "ibis.backends.trino"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["ibis"]

[tool.hatch.build.targets.sdist]
packages = ["ibis"]
include = ["ibis/examples/metadata.json", "ibis/examples/CITATIONS.md"]
exclude = [
  "ibis/examples/gen_examples.R",
  "ibis/examples/gen_registry.py",
  "ibis/examples/data",
  "ibis/examples/descriptions",
]

[tool.pytest.ini_options]
doctest_optionflags = [
  "NORMALIZE_WHITESPACE",
  "IGNORE_EXCEPTION_DETAIL",
  "ELLIPSIS",
]
xfail_strict = true
addopts = [
  "--strict-markers",
  "--strict-config",
  "--benchmark-disable",
  "--benchmark-group-by=name",
  "--benchmark-sort=name",
]
norecursedirs = [
  "**/snapshots",
  ".benchmarks",
  ".direnv",
  ".git",
  ".github",
  ".hypothesis",
  ".pytest_cache",
  ".streamlit",
  "LICENSES",
  "ci",
  "conda-lock",
  "dev",
  "docker",
  "docs",
  "nix",
  "result*",
]
filterwarnings = [
  # fail on any warnings that are not explicitly matched below
  "error",
  # pyspark uses a deprecated pandas API
  "ignore:is_datetime64tz_dtype is deprecated and will be removed in a future version:DeprecationWarning",
  "ignore:is_categorical_dtype is deprecated .+:DeprecationWarning",
  # pyspark and impala leave sockets open
  "ignore:Exception ignored in:",
  # pandas
  "ignore:Boolean Series key will be reindexed:UserWarning",
  'ignore:Using \.astype to convert from timezone-(naive|aware) dtype:FutureWarning',
  "ignore:The default dtype for empty Series will be 'object':FutureWarning",
  # pandas 1.5.x
  "ignore:iteritems is deprecated and will be removed in a future version:FutureWarning",
  'ignore:Passing unit-less datetime64 dtype to \.astype is deprecated:FutureWarning',
  # numpy
  "ignore:Creating an ndarray from ragged nested sequences:",
  'ignore:`np\.bool` is a deprecated alias for the builtin `bool`:DeprecationWarning',
  # numpy, coming from a pandas call
  'ignore:In the future `np\.bool` will be defined as the corresponding NumPy scalar:FutureWarning',
  # pandas by way of polars when comparing arrays
  'ignore:The truth value of an empty array is ambiguous\.:DeprecationWarning',
  # ibis
  'ignore:`StructValue\.destructure` is deprecated as of v10\.0; use lift or unpack instead:FutureWarning',
  # spark
  "ignore:distutils Version classes are deprecated:DeprecationWarning",
  "ignore:The distutils package is deprecated and slated for removal:DeprecationWarning",
  "ignore:In Python .*, it is preferred .* type hints .* UDF:UserWarning",
  "ignore:`np.object` is a deprecated alias for the builtin `object`:DeprecationWarning",
  # windows
  "ignore:getargs.* The 'u' format is deprecated:DeprecationWarning",
  # google
  "ignore:Deprecated call to `pkg_resources\\.declare_namespace\\('.*'\\):DeprecationWarning",
  # pyspark on python 3.11
  "ignore:typing\\.io is deprecated:DeprecationWarning",
  # warnings from google's use of the cgi module
  "ignore:'cgi' is deprecated and slated for removal in Python 3\\.13:DeprecationWarning",
  # warnings from google's use of pkg_resources
  "ignore:pkg_resources is deprecated as an API:DeprecationWarning",
  # snowflake vendors an older version requests
  "ignore:'urllib3\\.contrib\\.pyopenssl' module is deprecated and will be removed in a future release of urllib3:DeprecationWarning",
  # apache-beam
  "ignore:the imp module is deprecated in favour of importlib:DeprecationWarning",
  # pytest raises a syntax error when encountering this from *any* module, including third party modules
  "ignore:invalid escape sequence:DeprecationWarning",
  # geopandas raises user warning on geometry column
  "ignore:Geometry is in a geographic CRS",
  # `is_sparse` deprecation was addressed in pyarrow 13.0.0 (see https://github.com/apache/arrow/pull/35366),
  # but flink requires apache-beam<2.49, which caps its pyarrow dependency (see https://github.com/apache/beam/blob/v2.48.0/sdks/python/setup.py#L144)
  "ignore:is_sparse is deprecated and will be removed in a future version:FutureWarning",
  "ignore:is_sparse is deprecated and will be removed in a future version:DeprecationWarning",
  # google-api-core
  "ignore:Please install grpcio-status to obtain helpful grpc error messages.",
  # dateutil tz
  'ignore:datetime\.datetime\.utcfromtimestamp\(\) is deprecated and scheduled for removal:DeprecationWarning',
  # types using custom tp_new are deprecated in python 3.12
  "ignore:Type .+ uses PyType_Spec with a metaclass that has custom tp_new:DeprecationWarning",
  # pandas 2.2 warnings
  'ignore:DataFrameGroupBy\.apply operated on the grouping columns\. This behavior is deprecated:DeprecationWarning',
  'ignore:Downcasting object dtype arrays on \.fillna, \.ffill, \.bfill is deprecated:FutureWarning',
  # pandas 2.2 warnings coming directly from the way flink uses pandas
  "ignore:Passing a BlockManager to DataFrame is deprecated:DeprecationWarning",
  # snowpark logging warnings
  "ignore:The 'warn' method is deprecated, use 'warning' instead:DeprecationWarning",
  # botocore is still using utcnow
  "ignore:datetime\\.datetime\\.utcnow\\(\\) is deprecated and scheduled for removal:DeprecationWarning",
]
empty_parameter_set_mark = "fail_at_collect"
markers = [
  "backend: tests specific to a backend",
  "benchmark: benchmarks",
  "core: tests that do not required a backend",
  "examples: tests that exercise examples",
  "geospatial: tests for geospatial functionality",
  "xfail_version: backend tests that for a specific version of a dependency",
  "notimpl: We could implement/fix this in ibis, but haven't yet",
  "notyet: This requires upstream to implement/fix something. We can't/won't workaround on the ibis side",
  "never: The backend will never support this / pass this test. Don't bother trying to fix it",
  "athena: Amazon Athena tests",
  "bigquery: BigQuery tests",
  "clickhouse: ClickHouse tests",
  "databricks: Databricks SQL tests",
  "datafusion: Apache Datafusion tests",
  "druid: Apache Druid tests",
  "duckdb: DuckDB tests",
  "exasol: ExasolDB tests",
  "flink: Flink tests",
  "impala: Apache Impala tests",
  "mysql: MySQL tests",
  "mssql: MS SQL Server tests",
  "oracle: Oracle tests",
  "polars: Polars tests",
  "postgres: PostgreSQL tests",
  "risingwave: RisingWave tests",
  "pyspark: PySpark tests",
  "snowflake: Snowflake tests",
  "sqlite: SQLite tests",
  "trino: Trino tests",
  "tpch: TPC-H tests",
  "tpcds: TPC-DS tests",
]

[tool.ruff]
line-length = 88
respect-gitignore = true
exclude = [".direnv", "result-*", "*_py310.py", "decompiled.py", "out_tpch.py"]

[tool.ruff.lint]
select = [
  "B",   # flake8-bugbear
  "BLE", # flake8-blind-except
  "C4",  # comprehensions
  "D",   # pydocstyle
  "E",   # pycodestyle
  "EXE", # flake8-executable
  "F",   # pyflakes
  "FA",  # flake8-future-annotations
  "G",   # flake8-logging-format
  "FLY", # flynt (format string conversion)
  "I",   # isort
  "ICN", # flake8-import-conventions
  "INP", # flake8-no-pep420 (implicit namespace packages)
  "ISC", # flake8-implicit-str-concat
  "PGH", # pygrep-hooks
  "PIE", # flake8-pie
  "PL",  # pylint
  "RET", # flake8-return
  "RUF", # ruff-specific rules
  "SIM", # flake8-simplify
  "T10", # flake8-debugger
  "T20", # flake8-print
  "TCH", # flake8-type-checking
  "TID", # flake8-tidy-imports
  "UP",  # pyupgrade
  "W",   # pycodestyle
  "YTT", # flake8-2020
  "S",   # flake8-bandit
]
ignore = [
  "B028",    # required stacklevel argument to warn
  "B904",    # raise from e or raise from None in exception handlers
  "B905",    # zip-without-explicit-strict
  "C408",    # dict(...) as literal
  "D100",    # public module
  "D101",    # public class
  "D102",    # public method
  "D103",    # public function
  "D104",    # public package
  "D105",    # magic methods
  "D106",    # nested class
  "D107",    # init
  "D202",    # blank lines after function docstring
  "D203",    # blank line before class docstring
  "D213",    # Multi-line docstring summary should start at the second line
  "D401",    # Imperative mood
  "D402",    # First line should not be the function's signature
  "D413",    # Blank line required after last section
  "E501",    # line-too-long, this is automatically enforced by ruff format
  "E731",    # lambda-assignment
  "ISC001",  # single line implicit string concat, handled by ruff format
  "PGH003",  # blanket-type-ignore
  "PLC0105", # covariant type parameters should have a _co suffix
  "PLR0124", # name compared with self, e.g., a == a
  "PLR0911", # too many return statements
  "PLR0912", # too many branches
  "PLR0913", # too many arguments
  "PLR0915", # too many statements
  "PLR2004", # forces everything to be a constant
  "PLW2901", # overwriting loop variable
  "RET504",  # unnecessary-assign, these are useful for debugging
  "RET505",  # superfluous-else-return, stylistic choice
  "RET506",  # superfluous-else-raise, stylistic choice
  "RET507",  # superfluous-else-continue, stylistic choice
  "RET508",  # superfluous-else-break, stylistic choice
  "RUF005",  # splat instead of concat
  "RUF012",  # Mutable class attributes should be annotated with `typing.ClassVar`
  "SIM102",  # nested ifs
  "SIM108",  # convert everything to ternary operator
  "SIM114",  # combine `if` branches using logical `or` operator
  "SIM116",  # dictionary instead of `if` statements
  "SIM117",  # nested with statements
  "SIM118",  # remove .keys() calls from dictionaries
  "SIM300",  # yoda conditions
  "UP007",   # Optional[str] -> str | None
  "UP038",   # non-pep604-isinstance, results in slower code
  "S101",    # ignore "Use of `assert` detected"
]
# none of these codes will be automatically fixed by ruff
unfixable = [
  "T201",   # print statements
  "F401",   # unused imports
  "RUF100", # unused noqa comments
  "F841",   # unused variables
]

[tool.ruff.lint.isort]
required-imports = ["from __future__ import annotations"]

[tool.ruff.lint.per-file-ignores]
"*test*.py" = [
  "D",    # ignore all docstring lints in tests
  "S301", # pickle is allowed in tests
  "S603", # ignore subprocess untrusted input warnings in test files, input is under control of ibis
  "S607", # ignore subprocess untrusted exe path warnings in test files, input is under control of ibis
  "S608", # ignore sql injection warnings in test files, input is under control of ibis
  "S108", # /tmp usage refers to hdfs path
]
"{docs,ci}/**/*.py" = ["INP001"]
"{ci/release/verify_release,docs/**/*_impl}.py" = [
  "T201",
] # prints output using `print`
"docs/**/{datafusion,polars}_*.py" = ["T201"] # prints output using `print`

[tool.ruff.format]
docstring-code-format = true
docstring-code-line-length = 88

[tool.coverage.run]
branch = true
source = ["ibis"]

[tool.coverage.report]
exclude_lines = [
  "if self.debug:",
  "pragma: no cover",
  "raise NotImplementedError",
  "if __name__ == .__main__.:",
  "if TYPE_CHECKING:",
]
ignore_errors = true
omit = [
  "*_version.py",
  "*tests*",
  "ibis/interactive.py",
  "ibis/examples/gen_registry.py",
]
