jobs:
- job: Windows
  pool:
    vmImage: vs2017-win2017
  strategy:
    maxParallel: 3
    matrix:
      py27:
        python.version: "2.7"
        pyarrow.version: "0.9.0"
      py35:
        python.version: "3.5"
        pyarrow.version: "0.10.0"
      py36:
        python.version: "3.6"
        pyarrow.version: "0.10.0"
  steps:
    - task: CondaEnvironment@1
      inputs:
        createCustomEnvironment: True
        environmentName: "ibis_$(python.version)"
        packageSpecs: pytables numpy pandas ruamel.yaml jinja2 pyarrow=$(pyarrow.version) multipledispatch sqlalchemy psycopg2 graphviz click mock plumbum flake8 pytest-xdist
        installOptions: -c conda-forge
        createOptions: python="$(python.version)" -c conda-forge
        cleanEnvironment: True
        updateConda: False
    - script: python setup.py develop
      displayName: 'Install ibis'
    - script: conda list
      displayName: 'Show installed packages'
    - script: python ci\\datamgr.py download
      displayName: 'Download data'
    - script: python ci\\datamgr.py parquet -i
      displayName: 'Load Parquet data'
    - script: python ci\\datamgr.py sqlite
      displayName: 'Load SQLite data'
    - script: pytest --tb=short --junitxml=junit.xml -n auto -m "not backend and not clickhouse and not impala and not hdfs and not bigquery and not mapd and not mysql and not postgresql" -ra ibis
      displayName: 'Run tests'

    # publish test results
    - task: PublishTestResults@2
      inputs:
        testResultsFiles: junit.xml
        testRunTitle: 'Publish test results'

    # build source dist and wheel
    - script: python setup.py sdist bdist_wheel
      displayName: 'Build source distribution and wheel'

    # publish sdist and wheel
    - task: PublishBuildArtifacts@1
      displayName: 'Publish artifact: sdist bdist_wheel'
      inputs:
        pathToPublish: dist
        artifactName: dist

    # build a conda package
    - script: python ci\\feedstock.py test
      displayName: 'Clone, update and build conda-forge recipe'
