parameters:
  name: ''
  vmImage: ''

jobs:
- job: ${{ parameters.name }}Test

  pool:
    vmImage: ${{ parameters.vmImage }}

  variables:
    AZURECI: 1
    COMPOSE_FILE: ci/docker-compose.yml
    PYTHONHASHSEED: "random"
    BACKENDS_SQL_PARQUET: "mysql postgres sqlite parquet"
    BACKENDS_IMPALA_KUDU_CLICKHOUSE: "impala kudu-master kudu-tserver clickhouse"
    BACKENDS_OMNISCI: "omniscidb"
    BACKENDS_PYSPARK_SPARK: ""
    PYTEST_MARK_EXPRESSION_SQL_PARQUET: "not udf and not clickhouse and not impala and not kudu and not hdfs and not omniscidb and not spark and not pyspark"
    PYTEST_MARK_EXPRESSION_IMPALA_KUDU_CLICKHOUSE: "not udf and not mysql and not parquet and not postgresql and not postgis and not postgres_extensions and not sqlite and not omniscidb and not spark and not pyspark"
    PYTEST_MARK_EXPRESSION_OMNISCI: "not udf and not clickhouse and not impala and not kudu and not hdfs and not mysql and not parquet and not postgresql and not postgis and not postgres_extensions and not sqlite and not pyspark and not spark"
    PYTEST_MARK_EXPRESSION_PYSPARK_SPARK: "not udf and not clickhouse and not impala and not kudu and not hdfs and not mysql and not parquet and not postgresql and not postgis and not postgres_extensions and not sqlite and not omniscidb"
  strategy:
    matrix:

      # SQL and parquet backends
      py36_sql_parquet:
        PYTHON_VERSION: "3.6"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_SQL_PARQUET)
        BACKENDS: $(BACKENDS_SQL_PARQUET)
        REQUIREMENTS_TAG: "main"
      py37_sql_parquet:
        PYTHON_VERSION: "3.7"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_SQL_PARQUET)
        BACKENDS: $(BACKENDS_SQL_PARQUET)
        REQUIREMENTS_TAG: "main"
      py38_sql_parquet:
        PYTHON_VERSION: "3.8"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_SQL_PARQUET)
        BACKENDS: $(BACKENDS_SQL_PARQUET)
        REQUIREMENTS_TAG: "main"

      # Impala, kudu and clickhouse backends
      py36_impala_kudu_clickhouse:
        PYTHON_VERSION: "3.6"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_IMPALA_KUDU_CLICKHOUSE)
        BACKENDS: $(BACKENDS_IMPALA_KUDU_CLICKHOUSE)
        REQUIREMENTS_TAG: "main"
      py37_impala_kudu_clickhouse:
        PYTHON_VERSION: "3.7"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_IMPALA_KUDU_CLICKHOUSE)
        BACKENDS: $(BACKENDS_IMPALA_KUDU_CLICKHOUSE)
        REQUIREMENTS_TAG: "main"
      py38_impala_kudu_clickhouse:
        PYTHON_VERSION: "3.8"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_IMPALA_KUDU_CLICKHOUSE)
        BACKENDS: $(BACKENDS_IMPALA_KUDU_CLICKHOUSE)
        REQUIREMENTS_TAG: "main"

      # Omnisci backend
      py36_omnisci:
        PYTHON_VERSION: "3.6"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_OMNISCI)
        BACKENDS: $(BACKENDS_OMNISCI)
        REQUIREMENTS_TAG: "main"
      py37_omnisci:
        PYTHON_VERSION: "3.7"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_OMNISCI)
        BACKENDS: $(BACKENDS_OMNISCI)
        REQUIREMENTS_TAG: "main"
      # TODO: pymapd is not working on Ibis with Python 3.8, so not added to the matrix yet
      # https://github.com/ibis-project/ibis/issues/2090

      # PySpark and Spark backends
      py36_pyspark_spark:
        PYTHON_VERSION: "3.6"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_PYSPARK_SPARK)
        BACKENDS: $(BACKENDS_PYSPARK_SPARK)
        REQUIREMENTS_TAG: "pyspark-spark"
      py37_pyspark_spark:
        PYTHON_VERSION: "3.7"
        PYTEST_MARK_EXPRESSION: $(PYTEST_MARK_EXPRESSION_PYSPARK_SPARK)
        BACKENDS: $(BACKENDS_PYSPARK_SPARK)
        REQUIREMENTS_TAG: "pyspark-spark"
      # TODO: pyspark is not working on Ibis with Python 3.8, so not added to the matrix yet
      # https://github.com/ibis-project/ibis/issues/2091

  steps:
    - bash: |
        echo "##vso[task.setvariable variable=PIPELINE_ARTIFACT_TAG]${PYTHON_VERSION/./}-${REQUIREMENTS_TAG}"
        if [ -z "$PYTEST_MARK_EXPRESSION" ]; then
          echo "##vso[task.logissue type=error]The env variable PYTEST_MARK_EXPRESSION is not set. It is expected to be set in all the matrix builds, since not all tests can be run in a single build. It's probably caused by a typo."
          exit 1
        fi
      displayName: 'Set environment variables'

    - bash: |
        if [ -n "${GCLOUD_SERVICE_KEY}" ]; then
          mkdir -p /tmp/ibis
          base64 --decode --ignore-garbage <<< "${GCLOUD_SERVICE_KEY}" > /tmp/ibis/gcloud-service-key.json
        fi
      env:
        GCLOUD_SERVICE_KEY: $(GCLOUD_SERVICE_KEY)
      displayName: 'Setup BigQuery credentials'
      condition: eq(variables['System.PullRequest.IsFork'], 'False')

    # Start databases if BACKENDS is not an empty string. Without this check, docker-compose would start all services (instead of none of them) if no BACKENDS are specified.
    - bash: |
        if [ -n "${BACKENDS}" ]; then
          make start PYTHON_VERSION=$PYTHON_VERSION BACKENDS="${BACKENDS}"
        fi
      displayName: 'Start databases'

    - bash: make wait PYTHON_VERSION=$PYTHON_VERSION BACKENDS="${BACKENDS}"
      displayName: 'Wait for databases'

    - bash: docker ps
      displayName: 'Show running containers'

    - bash: make build PYTHON_VERSION=$PYTHON_VERSION REQUIREMENTS_TAG="${REQUIREMENTS_TAG}"
      displayName: 'Build ibis image'

    - bash: docker images
      displayName: 'List docker images'

    - bash: make docker_lint PYTHON_VERSION=$PYTHON_VERSION
      displayName: 'Lint'

    # TODO: change match-dir when docstrings are fixed for other backends
    - bash: docker-compose run ibis pydocstyle --match-dir="(ibis|omniscidb)"
      displayName: "Docstring check"

    - bash: make docker_check_pre_commit_hooks PYTHON_VERSION=$PYTHON_VERSION
      displayName: 'Ensure all pre-commit hooks checking are passing.'

    - bash: |
        sudo mkdir -p /tmp/ibis/test-reports/pytest
        mkdir -p /tmp/env
      displayName: 'Make artifacts directories'

    - bash: make docker_run PYTHON_VERSION=$PYTHON_VERSION REQUIREMENTS_TAG="${REQUIREMENTS_TAG}" DOCKER_RUN_COMMAND="conda list"
      displayName: 'Show packages in conda environment'

    - bash: make docker_run PYTHON_VERSION=$PYTHON_VERSION REQUIREMENTS_TAG="${REQUIREMENTS_TAG}" DOCKER_RUN_COMMAND="conda list --export > /tmp/env/env.yml"
      displayName: 'Capture packages in conda environment'

    - bash: make load PYTHON_VERSION=$PYTHON_VERSION BACKENDS="${BACKENDS}"
      displayName: 'Load test datasets'

    - bash: |
        echo "PYTEST_MARK_EXPRESSION: ${PYTEST_MARK_EXPRESSION}"
        docker-compose run \
          -e PYTHONHASHSEED=$PYTHONHASHSEED \
          -e AZURECI=$AZURECI \
          -e GOOGLE_APPLICATION_CREDENTIALS=/tmp/gcloud-service-key.json \
          ibis \
          pytest ibis -m "${PYTEST_MARK_EXPRESSION}" \
                      -ra \
                      --numprocesses auto \
                      --doctest-modules \
                      --doctest-ignore-import-errors \
                      -k"-compile -connect" \
                      --junitxml=/tmp/test-reports/pytest/junit.xml \
                      --cov=ibis \
                      --cov-report=xml:/tmp/test-reports/pytest-cov/coverage.xml
      displayName: 'Run tests'

    # See #1954
    # - bash: |
    #     bash <(curl -s https://codecov.io/bash) \
    #       -f /tmp/ibis/test-reports/pytest-cov/coverage.xml
    #   displayName: 'Upload coverage'

    - task: PublishTestResults@2
      displayName: 'Publish test results from pytest JUnitXML'
      inputs:
        testResultsFiles: /tmp/ibis/test-reports/pytest/junit.xml
        testRunTitle: 'Publish test results'
        mergeTestResults: False
      condition: succeededOrFailed()  # pass or fail, but not cancelled

    - task: PublishPipelineArtifact@1
      inputs:
        path: /tmp/env/env.yml
        artifact: LinuxCondaEnvironment-$(PIPELINE_ARTIFACT_TAG)
      displayName: 'Publish Linux environment YAML to Azure'
      condition: succeededOrFailed()  # pass or fail, but not cancelled

- job: ${{ parameters.name }}BuildConda

  pool:
    vmImage: ${{ parameters.vmImage }}

  variables:
    PYTHON_VERSION: "3.7"
    AZURECI: 1
    COMPOSE_FILE: ci/docker-compose.yml

  steps:
    - bash: make build PYTHON_VERSION=$PYTHON_VERSION
      displayName: 'Build ibis image'

    - bash: docker images
      displayName: 'List docker images'

    - bash: make docker_run PYTHON_VERSION=$PYTHON_VERSION DOCKER_RUN_COMMAND="ci/feedstock.py test --python 3.7"
      displayName: 'Clone, update and build conda-forge recipe'

    - task: PublishPipelineArtifact@1
      inputs:
        path: /tmp/ibis/packages
        artifact: LinuxCondaPackage
      displayName: 'Publish conda package to Azure'
      condition: and(succeeded(), eq(variables['System.PullRequest.IsFork'], 'False'))

- job: ${{ parameters.name }}Benchmark

  pool:
    vmImage: ${{ parameters.vmImage }}

  variables:
    PYTHON_VERSION: "3.6"
    AZURECI: 1
    COMPOSE_FILE: ci/docker-compose.yml

  steps:
    - bash: make build PYTHON_VERSION=$PYTHON_VERSION
      displayName: 'Build Ibis Image'

    - bash: make docker_run PYTHON_VERSION=$PYTHON_VERSION DOCKER_RUN_COMMAND='ci/benchmark.sh azure "$(Build.SourceVersion)"'
      displayName: 'Run Benchmark (ASV)'

- job: ${{ parameters.name }}BuildDocs

  pool:
    vmImage: ${{ parameters.vmImage }}

  variables:
    PYTHON_VERSION: "3.6"
    AZURECI: 1
    COMPOSE_FILE: ci/docker-compose.yml
    BACKENDS: "impala postgres"
    LOADS: "impala postgres"

  steps:
    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.6' 

    - bash: make start PYTHON_VERSION=$PYTHON_VERSION BACKENDS="${BACKENDS}"
      displayName: 'Start databases'

    - bash: make wait PYTHON_VERSION=$PYTHON_VERSION BACKENDS="${BACKENDS}"
      displayName: 'Wait for databases'

    - bash: make builddoc PYTHON_VERSION=$PYTHON_VERSION
      displayName: 'build ibis documentation image'

    - bash: docker images
      displayName: 'List docker images'

    - bash: docker ps
      displayName: 'Show running containers'

    - bash: make load PYTHON_VERSION=$PYTHON_VERSION BACKENDS="${BACKENDS}" LOADS="${LOADS}"
      displayName: 'Load test datasets'

    - bash: |
        docker-compose -f ci/docker-compose.yml run --rm ibis-docs bash -c "\
            ping -c 1 impala && conda list && \
            mkdir -p /tmp/ibis-project.org && \
            cd /tmp/ibis-project.org && \
            echo \"ibis-project.org\" > CNAME && \
            touch .nojekyll && \
            python -m pysuerga /ibis/docs/web --target-path=/tmp/ibis-project.org/ && \
            sphinx-build -b html /ibis/docs/source /tmp/ibis-project.org/docs -W -T --keep-going"
      displayName: 'Build website and docs'

    - task: PublishPipelineArtifact@1
      inputs:
        path: /tmp/ibis/ibis-project.org
        artifact: Documentation
      displayName: 'Publish documentation to Azure'
      condition: and(succeeded(), eq(variables['System.PullRequest.IsFork'], 'False'))

    - bash: |
        mkdir ~/.ssh
        base64 --decode --ignore-garbage <<< "${IBIS_GH_TOKEN}" > ~/.ssh/id_rsa
        chmod 700 ~/.ssh
        chmod 600 ~/.ssh/id_rsa

        ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
      displayName: 'Set up ssh'
      env:
        IBIS_GH_TOKEN: $(IBIS_GH_TOKEN)
      condition: |
        and(eq(variables['System.PullRequest.IsFork'], 'False'),
            eq(variables['Build.Repository.Name'], 'ibis-project/ibis'),
            eq(variables['Build.SourceBranchName'], 'master'))

    - bash: |
        sudo chown -R "${USER}":"${USER}" /tmp/ibis
        pushd /tmp/ibis/ibis-project.org

        git init
        git checkout -b gh-pages
        git remote add origin git@github.com:ibis-project/docs.ibis-project.org
        git config user.name 'Ibis Documentation Bot'
        git config user.email ''

        git add --all .
        git commit -m "Docs from ibis at $(Build.SourceVersion)"
        git push --force origin gh-pages
      displayName: 'Push web to remote repo'
      condition: |
        and(eq(variables['System.PullRequest.IsFork'], 'False'),
            eq(variables['Build.Repository.Name'], 'ibis-project/ibis'),
            eq(variables['Build.SourceBranchName'], 'master'))
