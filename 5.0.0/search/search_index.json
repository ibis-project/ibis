{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"image/svg+xml                                  The Ibis Project","text":""},{"location":"#the-flexibility-of-python-analytics-with-the-scale-and-performance-of-modern-sql","title":"The flexibility of Python analytics with the scale and performance of modern SQL.","text":"<p>Install Tutorial</p> Write high-level Python code<pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; con = ibis.connect('movielens.sqlite')\n&gt;&gt;&gt; movies = con.tables.movies\n&gt;&gt;&gt; rating_by_year = movies.group_by('year').avg_rating.mean()\n&gt;&gt;&gt; q = rating_by_year.order_by(rating_by_year.year.desc())\n</code></pre> Compile to SQL<pre><code>&gt;&gt;&gt; con.compile(q)\n\nSELECT year, avg(avg_rating)\nFROM movies t1\nGROUP BY t1.year\nORDER BY t1.year DESC\n</code></pre> Execute on multiple backends<pre><code>&gt;&gt;&gt; con.execute(q)\n\n     year  mean(avg_rating)\n0    2021          2.586362\n1    2020          2.719994\n2    2019          2.932275\n3    2018          3.005046\n4    2017          3.071669\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>Consistent syntax across backends: Enjoy a uniform Python API, whether using DuckDB, PostgreSQL, PySpark, BigQuery, or any other supported backend.</li> <li>Performant: Execute queries as fast as the database engine itself.</li> <li>Interactive: Explore data in a notebook or REPL.</li> <li>Extensible: Add new operations, optimizations, and custom APIs.</li> <li>Free and open-source: licensed under Apache 2.0, available on Github</li> </ul>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Home</li> <li>Install</li> <li>Docs<ul> <li>How To Guide</li> <li>Execution Backends</li> <li>User Guide</li> <li>API Reference<ul> <li>Expressions<ul> <li>Top Level</li> <li>Tables</li> <li>Generic Values</li> <li>Numeric + Boolean</li> <li>Strings</li> <li>Timestamps + Dates + Times</li> <li>Collections</li> <li>Geospatial</li> </ul> </li> <li>Column Selectors</li> <li>Data Types</li> <li>Schemas</li> <li>Backend Interfaces</li> <li>Configuration</li> </ul> </li> <li>Ibis for SQL Programmers</li> <li>Ibis for pandas Users</li> <li>Backend Operations Matrix</li> </ul> </li> <li>Releases</li> <li>Blog<ul> <li>Ibis Sneak Peek: Writing to Files</li> <li>Ibis Sneak Peek: Examples</li> <li>Maximizing Productivity with Selectors</li> <li>Ibis + DuckDB + Substrait</li> <li>Ibis v4.0.0</li> <li>Analyzing Ibis's CI Data with Ibis</li> <li>ffill and bfill using ibis</li> <li>Ibis v3.1.0</li> <li>Ibis v3.0.0</li> </ul> </li> <li>Community<ul> <li>Contribute</li> </ul> </li> </ul>"},{"location":"ibis-for-pandas-users/","title":"Ibis for pandas Users","text":"In\u00a0[1]: Copied! <pre>import ibis\nimport pandas as pd\n\nibis.options.interactive = True\n</pre> import ibis import pandas as pd  ibis.options.interactive = True <p>We'll be using the pandas backend in Ibis in the examples below. First we'll create a simple <code>DataFrame</code>.</p> In\u00a0[2]: Copied! <pre>df = pd.DataFrame(\n    [\n        ['a', 1, 2],\n        ['b', 3, 4]\n    ], \n    columns=['one', 'two', 'three'],\n    index=[5,6],\n)\ndf\n</pre> df = pd.DataFrame(     [         ['a', 1, 2],         ['b', 3, 4]     ],      columns=['one', 'two', 'three'],     index=[5,6], ) df Out[2]: one two three 5 a 1 2 6 b 3 4 <p>Now we can create an Ibis table from the above <code>DataFrame</code>.</p> <p>Note that the index from the Pandas <code>DataFrame</code> is dropped. Ibis has no notion of an index: If you want to use the index, you will need to turn it into a column.</p> In\u00a0[3]: Copied! <pre>t = ibis.pandas.connect({'t': df}).table('t')\nt\n</pre> t = ibis.pandas.connect({'t': df}).table('t') t Out[3]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503 two   \u2503 three \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502     2 \u2502\n\u2502 b      \u2502     3 \u2502     4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[4]: Copied! <pre>df.dtypes\n</pre> df.dtypes Out[4]: <pre>one      object\ntwo       int64\nthree     int64\ndtype: object</pre> <p>In Ibis, you use the <code>schema</code> method which returns an <code>ibis.Schema</code> object.</p> In\u00a0[5]: Copied! <pre>t.schema()\n</pre> t.schema() Out[5]: <pre>ibis.Schema {\n  one    string\n  two    int64\n  three  int64\n}</pre> <p>It is possible to convert the schema information to pandas data types using the <code>to_pandas</code> method, if needed.</p> In\u00a0[6]: Copied! <pre>t.schema().to_pandas()\n</pre> t.schema().to_pandas() Out[6]: <pre>[('one', dtype('O')), ('two', dtype('int64')), ('three', dtype('int64'))]</pre> In\u00a0[7]: Copied! <pre>len(t.schema())\n</pre> len(t.schema()) Out[7]: <pre>3</pre> <p>To get the number of rows of a table, you use the <code>count</code> method.</p> In\u00a0[8]: Copied! <pre>t.count()\n</pre> t.count() <pre></pre> Out[8]: <pre>2</pre> <p>To mimic pandas' behavior, you would use the following code. Note that you need to use the <code>execute</code> method after <code>count</code> to evaluate the expression returned by <code>count</code>.</p> In\u00a0[9]: Copied! <pre>(t.count().execute(), len(t.schema()))\n</pre> (t.count().execute(), len(t.schema())) Out[9]: <pre>(2, 3)</pre> In\u00a0[10]: Copied! <pre>df.shape\n</pre> df.shape Out[10]: <pre>(2, 3)</pre> In\u00a0[11]: Copied! <pre>t[['one', 'two']]\n</pre> t[['one', 'two']] Out[11]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503 two   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502\n\u2502 b      \u2502     3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>However, since row-level indexing is not supported in Ibis, the inner list is not necessary.</p> In\u00a0[12]: Copied! <pre>t['one', 'two']\n</pre> t['one', 'two'] Out[12]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503 two   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502\n\u2502 b      \u2502     3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[13]: Copied! <pre>t['one']\n</pre> t['one'] Out[13]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502\n\u2502 b      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>or:</p> In\u00a0[14]: Copied! <pre>t.one\n</pre> t.one Out[14]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502\n\u2502 b      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[15]: Copied! <pre>mutated = t.mutate(new_col=t.three * 2)\nmutated\n</pre> mutated = t.mutate(new_col=t.three * 2) mutated Out[15]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503 two   \u2503 three \u2503 new_col \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502 int64   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502     2 \u2502       4 \u2502\n\u2502 b      \u2502     3 \u2502     4 \u2502       8 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Notice that the original table object remains unchanged. Only the <code>mutated</code> object that was returned contains the new column.</p> In\u00a0[16]: Copied! <pre>t\n</pre> t Out[16]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503 two   \u2503 three \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502     2 \u2502\n\u2502 b      \u2502     3 \u2502     4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>It is also possible to create a column in isolation. This is similar to a <code>Series</code> in pandas. Note that the name of the column by default is a representation of the expression:</p> In\u00a0[17]: Copied! <pre>unnamed = (t.three * 2)\nunnamed\n</pre> unnamed = (t.three * 2) unnamed Out[17]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Multiply(three, 2) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                  4 \u2502\n\u2502                  8 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>To get a version with a specific name, you can use the <code>name</code> method:</p> In\u00a0[18]: Copied! <pre>new_col = unnamed.name(\"new_col\")\nnew_col\n</pre> new_col = unnamed.name(\"new_col\") new_col Out[18]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 new_col \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502       4 \u2502\n\u2502       8 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>You can then add this column to the table using a projection.</p> In\u00a0[19]: Copied! <pre>proj = t['one', 'two', new_col]\nproj\n</pre> proj = t['one', 'two', new_col] proj Out[19]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503 two   \u2503 new_col \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502       4 \u2502\n\u2502 b      \u2502     3 \u2502       8 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[20]: Copied! <pre>t.columns\n</pre> t.columns Out[20]: <pre>['one', 'two', 'three']</pre> In\u00a0[21]: Copied! <pre>subset = t.drop('one', 'two')\nsubset.columns\n</pre> subset = t.drop('one', 'two') subset.columns Out[21]: <pre>['three']</pre> <p>It is also possible to drop columns by selecting the columns you want to remain.</p> In\u00a0[22]: Copied! <pre>subset = t['two', 'three']\nsubset.columns\n</pre> subset = t['two', 'three'] subset.columns Out[22]: <pre>['two', 'three']</pre> In\u00a0[23]: Copied! <pre>t\n</pre> t Out[23]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503 two   \u2503 three \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502     2 \u2502\n\u2502 b      \u2502     3 \u2502     4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[24]: Copied! <pre>mutated = t.mutate(two=t.two * 2)\nmutated\n</pre> mutated = t.mutate(two=t.two * 2) mutated Out[24]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 one    \u2503 two   \u2503 three \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     2 \u2502     2 \u2502\n\u2502 b      \u2502     6 \u2502     4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[25]: Copied! <pre>relabeled = t.relabel(dict(\n    one='a',\n    two='b',\n))\nrelabeled\n</pre> relabeled = t.relabel(dict(     one='a',     two='b', )) relabeled Out[25]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a      \u2503 b     \u2503 three \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502     2 \u2502\n\u2502 b      \u2502     3 \u2502     4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[26]: Copied! <pre>df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\ndf.head()\n</pre> df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv') df.head() Out[26]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 setosa 1 4.9 3.0 1.4 0.2 setosa 2 4.7 3.2 1.3 0.2 setosa 3 4.6 3.1 1.5 0.2 setosa 4 5.0 3.6 1.4 0.2 setosa <p>Create an Ibis table from the <code>DataFrame</code> above.</p> In\u00a0[27]: Copied! <pre>t = ibis.pandas.connect({'t': df}).table('t')\nt\n</pre> t = ibis.pandas.connect({'t': df}).table('t') t Out[27]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.1 \u2502         3.5 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.9 \u2502         3.0 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.7 \u2502         3.2 \u2502          1.3 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.6 \u2502         3.1 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.0 \u2502         3.6 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.4 \u2502         3.9 \u2502          1.7 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          4.6 \u2502         3.4 \u2502          1.4 \u2502         0.3 \u2502 setosa  \u2502\n\u2502          5.0 \u2502         3.4 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.4 \u2502         2.9 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.9 \u2502         3.1 \u2502          1.5 \u2502         0.1 \u2502 setosa  \u2502\n\u2502            \u2026 \u2502           \u2026 \u2502            \u2026 \u2502           \u2026 \u2502 \u2026       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[28]: Copied! <pre>t.head(5)\n</pre> t.head(5) Out[28]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.1 \u2502         3.5 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.9 \u2502         3.0 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.7 \u2502         3.2 \u2502          1.3 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.6 \u2502         3.1 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.0 \u2502         3.6 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>However, the tail method is not implemented since it is not supported in all databases. It is possible to emulate the <code>tail</code> method if you use sorting in your table to do a  reverse sort then use the <code>head</code> method to retrieve the \"top\" rows.</p> <p>Another way to limit the number of retrieved rows is using the <code>limit</code> method. The following will return the same result as <code>head(5)</code>. This is often used in conjunction with other filtering techniques that we will cover later.</p> In\u00a0[29]: Copied! <pre>t.limit(5)\n</pre> t.limit(5) Out[29]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.1 \u2502         3.5 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.9 \u2502         3.0 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.7 \u2502         3.2 \u2502          1.3 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.6 \u2502         3.1 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.0 \u2502         3.6 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>The starting position of the returned rows can be specified using the <code>offset</code> parameter.</p> In\u00a0[30]: Copied! <pre>t.limit(5, offset=4)\n</pre> t.limit(5, offset=4) Out[30]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.0 \u2502         3.6 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.4 \u2502         3.9 \u2502          1.7 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          4.6 \u2502         3.4 \u2502          1.4 \u2502         0.3 \u2502 setosa  \u2502\n\u2502          5.0 \u2502         3.4 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.4 \u2502         2.9 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[31]: Copied! <pre>expr = t.sepal_width &gt; 3.8\nexpr\n</pre> expr = t.sepal_width &gt; 3.8 expr Out[31]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Greater(sepal_width, 3.8) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 False                     \u2502\n\u2502 False                     \u2502\n\u2502 False                     \u2502\n\u2502 False                     \u2502\n\u2502 False                     \u2502\n\u2502 True                      \u2502\n\u2502 False                     \u2502\n\u2502 False                     \u2502\n\u2502 False                     \u2502\n\u2502 False                     \u2502\n\u2502 \u2026                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>We can evaluate the value counts to see how many rows we will expect to get back after filtering.</p> In\u00a0[32]: Copied! <pre>expr.value_counts()\n</pre> expr.value_counts() Out[32]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Greater(sepal_width, 3.8) \u2503 Greater(sepal_width, 3.8)_count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean                   \u2502 int64                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 False                     \u2502                             144 \u2502\n\u2502 True                      \u2502                               6 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Now we apply the filter to the table. Since there are 6 True values in the expression, we should get 6 rows back.</p> In\u00a0[33]: Copied! <pre>filtered = t[expr]\nfiltered\n</pre> filtered = t[expr] filtered Out[33]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.4 \u2502         3.9 \u2502          1.7 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          5.8 \u2502         4.0 \u2502          1.2 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.7 \u2502         4.4 \u2502          1.5 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          5.4 \u2502         3.9 \u2502          1.3 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          5.2 \u2502         4.1 \u2502          1.5 \u2502         0.1 \u2502 setosa  \u2502\n\u2502          5.5 \u2502         4.2 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Of course, the filtering expression can be applied inline as well.</p> In\u00a0[34]: Copied! <pre>filtered = t[t.sepal_width &gt; 3.8]\nfiltered\n</pre> filtered = t[t.sepal_width &gt; 3.8] filtered Out[34]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.4 \u2502         3.9 \u2502          1.7 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          5.8 \u2502         4.0 \u2502          1.2 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.7 \u2502         4.4 \u2502          1.5 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          5.4 \u2502         3.9 \u2502          1.3 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          5.2 \u2502         4.1 \u2502          1.5 \u2502         0.1 \u2502 setosa  \u2502\n\u2502          5.5 \u2502         4.2 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Multiple filtering expressions can be combined into a single expression or chained onto existing table expressions.</p> In\u00a0[35]: Copied! <pre>filtered = t[(t.sepal_width &gt; 3.8) &amp; (t.sepal_length &gt; 5.5)]\nfiltered\n</pre> filtered = t[(t.sepal_width &gt; 3.8) &amp; (t.sepal_length &gt; 5.5)] filtered Out[35]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.8 \u2502         4.0 \u2502          1.2 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.7 \u2502         4.4 \u2502          1.5 \u2502         0.4 \u2502 setosa  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>The code above will return the same rows as the code below.</p> In\u00a0[36]: Copied! <pre>filtered = t[t.sepal_width &gt; 3.8][t.sepal_length &gt; 5.5]\nfiltered\n</pre> filtered = t[t.sepal_width &gt; 3.8][t.sepal_length &gt; 5.5] filtered Out[36]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.8 \u2502         4.0 \u2502          1.2 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.7 \u2502         4.4 \u2502          1.5 \u2502         0.4 \u2502 setosa  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Aggregation has not been discussed yet, but aggregate values can be used in expressions to return things such as all of the rows in a data set where the value in a column is greater than the mean.</p> In\u00a0[37]: Copied! <pre>filtered = t[t.sepal_width &gt; t.sepal_width.mean()]\nfiltered\n</pre> filtered = t[t.sepal_width &gt; t.sepal_width.mean()] filtered Out[37]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.1 \u2502         3.5 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.7 \u2502         3.2 \u2502          1.3 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.6 \u2502         3.1 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.0 \u2502         3.6 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          5.4 \u2502         3.9 \u2502          1.7 \u2502         0.4 \u2502 setosa  \u2502\n\u2502          4.6 \u2502         3.4 \u2502          1.4 \u2502         0.3 \u2502 setosa  \u2502\n\u2502          5.0 \u2502         3.4 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.9 \u2502         3.1 \u2502          1.5 \u2502         0.1 \u2502 setosa  \u2502\n\u2502          5.4 \u2502         3.7 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.8 \u2502         3.4 \u2502          1.6 \u2502         0.2 \u2502 setosa  \u2502\n\u2502            \u2026 \u2502           \u2026 \u2502            \u2026 \u2502           \u2026 \u2502 \u2026       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[38]: Copied! <pre>wide_sepals = t.sepal_width &gt; 3.3\nspecies_modified = wide_sepals.ifelse('wide', t.species)\nt.mutate(species_modified=species_modified)\n</pre> wide_sepals = t.sepal_width &gt; 3.3 species_modified = wide_sepals.ifelse('wide', t.species) t.mutate(species_modified=species_modified) Out[38]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503 species_modified \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502 string           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          5.1 \u2502         3.5 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502 wide             \u2502\n\u2502          4.9 \u2502         3.0 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502 setosa           \u2502\n\u2502          4.7 \u2502         3.2 \u2502          1.3 \u2502         0.2 \u2502 setosa  \u2502 setosa           \u2502\n\u2502          4.6 \u2502         3.1 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502 setosa           \u2502\n\u2502          5.0 \u2502         3.6 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502 wide             \u2502\n\u2502          5.4 \u2502         3.9 \u2502          1.7 \u2502         0.4 \u2502 setosa  \u2502 wide             \u2502\n\u2502          4.6 \u2502         3.4 \u2502          1.4 \u2502         0.3 \u2502 setosa  \u2502 wide             \u2502\n\u2502          5.0 \u2502         3.4 \u2502          1.5 \u2502         0.2 \u2502 setosa  \u2502 wide             \u2502\n\u2502          4.4 \u2502         2.9 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502 setosa           \u2502\n\u2502          4.9 \u2502         3.1 \u2502          1.5 \u2502         0.1 \u2502 setosa  \u2502 setosa           \u2502\n\u2502            \u2026 \u2502           \u2026 \u2502            \u2026 \u2502           \u2026 \u2502 \u2026       \u2502 \u2026                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[39]: Copied! <pre>df.sort_values(['sepal_length', 'sepal_width'], ascending=[True, False]).head(5)\n</pre> df.sort_values(['sepal_length', 'sepal_width'], ascending=[True, False]).head(5) Out[39]: sepal_length sepal_width petal_length petal_width species 13 4.3 3.0 1.1 0.1 setosa 42 4.4 3.2 1.3 0.2 setosa 38 4.4 3.0 1.3 0.2 setosa 8 4.4 2.9 1.4 0.2 setosa 41 4.5 2.3 1.3 0.3 setosa <p>The same operation in Ibis would look like the following. Note that the index values of the resulting <code>DataFrame</code> start from zero and count up, whereas in the example above, they retain their original index value. This is simply due to the fact that rows in tables don't necessarily have a stable index in database backends, so the index is just generated on the result.</p> In\u00a0[40]: Copied! <pre>sorted = t.order_by(['sepal_length', ibis.desc('sepal_width')]).head(5)\nsorted\n</pre> sorted = t.order_by(['sepal_length', ibis.desc('sepal_width')]).head(5) sorted Out[40]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sepal_length \u2503 sepal_width \u2503 petal_length \u2503 petal_width \u2503 species \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64      \u2502 float64     \u2502 float64      \u2502 float64     \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          4.3 \u2502         3.0 \u2502          1.1 \u2502         0.1 \u2502 setosa  \u2502\n\u2502          4.4 \u2502         3.2 \u2502          1.3 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.4 \u2502         3.0 \u2502          1.3 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.4 \u2502         2.9 \u2502          1.4 \u2502         0.2 \u2502 setosa  \u2502\n\u2502          4.5 \u2502         2.3 \u2502          1.3 \u2502         0.3 \u2502 setosa  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[41]: Copied! <pre>stats = [df.sepal_width.sum(), df.sepal_length.mean()]\npd.DataFrame([stats], columns=['total_sepal_width', 'avg.sepal_length'])\n</pre> stats = [df.sepal_width.sum(), df.sepal_length.mean()] pd.DataFrame([stats], columns=['total_sepal_width', 'avg.sepal_length']) Out[41]: total_sepal_width avg.sepal_length 0 458.6 5.843333 <p>In Ibis, you construct aggregate expressions then apply them to the table using the <code>aggregate</code> method.</p> In\u00a0[42]: Copied! <pre>stats = [t.sepal_width.sum().name('total_sepal_width'), t.sepal_length.mean().name('avg_sepal_length')]\nagged = t.aggregate(stats)\nagged\n</pre> stats = [t.sepal_width.sum().name('total_sepal_width'), t.sepal_length.mean().name('avg_sepal_length')] agged = t.aggregate(stats) agged Out[42]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 total_sepal_width \u2503 avg_sepal_length \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64           \u2502 float64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502             458.6 \u2502         5.843333 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>You can also combine both operations into one and pass the aggregate expressions using keyword parameters.</p> In\u00a0[43]: Copied! <pre>agged = t.aggregate(\n    total_sepal_width=t.sepal_width.sum(),\n    avg_sepal_length=t.sepal_length.mean(),\n)\nagged\n</pre> agged = t.aggregate(     total_sepal_width=t.sepal_width.sum(),     avg_sepal_length=t.sepal_length.mean(), ) agged Out[43]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 total_sepal_width \u2503 avg_sepal_length \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64           \u2502 float64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502             458.6 \u2502         5.843333 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[44]: Copied! <pre>agged = t.aggregate(\n    by='species',\n    total_sepal_width=t.sepal_width.sum(),\n    avg_sepal_length=t.sepal_length.mean(),\n)\nagged\n</pre> agged = t.aggregate(     by='species',     total_sepal_width=t.sepal_width.sum(),     avg_sepal_length=t.sepal_length.mean(), ) agged Out[44]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species    \u2503 total_sepal_width \u2503 avg_sepal_length \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string     \u2502 float64           \u2502 float64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 setosa     \u2502             171.4 \u2502            5.006 \u2502\n\u2502 versicolor \u2502             138.5 \u2502            5.936 \u2502\n\u2502 virginica  \u2502             148.7 \u2502            6.588 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Alternatively, by groups can be computed using a grouped table.</p> In\u00a0[45]: Copied! <pre>agged = t.group_by('species').aggregate(\n    total_sepal_width=t.sepal_width.sum(),\n    avg_sepal_length=t.sepal_length.mean(),\n)\nagged\n</pre> agged = t.group_by('species').aggregate(     total_sepal_width=t.sepal_width.sum(),     avg_sepal_length=t.sepal_length.mean(), ) agged Out[45]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species    \u2503 total_sepal_width \u2503 avg_sepal_length \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string     \u2502 float64           \u2502 float64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 setosa     \u2502             171.4 \u2502            5.006 \u2502\n\u2502 versicolor \u2502             138.5 \u2502            5.936 \u2502\n\u2502 virginica  \u2502             148.7 \u2502            6.588 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[46]: Copied! <pre>no_null_t = t.dropna(['sepal_width', 'sepal_length'], how='any')\n</pre> no_null_t = t.dropna(['sepal_width', 'sepal_length'], how='any') In\u00a0[47]: Copied! <pre>no_null_t = t.fillna(dict(sepal_width=0, sepal_length=0))\n</pre> no_null_t = t.fillna(dict(sepal_width=0, sepal_length=0)) In\u00a0[48]: Copied! <pre>df.sepal_width.astype(str)\n</pre> df.sepal_width.astype(str) Out[48]: <pre>0      3.5\n1      3.0\n2      3.2\n3      3.1\n4      3.6\n      ... \n145    3.0\n146    2.5\n147    3.0\n148    3.4\n149    3.0\nName: sepal_width, Length: 150, dtype: object</pre> <p>In Ibis, you cast the column type using the <code>cast</code> method.</p> In\u00a0[49]: Copied! <pre>t.sepal_width.cast('int')\n</pre> t.sepal_width.cast('int') Out[49]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Cast(sepal_width, int64) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                        3 \u2502\n\u2502                        3 \u2502\n\u2502                        3 \u2502\n\u2502                        3 \u2502\n\u2502                        3 \u2502\n\u2502                        3 \u2502\n\u2502                        3 \u2502\n\u2502                        3 \u2502\n\u2502                        2 \u2502\n\u2502                        3 \u2502\n\u2502                        \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Casted columns can be assigned back to the table using the <code>mutate</code> method described earlier.</p> In\u00a0[50]: Copied! <pre>casted = t.mutate(\n    sepal_width=t.sepal_width.cast('int'),\n    sepal_length=t.sepal_length.cast('int'),\n)\ncasted.schema()\n</pre> casted = t.mutate(     sepal_width=t.sepal_width.cast('int'),     sepal_length=t.sepal_length.cast('int'), ) casted.schema() Out[50]: <pre>ibis.Schema {\n  sepal_length  int64\n  sepal_width   int64\n  petal_length  float64\n  petal_width   float64\n  species       string\n}</pre> In\u00a0[51]: Copied! <pre>sepal_length_no_nulls = t.sepal_length.fillna(0)\n</pre> sepal_length_no_nulls = t.sepal_length.fillna(0) In\u00a0[52]: Copied! <pre>t.species.value_counts()\n</pre> t.species.value_counts() Out[52]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species    \u2503 species_count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string     \u2502 int64         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 setosa     \u2502            50 \u2502\n\u2502 versicolor \u2502            50 \u2502\n\u2502 virginica  \u2502            50 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[53]: Copied! <pre>refined = t.species.isin(['versicolor', 'virginica'])\nrefined.value_counts()\n</pre> refined = t.species.isin(['versicolor', 'virginica']) refined.value_counts() Out[53]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Contains(species) \u2503 Contains(species)_count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean           \u2502 int64                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 False             \u2502                      50 \u2502\n\u2502 True              \u2502                     100 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[54]: Copied! <pre>df_left = pd.DataFrame([\n    ['a', 1, 2],\n    ['b', 3, 4],\n    ['c', 4, 6],\n], columns=['name', 'x', 'y'])\n\ndf_right = pd.DataFrame([\n    ['a', 100, 200],\n    ['m', 300, 400],\n    ['n', 400, 600],\n], columns=['name', 'x_100', 'y_100'])\n</pre> df_left = pd.DataFrame([     ['a', 1, 2],     ['b', 3, 4],     ['c', 4, 6], ], columns=['name', 'x', 'y'])  df_right = pd.DataFrame([     ['a', 100, 200],     ['m', 300, 400],     ['n', 400, 600], ], columns=['name', 'x_100', 'y_100']) In\u00a0[55]: Copied! <pre>df_left.merge(df_right, on='name')\n</pre> df_left.merge(df_right, on='name') Out[55]: name x y x_100 y_100 0 a 1 2 100 200 In\u00a0[56]: Copied! <pre>df_left.merge(df_right, on='name', how='outer')\n</pre> df_left.merge(df_right, on='name', how='outer') Out[56]: name x y x_100 y_100 0 a 1.0 2.0 100.0 200.0 1 b 3.0 4.0 NaN NaN 2 c 4.0 6.0 NaN NaN 3 m NaN NaN 300.0 400.0 4 n NaN NaN 400.0 600.0 <p>We can now convert <code>DataFrames</code> to Ibis tables to do <code>join</code>s.</p> In\u00a0[57]: Copied! <pre>pd_ibis = ibis.pandas.connect({'t_left': df_left, 't_right': df_right})\nt_left = pd_ibis.table('t_left')\nt_right = pd_ibis.table('t_right')\n</pre> pd_ibis = ibis.pandas.connect({'t_left': df_left, 't_right': df_right}) t_left = pd_ibis.table('t_left') t_right = pd_ibis.table('t_right') In\u00a0[58]: Copied! <pre>t_left.join(t_right, t_left.name == t_right.name)\n</pre> t_left.join(t_right, t_left.name == t_right.name) Out[58]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 name   \u2503 x     \u2503 y     \u2503 x_100 \u2503 y_100 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502 int64 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502     2 \u2502   100 \u2502   200 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>You may notice that in Ibis joins, even if the predicate is an equality expression and both tables have the same column name, you will still get multiple output columns with suffixes added. This may change in a future version to match the pandas behavior.</p> <p>Below is an outer join where missing values are filled with <code>NaN</code>.</p> In\u00a0[59]: Copied! <pre>t_left.join(t_right, t_left.name == t_right.name, how='outer')\n</pre> t_left.join(t_right, t_left.name == t_right.name, how='outer') Out[59]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 name_x \u2503 x     \u2503 y     \u2503 name_y \u2503 x_100 \u2503 y_100 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502 string \u2502 int64 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502     2 \u2502 a      \u2502   100 \u2502   200 \u2502\n\u2502 b      \u2502     3 \u2502     4 \u2502 b      \u2502     \u2205 \u2502     \u2205 \u2502\n\u2502 c      \u2502     4 \u2502     6 \u2502 c      \u2502     \u2205 \u2502     \u2205 \u2502\n\u2502 m      \u2502     \u2205 \u2502     \u2205 \u2502 m      \u2502   300 \u2502   400 \u2502\n\u2502 n      \u2502     \u2205 \u2502     \u2205 \u2502 n      \u2502   400 \u2502   600 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[60]: Copied! <pre>df_1 = pd.DataFrame([\n    ['a', 1, 2],\n    ['b', 3, 4],\n    ['c', 4, 6],\n], columns=['name', 'x', 'y'])\n\ndf_2 = pd.DataFrame([\n    ['a', 100, 200],\n    ['m', 300, 400],\n    ['n', 400, 600],\n], columns=['name', 'x', 'y'])\n</pre> df_1 = pd.DataFrame([     ['a', 1, 2],     ['b', 3, 4],     ['c', 4, 6], ], columns=['name', 'x', 'y'])  df_2 = pd.DataFrame([     ['a', 100, 200],     ['m', 300, 400],     ['n', 400, 600], ], columns=['name', 'x', 'y']) In\u00a0[61]: Copied! <pre>pd.concat([df_1, df_2])\n</pre> pd.concat([df_1, df_2]) Out[61]: name x y 0 a 1 2 1 b 3 4 2 c 4 6 0 a 100 200 1 m 300 400 2 n 400 600 <p>Now we can convert the <code>DataFrame</code>s to Ibis tables and combine the tables using a union.</p> In\u00a0[62]: Copied! <pre>pd_ibis = ibis.pandas.connect({'t_1': df_1, 't_2': df_2})\nt_1 = pd_ibis.table('t_1')\nt_2 = pd_ibis.table('t_2')\n</pre> pd_ibis = ibis.pandas.connect({'t_1': df_1, 't_2': df_2}) t_1 = pd_ibis.table('t_1') t_2 = pd_ibis.table('t_2') In\u00a0[63]: Copied! <pre>unioned = ibis.union(t_1, t_2)\nunioned\n</pre> unioned = ibis.union(t_1, t_2) unioned Out[63]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 name   \u2503 x     \u2503 y     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502     2 \u2502\n\u2502 b      \u2502     3 \u2502     4 \u2502\n\u2502 c      \u2502     4 \u2502     6 \u2502\n\u2502 a      \u2502   100 \u2502   200 \u2502\n\u2502 m      \u2502   300 \u2502   400 \u2502\n\u2502 n      \u2502   400 \u2502   600 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre>"},{"location":"ibis-for-pandas-users/#Ibis-for-pandas-Users","title":"Ibis for pandas Users\u00b6","text":"<p>Much of the syntax and many of the operations in Ibis are inspired by the pandas DataFrame, however, the primary domain of Ibis is SQL so there are some differences in how they operate.</p> <p>One primary difference between Ibis tables and pandas <code>DataFrame</code>s are that many of the pandas <code>DataFrame</code> operations do in-place operations (they are \"mutable\"), whereas Ibis table operations always return a new table expression (\"immutable\").</p> <p>Another difference is that Ibis expressions are lazy, meaning that as you build up an expression, no computation is actually performed until you call an action method such as <code>execute</code>. Only then does Ibis compile the expression into SQL and send it to the backend. (Note that we'll be using Ibis' interactive mode to automatically execute queries at the end of each cell in this notebook. If you are using similar code in a program, you will have to add <code>.execute()</code> to each operation that you want to evaluate.)</p>"},{"location":"ibis-for-pandas-users/#Data-types","title":"Data types\u00b6","text":"<p>The data types of columns in pandas are accessed using the <code>dtypes</code> attribute. This returns a <code>Series</code> object.</p>"},{"location":"ibis-for-pandas-users/#Table-layout","title":"Table layout\u00b6","text":"<p>In pandas, the layout of the table is contained in the <code>shape</code> attribute which contains the number of rows and number of columns in a tuple. The number of columns in an Ibis table can be gotten  from the length of the schema.</p>"},{"location":"ibis-for-pandas-users/#Subsetting-columns","title":"Subsetting columns\u00b6","text":"<p>Selecting columns is very similar to in pandas. In fact, you can use the same syntax.</p>"},{"location":"ibis-for-pandas-users/#Selecting-columns","title":"Selecting columns\u00b6","text":"<p>Selecting columns is done using the same syntax as in pandas <code>DataFrames</code>. You can use either  the indexing syntax or attribute syntax.</p>"},{"location":"ibis-for-pandas-users/#Adding,-removing,-and-modifying-columns","title":"Adding, removing, and modifying columns\u00b6","text":"<p>Modifying the columns of an Ibis table is a bit different than doing the same operations in a pandas <code>DataFrame</code>. This is primarily due to the fact that in-place operations are not  supported on Ibis tables. Each time you do a column modification to a table, a new table expression is returned.</p>"},{"location":"ibis-for-pandas-users/#Adding-columns","title":"Adding columns\u00b6","text":"<p>Adding columns is done through the <code>mutate</code> method.</p>"},{"location":"ibis-for-pandas-users/#Removing-columns","title":"Removing columns\u00b6","text":"<p>Removing a column is done using the <code>drop</code> method.</p>"},{"location":"ibis-for-pandas-users/#Modifying-columns","title":"Modifying columns\u00b6","text":"<p>Replacing existing columns is done using the <code>mutate</code> method just like adding columns. You simply add a column of the same name to replace it.</p>"},{"location":"ibis-for-pandas-users/#Renaming-columns","title":"Renaming columns\u00b6","text":"<p>In addition to replacing columns, you can simply rename them as well. This is done with the <code>relabel</code> method which takes a dictionary containing the name mappings.</p>"},{"location":"ibis-for-pandas-users/#Selecting-rows","title":"Selecting rows\u00b6","text":"<p>There are several methods that can be used to select rows of data in various ways. These are described in the sections below. We'll use the ubiquitous iris dataset for these examples.</p>"},{"location":"ibis-for-pandas-users/#Head,-tail-and-limit","title":"Head, tail and limit\u00b6","text":"<p>The <code>head</code> method works the same ways as in pandas. Note that some Ibis backends may not have an  inherent ordering of their rows and using <code>head</code> may not return deterministic results. In those cases, you can use sorting before calling <code>head</code> to ensure a stable result.</p>"},{"location":"ibis-for-pandas-users/#Filtering-rows","title":"Filtering rows\u00b6","text":"<p>In addition to simply limiting the number of rows that are returned, it is possible to filter the  rows using expressions. Expressions are constructed very similarly to the way they are in pandas. Ibis expressions are constructed from operations on colunms in a table which return a boolean result. This result is then used to filter the table.</p>"},{"location":"ibis-for-pandas-users/#Modifying-rows","title":"Modifying rows\u00b6","text":"<p>Sometimes you want to modify the values in a column based on some condition. In pandas, you would do something like <code>df.loc[condition] = new_value</code>. In Ibis though, remember that all expressions are immutable, so you need to create a new table expression with the modified values. You do this using the <code>ifelse</code> method on boolean columns:</p>"},{"location":"ibis-for-pandas-users/#Sorting-rows","title":"Sorting rows\u00b6","text":"<p>Sorting rows in Ibis uses a somewhat different API than in pandas. In pandas, you would use the <code>sort_values</code> method to order rows by values in specified columns. Ibis uses a method called <code>order_by</code>. To specify ascending or descending orders, pandas uses an <code>ascending=</code> argument to <code>sort_values</code> that indicates the order for each sorting column. Ibis allows you to tag the column name in the <code>order_by</code> list as ascending or descending by wrapping it with <code>ibis.asc</code> or <code>ibis.desc</code>.</p> <p>Here is an example of sorting a <code>DataFrame</code> using two sort keys. One key is sorting in ascending order and the other is in descending order.</p>"},{"location":"ibis-for-pandas-users/#Aggregation","title":"Aggregation\u00b6","text":"<p>Aggregation in pandas is typically done by computing columns based on an aggregate function.</p>"},{"location":"ibis-for-pandas-users/#Group-by","title":"Group by\u00b6","text":"<p>Aggregations can also be done across groupings using the <code>by=</code> parameter.</p>"},{"location":"ibis-for-pandas-users/#Dropping-rows-with-NULLs","title":"Dropping rows with <code>NULL</code>s\u00b6","text":"<p>Both pandas and Ibis allow you to drop rows from a table based on whether a set of columns contains a <code>NULL</code> value. This method is called <code>dropna</code> in both packages. The common set of parameters in the two are <code>subset=</code> and <code>how=</code>. The <code>subset=</code> parameter indicates which columns to inspect for <code>NULL</code> values. The <code>how=</code> parameter specifies whether 'any' or 'all' of the specified columns must be <code>NULL</code> in order for the row to be dropped.</p>"},{"location":"ibis-for-pandas-users/#Filling-NULL-values","title":"Filling <code>NULL</code> values\u00b6","text":"<p>Both pandas and Ibis allow you to fill <code>NULL</code> values in a table. In Ibis, the replacement value can only be a scalar value of a dictionary of values. If it is a dictionary, the keys of the dictionary specify the column name for the value to apply to.</p>"},{"location":"ibis-for-pandas-users/#Common-column-expressions","title":"Common column expressions\u00b6","text":"<p>See the full API documentation for all of the available value methods and tools for creating value expressions. We mention a few common ones here as they relate to common SQL queries.</p>"},{"location":"ibis-for-pandas-users/#Type-casts","title":"Type casts\u00b6","text":"<p>Type casting in pandas is done using the <code>astype</code> method on columns.</p>"},{"location":"ibis-for-pandas-users/#Replacing-NULLs","title":"Replacing <code>NULL</code>s\u00b6","text":"<p>Both pandas and Ibis have <code>fillna</code> methods which allow you to specify a replacement value for <code>NULL</code> values.</p>"},{"location":"ibis-for-pandas-users/#Set-membership","title":"Set membership\u00b6","text":"<p>pandas set membership uses the <code>in</code> and <code>not in</code> operators such as <code>'a' in df.species</code>. Ibis uses <code>isin</code> and <code>notin</code> methods. In addition to testing membership in a set, these methods allow you to specify an else case to assign a value when the value isn't in the set.</p>"},{"location":"ibis-for-pandas-users/#Merging-tables","title":"Merging tables\u00b6","text":"<p>While pandas uses the <code>merge</code> method to combine data from multiple <code>DataFrames</code>, Ibis uses the <code>join</code> method. They both have similar capabilities. The signature for the <code>join</code> method in Ibis is: <code>join(right, predicates=(), how='inner', *, suffixes=('_x', '_y'))</code>. The <code>merge</code> method on pandas' <code>DataFrame</code> allows many more parameters, but the signature with the corresponding parameters would be: <code>join(right, on=(), how='inner', *, suffixes=('_x', '_y'))</code>. The valid values of the <code>how=</code> parameter will vary depending on the backend, but common values are 'inner', 'outer', 'left', and 'right'.</p> <p>The biggest difference between Ibis' <code>join</code> method and pandas' <code>merge</code> method is that pandas only accepts column names or index levels to join on, whereas Ibis can merge on expressions.</p> <p>Here are some examples of merging using pandas.</p>"},{"location":"ibis-for-pandas-users/#Concatenating-tables","title":"Concatenating tables\u00b6","text":"<p>Concatenating <code>DataFrame</code>s in pandas is done with the <code>concat</code> top-level function. It takes multiple <code>DataFrames</code> and concatenates the rows of one <code>DataFrame</code> to the next. If the columns are mis-matched, it extends the list of columns to include the full set of columns and inserts <code>NaN</code>s and <code>None</code>s into the missing values.</p> <p>Concatenating tables in Ibis can only be done on tables with matching schemas. The concatenation is done using the top-level <code>union</code> function or the <code>union</code> method on a table.</p> <p>We'll demonstrate a pandas <code>concat</code> first.</p>"},{"location":"ibis-for-sql-programmers/","title":"Ibis for SQL Programmers","text":"In\u00a0[1]: Copied! <pre>import ibis\n\nibis.options.sql.default_limit = None\n</pre> import ibis  ibis.options.sql.default_limit = None In\u00a0[2]: Copied! <pre>t = ibis.table(\n    [('one', 'string'), ('two', 'float'), ('three', 'int32')], 'my_data'\n)\nt\n</pre> t = ibis.table(     [('one', 'string'), ('two', 'float'), ('three', 'int32')], 'my_data' ) t Out[2]: <pre>UnboundTable: my_data\n  one   string\n  two   float64\n  three int32\n</pre> <p>In SQL, you might write something like:</p> <pre>SELECT two, one\nFROM my_data\n</pre> <p>In Ibis, this is</p> In\u00a0[3]: Copied! <pre>proj = t['two', 'one']\n</pre> proj = t['two', 'one'] <p>or</p> In\u00a0[4]: Copied! <pre>proj = t.projection(['two', 'one'])\n</pre> proj = t.projection(['two', 'one']) <p>This generates the expected SQL:</p> In\u00a0[5]: Copied! <pre>ibis.show_sql(proj)\n</pre> ibis.show_sql(proj) <pre>SELECT\n  t0.two,\n  t0.one\nFROM my_data AS t0\n</pre> <p>What about adding new columns? To form a valid projection, all column expressions must be named. Let's look at the SQL:</p> <pre>SELECT two, one, three * 2 AS new_col\nFROM my_data\n</pre> <p>The last expression is written:</p> In\u00a0[6]: Copied! <pre>new_col = (t.three * 2).name('new_col')\n</pre> new_col = (t.three * 2).name('new_col') <p>Now, we have:</p> In\u00a0[7]: Copied! <pre>proj = t['two', 'one', new_col]\nibis.show_sql(proj)\n</pre> proj = t['two', 'one', new_col] ibis.show_sql(proj) <pre>SELECT\n  t0.two,\n  t0.one,\n  t0.three * CAST(2 AS SMALLINT) AS new_col\nFROM my_data AS t0\n</pre> In\u00a0[8]: Copied! <pre>mutated = t.mutate(new_col=t.three * 2)\n</pre> mutated = t.mutate(new_col=t.three * 2) <p>Notice that using the <code>name</code> was not necessary here because we're using Python keywords to provide the name. Indeed:</p> In\u00a0[9]: Copied! <pre>ibis.show_sql(mutated)\n</pre> ibis.show_sql(mutated) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  t0.three * CAST(2 AS SMALLINT) AS new_col\nFROM my_data AS t0\n</pre> <p>If you modify an existing column with <code>mutate</code> it will list out all the other columns:</p> In\u00a0[10]: Copied! <pre>mutated = t.mutate(two=t.two * 2)\nibis.show_sql(mutated)\n</pre> mutated = t.mutate(two=t.two * 2) ibis.show_sql(mutated) <pre>SELECT\n  t0.one,\n  t0.two * CAST(2 AS SMALLINT) AS two,\n  t0.three\nFROM my_data AS t0\n</pre> In\u00a0[11]: Copied! <pre>proj = t[t]\nibis.show_sql(proj)\n</pre> proj = t[t] ibis.show_sql(proj) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three\nFROM my_data AS t0\n</pre> <p>This is how <code>mutate</code> is implemented. The example above <code>t.mutate(new_col=t.three * 2)</code> can be written as a normal projection:</p> In\u00a0[12]: Copied! <pre>proj = t[t, new_col]\nibis.show_sql(proj)\n</pre> proj = t[t, new_col] ibis.show_sql(proj) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  t0.three * CAST(2 AS SMALLINT) AS new_col\nFROM my_data AS t0\n</pre> <p>Let's consider a table we might wish to join with <code>t</code>:</p> In\u00a0[13]: Copied! <pre>t2 = ibis.table([('key', 'string'), ('value', 'float')], 'dim_table')\n</pre> t2 = ibis.table([('key', 'string'), ('value', 'float')], 'dim_table') <p>Now let's take the SQL:</p> <pre>SELECT t0.*, t0.two - t1.value AS diff\nFROM my_data t0\nINNER JOIN dim_table t1\nON t0.one = t1.key\n</pre> <p>To write this with Ibis, it is:</p> In\u00a0[14]: Copied! <pre>diff = (t.two - t2.value).name('diff')\njoined = t.join(t2, t.one == t2.key)[t, diff]\n</pre> diff = (t.two - t2.value).name('diff') joined = t.join(t2, t.one == t2.key)[t, diff] <p>And verify the generated SQL:</p> In\u00a0[15]: Copied! <pre>ibis.show_sql(joined)\n</pre> ibis.show_sql(joined) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  t0.two - t1.value AS diff\nFROM my_data AS t0\nJOIN dim_table AS t1\n  ON t0.one = t1.key\n</pre> In\u00a0[16]: Copied! <pre>expr = (\n    t.group_by(['one', 'three'])\n    .aggregate(the_sum=t.two.sum())\n    .group_by('one')\n    .aggregate(mad=lambda x: x.the_sum.abs().mean())\n)\n</pre> expr = (     t.group_by(['one', 'three'])     .aggregate(the_sum=t.two.sum())     .group_by('one')     .aggregate(mad=lambda x: x.the_sum.abs().mean()) ) <p>Indeed:</p> In\u00a0[17]: Copied! <pre>ibis.show_sql(expr)\n</pre> ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  AVG(ABS(t0.the_sum)) AS mad\nFROM (\n  SELECT\n    t1.one AS one,\n    t1.three AS three,\n    SUM(t1.two) AS the_sum\n  FROM my_data AS t1\n  GROUP BY\n    1,\n    2\n) AS t0\nGROUP BY\n  1\n</pre> In\u00a0[18]: Copied! <pre>filtered = t[t.two &gt; 0]\nibis.show_sql(filtered)\n</pre> filtered = t[t.two &gt; 0] ibis.show_sql(filtered) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three\nFROM my_data AS t0\nWHERE\n  t0.two &gt; CAST(0 AS SMALLINT)\n</pre> <p><code>filter</code> can take a list of expressions, which must all be satisfied for a row to be included in the result:</p> In\u00a0[19]: Copied! <pre>filtered = t.filter([t.two &gt; 0, t.one.isin(['A', 'B'])])\nibis.show_sql(filtered)\n</pre> filtered = t.filter([t.two &gt; 0, t.one.isin(['A', 'B'])]) ibis.show_sql(filtered) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three\nFROM my_data AS t0\nWHERE\n  t0.two &gt; CAST(0 AS SMALLINT) AND t0.one IN ('A', 'B')\n</pre> <p>To compose boolean expressions with <code>AND</code> or <code>OR</code>, use the respective <code>&amp;</code> and <code>|</code> operators:</p> In\u00a0[20]: Copied! <pre>cond = (t.two &lt; 0) | ((t.two &gt; 0) | t.one.isin(['A', 'B']))\nfiltered = t[cond]\nibis.show_sql(filtered)\n</pre> cond = (t.two &lt; 0) | ((t.two &gt; 0) | t.one.isin(['A', 'B'])) filtered = t[cond] ibis.show_sql(filtered) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three\nFROM my_data AS t0\nWHERE\n  t0.two &lt; CAST(0 AS SMALLINT) OR t0.two &gt; CAST(0 AS SMALLINT) OR t0.one IN ('A', 'B')\n</pre> In\u00a0[21]: Copied! <pre>stats = [t.two.sum().name('total_two'), t.three.mean().name('avg_three')]\nagged = t.aggregate(stats)\n</pre> stats = [t.two.sum().name('total_two'), t.three.mean().name('avg_three')] agged = t.aggregate(stats) <p>If you don't use any group expressions, the result will have a single row with your statistics of interest:</p> In\u00a0[22]: Copied! <pre>agged.schema()\n</pre> agged.schema() Out[22]: <pre>ibis.Schema {\n  total_two  float64\n  avg_three  float64\n}</pre> In\u00a0[23]: Copied! <pre>ibis.show_sql(agged)\n</pre> ibis.show_sql(agged) <pre>SELECT\n  SUM(t0.two) AS total_two,\n  AVG(t0.three) AS avg_three\nFROM my_data AS t0\n</pre> <p>To add groupings, use either the <code>by</code> argument of <code>aggregate</code> or use the <code>group_by</code> construct:</p> In\u00a0[24]: Copied! <pre>agged2 = t.aggregate(stats, by='one')\nagged3 = t.group_by('one').aggregate(stats)\nibis.show_sql(agged3)\n</pre> agged2 = t.aggregate(stats, by='one') agged3 = t.group_by('one').aggregate(stats) ibis.show_sql(agged3) <pre>SELECT\n  t0.one,\n  SUM(t0.two) AS total_two,\n  AVG(t0.three) AS avg_three\nFROM my_data AS t0\nGROUP BY\n  1\n</pre> In\u00a0[25]: Copied! <pre>events = ibis.table(\n    [('ts', 'timestamp'), ('event_type', 'int32'), ('session_id', 'int64')],\n    name='web_events',\n)\n</pre> events = ibis.table(     [('ts', 'timestamp'), ('event_type', 'int32'), ('session_id', 'int64')],     name='web_events', ) <p>Suppose we wanted to total up event types by year and month:</p> In\u00a0[26]: Copied! <pre>keys = [events.ts.year().name('year'), events.ts.month().name('month')]\n\nsessions = events.session_id.nunique()\nstats = events.group_by(keys).aggregate(\n    total=events.count(), sessions=sessions\n)\n</pre> keys = [events.ts.year().name('year'), events.ts.month().name('month')]  sessions = events.session_id.nunique() stats = events.group_by(keys).aggregate(     total=events.count(), sessions=sessions ) <p>Now we have:</p> In\u00a0[27]: Copied! <pre>ibis.show_sql(stats)\n</pre> ibis.show_sql(stats) <pre>SELECT\n  CAST(EXTRACT(year FROM t0.ts) AS SMALLINT) AS year,\n  CAST(EXTRACT(month FROM t0.ts) AS SMALLINT) AS month,\n  COUNT(*) AS total,\n  COUNT(DISTINCT t0.session_id) AS sessions\nFROM web_events AS t0\nGROUP BY\n  1,\n  2\n</pre> In\u00a0[28]: Copied! <pre>pop = ibis.table(\n    [\n        ('name', 'string'),\n        ('country', 'string'),\n        ('gender', 'string'),\n        ('age', 'int16'),\n    ],\n    name='population',\n)\n</pre> pop = ibis.table(     [         ('name', 'string'),         ('country', 'string'),         ('gender', 'string'),         ('age', 'int16'),     ],     name='population', ) <p>Now, suppose you wanted to know for each country:</p> <ul> <li>Average overall age</li> <li>Average male age</li> <li>Average female age</li> <li>Total number of persons</li> </ul> <p>In SQL, you may write:</p> <pre>SELECT country,\ncount(*) AS num_persons,\nAVG(age) AS avg_age\nAVG(CASE WHEN gender = 'M'\nTHEN age\nELSE NULL\nEND) AS avg_male,\nAVG(CASE WHEN gender = 'F'\nTHEN age\nELSE NULL\nEND) AS avg_female,\nFROM population\nGROUP BY 1\n</pre> <p>Ibis makes this much simpler by giving you <code>where</code> option in aggregation functions:</p> In\u00a0[29]: Copied! <pre>expr = pop.group_by('country').aggregate(\n    num_persons=pop.count(),\n    avg_age=pop.age.mean(),\n    avg_male=pop.age.mean(where=pop.gender == 'M'),\n    avg_female=pop.age.mean(where=pop.gender == 'F'),\n)\n</pre> expr = pop.group_by('country').aggregate(     num_persons=pop.count(),     avg_age=pop.age.mean(),     avg_male=pop.age.mean(where=pop.gender == 'M'),     avg_female=pop.age.mean(where=pop.gender == 'F'), ) <p>This indeed generates the correct SQL. Note that SQL engines handle <code>NULL</code> values differently in aggregation functions, but Ibis will write the SQL expression that is correct for your query engine.</p> In\u00a0[30]: Copied! <pre>ibis.show_sql(expr)\n</pre> ibis.show_sql(expr) <pre>SELECT\n  t0.country,\n  COUNT(*) AS num_persons,\n  AVG(t0.age) AS avg_age,\n  AVG(t0.age) FILTER(WHERE\n    t0.gender = 'M') AS avg_male,\n  AVG(t0.age) FILTER(WHERE\n    t0.gender = 'F') AS avg_female\nFROM population AS t0\nGROUP BY\n  1\n</pre> In\u00a0[31]: Copied! <pre>freqs = events.group_by(keys).size()\nibis.show_sql(freqs)\n</pre> freqs = events.group_by(keys).size() ibis.show_sql(freqs) <pre>SELECT\n  CAST(EXTRACT(year FROM t0.ts) AS SMALLINT) AS year,\n  CAST(EXTRACT(month FROM t0.ts) AS SMALLINT) AS month,\n  COUNT(*) AS count\nFROM web_events AS t0\nGROUP BY\n  1,\n  2\n</pre> In\u00a0[32]: Copied! <pre>expr = events.ts.year().value_counts()\nibis.show_sql(expr)\n</pre> expr = events.ts.year().value_counts() ibis.show_sql(expr) <pre>SELECT\n  t0.\"ExtractYear(ts)\",\n  COUNT(*) AS \"ExtractYear(ts)_count\"\nFROM (\n  SELECT\n    CAST(EXTRACT(year FROM t1.ts) AS SMALLINT) AS \"ExtractYear(ts)\"\n  FROM web_events AS t1\n) AS t0\nGROUP BY\n  1\n</pre> In\u00a0[33]: Copied! <pre>expr = (\n    t.group_by('one')\n    .having(t.count() &gt;= 1000)\n    .aggregate(t.two.sum().name('total'))\n)\nibis.show_sql(expr)\n</pre> expr = (     t.group_by('one')     .having(t.count() &gt;= 1000)     .aggregate(t.two.sum().name('total')) ) ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  SUM(t0.two) AS total\nFROM my_data AS t0\nGROUP BY\n  1\nHAVING\n  COUNT(*) &gt;= CAST(1000 AS SMALLINT)\n</pre> In\u00a0[34]: Copied! <pre>sorted = events.order_by([events.ts.year(), events.ts.month()])\n\nibis.show_sql(sorted)\n</pre> sorted = events.order_by([events.ts.year(), events.ts.month()])  ibis.show_sql(sorted) <pre>SELECT\n  t0.ts,\n  t0.event_type,\n  t0.session_id\nFROM web_events AS t0\nORDER BY\n  CAST(EXTRACT(year FROM t0.ts) AS SMALLINT),\n  CAST(EXTRACT(month FROM t0.ts) AS SMALLINT)\n</pre> <p>The default for sorting is in ascending order. To reverse the sort direction of any key, either wrap it in <code>ibis.desc</code> or pass a tuple with <code>False</code> as the second value:</p> In\u00a0[35]: Copied! <pre>sorted = events.order_by(\n    [ibis.desc('event_type'), (events.ts.month(), False)]\n).limit(100)\n\nibis.show_sql(sorted)\n</pre> sorted = events.order_by(     [ibis.desc('event_type'), (events.ts.month(), False)] ).limit(100)  ibis.show_sql(sorted) <pre>SELECT\n  t0.ts,\n  t0.event_type,\n  t0.session_id\nFROM web_events AS t0\nORDER BY\n  t0.event_type DESC,\n  CAST(EXTRACT(month FROM t0.ts) AS SMALLINT) DESC\nLIMIT 100\n</pre> In\u00a0[36]: Copied! <pre>limited = t.limit(1000)\nibis.show_sql(limited)\n</pre> limited = t.limit(1000) ibis.show_sql(limited) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three\nFROM my_data AS t0\nLIMIT 1000\n</pre> <p>The <code>offset</code> option in <code>limit</code> skips rows. So if you wanted rows 11 through 20, you could do:</p> In\u00a0[37]: Copied! <pre>limited = t.limit(10, offset=10)\nibis.show_sql(limited)\n</pre> limited = t.limit(10, offset=10) ibis.show_sql(limited) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three\nFROM my_data AS t0\nLIMIT 10\nOFFSET 10\n</pre> In\u00a0[38]: Copied! <pre>expr = t.mutate(date=t.one.cast('timestamp'), four=t.three.cast('float32'))\n\nibis.show_sql(expr)\n</pre> expr = t.mutate(date=t.one.cast('timestamp'), four=t.three.cast('float32'))  ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  CAST(t0.one AS TIMESTAMP) AS date,\n  CAST(t0.three AS REAL) AS four\nFROM my_data AS t0\n</pre> In\u00a0[39]: Copied! <pre>case = (\n    t.one.cast('timestamp')\n    .year()\n    .case()\n    .when(2015, 'This year')\n    .when(2014, 'Last year')\n    .else_('Earlier')\n    .end()\n)\n\nexpr = t.mutate(year_group=case)\nibis.show_sql(expr)\n</pre> case = (     t.one.cast('timestamp')     .year()     .case()     .when(2015, 'This year')     .when(2014, 'Last year')     .else_('Earlier')     .end() )  expr = t.mutate(year_group=case) ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  CASE CAST(EXTRACT(year FROM CAST(t0.one AS TIMESTAMP)) AS SMALLINT)\n    WHEN CAST(2015 AS SMALLINT)\n    THEN 'This year'\n    WHEN CAST(2014 AS SMALLINT)\n    THEN 'Last year'\n    ELSE 'Earlier'\n  END AS year_group\nFROM my_data AS t0\n</pre> <p>The more general case is that of an arbitrary list of boolean expressions and result values:</p> <pre>CASE\nWHEN boolean_expr1 THEN result_1\nWHEN boolean_expr2 THEN result_2\nWHEN boolean_expr3 THEN result_3\nELSE default\nEND\n</pre> <p>To do this, use <code>ibis.case</code>:</p> In\u00a0[40]: Copied! <pre>case = (\n    ibis.case()\n    .when(t.two &lt; 0, t.three * 2)\n    .when(t.two &gt; 1, t.three)\n    .else_(t.two)\n    .end()\n)\n\nexpr = t.mutate(cond_value=case)\nibis.show_sql(expr)\n</pre> case = (     ibis.case()     .when(t.two &lt; 0, t.three * 2)     .when(t.two &gt; 1, t.three)     .else_(t.two)     .end() )  expr = t.mutate(cond_value=case) ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  CASE\n    WHEN (\n      t0.two &lt; CAST(0 AS SMALLINT)\n    )\n    THEN t0.three * CAST(2 AS SMALLINT)\n    WHEN (\n      t0.two &gt; CAST(1 AS SMALLINT)\n    )\n    THEN t0.three\n    ELSE t0.two\n  END AS cond_value\nFROM my_data AS t0\n</pre> <p>There are several places where Ibis builds cases for you in a simplified way. One example is the <code>ifelse</code> function:</p> In\u00a0[41]: Copied! <pre>switch = (t.two &lt; 0).ifelse('Negative', 'Non-Negative')\nexpr = t.mutate(group=switch)\nibis.show_sql(expr)\n</pre> switch = (t.two &lt; 0).ifelse('Negative', 'Non-Negative') expr = t.mutate(group=switch) ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  CASE WHEN (\n    t0.two &lt; CAST(0 AS SMALLINT)\n  ) THEN 'Negative' ELSE 'Non-Negative' END AS \"group\"\nFROM my_data AS t0\n</pre> In\u00a0[42]: Copied! <pre>pos_two = (t.two &gt; 0).ifelse(t.two, ibis.NA)\nexpr = t.mutate(two_positive=pos_two)\nibis.show_sql(expr)\n</pre> pos_two = (t.two &gt; 0).ifelse(t.two, ibis.NA) expr = t.mutate(two_positive=pos_two) ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  CASE WHEN (\n    t0.two &gt; CAST(0 AS SMALLINT)\n  ) THEN t0.two ELSE NULL END AS two_positive\nFROM my_data AS t0\n</pre> In\u00a0[43]: Copied! <pre>refined = (\n    pop.country.upper()\n    .isin(['UNITED STATES', 'CANADA'])\n    .ifelse('North America', pop.country)\n)\n\nexpr = pop.mutate(refined_group=refined)\nibis.show_sql(expr)\n</pre> refined = (     pop.country.upper()     .isin(['UNITED STATES', 'CANADA'])     .ifelse('North America', pop.country) )  expr = pop.mutate(refined_group=refined) ibis.show_sql(expr) <pre>SELECT\n  t0.name,\n  t0.country,\n  t0.gender,\n  t0.age,\n  CASE\n    WHEN (\n      UPPER(t0.country) IN ('UNITED STATES', 'CANADA')\n    )\n    THEN 'North America'\n    ELSE t0.country\n  END AS refined_group\nFROM population AS t0\n</pre> <p>The opposite of <code>isin</code> is <code>notin</code>.</p> In\u00a0[44]: Copied! <pre>t3 = ibis.table(\n    [('column1', 'string'), ('column2', 'string'), ('column3', 'float')],\n    'data',\n)\n\nvalue = ibis.literal('foo')\n</pre> t3 = ibis.table(     [('column1', 'string'), ('column2', 'string'), ('column3', 'float')],     'data', )  value = ibis.literal('foo') <p>Once you've done this, you can use the literal expression like any other array or scalar expression:</p> In\u00a0[45]: Copied! <pre>has_foo = value.isin([t3.column1, t3.column2])\n\nexpr = t3.mutate(has_foo=has_foo)\nibis.show_sql(expr)\n</pre> has_foo = value.isin([t3.column1, t3.column2])  expr = t3.mutate(has_foo=has_foo) ibis.show_sql(expr) <pre>SELECT\n  t0.column1,\n  t0.column2,\n  t0.column3,\n  'foo' IN (t0.column1, t0.column2) AS has_foo\nFROM data AS t0\n</pre> <p>In many other situations, you can use constants without having to use <code>ibis.literal</code>. For example, we could add a column containing nothing but the number 5 like so:</p> In\u00a0[46]: Copied! <pre>expr = t3.mutate(number5=5)\nibis.show_sql(expr)\n</pre> expr = t3.mutate(number5=5) ibis.show_sql(expr) <pre>SELECT\n  t0.column1,\n  t0.column2,\n  t0.column3,\n  CAST(5 AS SMALLINT) AS number5\nFROM data AS t0\n</pre> In\u00a0[47]: Copied! <pre>indic = t.two.isnull().ifelse('valid', 'invalid')\nexpr = t.mutate(is_valid=indic)\nibis.show_sql(expr)\n</pre> indic = t.two.isnull().ifelse('valid', 'invalid') expr = t.mutate(is_valid=indic) ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  CASE WHEN (\n    t0.two IS NULL\n  ) THEN 'valid' ELSE 'invalid' END AS is_valid\nFROM my_data AS t0\n</pre> In\u00a0[48]: Copied! <pre>agged = (\n    expr[expr.one.notnull()]\n    .group_by('is_valid')\n    .aggregate(three_count=lambda t: t.three.notnull().sum())\n)\n\nibis.show_sql(agged)\n</pre> agged = (     expr[expr.one.notnull()]     .group_by('is_valid')     .aggregate(three_count=lambda t: t.three.notnull().sum()) )  ibis.show_sql(agged) <pre>SELECT\n  t0.is_valid,\n  SUM(CAST(NOT t0.three IS NULL AS INT)) AS three_count\nFROM (\n  SELECT\n    t1.one AS one,\n    t1.two AS two,\n    t1.three AS three,\n    CASE WHEN (\n      t1.two IS NULL\n    ) THEN 'valid' ELSE 'invalid' END AS is_valid\n  FROM my_data AS t1\n  WHERE\n    NOT t1.one IS NULL\n) AS t0\nGROUP BY\n  1\n</pre> In\u00a0[49]: Copied! <pre>expr = t[t.two.between(10, 50) &amp; t.one.notnull()]\nibis.show_sql(expr)\n</pre> expr = t[t.two.between(10, 50) &amp; t.one.notnull()] ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three\nFROM my_data AS t0\nWHERE\n  t0.two BETWEEN CAST(10 AS SMALLINT) AND CAST(50 AS SMALLINT) AND NOT t0.one IS NULL\n</pre> In\u00a0[50]: Copied! <pre>t1 = ibis.table(\n    [('value1', 'float'), ('key1', 'string'), ('key2', 'string')], 'table1'\n)\n\nt2 = ibis.table(\n    [('value2', 'float'), ('key3', 'string'), ('key4', 'string')], 'table2'\n)\n</pre> t1 = ibis.table(     [('value1', 'float'), ('key1', 'string'), ('key2', 'string')], 'table1' )  t2 = ibis.table(     [('value2', 'float'), ('key3', 'string'), ('key4', 'string')], 'table2' ) <p>Let's join on one key:</p> In\u00a0[51]: Copied! <pre>joined = t1.left_join(t2, t1.key1 == t2.key3)\n</pre> joined = t1.left_join(t2, t1.key1 == t2.key3) <p>The immediate result of a join does not yet have a set schema. That is determined by the next action that you take. There's several ways forward from here that address the spectrum of SQL use cases.</p> In\u00a0[52]: Copied! <pre>expr = joined[t1, t2.value2]\nibis.show_sql(expr)\n</pre> expr = joined[t1, t2.value2] ibis.show_sql(expr) <pre>SELECT\n  t0.value1,\n  t0.key1,\n  t0.key2,\n  t1.value2\nFROM table1 AS t0\nLEFT OUTER JOIN table2 AS t1\n  ON t0.key1 = t1.key3\n</pre> <p>If you need to compute an expression that involves both tables, you can do that also:</p> In\u00a0[53]: Copied! <pre>expr = joined[t1.key1, (t1.value1 - t2.value2).name('diff')]\nibis.show_sql(expr)\n</pre> expr = joined[t1.key1, (t1.value1 - t2.value2).name('diff')] ibis.show_sql(expr) <pre>SELECT\n  t0.key1,\n  t0.value1 - t1.value2 AS diff\nFROM table1 AS t0\nLEFT OUTER JOIN table2 AS t1\n  ON t0.key1 = t1.key3\n</pre> In\u00a0[54]: Copied! <pre>avg_diff = (t1.value1 - t2.value2).mean()\nexpr = (\n    t1.left_join(t2, t1.key1 == t2.key3)\n    .group_by(t1.key1)\n    .aggregate(avg_diff=avg_diff)\n)\nibis.show_sql(expr)\n</pre> avg_diff = (t1.value1 - t2.value2).mean() expr = (     t1.left_join(t2, t1.key1 == t2.key3)     .group_by(t1.key1)     .aggregate(avg_diff=avg_diff) ) ibis.show_sql(expr) <pre>SELECT\n  t0.key1,\n  AVG(t0.value1 - t1.value2) AS avg_diff\nFROM table1 AS t0\nLEFT OUTER JOIN table2 AS t1\n  ON t0.key1 = t1.key3\nGROUP BY\n  1\n</pre> In\u00a0[55]: Copied! <pre>joined = t1.left_join(t2, t1.key1 == t2.key3)\nibis.show_sql(joined)\n</pre> joined = t1.left_join(t2, t1.key1 == t2.key3) ibis.show_sql(joined) <pre>SELECT\n  t0.value1,\n  t0.key1,\n  t0.key2,\n  t1.value2,\n  t1.key3,\n  t1.key4\nFROM table1 AS t0\nLEFT OUTER JOIN table2 AS t1\n  ON t0.key1 = t1.key3\n</pre> In\u00a0[56]: Copied! <pre>t3 = ibis.table([('value3', 'float'), ('key5', 'string')], 'table3')\n\ntotal = (t1.value1 + t2.value2 + t3.value3).sum()\nexpr = (\n    t1.join(t2, [t1.key1 == t2.key3, t1.key2 == t2.key4])\n    .join(t3, t1.key1 == t3.key5)\n    .group_by([t2.key4, t3.key5])\n    .aggregate(total=total)\n)\nibis.show_sql(expr)\n</pre> t3 = ibis.table([('value3', 'float'), ('key5', 'string')], 'table3')  total = (t1.value1 + t2.value2 + t3.value3).sum() expr = (     t1.join(t2, [t1.key1 == t2.key3, t1.key2 == t2.key4])     .join(t3, t1.key1 == t3.key5)     .group_by([t2.key4, t3.key5])     .aggregate(total=total) ) ibis.show_sql(expr) <pre>SELECT\n  t1.key4,\n  t2.key5,\n  SUM(t0.value1 + t1.value2 + t2.value3) AS total\nFROM table1 AS t0\nJOIN table2 AS t1\n  ON t0.key1 = t1.key3 AND t0.key2 = t1.key4\nJOIN table3 AS t2\n  ON t0.key1 = t2.key5\nGROUP BY\n  1,\n  2\n</pre> In\u00a0[57]: Copied! <pre>t_view = t.view()\n\nstat = (t.two - t_view.three).mean()\nexpr = (\n    t.join(t_view, t.three.cast('string') == t_view.one)\n    .group_by(t.one)\n    .aggregate(metric=stat)\n)\nibis.show_sql(expr)\n</pre> t_view = t.view()  stat = (t.two - t_view.three).mean() expr = (     t.join(t_view, t.three.cast('string') == t_view.one)     .group_by(t.one)     .aggregate(metric=stat) ) ibis.show_sql(expr) <pre>SELECT\n  t1.one,\n  AVG(t1.two - t1.three) AS metric\nFROM my_data AS t1, my_data AS t1, (\n  SELECT\n    t1.one AS one_x,\n    t1.two AS two_x,\n    t1.three AS three_x,\n    t2.one AS one_y,\n    t2.two AS two_y,\n    t2.three AS three_y\n  FROM my_data AS t1\n  JOIN my_data AS t2\n    ON CAST(t1.three AS TEXT) = t2.one\n) AS t0\nGROUP BY\n  1\n</pre> In\u00a0[58]: Copied! <pre>t4 = ibis.table(\n    [\n        ('key1', 'string'),\n        ('key2', 'string'),\n        ('key3', 'string'),\n        ('value1', 'float'),\n    ],\n    'table4',\n)\n\nt5 = ibis.table(\n    [\n        ('key1', 'string'),\n        ('key2', 'string'),\n        ('key3', 'string'),\n        ('value2', 'float'),\n    ],\n    'table5',\n)\n</pre> t4 = ibis.table(     [         ('key1', 'string'),         ('key2', 'string'),         ('key3', 'string'),         ('value1', 'float'),     ],     'table4', )  t5 = ibis.table(     [         ('key1', 'string'),         ('key2', 'string'),         ('key3', 'string'),         ('value2', 'float'),     ],     'table5', ) <p>In these case, we can specify a list of common join keys:</p> In\u00a0[59]: Copied! <pre>joined = t4.join(t5, ['key1', 'key2', 'key3'])\nexpr = joined[t4, t5.value2]\nibis.show_sql(expr)\n</pre> joined = t4.join(t5, ['key1', 'key2', 'key3']) expr = joined[t4, t5.value2] ibis.show_sql(expr) <pre>SELECT\n  t0.key1,\n  t0.key2,\n  t0.key3,\n  t0.value1,\n  t1.value2\nFROM table4 AS t0\nJOIN table5 AS t1\n  ON t0.key1 = t1.key1 AND t0.key2 = t1.key2 AND t0.key3 = t1.key3\n</pre> <p>You can mix the overlapping key names with other expressions:</p> In\u00a0[60]: Copied! <pre>joined = t4.join(t5, ['key1', 'key2', t4.key3.left(4) == t4.key3.left(4)])\nexpr = joined[t4, t5.value2]\nibis.show_sql(expr)\n</pre> joined = t4.join(t5, ['key1', 'key2', t4.key3.left(4) == t4.key3.left(4)]) expr = joined[t4, t5.value2] ibis.show_sql(expr) <pre>SELECT\n  t0.key1,\n  t0.key2,\n  t0.key3,\n  t0.value1,\n  t1.value2\nFROM table4 AS t0\nJOIN table5 AS t1\n  ON t0.key1 = t1.key1\n  AND t0.key2 = t1.key2\n  AND CASE\n    WHEN (\n      CAST(0 AS SMALLINT) + 1 &gt;= 1\n    )\n    THEN SUBSTR(t0.key3, CAST(0 AS SMALLINT) + 1, CAST(4 AS SMALLINT))\n    ELSE SUBSTR(t0.key3, CAST(0 AS SMALLINT) + 1 + LENGTH(t0.key3), CAST(4 AS SMALLINT))\n  END = CASE\n    WHEN (\n      CAST(0 AS SMALLINT) + 1 &gt;= 1\n    )\n    THEN SUBSTR(t0.key3, CAST(0 AS SMALLINT) + 1, CAST(4 AS SMALLINT))\n    ELSE SUBSTR(t0.key3, CAST(0 AS SMALLINT) + 1 + LENGTH(t0.key3), CAST(4 AS SMALLINT))\n  END\n</pre> In\u00a0[61]: Copied! <pre>expr = t1.join(t2, t1.value1 &lt; t2.value2).group_by(t1.key1).size()\nibis.show_sql(expr)\n</pre> expr = t1.join(t2, t1.value1 &lt; t2.value2).group_by(t1.key1).size() ibis.show_sql(expr) <pre>SELECT\n  t0.key1,\n  COUNT(*) AS count\nFROM table1 AS t0\nJOIN table2 AS t1\n  ON t0.value1 &lt; t1.value2\nGROUP BY\n  1\n</pre> In\u00a0[62]: Copied! <pre>joined = t1.join(t2, [('key1', 'key3'), ('key2', 'key4')])\n</pre> joined = t1.join(t2, [('key1', 'key3'), ('key2', 'key4')]) In\u00a0[63]: Copied! <pre>events = ibis.table(\n    [\n        ('session_id', 'int64'),\n        ('user_id', 'int64'),\n        ('event_type', 'int32'),\n        ('ts', 'timestamp'),\n    ],\n    'events',\n)\n\npurchases = ibis.table(\n    [\n        ('item_id', 'int64'),\n        ('user_id', 'int64'),\n        ('price', 'float'),\n        ('ts', 'timestamp'),\n    ],\n    'purchases',\n)\n</pre> events = ibis.table(     [         ('session_id', 'int64'),         ('user_id', 'int64'),         ('event_type', 'int32'),         ('ts', 'timestamp'),     ],     'events', )  purchases = ibis.table(     [         ('item_id', 'int64'),         ('user_id', 'int64'),         ('price', 'float'),         ('ts', 'timestamp'),     ],     'purchases', ) <p>Now, the key <code>user_id</code> appears with high frequency in both tables. But let's say you want to limit your analysis of the <code>events</code> table to only sessions by users who have made a purchase.</p> <p>In SQL, you can do this using the somewhat esoteric <code>EXISTS</code> construct:</p> <pre>SELECT t0.*\nFROM events t0\nWHERE EXISTS (\nSELECT 1\nFROM purchases t1\nWHERE t0.user_id = t1.user_id\n)\n</pre> <p>To describe this operation in Ibis, you compare the <code>user_id</code> columns and use the <code>any</code> reduction:</p> In\u00a0[64]: Copied! <pre>cond = (events.user_id == purchases.user_id).any()\n</pre> cond = (events.user_id == purchases.user_id).any() <p>This can now be used to filter <code>events</code>:</p> In\u00a0[65]: Copied! <pre>expr = events[cond]\nibis.show_sql(expr)\n</pre> expr = events[cond] ibis.show_sql(expr) <pre>SELECT\n  t0.session_id,\n  t0.user_id,\n  t0.event_type,\n  t0.ts\nFROM events AS t0\nWHERE\n  EXISTS(\n    SELECT\n      CAST(1 AS SMALLINT) AS anon_1\n    FROM purchases AS t1\n    WHERE\n      t0.user_id = t1.user_id\n  )\n</pre> <p>If you negate the condition, it will instead give you only event data from user that have not made a purchase:</p> In\u00a0[66]: Copied! <pre>expr = events[-cond]\nibis.show_sql(expr)\n</pre> expr = events[-cond] ibis.show_sql(expr) <pre>SELECT\n  t0.session_id,\n  t0.user_id,\n  t0.event_type,\n  t0.ts\nFROM events AS t0\nWHERE\n  NOT (\n    EXISTS(\n      SELECT\n        CAST(1 AS SMALLINT) AS anon_1\n      FROM purchases AS t1\n      WHERE\n        t0.user_id = t1.user_id\n    )\n  )\n</pre> In\u00a0[67]: Copied! <pre>cond = events.user_id.isin(purchases.user_id)\nexpr = events[cond]\nibis.show_sql(expr)\n</pre> cond = events.user_id.isin(purchases.user_id) expr = events[cond] ibis.show_sql(expr) <pre>SELECT\n  t0.session_id,\n  t0.user_id,\n  t0.event_type,\n  t0.ts\nFROM events AS t0\nWHERE\n  t0.user_id IN (\n    SELECT\n      t1.user_id\n    FROM purchases AS t1\n  )\n</pre> <p>Depending on the query engine, the query planner/optimizer will often rewrite <code>IN</code> or <code>EXISTS</code> subqueries into the same set of relational algebra operations.</p> In\u00a0[68]: Copied! <pre>expr = t1[t1.value1 &gt; t2.value2.max()]\nibis.show_sql(expr)\n</pre> expr = t1[t1.value1 &gt; t2.value2.max()] ibis.show_sql(expr) <pre>SELECT\n  t0.value1,\n  t0.key1,\n  t0.key2\nFROM table1 AS t0\nWHERE\n  t0.value1 &gt; (\n    SELECT\n      MAX(t1.value2) AS \"Max(value2)\"\n    FROM table2 AS t1\n  )\n</pre> In\u00a0[69]: Copied! <pre>stat = t2[t1.key1 == t2.key3].value2.mean()\nexpr = t1[t1.value1 &gt; stat]\nibis.show_sql(expr)\n</pre> stat = t2[t1.key1 == t2.key3].value2.mean() expr = t1[t1.value1 &gt; stat] ibis.show_sql(expr) <pre>SELECT\n  t0.value1,\n  t0.key1,\n  t0.key2\nFROM table1 AS t0\nWHERE\n  t0.value1 &gt; (\n    SELECT\n      AVG(t1.value2) AS \"Mean(value2)\"\n    FROM table2 AS t1\n    WHERE\n      t0.key1 = t1.key3\n  )\n</pre> In\u00a0[70]: Copied! <pre>expr = t1.distinct()\nibis.show_sql(expr)\n</pre> expr = t1.distinct() ibis.show_sql(expr) <pre>SELECT DISTINCT\n  t0.value1,\n  t0.key1,\n  t0.key2\nFROM table1 AS t0\n</pre> <p>For distinct aggregates, the most common case is <code>COUNT(DISTINCT ...)</code>, which computes the number of unique values in an expression. So if we're looking at the <code>events</code> table, let's compute the number of distinct <code>event_type</code> values for each <code>user_id</code>. First, the SQL:</p> <pre>SELECT user_id, COUNT(DISTINCT event_type) AS unique_events\nFROM events\nGROUP BY 1\n</pre> <p>In Ibis this is:</p> In\u00a0[71]: Copied! <pre>metric = events.event_type.nunique()\nexpr = events.group_by('user_id').aggregate(unique_events=metric)\nibis.show_sql(expr)\n</pre> metric = events.event_type.nunique() expr = events.group_by('user_id').aggregate(unique_events=metric) ibis.show_sql(expr) <pre>SELECT\n  t0.user_id,\n  COUNT(DISTINCT t0.event_type) AS unique_events\nFROM events AS t0\nGROUP BY\n  1\n</pre> In\u00a0[72]: Copied! <pre>expr = t.mutate(two_demean=t.two - t.two.mean())\nibis.show_sql(expr)\n</pre> expr = t.mutate(two_demean=t.two - t.two.mean()) ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  t0.two - AVG(t0.two) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS two_demean\nFROM my_data AS t0\n</pre> <p>If you use <code>mutate</code> in conjunction with <code>group_by</code>, it will add a <code>PARTITION BY</code> to the <code>OVER</code> specification:</p> In\u00a0[73]: Copied! <pre>expr = t.group_by('one').mutate(two_demean=t.two - t.two.mean())\n\nibis.show_sql(expr)\n</pre> expr = t.group_by('one').mutate(two_demean=t.two - t.two.mean())  ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  t0.two - AVG(t0.two) OVER (PARTITION BY t0.one ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS two_demean\nFROM my_data AS t0\n</pre> <p>For functions like <code>LAG</code> that require an ordering, we can add an <code>order_by</code> call:</p> In\u00a0[74]: Copied! <pre>expr = (\n    t.group_by('one')\n    .order_by(t.two)\n    .mutate(two_first_diff=t.two - t.two.lag())\n)\n\nibis.show_sql(expr)\n</pre> expr = (     t.group_by('one')     .order_by(t.two)     .mutate(two_first_diff=t.two - t.two.lag()) )  ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  t0.two - LAG(t0.two, 1) OVER (PARTITION BY t0.one ORDER BY t0.two ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS two_first_diff\nFROM my_data AS t0\n</pre> <p>For more precision, you can create a <code>Window</code> object that also includes a window frame clause:</p> In\u00a0[75]: Copied! <pre>w = ibis.window(group_by='one', preceding=5, following=5)\nexpr = t.mutate(group_demeaned=t.two - t.two.mean().over(w))\nibis.show_sql(expr)\n</pre> w = ibis.window(group_by='one', preceding=5, following=5) expr = t.mutate(group_demeaned=t.two - t.two.mean().over(w)) ibis.show_sql(expr) <pre>SELECT\n  t0.one,\n  t0.two,\n  t0.three,\n  t0.two - AVG(t0.two) OVER (PARTITION BY t0.one ROWS BETWEEN 5 PRECEDING AND 5 FOLLOWING) AS group_demeaned\nFROM my_data AS t0\n</pre> In\u00a0[76]: Copied! <pre>expr = t1.key1.topk(10)\n</pre> expr = t1.key1.topk(10) <p>This can be evaluated directly, yielding the above query:</p> In\u00a0[77]: Copied! <pre>ibis.show_sql(expr)\n</pre> ibis.show_sql(expr) <pre>SELECT\n  t0.key1,\n  t0.count\nFROM (\n  SELECT\n    t1.key1 AS key1,\n    COUNT(t1.key1) AS count\n  FROM table1 AS t1\n  GROUP BY\n    1\n) AS t0\nORDER BY\n  t0.count DESC\nLIMIT 10\n</pre> In\u00a0[78]: Copied! <pre>expr = events.mutate(year=events.ts.year(), month=events.ts.month())\n\nibis.show_sql(expr)\n</pre> expr = events.mutate(year=events.ts.year(), month=events.ts.month())  ibis.show_sql(expr) <pre>SELECT\n  t0.session_id,\n  t0.user_id,\n  t0.event_type,\n  t0.ts,\n  CAST(EXTRACT(year FROM t0.ts) AS SMALLINT) AS year,\n  CAST(EXTRACT(month FROM t0.ts) AS SMALLINT) AS month\nFROM events AS t0\n</pre> In\u00a0[79]: Copied! <pre>expr = events[events.ts &gt; (ibis.now() - ibis.interval(years=1))]\nibis.show_sql(expr)\n</pre> expr = events[events.ts &gt; (ibis.now() - ibis.interval(years=1))] ibis.show_sql(expr) <pre>SELECT\n  t0.session_id,\n  t0.user_id,\n  t0.event_type,\n  t0.ts\nFROM events AS t0\nWHERE\n  t0.ts &gt; CAST(NOW() AS TIMESTAMP) - INTERVAL '1 year'\n</pre> <p>The implementation of each timedelta offset will depend on the query engine.</p> In\u00a0[80]: Copied! <pre>expr1 = t1.limit(10)\nexpr2 = t1.limit(10, offset=10)\n\nexpr = expr1.union(expr2)\nibis.show_sql(expr)\n</pre> expr1 = t1.limit(10) expr2 = t1.limit(10, offset=10)  expr = expr1.union(expr2) ibis.show_sql(expr) <pre>WITH anon_1 AS (\n  SELECT\n    t0.value1 AS value1,\n    t0.key1 AS key1,\n    t0.key2 AS key2\n  FROM table1 AS t0\n  LIMIT 10\n), anon_2 AS (\n  SELECT\n    t0.value1 AS value1,\n    t0.key1 AS key1,\n    t0.key2 AS key2\n  FROM table1 AS t0\n  LIMIT 10\n  OFFSET 10\n)\nSELECT\n  anon_1.value1,\n  anon_1.key1,\n  anon_1.key2\nFROM anon_1\nUNION ALL\nSELECT\n  anon_2.value1,\n  anon_2.key1,\n  anon_2.key2\nFROM anon_2\n</pre> In\u00a0[81]: Copied! <pre>purchases = ibis.table(\n    [\n        ('region', 'string'),\n        ('kind', 'string'),\n        ('user', 'int64'),\n        ('amount', 'float'),\n    ],\n    'purchases',\n)\n\nmetric = purchases.amount.sum().name('total')\nagged = purchases.group_by(['region', 'kind']).aggregate(metric)\n\nleft = agged[agged.kind == 'foo']\nright = agged[agged.kind == 'bar']\n\nresult = left.join(right, left.region == right.region)[\n    left.region, (left.total - right.total).name('diff')\n]\n</pre> purchases = ibis.table(     [         ('region', 'string'),         ('kind', 'string'),         ('user', 'int64'),         ('amount', 'float'),     ],     'purchases', )  metric = purchases.amount.sum().name('total') agged = purchases.group_by(['region', 'kind']).aggregate(metric)  left = agged[agged.kind == 'foo'] right = agged[agged.kind == 'bar']  result = left.join(right, left.region == right.region)[     left.region, (left.total - right.total).name('diff') ] <p>Ibis automatically creates a CTE for <code>agged</code>:</p> In\u00a0[82]: Copied! <pre>ibis.show_sql(result)\n</pre> ibis.show_sql(result) <pre>WITH t0 AS (\n  SELECT\n    t3.region AS region,\n    t3.kind AS kind,\n    SUM(t3.amount) AS total\n  FROM purchases AS t3\n  GROUP BY\n    1,\n    2\n), t2 AS (\n  SELECT\n    t0.region AS region,\n    t0.kind AS kind,\n    t0.total AS total\n  FROM t0\n  WHERE\n    t0.kind = 'foo'\n), t1 AS (\n  SELECT\n    t0.region AS region,\n    t0.kind AS kind,\n    t0.total AS total\n  FROM t0\n  WHERE\n    t0.kind = 'bar'\n)\nSELECT\n  t2.region,\n  t2.total - t1.total AS diff\nFROM t2\nJOIN t1\n  ON t2.region = t1.region\n</pre>"},{"location":"ibis-for-sql-programmers/#Ibis-for-SQL-Programmers","title":"Ibis for SQL Programmers\u00b6","text":"<p>Ibis provides a full-featured replacement for SQL <code>SELECT</code> queries, but expressed with Python code that is:</p> <ul> <li>Type-checked and validated as you go. No more debugging cryptic database errors; Ibis catches your mistakes right away.</li> <li>Easier to write. Pythonic function calls with tab completion in IPython.</li> <li>More composable. Break complex queries down into easier-to-digest pieces</li> <li>Easier to reuse. Mix and match Ibis snippets to create expressions tailored for your analysis.</li> </ul> <p>We intend for all <code>SELECT</code> queries to be fully portable to Ibis. Coverage of other DDL statements (e.g. <code>CREATE TABLE</code> or <code>INSERT</code>) may vary from engine to engine.</p> <p>Note: If you find any SQL idioms or use cases in your work that are not represented here, please reach out so we can add more to this guide!</p>"},{"location":"ibis-for-sql-programmers/#Projections:-select/add/remove-columns","title":"Projections: select/add/remove columns\u00b6","text":"<p>All tables in Ibis are immutable. To select a subset of a table's columns, or to add new columns, you must produce a new table by means of a projection.</p>"},{"location":"ibis-for-sql-programmers/#mutate:-Add-or-modify-columns-easily","title":"<code>mutate</code>: Add or modify columns easily\u00b6","text":"<p>Since adding new columns or modifying existing columns is so common, there is a convenience method <code>mutate</code>:</p>"},{"location":"ibis-for-sql-programmers/#SELECT-*-equivalent","title":"<code>SELECT *</code> equivalent\u00b6","text":"<p>Especially in combination with relational joins, it's convenient to be able to select all columns in a table using the <code>SELECT *</code> construct. To do this, use the table expression itself in a projection:</p>"},{"location":"ibis-for-sql-programmers/#Using-functions-in-projections","title":"Using functions in projections\u00b6","text":"<p>If you pass a function instead of a string or Ibis expression in any projection context, it will be invoked with the \"parent\" table as its argument. This can help significantly when [composing complex operations. Consider this SQL:</p> <pre>SELECT one, avg(abs(the_sum)) AS mad\nFROM (\nSELECT one, three, sum(two) AS the_sum\nFROM my_data\nGROUP BY 1, 2\n) t0\nGROUP BY 1\n</pre> <p>This can be written as one chained expression:</p>"},{"location":"ibis-for-sql-programmers/#Filtering-/-WHERE","title":"Filtering / <code>WHERE</code>\u00b6","text":"<p>You can add filter clauses to a table expression either by indexing with <code>[]</code> (like pandas) or use the <code>filter</code> method:</p>"},{"location":"ibis-for-sql-programmers/#Aggregation-/-GROUP-BY","title":"Aggregation / <code>GROUP BY</code>\u00b6","text":"<p>To aggregate a table, you need:</p> <ul> <li>Zero or more grouping expressions (these can be column names)</li> <li>One or more aggregation expressions</li> </ul> <p>Let's look at the <code>aggregate</code> method on tables:</p>"},{"location":"ibis-for-sql-programmers/#Non-trivial-grouping-keys","title":"Non-trivial grouping keys\u00b6","text":"<p>You can use any expression (or function, like in projections) deriving from the table you are aggregating. The only constraint is that the expressions must be named. Let's look at an example:</p>"},{"location":"ibis-for-sql-programmers/#Aggregates-considering-table-subsets","title":"Aggregates considering table subsets\u00b6","text":"<p>In analytics is it common to compare statistics from different subsets of a table. Let's consider a dataset containing people's name, age, gender, and nationality:</p>"},{"location":"ibis-for-sql-programmers/#count(*)-convenience:-size()","title":"<code>count(*)</code> convenience: <code>size()</code>\u00b6","text":"<p>Computing group frequencies is so common that, like pandas, we have a method <code>size</code> that is a shortcut for the <code>count(*)</code> idiom:</p>"},{"location":"ibis-for-sql-programmers/#Frequency-table-convenience:-value_counts","title":"Frequency table convenience: <code>value_counts</code>\u00b6","text":"<p>Consider the SQL idiom:</p> <pre>SELECT some_column_expression, count(*)\nFROM table\nGROUP BY 1\n</pre> <p>This is so common that, like pandas, there is a generic array method <code>value_counts</code> which does this for us:</p>"},{"location":"ibis-for-sql-programmers/#HAVING-clause","title":"<code>HAVING</code> clause\u00b6","text":"<p>The SQL <code>HAVING</code> clause enables you to filter the results of an aggregation based on some group-wise condition holding true. For example, suppose we wanted to limit our analysis to groups containing at least 1000 observations:</p> <pre>SELECT one, sum(two) AS total\nFROM my_data\nGROUP BY 1\nHAVING count(*) &gt;= 1000\n</pre> <p>With Ibis, you can do:</p>"},{"location":"ibis-for-sql-programmers/#Sorting-/-ORDER-BY","title":"Sorting / <code>ORDER BY</code>\u00b6","text":"<p>To sort a table, use the <code>order_by</code> method along with either column names or expressions that indicate the sorting keys:</p>"},{"location":"ibis-for-sql-programmers/#LIMIT-and-OFFSET","title":"<code>LIMIT</code> and <code>OFFSET</code>\u00b6","text":"<p>This one is easy. The table <code>limit</code> function truncates a table to the indicates number of rows. So if you only want the first 1000 rows (which may not be deterministic depending on the SQL engine), you can do:</p>"},{"location":"ibis-for-sql-programmers/#Common-column-expressions","title":"Common column expressions\u00b6","text":"<p>See the full <code>API documentation &lt;api&gt;</code>{.interpreted-text role=\"ref\"} for all of the available value methods and tools for creating value expressions. We mention a few common ones here as they relate to common SQL queries.</p>"},{"location":"ibis-for-sql-programmers/#Type-casts","title":"Type casts\u00b6","text":"<p>Ibis's type system is independent of any SQL system. You cast Ibis expressions from one Ibis type to another. For example:</p>"},{"location":"ibis-for-sql-programmers/#CASE-statements","title":"<code>CASE</code> statements\u00b6","text":"<p>SQL dialects typically support one or more kind of <code>CASE</code> statements. The first is the simple case that compares against exact values of an expression.</p> <pre>CASE expr\nWHEN value_1 THEN result_1\nWHEN value_2 THEN result_2\nELSE default\nEND\n</pre> <p>Value expressions in Ibis have a <code>case</code> method that allows us to emulate these semantics:</p>"},{"location":"ibis-for-sql-programmers/#Using-NULL-in-expressions","title":"Using <code>NULL</code> in expressions\u00b6","text":"<p>To use <code>NULL</code> in an expression, either use the special <code>ibis.NA</code> value or <code>ibis.null()</code>:</p>"},{"location":"ibis-for-sql-programmers/#Set-membership:-IN-/-NOT-IN","title":"Set membership: <code>IN</code> / <code>NOT IN</code>\u00b6","text":"<p>Let's look again at the population dataset. Suppose you wanted to combine the United States and Canada data into a \"North America\" category. Here would be some SQL to do it:</p> <pre>CASE\nWHEN upper(country) IN ('UNITED STATES', 'CANADA')\nTHEN 'North America'\nELSE country\nEND AS refined_group\n</pre> <p>The Ibis equivalent of <code>IN</code> is the <code>isin</code> method. So we can write:</p>"},{"location":"ibis-for-sql-programmers/#Constant-and-literal-expressions","title":"Constant and literal expressions\u00b6","text":"<p>Consider a SQL expression like:</p> <pre>'foo' IN (column1, column2)\n</pre> <p>which is equivalent to</p> <pre>column1 = 'foo' OR column2 = 'foo'\n</pre> <p>To build expressions off constant values, you must first convert the value (whether a Python string or number) to an Ibis expression using <code>ibis.literal</code>:</p>"},{"location":"ibis-for-sql-programmers/#IS-NULL-and-IS-NOT-NULL","title":"<code>IS NULL</code> and <code>IS NOT NULL</code>\u00b6","text":"<p>These are simple: use the <code>isnull</code> and <code>notnull</code> functions respectively, which yield boolean arrays:</p>"},{"location":"ibis-for-sql-programmers/#BETWEEN","title":"<code>BETWEEN</code>\u00b6","text":"<p>The <code>between</code> method on arrays and scalars compiles to the SQL <code>BETWEEN</code> keyword. The result of <code>between</code> is boolean and can be used with any other boolean expression:</p>"},{"location":"ibis-for-sql-programmers/#Joins","title":"Joins\u00b6","text":"<p>Ibis supports several kinds of joins between table expressions:</p> <ul> <li><code>inner_join</code>: maps to SQL <code>INNER JOIN</code></li> <li><code>cross_join</code>: a cartesian product join with no keys. Equivalent to <code>inner_join</code> with no join predicates</li> <li><code>left_join</code>: maps to SQL <code>LEFT OUTER JOIN</code></li> <li><code>outer_join</code>: maps to SQL <code>FULL OUTER JOIN</code></li> <li><code>semi_join</code>: maps to SQL <code>LEFT SEMI JOIN</code>. May or may not be an explicit join type in your query engine.</li> <li><code>anti_join</code>: maps to SQL <code>LEFT ANTI JOIN</code>. May or may not be an explicit join type in your query engine.</li> </ul> <p>The <code>join</code> table method is by default the same as <code>inner_join</code>.</p> <p>Let's look at a couple example tables to see how joins work in Ibis:</p>"},{"location":"ibis-for-sql-programmers/#Join-+-projection","title":"Join + projection\u00b6","text":"<p>Consider the SQL:</p> <pre>SELECT t0.*, t1.value2\nFROM table1 t0\nLEFT OUTER JOIN table2 t1\nON t0.key1 = t1.key3\n</pre> <p>After one or more joins, you can reference any of the joined tables in a projection immediately after:</p>"},{"location":"ibis-for-sql-programmers/#Join-+-aggregation","title":"Join + aggregation\u00b6","text":"<p>You can directly aggregate a join without need for projection, which also allows you to form statistics that reference any of the joined tables.</p> <p>Consider this SQL:</p> <pre>SELECT t0.key1, avg(t0.value1 - t1.value2) AS avg_diff\nFROM table1 t0\nLEFT OUTER JOIN table2 t1\nON t0.key1 = t1.key3\nGROUP BY 1\n</pre> <p>As you would hope, the code is as follows:</p>"},{"location":"ibis-for-sql-programmers/#Join-with-SELECT-*","title":"Join with <code>SELECT *</code>\u00b6","text":"<p>If you try to compile or execute a join that has not been projected or aggregated, it will be fully materialized:</p>"},{"location":"ibis-for-sql-programmers/#Multiple-joins","title":"Multiple joins\u00b6","text":"<p>You can join multiple tables together in succession without needing to address any of the above concerns.</p>"},{"location":"ibis-for-sql-programmers/#Self-joins","title":"Self joins\u00b6","text":"<p>What about when you need to join a table on itself? For example:</p> <pre>SELECT t0.one, avg(t0.two - t1.three) AS metric\nFROM my_data t0\nINNER JOIN my_data t1\nON t0.one = t1.one\nGROUP BY 1\n</pre> <p>The table <code>view</code> method enables you to form a self-reference that is referentially distinct in expressions. Now you can proceed normally:</p>"},{"location":"ibis-for-sql-programmers/#Overlapping-join-keys","title":"Overlapping join keys\u00b6","text":"<p>In many cases the columns being joined between two tables or table expressions have the same name. Consider this example:</p>"},{"location":"ibis-for-sql-programmers/#Non-equality-join-predicates","title":"Non-equality join predicates\u00b6","text":"<p>You can join tables with boolean clauses that are not equality. Some query engines support these efficiently, some inefficiently, or some not at all. In the latter case, these conditions get moved by Ibis into the <code>WHERE</code> part of the <code>SELECT</code> query.</p>"},{"location":"ibis-for-sql-programmers/#Other-ways-to-specify-join-keys","title":"Other ways to specify join keys\u00b6","text":"<p>You can also pass a list of column names instead of forming boolean expressions:</p>"},{"location":"ibis-for-sql-programmers/#Subqueries","title":"Subqueries\u00b6","text":"<p>Ibis creates inline views and nested subqueries automatically. This section concerns more complex subqueries involving foreign references and other advanced relational algebra.</p>"},{"location":"ibis-for-sql-programmers/#Correlated-EXISTS-/-NOT-EXISTS-filters","title":"Correlated <code>EXISTS</code> / <code>NOT EXISTS</code> filters\u00b6","text":"<p>The SQL <code>EXISTS</code> and <code>NOT EXISTS</code> constructs are typically used for efficient filtering in large many-to-many relationships.</p> <p>Let's consider a web dataset involving website session / usage data and purchases:</p>"},{"location":"ibis-for-sql-programmers/#Subqueries-with-IN-/-NOT-IN","title":"Subqueries with <code>IN</code> / <code>NOT IN</code>\u00b6","text":"<p>Subquery filters with <code>IN</code> (and <code>NOT IN</code>) are functionally similar to <code>EXISTS</code> subqueries. Let's look at some SQL:</p> <pre>SELECT *\nFROM events\nWHERE user_id IN (\nSELECT user_id\nFROM purchases\n)\n</pre> <p>This is almost semantically the same as the <code>EXISTS</code> example. Indeed, you can write with Ibis:</p>"},{"location":"ibis-for-sql-programmers/#Comparison-with-scalar-aggregates","title":"Comparison with scalar aggregates\u00b6","text":"<p>Sometime you want to compare a value with an unconditional aggregate value from a different table. Take the SQL:</p> <pre>SELECT *\nFROM table1\nWHERE value1 &gt; (\nSELECT max(value2)\nFROM table2\n)\n</pre> <p>With Ibis, the code is simpler and more pandas-like:</p>"},{"location":"ibis-for-sql-programmers/#Conditional-aggregates","title":"Conditional aggregates\u00b6","text":"<p>Suppose you want to compare a value with the aggregate value for some common group values between two tables. Here's some SQL:</p> <pre>SELECT *\nFROM table1 t0\nWHERE value1 &gt; (\nSELECT avg(value2)\nFROM table2 t1\nWHERE t0.key1 = t1.key3\n)\n</pre> <p>This query computes the average for each distinct value of <code>key3</code> and uses the corresponding average for the comparison, rather than the whole-table average as above.</p> <p>With Ibis, the code is similar, but you add the correlated filter to the average statistic:</p>"},{"location":"ibis-for-sql-programmers/#DISTINCT-expressions","title":"<code>DISTINCT</code> expressions\u00b6","text":"<p>In SQL, the <code>DISTINCT</code> keyword is used in a couple of ways:</p> <ul> <li>Deduplicating identical rows in some <code>SELECT</code> statement</li> <li>Aggregating on the distinct values of some column expression</li> </ul> <p>Ibis supports both use cases. So let's have a look. The first case is the simplest: call <code>distinct</code> on a table expression. First, here's the SQL:</p> <pre>SELECT DISTINCT *\nFROM table1\n</pre> <p>And the Ibis Python code:</p>"},{"location":"ibis-for-sql-programmers/#Window-functions","title":"Window functions\u00b6","text":"<p>Window functions in SQL allow you to write expressions that involve possibly-ordered groups of a table. Each window function involves one of the following:</p> <ul> <li>An analytic function. Most aggregate functions are valid analytic functions, and there are additional ones such as <code>LEAD</code>, <code>LAG</code>, <code>NTILE</code>, and others.</li> <li>A <code>PARTITION BY</code> clause. This may be omitted.</li> <li>An <code>ORDER BY</code> clause. This may be omitted for many functions.</li> <li>A window frame clause. The default is to use the entire partition.</li> </ul> <p>So you may see SQL like:</p> <pre>AVG(value) OVER (PARTITION BY key1)\n</pre> <p>Or simply</p> <pre>AVG(value) OVER ()\n</pre> <p>Ibis will automatically write window clauses when you use aggregate functions in a non-aggregate context. Suppose you wanted to subtract the mean of a column from itself:</p>"},{"location":"ibis-for-sql-programmers/#Top-K-operations","title":"Top-K operations\u00b6","text":"<p>A common SQL idiom is the \"top-K\" or \"top-N\" operation: subsetting a dimension by aggregate statistics:</p> <pre>SELECT key1, count(*) AS `count`\nFROM table1\nGROUP BY 1\nORDER BY `count` DESC\nLIMIT 10\n</pre> <p>Ibis has a special analytic expression <code>topk</code>:</p>"},{"location":"ibis-for-sql-programmers/#Date-/-time-data","title":"Date / time data\u00b6","text":"<p>See <code>Timestamp methods &lt;api.timestamp&gt;</code>{.interpreted-text role=\"ref\"} for a table of available date/time methods.</p> <p>For example, we can do:</p>"},{"location":"ibis-for-sql-programmers/#Casting-to-date-/-time-types","title":"Casting to date / time types\u00b6","text":"<p>In many cases, you can convert string values to datetime / timestamp with <code>strings.cast('timestamp')</code>, but you may have to do some more reconnaissance into the data if this does not work.</p>"},{"location":"ibis-for-sql-programmers/#Intervals","title":"Intervals\u00b6","text":"<p>Ibis has a set of interval APIs that allow you to do date/time arithmetic. For example:</p>"},{"location":"ibis-for-sql-programmers/#Buckets-and-histograms","title":"Buckets and histograms\u00b6","text":"<p>To appear.</p>"},{"location":"ibis-for-sql-programmers/#Unions","title":"Unions\u00b6","text":"<p>SQL dialects often support two kinds of <code>UNION</code> operations:</p> <ul> <li><code>UNION</code>: the combination of distinct rows from each table.</li> <li><code>UNION ALL</code>: the combination of all rows from each table, whether or not they are distinct.</li> </ul> <p>The Ibis <code>union</code> function by distinct is a <code>UNION ALL</code>, and you can set <code>distinct=True</code> to get the normal <code>UNION</code> behavior:</p>"},{"location":"ibis-for-sql-programmers/#Esoterica","title":"Esoterica\u00b6","text":"<p>This area will be the spillover for miscellaneous SQL concepts and how queries featuring them can be ported to Ibis.</p>"},{"location":"ibis-for-sql-programmers/#Common-table-expressions-(CTEs)","title":"Common table expressions (CTEs)\u00b6","text":"<p>The simplest SQL CTE is a SQL statement that is used multiple times in a <code>SELECT</code> query, which can be \"factored\" out using the <code>WITH</code> keyword:</p> <pre>WITH t0 AS (\nSELECT region, kind, sum(amount) AS total\nFROM purchases\nGROUP BY 1, 2\n)\nSELECT t0.region, t0.total - t1.total\nFROM t0\nINNER JOIN t0 t1\nON t0.region = t1.region\nWHERE t0.kind = 'foo' AND t1.kind = 'bar'\n</pre> <p>Explicit CTEs are not necessary with Ibis. Let's look at an example involving joining an aggregated table on itself after filtering:</p>"},{"location":"install/","title":"Install Ibis","text":"pipcondamamba <pre><code>pip install 'ibis-framework[duckdb]' # (1) (2)\n</code></pre> <ol> <li> <p>We suggest starting with the DuckDB backend.  It's performant and fully featured.  If you would like to use a different backend, all of the available options are listed below.</p> </li> <li> <p>Note that the <code>ibis-framework</code> package is not the same as the <code>ibis</code> package in PyPI.  These two libraries cannot coexist in the same Python environment, as they are both imported with the <code>ibis</code> module name.</p> </li> </ol> <pre><code>conda install -c conda-forge ibis-framework\n</code></pre> <pre><code>mamba install -c conda-forge ibis-framework\n</code></pre>"},{"location":"install/#install-backend-dependencies","title":"Install backend dependencies","text":"bigqueryclickhousedaskdatafusiondruidduckdbimpalamssqlmysqlpandaspolarspostgrespysparksnowflakesqlitetrino <pre><code>pip install 'ibis-framework[bigquery]'\n</code></pre> <pre><code>pip install 'ibis-framework[clickhouse]'\n</code></pre> <pre><code>pip install 'ibis-framework[dask]'\n</code></pre> <pre><code>pip install 'ibis-framework[datafusion]'\n</code></pre> <pre><code>pip install 'ibis-framework[druid]'\n</code></pre> <pre><code>pip install 'ibis-framework[duckdb]'\n</code></pre> <pre><code>pip install 'ibis-framework[impala]'\n</code></pre> <pre><code>pip install 'ibis-framework[mssql]'\n</code></pre> <pre><code>pip install 'ibis-framework[mysql]'\n</code></pre> <pre><code>pip install 'ibis-framework[pandas]'\n</code></pre> <pre><code>pip install 'ibis-framework[polars]'\n</code></pre> <pre><code>pip install 'ibis-framework[postgres]'\n</code></pre> <pre><code>pip install 'ibis-framework[pyspark]'\n</code></pre> <pre><code>pip install 'ibis-framework[snowflake]'\n</code></pre> <pre><code>pip install 'ibis-framework[sqlite]'\n</code></pre> <pre><code>pip install 'ibis-framework[trino]'\n</code></pre> <p>After you've successfully installed Ibis, try going through the tutorial:</p> <p>Go to the Tutorial</p>"},{"location":"release_notes/","title":"Releases","text":""},{"location":"release_notes/#release-notes","title":"Release Notes","text":""},{"location":"release_notes/#500-2023-03-15","title":"5.0.0 (2023-03-15)","text":""},{"location":"release_notes/#breaking-changes","title":"\u26a0 BREAKING CHANGES","text":"<ul> <li>api: Snowflake identifiers are now kept as is from the database. Many table names and column names may now be in SHOUTING CASE. Adjust code accordingly.</li> <li>backend: Backends now raise <code>ibis.common.exceptions.UnsupportedOperationError</code> in more places during compilation. You may need to catch this error type instead of the previous type, which differed between backends.</li> <li>ux: <code>Table.info</code> now returns an expression</li> <li>ux: Passing a sequence of column names to <code>Table.drop</code> is removed. Replace <code>drop(cols)</code> with <code>drop(*cols)</code>.</li> <li>The <code>spark</code> plugin alias is removed. Use <code>pyspark</code> instead</li> <li>ir: removed <code>ibis.expr.scope</code> and <code>ibis.expr.timecontext</code> modules, access them under <code>ibis.backends.base.df.&lt;module&gt;</code></li> <li>some methods have been removed from the top-level <code>ibis.&lt;backend&gt;</code> namespaces, access them on a connected backend instance instead.</li> <li>common: removed <code>ibis.common.geospatial</code>, import the functions from <code>ibis.backends.base.sql.registry.geospatial</code></li> <li>datatypes: <code>JSON</code> is no longer a subtype of <code>String</code></li> <li>datatype: <code>Category</code>, <code>CategoryValue</code>/<code>Column</code>/<code>Scalar</code> are removed. Use string types instead.</li> <li>ux: The <code>metric_name</code> argument to <code>value_counts</code> is removed. Use <code>Table.relabel</code> to change the metric column's name.</li> <li>deps: the minimum version of <code>parsy</code> is now 2.0</li> <li>ir/backends: removed the following symbols:</li> <li><code>ibis.backends.duckdb.parse_type()</code> function</li> <li><code>ibis.backends.impala.Backend.set_database()</code> method</li> <li><code>ibis.backends.pyspark.Backend.set_database()</code> method</li> <li><code>ibis.backends.impala.ImpalaConnection.ping()</code> method</li> <li><code>ibis.expr.operations.DatabaseTable.change_name()</code> method</li> <li><code>ibis.expr.operations.ParseURL</code> class</li> <li><code>ibis.expr.operations.Value.to_projection()</code> method</li> <li><code>ibis.expr.types.Table.get_column()</code> method</li> <li><code>ibis.expr.types.Table.get_columns()</code> method</li> <li><code>ibis.expr.types.StringValue.parse_url()</code> method</li> <li>schema: <code>Schema.from_dict()</code>, <code>.delete()</code> and <code>.append()</code> methods are removed</li> <li>datatype: <code>struct_type.pairs</code> is removed, use <code>struct_type.fields</code> instead</li> <li>datatype: <code>Struct(names, types)</code> is not supported anymore, pass a dictionary to <code>Struct</code> constructor instead</li> </ul>"},{"location":"release_notes/#features","title":"Features","text":"<ul> <li>add <code>max_columns</code> option for table repr (a3aa236)</li> <li>add examples API (b62356e)</li> <li>api: add <code>map</code>/<code>array</code> accessors for easy conversion of JSON to stronger-typed values (d1e9d11)</li> <li>api: add array to string join operation (74de349)</li> <li>api: add builtin support for relabeling columns to snake case (1157273)</li> <li>api: add support for passing a mapping to <code>ibis.map</code> (d365fd4)</li> <li>api: allow single argument set operations (bb0a6f0)</li> <li>api: implement <code>to_pandas()</code> API for ecosystem compatibility (cad316c)</li> <li>api: implement isin (ac31db2)</li> <li>api: make <code>cache</code> evaluate only once per session per expression (5a8ffe9)</li> <li>api: make create_table uniform (833c698)</li> <li>api: more selectors (5844304)</li> <li>api: upcast pandas DataFrames to memtables in <code>rlz.table</code> rule (8dcfb8d)</li> <li>backends: implement <code>ops.Time</code> for sqlalchemy backends (713cd33)</li> <li>bigquery: add <code>BIGNUMERIC</code> type support (5c98ea4)</li> <li>bigquery: add UUID literal support (ac47c62)</li> <li>bigquery: enable subqueries in select statements (ef4dc86)</li> <li>bigquery: implement create and drop table method (5f3c22c)</li> <li>bigquery: implement create_view and drop_view method (a586473)</li> <li>bigquery: support creating tables from in-memory tables (c3a25f1)</li> <li>bigquery: support in-memory tables (37e3279)</li> <li>change Rich repr of dtypes from blue to dim (008311f)</li> <li>clickhouse: implement <code>ArrayFilter</code> translation (f2144b6)</li> <li>clickhouse: implement <code>ops.ArrayMap</code> (45000e7)</li> <li>clickhouse: implement <code>ops.MapLength</code> (fc82eaa)</li> <li>clickhouse: implement ops.Capitalize (914c64c)</li> <li>clickhouse: implement ops.ExtractMillisecond (ee74e3a)</li> <li>clickhouse: implement ops.RandomScalar (104aeed)</li> <li>clickhouse: implement ops.StringAscii (a507d17)</li> <li>clickhouse: implement ops.TimestampFromYMDHMS, ops.DateFromYMD (05f5ae5)</li> <li>clickhouse: improve error message for invalid types in literal (e4d7799)</li> <li>clickhouse: support asof_join (7ed5143)</li> <li>common: add abstract mapping collection with support for set operations (7d4aa0f)</li> <li>common: add support for variadic positional and variadic keyword annotations (baea1fa)</li> <li>common: hold typehint in the annotation objects (b3601c6)</li> <li>common: support <code>Callable</code> arguments and return types in <code>Validator.from_annotable()</code> (ae57c36)</li> <li>common: support positional only and keyword only arguments in annotations (340dca1)</li> <li>dask/pandas: raise OperationNotDefinedError exc for not defined operations (2833685)</li> <li>datafusion: implement ops.Degress, ops.Radians (7e61391)</li> <li>datafusion: implement ops.Exp (7cb3ade)</li> <li>datafusion: implement ops.Pi, ops.E (5a74cb4)</li> <li>datafusion: implement ops.RandomScalar (5d1cd0f)</li> <li>datafusion: implement ops.StartsWith (8099014)</li> <li>datafusion: implement ops.StringAscii (b1d7672)</li> <li>datafusion: implement ops.StrRight (016a082)</li> <li>datafusion: implement ops.Translate (2fe3fc4)</li> <li>datafusion: support substr without end (a19fd87)</li> <li>datatype/schema: support datatype and schema declaration using type annotated classes (6722c31)</li> <li>datatype: enable inference of <code>Decimal</code> type (8761732)</li> <li>datatype: implement <code>Mapping</code> abstract base class for <code>StructType</code> (5df2022)</li> <li>deps: add Python 3.11 support and tests (6f3f759)</li> <li>druid: add Apache Druid backend (c4cc2a6)</li> <li>druid: implement bitwise operations (3ac7447)</li> <li>druid: implement ops.Pi, ops.Modulus, ops.Power, ops.Log10 (090ff03)</li> <li>druid: implement ops.Sign (35f52cc)</li> <li>druid: implement ops.StringJoin (42cd9a3)</li> <li>duckdb: add support for reading tables from sqlite databases (9ba2211)</li> <li>duckdb: add UUID type support (5cd6d76)</li> <li>duckdb: implement <code>ArrayFilter</code> translation (5f35d5c)</li> <li>duckdb: implement <code>ops.ArrayMap</code> (063602d)</li> <li>duckdb: implement create_view and drop_view method (4f73953)</li> <li>duckdb: implement ops.Capitalize (b17116e)</li> <li>duckdb: implement ops.TimestampDiff, ops.IntervalAdd, ops.IntervalSubtract (a7fd8fb)</li> <li>duckdb: implement uuid result type (3150333)</li> <li>duckdb: support dt.MACADDR, dt.INET as string (c4739c7)</li> <li>duckdb: use <code>read_json_auto</code> when reading json (4193867)</li> <li>examples: add imdb dataset examples (3d63203)</li> <li>examples: add movielens small dataset (5f7c15c)</li> <li>examples: add wowah_data data to examples (bf9a7cc)</li> <li>examples: enable progressbar and faster hashing (4adfe29)</li> <li>impala: implement ops.Clip (279fd78)</li> <li>impala: implement ops.Radians, ops.Degress (a794ace)</li> <li>impala: implement ops.RandomScalar (874f2ff)</li> <li>io: add to_parquet, to_csv to backends (fecca42)</li> <li>ir: add <code>ArrayFilter</code> operation (e719d60)</li> <li>ir: add <code>ArrayMap</code> operation (49e5f7a)</li> <li>mysql: support in-memory tables (4dfabbd)</li> <li>pandas/dask: implement bitwise operations (4994add)</li> <li>pandas/dask: implement ops.Pi, ops.E (091be3c)</li> <li>pandas: add basic unnest support (dd36b9d)</li> <li>pandas: implement ops.StartsWith, ops.EndsWith (2725423)</li> <li>pandas: support more pandas extension dtypes (54818ef)</li> <li>polars: implement <code>ops.Union</code> (17c6011)</li> <li>polars: implement ops.Pi, ops.E (6d8fc4a)</li> <li>postgres: allow connecting with an explicit <code>schema</code> (39c9ea8)</li> <li>postgres: fix interval literal (c0fa933)</li> <li>postgres: implement <code>argmin</code>/<code>argmax</code> (82668ec)</li> <li>postgres: parse tsvector columns as strings (fac8c47), closes #5402</li> <li>pyspark: add support for <code>ops.ArgMin</code> and <code>ops.ArgMax</code> (a3fa57c)</li> <li>pyspark: implement ops.Between (ed83465)</li> <li>return Table from create_table(), create_view() (e4ea597)</li> <li>schema: implement <code>Mapping</code> abstract base class for <code>Schema</code> (167d85a)</li> <li>selectors: support ranges (e10caf4)</li> <li>snowflake: add support for alias in snowflake (b1b947a)</li> <li>snowflake: add support for bulk upload for temp tables in snowflake (6cc174f)</li> <li>snowflake: add UUID literal support (436c781)</li> <li>snowflake: implement argmin/argmax (8b998a5)</li> <li>snowflake: implement ops.BitwiseAnd, ops.BitwiseNot, ops.BitwiseOr, ops.BitwiseXor (1acd4b7)</li> <li>snowflake: implement ops.GroupConcat (2219866)</li> <li>snowflake: implement remaining map functions (c48c9a6)</li> <li>snowflake: support binary variance reduction with filters (eeabdee)</li> <li>snowflake: support cross-database table access (79cb445)</li> <li>sqlalchemy: generalize unnest to work on backends that don't support it (5943ce7)</li> <li>sqlite: add sqlite type support (addd6a9)</li> <li>sqlite: support in-memory tables (1b24848)</li> <li>sql: support for creating temporary tables in sql based backends (466cf35)</li> <li>tables: cast table using schema (96ce109)</li> <li>tables: implement <code>pivot_longer</code> API (11c5736)</li> <li>trino: enable <code>MapLength</code> operation (a7ad1db)</li> <li>trino: implement <code>ArrayFilter</code> translation (50f6fcc)</li> <li>trino: implement <code>ops.ArrayMap</code> (657bf61)</li> <li>trino: implement <code>ops.Between</code> (d70b9c0)</li> <li>trino: support sqlalchemy 2 (0d078c1)</li> <li>ux: accept selectors in <code>Table.drop</code> (325140f)</li> <li>ux: allow creating unbound tables using annotated class definitions (d7bf6a2)</li> <li>ux: easy interactive setup (6850146)</li> <li>ux: expose <code>between</code>, <code>rows</code> and <code>range</code> keyword arguments in <code>value.over()</code> (5763063)</li> </ul>"},{"location":"release_notes/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>analysis: extract <code>Limit</code> subqueries (62f6e14)</li> <li>api: add a <code>name</code> attribute to backend proxy modules (d6d8e7e)</li> <li>api: fix broken <code>__radd__</code> array concat operation (121d9a0)</li> <li>api: only include valid python identifiers in struct tab completion (8f33775)</li> <li>api: only include valid python identifiers in table tab completion (031a48c)</li> <li>backend: provide useful error if default backend is unavailable (1dbc682)</li> <li>backends: fix capitalize implementations across all backends (d4f0275)</li> <li>backends: fix null literal handling (7f46342)</li> <li>bigquery: ensure that memtables are translated correctly (d6e56c5)</li> <li>bigquery: fix decimal literals (4a04c9b)</li> <li>bigquery: regenerate negative string index sql snapshots (3f02c73)</li> <li>bigquery: regenerate sql for predicate pushdown fix (509806f)</li> <li>cache: remove bogus schema argument and validate database argument type (c4254f6)</li> <li>ci: fix invalid test id (f70de1d)</li> <li>clickhouse: fix decimal literal (4dcd2cb)</li> <li>clickhouse: fix set ops with table operands (86bcf32)</li> <li>clickhouse: raise OperationNotDefinedError if operation is not supported (71e2570)</li> <li>clickhouse: register in-memory tables in pyarrow-related calls (09a045c)</li> <li>clickhouse: use a bool type supported by <code>clickhouse_driver</code> (ab8f064)</li> <li>clickhouse: workaround sqlglot's insistence on uppercasing (6151f37)</li> <li>compiler: generate aliases in a less clever way (04a4aa5)</li> <li>datafusion: support sum aggregation on bool column (9421400)</li> <li>deps: bump duckdb to 0.7.0 (38d2276)</li> <li>deps: bump snowflake-connector-python upper bound (b368b04)</li> <li>deps: ensure that pyspark depends on sqlalchemy (60c7382)</li> <li>deps: update dependency pyarrow to v11 (2af5d8d)</li> <li>deps: update dependency sqlglot to v11 (e581e2f)</li> <li>don't expose backend methods on <code>ibis.&lt;backend&gt;</code> directly (5a16431)</li> <li>druid: remove invalid operations (19f214c)</li> <li>duckdb: add <code>null</code> to duckdb datatype parser (07d2a86)</li> <li>duckdb: ensure that <code>temp_directory</code> exists (00ba6cb)</li> <li>duckdb: explicitly set timezone to UTC on connection (6ae4a06)</li> <li>duckdb: fix blob type in literal (f66e8a1)</li> <li>duckdb: fix memtable <code>to_pyarrow</code>/<code>to_pyarrow_batches</code> (0e8b066)</li> <li>duckdb: in-memory objects registered with duckdb show up in list_tables (7772f79)</li> <li>duckdb: quote identifiers if necessary in <code>struct_pack</code> (6e598cc)</li> <li>duckdb: support casting to unsigned integer types (066c158)</li> <li>duckdb: treat <code>g</code> <code>re_replace</code> flag as literal text (aa3c31c)</li> <li>duckdb: workaround an ownership bug at the interaction of duckdb, pandas and pyarrow (2819cff)</li> <li>duckdb: workaround duckdb bug that prevents multiple substitutions (0e09220)</li> <li>imports: remove top-level import of sqlalchemy from base backend (b13cf25)</li> <li>io: add <code>read_parquet</code> and <code>read_csv</code> to base backend mixin (ce80d36), closes #5420</li> <li>ir: incorrect predicate pushdown (9a9204f)</li> <li>ir: make <code>find_subqueries</code> return in topological order (3587910)</li> <li>ir: properly raise error if literal cannot be coerced to a datatype (e16b91f)</li> <li>ir: reorder the right schema of set operations to align with the left schema (58e60ae)</li> <li>ir: use <code>rlz.map_to()</code> rule instead of <code>isin</code> to normalize temporal units (a1c46a2)</li> <li>ir: use static connection pooling to prevent dropping temporary state (6d2ae26)</li> <li>mssql: set sqlglot to tsql (1044573)</li> <li>mysql: remove invalid operations (8f34a2b)</li> <li>pandas/dask: handle non numpy scalar results in <code>wrap_case_result</code> (a3b82f7)</li> <li>pandas: don't try to dispatch on arrow dtype if not available (d22ae7b)</li> <li>pandas: handle casting to arrays with None elements (382b90f)</li> <li>pandas: handle NAs in array conversion (06bd15d)</li> <li>polars: back compat for <code>concat_str</code> separator argument (ced5a61)</li> <li>polars: back compat for the <code>reverse</code>/<code>descending</code> argument (f067d81)</li> <li>polars: polars execute respect limit kwargs (d962faf)</li> <li>polars: properly infer polars categorical dtype (5a4707a)</li> <li>polars: use metric name in aggregate output to dedupe columns (234d8c1)</li> <li>pyspark: fix incorrect <code>ops.EndsWith</code> translation rule (4c0a5a2)</li> <li>pyspark: fix isnan and isinf to work on bool (8dc623a)</li> <li>snowflake: allow loose casting of objects and arrays (1cf8df0)</li> <li>snowflake: ensure that memtables are translated correctly (b361e07)</li> <li>snowflake: ensure that null comparisons are correct (9b83699)</li> <li>snowflake: ensure that quoting matches snowflake behavior, not sqlalchemy (b6b67f9)</li> <li>snowflake: ensure that we do not try to use a None schema or database (03e0265)</li> <li>snowflake: handle the case where pyarrow isn't installed (b624fa3)</li> <li>snowflake: make <code>array_agg</code> preserve nulls (24b95bf)</li> <li>snowflake: quote column names on construction of <code>sa.Column</code> (af4db5c)</li> <li>snowflake: remove broken pyarrow fetch support (c440adb)</li> <li>snowflake: return <code>NULL</code> when trying to call map functions on non-object JSON (d85fb28)</li> <li>snowflake: use <code>_flatten</code> to avoid overriding unrelated function in other backends (8c31594)</li> <li>sqlalchemy: ensure that isin contains full column expression (9018eb6)</li> <li>sqlalchemy: get builtin dialects working; mysql/mssql/postgres/sqlite (d2356bc)</li> <li>sqlalchemy: make <code>strip</code> family of functions behave like Python (dd0a04c)</li> <li>sqlalchemy: reflect most recent schema when view is replaced (62c8dea)</li> <li>sqlalchemy: use <code>sa.true</code> instead of Python literal (8423eba)</li> <li>sqlalchemy: use indexed group by key references everywhere possible (9f1ddd8)</li> <li>sql: ensure that set operations generate valid sql in the presence of additional constructs such as sort keys (3e2c364)</li> <li>sqlite: explicite disallow array in literal (de73b37)</li> <li>sqlite: fix random scalar range (26d0dde)</li> <li>support negative string indices (f84a54d)</li> <li>trino: workaround broken dialect (b502faf)</li> <li>types: fix argument types of Table.order_by() (6ed3a97)</li> <li>util: make convert_unit work with python types (cb3a90c)</li> <li>ux: give the <code>value_counts</code> aggregate column a better name (abab1d7)</li> <li>ux: make string range selectors inclusive (7071669)</li> <li>ux: make top level set operations work (f5976b2)</li> </ul>"},{"location":"release_notes/#performance","title":"Performance","text":"<ul> <li>duckdb: faster <code>to_parquet</code>/<code>to_csv</code> implementations (6071bb5)</li> <li> <p>fix duckdb insert-from-dataframe performance (cd27b99)</p> </li> <li> <p>deps: bump minimum required version of parsy (22020cb)</p> </li> <li>remove spark alias to pyspark and associated cruft (4b286bd)</li> </ul>"},{"location":"release_notes/#refactors","title":"Refactors","text":"<ul> <li>analysis: slightly simplify <code>find_subqueries()</code> (ab3712f)</li> <li>backend: normalize exceptions (065b66d)</li> <li>clickhouse: clean up parsing rules (6731772)</li> <li>common: move <code>frozendict</code> and <code>DotDict</code> to <code>ibis.common.collections</code> (4451375)</li> <li>common: move the <code>geospatial</code> module to the base SQL backend (3e7bfa3)</li> <li>dask: remove unneeded create_table() (86885a6)</li> <li>datatype: clean up parsing rules (c15fb5f)</li> <li>datatype: remove <code>Category</code> type and related APIs (bb0ee78)</li> <li>datatype: remove <code>StructType.pairs</code> property in favor of identical <code>fields</code> attribute (6668122)</li> <li>datatypes: move sqlalchemy datatypes to specfic backend (d7b49eb)</li> <li>datatypes: remove <code>String</code> parent type from <code>JSON</code> type (34f3898)</li> <li>datatype: use a dictionary to store <code>StructType</code> fields rather than <code>names</code> and <code>types</code> tuples (84455ac)</li> <li>datatype: use lazy dispatch when inferring pandas Timedelta objects (e5280ea)</li> <li>drop <code>limit</code> kwarg from <code>to_parquet</code>/<code>to_csv</code> (a54460c)</li> <li>duckdb: clean up parsing rules (30da8f9)</li> <li>duckdb: handle parsing timestamp scale (16c1443)</li> <li>duckdb: remove unused <code>list&lt;...&gt;</code> parsing rule (f040b86)</li> <li>duckdb: use a proper sqlalchemy construct for structs and reduce casting (8daa4a1)</li> <li>ir/api: introduce window frame operation and revamp the window API (2bc5e5e)</li> <li>ir/backends: remove various deprecated functions and methods (a8d3007)</li> <li>ir: reorganize the <code>scope</code> and <code>timecontext</code> utilities (80bd494)</li> <li>ir: update <code>ArrayMap</code> to use the new <code>callable_with</code> validation rule (560474e)</li> <li>move pretty repr tests back to their own file (4a75988)</li> <li>nix: clean up marker argument construction (12eb916)</li> <li>postgres: clean up datatype parsing (1f61661)</li> <li>postgres: clean up literal arrays (21b122d)</li> <li>pyspark: remove another private function (c5081cf)</li> <li>remove unnecessary top-level rich console (8083a6b)</li> <li>rules: remove unused <code>non_negative_integer</code> and <code>pair</code> rules (e00920a)</li> <li>schema: remove deprecated <code>Schema.from_dict()</code>, <code>.delete()</code> and <code>.append()</code> methods (8912b24)</li> <li>snowflake: remove the need for <code>parsy</code> (c53403a)</li> <li>sqlalchemy: set session parameters once per connection (ed4b476)</li> <li>sqlalchemy: use backend-specific startswith/endswith implementations (6101de2)</li> <li>test_sqlalchemy.py: move to snapshot testing (96998f0)</li> <li>tests: reorganize <code>rules</code> test file to the <code>ibis.expr</code> subpackage (47f0909)</li> <li>tests: reorganize <code>schema</code> test file to the <code>ibis.expr</code> subpackage (40033e1)</li> <li>tests: reorganize datatype test files to the datatypes subpackage (16199c6)</li> <li>trino: clean up datatype parsing (84c0e35)</li> <li>ux: return expression from <code>Table.info</code> (71cc0e0)</li> </ul>"},{"location":"release_notes/#deprecations","title":"Deprecations","text":"<ul> <li>api: deprecate <code>summary</code> API (e449c07)</li> <li>api: mark <code>ibis.sequence()</code> for removal (3589f80)</li> </ul>"},{"location":"release_notes/#documentation","title":"Documentation","text":"<ul> <li>add a bunch of string expression examples (18d3112)</li> <li>add Apache Druid to backend matrix (764d9c3)</li> <li>add CNAME file to mkdocs source (6d19111)</li> <li>add druid to the backends index docs page (ad0b6a3)</li> <li>add missing DataFusion entry to the backends in the README (8ce025a)</li> <li>add redirects for common old pages (c9087f2)</li> <li>api: document deferred API and its pitfalls (8493604)</li> <li>api: improve <code>collect</code> method API documentation (b4fcef1)</li> <li>array expression examples (6812c17)</li> <li>backends: document default backend configuration (6d917d3)</li> <li>backends: link to configuration from the backends list (144044d)</li> <li>blob: blog on ibis + substrait + duckdb (5dc7a0a)</li> <li>blog: adds examples sneak peek blog + assets folder (fcbb3d5)</li> <li>blog: adds to file sneak peek blog (128194f)</li> <li>blog: specify parsy 2.0 in substrait blog article (c264477)</li> <li>bump query engine count in README and use project-preferred names (11169f7)</li> <li>don't sort backends by coverage percentage by default (68f73b1)</li> <li>drop docs versioning (d7140e7)</li> <li>duckdb: fix broken docstring examples (51084ad)</li> <li>enable light/dark mode toggle in docs (b9e812a)</li> <li>fill out table API with working examples (16fc8be)</li> <li>fix notebook logging example (04b75ef)</li> <li>how-to: fix sessionize.md to use ibis.read_parquet (ff9cbf7)</li> <li>improve Expr.substitute() docstring (b954edd)</li> <li>improve/update pandas walkthrough (80b05d8)</li> <li>io: doc/ux improvements for read_parquet and friends (2541556), closes #5420</li> <li>io: update README.md to recommend installing duckdb as default backend (0a72ec0), closes #5423 #5420</li> <li>move tutorial from docs to external ibis-examples repo (11b0237)</li> <li>parquet: add docstring examples for to_parquet incl. partitioning (8040164)</li> <li>point to <code>ibis-examples</code> repo in the README (1205636)</li> <li>README.md: clean up readme, fix typos, alter the example (383a3d3)</li> <li>remove duplicate \"or\" (b6ef3cc)</li> <li>remove duplicate spark backend in install docs (5954618)</li> <li>render <code>__dunder__</code> method API documentation (b532c63)</li> <li>rerender ci-analysis notebook with new table header colors (50507b6)</li> <li>streamlit: fix url for support matrix (594199b)</li> <li>tutorial: remove impala from sql tutorial (7627c13)</li> <li>use teal for primary &amp; accent colors (24be961)</li> </ul>"},{"location":"release_notes/#410-2023-01-25","title":"4.1.0 (2023-01-25)","text":""},{"location":"release_notes/#features_1","title":"Features","text":"<ul> <li>add <code>ibis.get_backend</code> function (2d27df8)</li> <li>add py.typed to allow mypy to type check packages that use ibis (765d42e)</li> <li>api: add <code>ibis.set_backend</code> function (e7fabaf)</li> <li>api: add selectors for easier selection of columns (306bc88)</li> <li>bigquery: add JS UDF support (e74328b)</li> <li>bigquery: add SQL UDF support (db24173)</li> <li>bigquery: add to_pyarrow method (30157c5)</li> <li>bigquery: implement bitwise operations (55b69b1)</li> <li>bigquery: implement ops.Typeof (b219919)</li> <li>bigquery: implement ops.ZeroIfNull (f4c5607)</li> <li>bigquery: implement struct literal (c5f2a1d)</li> <li>clickhouse: properly support native boolean types (31cc7ba)</li> <li>common: add support for annotating with coercible types (ae4a415)</li> <li>common: make frozendict truly immutable (1c25213)</li> <li>common: support annotations with typing.Literal (6f89f0b)</li> <li>common: support generic mapping and sequence type annotations (ddc6603)</li> <li>dask: support <code>connect()</code> with no arguments (67eed42)</li> <li>datatype: add optional timestamp scale parameter (a38115a)</li> <li>datatypes: add <code>as_struct</code> method to convert schemas to structs (64be7b1)</li> <li>duckdb: add <code>read_json</code> function for consuming newline-delimited JSON files (65e65c1)</li> <li>mssql: add a bunch of missing types (c698d35)</li> <li>mssql: implement inference for <code>DATETIME2</code> and <code>DATETIMEOFFSET</code> (aa9f151)</li> <li>nicer repr for Backend.tables (0d319ca)</li> <li>pandas: support <code>connect()</code> with no arguments (78cbbdd)</li> <li>polars: allow ibis.polars.connect() to function without any arguments (d653a07)</li> <li>polars: handle casting to scaled timestamps (099d1ec)</li> <li>postgres: add <code>Map(string, string)</code> support via the built-in <code>HSTORE</code> extension (f968f8f)</li> <li>pyarrow: support conversion to pyarrow map and struct types (54a4557)</li> <li>snowflake: add more array operations (8d8bb70)</li> <li>snowflake: add more map operations (7ae6e25)</li> <li>snowflake: any/all/notany/notall reductions (ba1af5e)</li> <li>snowflake: bitwise reductions (5aba997)</li> <li>snowflake: date from ymd (035f856)</li> <li>snowflake: fix array slicing (bd7af2a)</li> <li>snowflake: implement <code>ArrayCollect</code> (c425f68)</li> <li>snowflake: implement <code>NthValue</code> (0dca57c)</li> <li>snowflake: implement <code>ops.Arbitrary</code> (45f4f05)</li> <li>snowflake: implement <code>ops.StructColumn</code> (41698ed)</li> <li>snowflake: implement <code>StringSplit</code> (e6acc09)</li> <li>snowflake: implement <code>StructField</code> and struct literals (286a5c3)</li> <li>snowflake: implement <code>TimestampFromUNIX</code> (314637d)</li> <li>snowflake: implement <code>TimestampFromYMDHMS</code> (1eba8be)</li> <li>snowflake: implement <code>typeof</code> operation (029499c)</li> <li>snowflake: implement exists/not exists (7c8363b)</li> <li>snowflake: implement extract millisecond (3292e91)</li> <li>snowflake: make literal maps and params work (dd759d3)</li> <li>snowflake: regex extract, search and replace (9c82179)</li> <li>snowflake: string to timestamp (095ded6)</li> <li>sqlite: implement <code>_get_schema_using_query</code> in SQLite backend (7ff84c8)</li> <li>trino: compile timestamp types with scale (67683d3)</li> <li>trino: enable <code>ops.ExistsSubquery</code> and <code>ops.NotExistsSubquery</code> (9b9b315)</li> <li>trino: map parameters (53bd910)</li> <li>ux: improve error message when column is not found (b527506)</li> </ul>"},{"location":"release_notes/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>backend: read the default backend setting in <code>_default_backend</code> (11252af)</li> <li>bigquery: move connection logic to do_connect (42f2106)</li> <li>bigquery: remove invalid operations from registry (911a080)</li> <li>bigquery: resolve deprecation warnings for <code>StructType</code> and <code>Schema</code> (c9e7078)</li> <li>clickhouse: fix position call (702de5d)</li> <li>correctly visualize array type (26b0b3f)</li> <li>deps: make sure pyarrow is not an implicit dependency (10373f4)</li> <li>duckdb: make <code>read_csv</code> on URLs work (9e61816)</li> <li>duckdb: only try to load extensions when necessary for csv (c77bde7)</li> <li>duckdb: remove invalid operations from registry (ba2ec59)</li> <li>fallback to default backend with <code>to_pyarrow</code>/<code>to_pyarrow_batches</code> (a1a6902)</li> <li>impala: remove broken alias elision (32b120f)</li> <li>ir: error for <code>order_by</code> on nonexistent column (57b1dd8)</li> <li>ir: ops.Where output shape should consider all arguments (6f87064)</li> <li>mssql: infer bit as boolean everywhere (24f9d7c)</li> <li>mssql: pull nullability from column information (490f8b4)</li> <li>mysql: fix mysql query schema inference (12f6438)</li> <li>polars: remove non-working Binary and Decimal literal inference (0482d15)</li> <li>postgres: use permanent views to avoid connection pool defeat (49a4991)</li> <li>pyspark: fix substring constant translation (40d2072)</li> <li>set ops: raise if no tables passed to set operations (bf4bdde)</li> <li>snowflake: bring back bitwise operations (260facd)</li> <li>snowflake: don't always insert a cast (ee8817b)</li> <li>snowflake: implement working <code>TimestampNow</code> (42d95b0)</li> <li>snowflake: make sqlalchemy 2.0 compatible (8071255)</li> <li>snowflake: re-enable <code>ops.TableArrayView</code> (a1ad2b7)</li> <li>snowflake: remove invalid operations from registry (2831559)</li> <li>sql: add <code>typeof</code> test and bring back implementations (7dc5356)</li> <li>sqlalchemy: 2.0 compatibility (837a736)</li> <li>sqlalchemy: fix view creation with select stmts that have bind parameters (d760e69)</li> <li>sqlalchemy: handle correlated exists sanely (efa42bd)</li> <li>sqlalchemy: handle generic geography/geometry by name instead of geotype (23c35e1)</li> <li>sqlalchemy: use <code>exec_driver_sql</code> in view teardown (2599c9b)</li> <li>sqlalchemy: use the backend's compiler instead of <code>AlchemyCompiler</code> (9f4ff54)</li> <li>sql: fix broken call to <code>ibis.map</code> (045edc7)</li> <li>sqlite: interpolate <code>pathlib.Path</code> correctly in <code>attach</code> (0415bd3)</li> <li>trino: ensure connecting works with trino 0.321 (07cee38)</li> <li>trino: remove invalid operations from registry (665265c)</li> <li>ux: remove extra trailing newline in expression repr (ee6d58a)</li> </ul>"},{"location":"release_notes/#documentation_1","title":"Documentation","text":"<ul> <li>add BigQuery backend docs (09d8995)</li> <li>add streamlit app for showing the backend operation matrix (3228f64)</li> <li>allow deselecting geospatial ops in backend support matrix (012da8c)</li> <li>api: document more public expression APIs (337018f)</li> <li>backend-info: prevent app from trying install duckdb extensions (3d94082)</li> <li>clean up gen_matrix.py after adding streamlit app (deb80f2)</li> <li>duckdb: add <code>to_pyarrow_batches</code> documentation (ec1ffce)</li> <li>embed streamlit operation matrix app to docs (469a50d)</li> <li>make firefox render the proper iframe height (ff1d4dc)</li> <li>publish raw data for operation matrix (62e68da)</li> <li>re-order when to download test data (8ce8c16)</li> <li>release: update breaking changes in the release notes for 4.0.0 (4e91401)</li> <li>remove trailing parenthesis (4294397)</li> <li>update ibis-version-4.0.0-release.md (f6701df)</li> <li>update links to contributing guides (da615e4)</li> </ul>"},{"location":"release_notes/#refactors_1","title":"Refactors","text":"<ul> <li>bigquery: explicite disallow INT64 in JS UDF (fb33bf9)</li> <li>datatype: add custom sqlalchemy nested types for backend differentiation (dec70f5)</li> <li>datatype: introduce to_sqla_type dispatching on dialect (a8bbc00)</li> <li>datatypes: remove Geography and Geometry types in favor of GeoSpatial (d44978c)</li> <li>datatype: use a mapping to store <code>StructType</code> fields rather than <code>names</code> and <code>types</code> tuples (ff34c7b)</li> <li>dtypes: expose nbytes property for integer and floating point datatypes (ccf80fd)</li> <li>duckdb: remove <code>.raw_sql</code> call (abc939e)</li> <li>duckdb: use sqlalchemy-views to reduce string hacking (c162750)</li> <li>ir: remove UnnamedMarker (dd352b1)</li> <li>postgres: use a bindparam for metadata queries (b6b4669)</li> <li>remove empty unused file (9d63fd6)</li> <li>schema: use a mapping to store <code>Schema</code> fields rather than <code>names</code> and <code>types</code> tuples (318179a)</li> <li>simplify <code>_find_backend</code> implementation (60f1a1b)</li> <li>snowflake: remove unnecessary <code>parse_json</code> call in <code>ops.StructField</code> impl (9e80231)</li> <li>snowflake: remove unnecessary casting (271554c)</li> <li>snowflake: use <code>unary</code> instead of <code>fixed_arity(..., 1)</code> (4a1c7c9)</li> <li>sqlalchemy: clean up quoting implementation (506ce01)</li> <li>sqlalchemy: generalize handling of failed type inference (b0f4e4c)</li> <li>sqlalchemy: move <code>_get_schema_using_query</code> to base class (296cd7d)</li> <li>sqlalchemy: remove the need for deferred columns (e4011aa)</li> <li>sqlalchemy: remove use of deprecated <code>isnot</code> (4ec53a4)</li> <li>sqlalchemy: use <code>exec_driver_sql</code> everywhere (e8f96b6)</li> <li>sql: finally remove <code>_CorrelatedRefCheck</code> (f49e429)</li> </ul>"},{"location":"release_notes/#deprecations_1","title":"Deprecations","text":"<ul> <li>api: deprecate <code>.to_projection</code> in favor of <code>.as_table</code> (7706a86)</li> <li>api: deprecate <code>get_column</code>/<code>s</code> in favor of <code>__getitem__</code>/<code>__getattr__</code> syntax (e6372e2)</li> <li>ir: schedule DatabaseTable.change_name for removal (e4bae26)</li> <li>schema: schedule <code>Schema.delete()</code> and <code>Schema.append()</code> for removal (45ac9a9)</li> </ul>"},{"location":"release_notes/#400-2023-01-09","title":"4.0.0 (2023-01-09)","text":""},{"location":"release_notes/#breaking-changes_1","title":"\u26a0 BREAKING CHANGES","text":"<ul> <li>functions, methods and classes marked as deprecated are removed now</li> <li>ir: replace <code>HLLCardinality</code> with <code>ApproxCountDistinct</code> and <code>CMSMedian</code> with <code>ApproxMedian</code> operations.</li> <li>backends: the datatype of returned execution results now more closely matches that of the ibis expression's type. Downstream code may need to be adjusted.</li> <li>ir: the <code>JSONB</code> type is replaced by the <code>JSON</code> type.</li> <li>dev-deps: expression types have been removed from <code>ibis.expr.api</code>. Use <code>import ibis.expr.types as ir</code> to access these types.</li> <li>common: removed <code>@immutable_property</code> decorator, use <code>@attribute.default</code> instead</li> <li>timestamps: the <code>timezone</code> argument to <code>to_timestamp</code> is gone. This was only supported in the BigQuery backend. Append <code>%Z</code> to the format string and the desired time zone to the input column if necessary.</li> <li>deps: ibis now supports at minimum duckdb 0.3.3. Please upgrade your duckdb install as needed.</li> <li>api: previously <code>ibis.connect</code> would return a <code>Table</code> object when calling <code>connect</code> on a parquet/csv file. This now returns a backend containing a single table created from that file. When possible users may use <code>ibis.read</code> instead to read files into ibis tables.</li> <li>api: <code>histogram()</code>'s <code>closed</code> argument no longer exists because it never had any effect. Remove it from your <code>histogram</code> method calls.</li> <li>pandas/dask: the Pandas and Dask backends now interpret casting ints to/from timestamps as seconds since the unix epoch, matching other backends.</li> <li>datafusion: <code>register_csv</code> and <code>register_parquet</code> are removed. Pass filename to <code>register</code> method instead.</li> <li>ir: <code>ops.NodeList</code> and <code>ir.List</code> are removed. Use tuples to represent sequence of expressions instead.</li> <li>api: <code>re_extract</code> now follows <code>re.match</code> behavior. In particular, the <code>0</code>th group is now the entire string if there's a match, otherwise the groups are 1-based.</li> <li>datatypes: enums are now strings. Likely no action needed since no functionality existed.</li> <li>ir: Replace <code>t[t.x.topk(...)]</code> with <code>t.semi_join(t.x.topk(...), \"x\")</code>.</li> <li>ir: <code>ir.Analytic.type()</code> and <code>ir.TopK.type()</code> methods are removed.</li> <li>api: the default limit for table/column expressions is now <code>None</code> (meaning no limit).</li> <li>ir: join changes: previously all column names that collided between <code>left</code> and <code>right</code> tables were renamed with an appended suffix. Now for the case of inner joins with only equality predicates, colliding columns that are known to be equal due to the join predicates aren't renamed.</li> <li>impala: kerberos support is no longer installed by default for the <code>impala</code> backend. To add support you'll need to install the <code>kerberos</code> package separately.</li> <li>ir: <code>ops.DeferredSortKey</code> is removed. Use <code>ops.SortKey</code> directly instead.</li> <li>ir: <code>ibis.common.grounds.Annotable</code> is mutable by default now</li> <li>ir: <code>node.has_resolved_name()</code> is removed, use <code>isinstance(node, ops.Named)</code> instead; <code>node.resolve_name()</code> is removed use <code>node.name</code> instead</li> <li>ir: removed <code>ops.Node.flat_args()</code>, directly use <code>node.args</code> property instead</li> <li>ir: removed <code>ops.Node.inputs</code> property, use the multipledispatched <code>get_node_arguments()</code> function in the pandas backend</li> <li>ir: <code>Node.blocks()</code> method has been removed.</li> <li>ir: <code>HasSchema</code> mixin class is no longer available, directly subclass <code>ops.TableNode</code> and implement schema property instead</li> <li>ir: Removed <code>Node.output_type</code> property in favor of abstractmethod <code>Node.to_expr()</code> which now must be explicitly implemented</li> <li>ir: <code>Expr(Op(Expr(Op(Expr(Op)))))</code> is now represented as <code>Expr(Op(Op(Op)))</code>, so code using ibis internals must be migrated</li> <li>pandas: Use timezone conversion functions to compute the original machine localized value</li> <li>common: use <code>ibis.common.validators.{Patameter, Signature}</code> instead</li> <li>ir: <code>ibis.expr.lineage.lineage()</code> is now removed</li> <li>ir: removed <code>ir.DestructValue</code>, <code>ir.DestructScalar</code> and <code>ir.DestructColumn</code>, use <code>table.unpack()</code> instead</li> <li>ir: removed <code>Node.root_tables()</code> method, use <code>ibis.expr.analysis.find_immediate_parent_tables()</code> instead</li> <li>impala: use other methods for pinging the database</li> </ul>"},{"location":"release_notes/#features_2","title":"Features","text":"<ul> <li>add experimental decorator (791335f)</li> <li>add to_pyarrow and to_pyarrow_batches (a059cf9)</li> <li>add unbind method to expressions (4b91b0b), closes #4536</li> <li>add way to specify sqlglot dialect on backend (f1c0608)</li> <li>alchemy: implement json getitem for sqlalchemy backends (7384087)</li> <li>api: add <code>agg</code> alias for <code>aggregate</code> (907583f)</li> <li>api: add <code>agg</code> alias to <code>group_by</code> (6b6367c)</li> <li>api: add <code>ibis.read</code> top level API function (e67132c)</li> <li>api: add JSON <code>__getitem__</code> operation (3e2efb4)</li> <li>api: implement <code>__array__</code> (1402347)</li> <li>api: make <code>drop</code> variadic (1d69702)</li> <li>api: return object from <code>to_sql</code> to support notebook syntax highlighting (87c9833)</li> <li>api: use <code>rich</code> for interactive <code>__repr__</code> (04758b8)</li> <li>backend: make <code>ArrayCollect</code> filterable (1e1a5cf)</li> <li>backends/mssql: add backend support for Microsoft Sql Server (fc39323)</li> <li>bigquery: add ops.DateFromYMD, ops.TimeFromHMS, ops.TimestampFromYMDHMS (a4a7936)</li> <li>bigquery: add ops.ExtractDayOfYear (30c547a)</li> <li>bigquery: add support for correlation (4df9f8b)</li> <li>bigquery: implement <code>argmin</code> and <code>argmax</code> (40c5f0d)</li> <li>bigquery: implement <code>pi</code> and <code>e</code> (b91370a)</li> <li>bigquery: implement array repeat (09d1e2f)</li> <li>bigquery: implement JSON getitem functionality (9c0e775)</li> <li>bigquery: implement ops.ArraySlice (49414ef)</li> <li>bigquery: implement ops.Capitalize (5757bb0)</li> <li>bigquery: implement ops.Clip (5495d6d)</li> <li>bigquery: implement ops.Degrees, ops.Radians (5119b93)</li> <li>bigquery: implement ops.ExtractWeekOfYear (477d287)</li> <li>bigquery: implement ops.RandomScalar (5dc8482)</li> <li>bigquery: implement ops.StructColumn, ops.ArrayColumn (2bbf73c)</li> <li>bigquery: implement ops.Translate (77a4b3e)</li> <li>bigquery: implementt ops.NthValue (b43ba28)</li> <li>bigquery: move bigquery backend back into the main repo (cd5e881)</li> <li>clickhouse: handle more options in <code>parse_url</code> implementation (874c5c0)</li> <li>clickhouse: implement <code>INTERSECT ALL</code>/<code>EXCEPT ALL</code> (f65fbc3)</li> <li>clickhouse: implement quantile/multiquantile (96d7d1b)</li> <li>common: support function annotations with both typehints and rules (7e23f3e)</li> <li>dask: implement <code>mode</code> aggregation (017f07a)</li> <li>dask: implement json getitem (381d805)</li> <li>datafusion: convert column expressions to pyarrow (0a888de)</li> <li>datafusion: enable <code>topk</code> (d44903f)</li> <li>datafusion: implement <code>Limit</code> (1ddc876)</li> <li>datafusion: implement <code>ops.StringConcat</code> (6bb5b4f)</li> <li>decompile: support rendering ibis expression as python code (7eebc67)</li> <li>deps: support shapely 2.0 (68dff10)</li> <li>display qualified named in deprecation warnings (a6e2a49)</li> <li>docs: first draft of Ibis for pandas users (7f7c9b5)</li> <li>duckdb: enable registration of parquet files from s3 (fced465)</li> <li>duckdb: implement <code>mode</code> aggregation (36fd152)</li> <li>duckdb: implement <code>to_timestamp</code> (26ca1e4)</li> <li>duckdb: implement quantile/multiquantile (fac9705)</li> <li>duckdb: overwrite views when calling <code>register</code> (ae07438)</li> <li>duckdb: pass through kwargs to file loaders (14fa2aa)</li> <li>duckdb: support out of core execution for in-memory connections (a4d4ba2)</li> <li>duckdb: support registering external postgres tables with duckdb (8633e6b)</li> <li>expr: split ParseURL operation into multiple URL extract operations (1f0fcea)</li> <li>impala: implement <code>strftime</code> (d3ede8d)</li> <li>impala: support date literals (cd334c4)</li> <li>insert: add support for list+dict to sqlalchemy backends (15d399e)</li> <li>ir/pandas/dask/clickhouse: revamp Map type support (62b6f2d)</li> <li>ir: add <code>is_*</code> methods to <code>DataType</code>s (79f5c2b)</li> <li>ir: prototype for parsing SQL into an ibis expression (1301183)</li> <li>ir: support python 3.10 pattern matching on Annotable nodes (eca93eb)</li> <li>mssql: add window function support (ef1be45)</li> <li>mssql: detect schema from SQL (ff79928)</li> <li>mssql: extract quarter (7d04266)</li> <li>mssql: implement ops.DayOfWeekIndex (4125593)</li> <li>mssql: implement ops.ExtractDayOfYear (ae026d5)</li> <li>mssql: implement ops.ExtractEpochSeconds (4f49b5b)</li> <li>mssql: implement ops.ExtractWeekOfYear (f1394bc)</li> <li>mssql: implement ops.Ln, ops.Log, ops.Log2, ops.Log10 (f8ee1d8)</li> <li>mssql: implement ops.RandomScalar (4149450)</li> <li>mssql: implement ops.TimestampTruncate, ops.DateTruncate (738e496)</li> <li>mssql: implementt ops.DateFromYMD, ops.TimestampFromYMDHMS, ops.TimeFromHMS (e84f2ce)</li> <li>open <code>*.db</code> files with sqlite in <code>ibis.connect</code> (37baf05)</li> <li>pandas: implement <code>mode</code> aggregation (fc023b5)</li> <li>pandas: implement <code>RegexReplace</code> for <code>str</code> (23713cc)</li> <li>pandas: implement json getitem (8fa1190)</li> <li>pandas: implement quantile/multiquantile (cd4dcaa)</li> <li>pandas: support <code>histogram</code> API (5bfc0fe)</li> <li>polars: enable <code>topk</code> (8bfb16a)</li> <li>polars: implement <code>mode</code> aggregation (7982ba2)</li> <li>polars: initial support for polars backend (afecb0a)</li> <li>postgres: implement <code>mode</code> aggregation (b2f1c2d)</li> <li>postgres: implement quantile and multiquantile (82ed4f5)</li> <li>postgres: prettify array literals (cdc60d5)</li> <li>pyspark: add support for struct operations (ce05987)</li> <li>pyspark: enable <code>topk</code> (0f748e0)</li> <li>pyspark: implement <code>pi</code> and <code>e</code> (fea81c6)</li> <li>pyspark: implement json getitem (9bfb748)</li> <li>pyspark: implement quantile and multiquantile (743f411)</li> <li>pyspark: support <code>histogram</code> API (8f4808c)</li> <li>snowflake: enable day-of-week column expression (6fd9c33)</li> <li>snowflake: handle date and timestamp literals (ec2392d)</li> <li>snowflake: implement <code>mode</code> aggregation (f35915e)</li> <li>snowflake: implement <code>parse_url</code> (a9746e3)</li> <li>snowflake: implement <code>rowid</code> scalar (7e1425a)</li> <li>snowflake: implement <code>time</code> literal (068fc50)</li> <li>snowflake: implement scalar (cc07d91)</li> <li>snowflake: initial commit for snowflake backend (a8687dd)</li> <li>snowflake: support reductions in window functions via automatic ordering (0234e5c)</li> <li>sql: add ops.StringSQLILike (7dc4924)</li> <li>sqlalchemy: implement <code>ops.Where</code> using <code>IF</code>/<code>IFF</code> functions (4cc9c15)</li> <li>sqlalchemy: in-memory tables have name in generated SQL (01b4c60)</li> <li>sql: improve error message in fixed_arity helper (891a1ad)</li> <li>sqlite: add <code>type_map</code> arg to override type inference (1961bad)</li> <li>sqlite: fix impl for missing <code>pi</code> and <code>e</code> functions (24b6d2f)</li> <li>sqlite: support <code>con.sql</code> with explicit schema specified (7ca82f3)</li> <li>sqlite: support wider range of datetime formats (f65093a)</li> <li>support both <code>postgresql://</code> and <code>postgres://</code> in <code>ibis.connect</code> (2f7a7b4)</li> <li>support deferred predicates in join (b51a64b)</li> <li>support more operations with unsigned integers (9992953)</li> <li>support passing callable to relabel (0bceefd)</li> <li>support tab completion for getitem access of table columns (732dba4)</li> <li>support Table.fillna for SQL backends (26d4cac)</li> <li>trino: add <code>bit_xor</code> aggregation (830acf4)</li> <li>trino: add <code>EXTRACT</code>-based functionality (6549657)</li> <li>trino: add milisecond scale to *_trunc function (3065248)</li> <li>trino: add some basic aggregation ops (7ecf7ab)</li> <li>trino: extract milliseconds (09517a5)</li> <li>trino: implement <code>approx_median</code> (1cba8bd)</li> <li>trino: implement <code>parse_url</code> (2bc87fc)</li> <li>trino: implement <code>round</code>, <code>cot</code>, <code>pi</code>, and <code>e</code> (c0e8736)</li> <li>trino: implement arbitrary first support (0c7d3b3)</li> <li>trino: implement array collect support (dfeb600)</li> <li>trino: implement array column support (dadf9a8)</li> <li>trino: implement array concat (240c55d)</li> <li>trino: implement array index (c5f3a96)</li> <li>trino: implement array length support (2d7cc65)</li> <li>trino: implement array literal support (2182177)</li> <li>trino: implement array repeat (2ee3d10)</li> <li>trino: implement array slicing (643792e)</li> <li>trino: implement basic struct operations (cc3c937)</li> <li>trino: implement bitwise agg support (5288b35)</li> <li>trino: implement bitwise scalar/column ops (ac4876c)</li> <li>trino: implement default precision and scale (37f8a47)</li> <li>trino: implement group concat support (5c41439)</li> <li>trino: implement json getitem support (7c41566)</li> <li>trino: implement map operations (4efc5ce)</li> <li>trino: implement more generic and numeric ops (63b45c8)</li> <li>trino: implement ops.Capitalize (dff14fc)</li> <li>trino: implement ops.DateFromYMD (edd2994)</li> <li>trino: implement ops.DateTruncate, ops.TimestampTruncate (32f4862)</li> <li>trino: implement ops.DayOfWeekIndex, ops.DayOfWeekName (a316d6d)</li> <li>trino: implement ops.ExtractDayOfYear (b0a3465)</li> <li>trino: implement ops.ExtractEpochSeconds (10b82f1)</li> <li>trino: implement ops.ExtractWeekOfYear (cf719b8)</li> <li>trino: implement ops.Repeat (e9f6851)</li> <li>trino: implement ops.Strftime (a436823)</li> <li>trino: implement ops.StringAscii (93fd32d)</li> <li>trino: implement ops.StringContains (d5cb2ec)</li> <li>trino: implement ops.StringSplit (62d79a6)</li> <li>trino: implement ops.StringToTimestamp (b766f62)</li> <li>trino: implement ops.StrRight (691b39c)</li> <li>trino: implement ops.TimeFromHMS (e5cacc2)</li> <li>trino: implement ops.TimestampFromUNIX (ce5d726)</li> <li>trino: implement ops.TimestampFromYMDHMS (9fa7304)</li> <li>trino: implement ops.TimestampNow (c832e4c)</li> <li>trino: implement ops.Translate (410ae1e)</li> <li>trino: implement quantile/multiquantile (bc7fdab)</li> <li>trino: implement regex functions (9e493c5)</li> <li>trino: implement window function support (5b6cc45)</li> <li>trino: initial trino backend (c367865)</li> <li>trino: support string date scalar parameter (9092530)</li> <li>trino: use proper <code>approx_distinct</code> function (3766fff)</li> </ul>"},{"location":"release_notes/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li><code>ibis.connect</code> always returns a backend (2d5b155)</li> <li>allow inserting memtable with alchemy backends (c02fcc3)</li> <li>always display at least one column in the table repr (5ea9e5a)</li> <li>analysis: only lower sort keys that are in an agg's output (6bb4f66)</li> <li>api: allow arbitrary sort keys (a980b34)</li> <li>api: allow boolean scalars in predicate APIs (2a2636b)</li> <li>api: allow deferred instances as input to <code>ibis.desc</code> and <code>ibis.asc</code> (6861347)</li> <li>api: ensure that window functions are propagated (4fb1106)</li> <li>api: make <code>re_extract</code> conform to semantics of Python's <code>re.match</code> (5981227)</li> <li>auto-register csv and parquet with duckdb using <code>ibis.connect</code> (67c4f87)</li> <li>avoid renaming known equal columns for inner joins with equality predicates (5d4b0ed)</li> <li>backends: fix casting and execution result types in many backends (46c21dc)</li> <li>bigquery: don't try to parse database when name is already fully qualified (ae3c113)</li> <li>bigquery: fix integer to timestamp casting (f5bacad)</li> <li>bigquery: normalize W frequency in *_trunc (893cd49)</li> <li>catch <code>TypeError</code> instead of more specific error (6db19d8)</li> <li>change default limit to None (8d1526a)</li> <li>clarify and normalize behavior of <code>Table.rowid</code> (92b03d6)</li> <li>clickhouse: ensure that correlated subqueries' columns can be referenced (708d682)</li> <li>clickhouse: fix list_tables to use database name (edc3511)</li> <li>clickhouse: make <code>any</code>/<code>all</code> filterable and reduce code size (99b10e2)</li> <li>clickhouse: use clickhouse's dbapi (bd0da12)</li> <li>common: support copying variadic annotable instances (ee0d9ad)</li> <li>dask: make filterable reductions work (0f759fc)</li> <li>dask: raise TypeError with informative message in ibis.dask.connect (4e67f7a)</li> <li>define <code>to_pandas</code>/<code>to_pyarrow</code> on DataType/Schema classes directly (22f3b4d)</li> <li>deps: bound shapely to a version that doesn't segfault (be5a779)</li> <li>deps: update dependency datafusion to &gt;=0.6,&lt;0.8 (4c73870)</li> <li>deps: update dependency geopandas to &gt;=0.6,&lt;0.13 (58a32dc)</li> <li>deps: update dependency packaging to v22 (e0b6177)</li> <li>deps: update dependency rich to v13 (4f313dd)</li> <li>deps: update dependency sqlglot to v10 (db19d43)</li> <li>deps: update dependency sqlglot to v9 (cf330ac)</li> <li>docs: make sure data can be downloaded when building notebooks (fa7da17)</li> <li>don't fuse filters &amp; selections that contain window functions (d757069)</li> <li>drop snowflake support for RowID (dd378f1)</li> <li>duckdb: drop incorrect <code>translate</code> implementation (8690151)</li> <li>duckdb: fix bug in json getitem for duckdb (49ce739)</li> <li>duckdb: keep <code>ibis.now()</code> type semantics (eca4a2c)</li> <li>duckdb: make array repeat actually work (021f4de)</li> <li>duckdb: replace all in <code>re_replace</code> (c138f0f)</li> <li>duckdb: rereflect sqla table on re-registration (613b311), closes #4729</li> <li>duckdb: s3 priority (a2d03d1)</li> <li>duckdb: silence duckdb-engine warnings (359adc3)</li> <li>ensure numpy ops dont accidentally cast ibis types (a7ca6c8)</li> <li>exclude geospatial ops from pandas/dask/polars <code>has_operation</code> (6f1d265)</li> <li>fix <code>table.mutate</code> with deferred named expressions (5877d0b)</li> <li>fix bug when disabling <code>show_types</code> in interactive repr (2402506)</li> <li>fix expression repr for table -&gt; value operations (dbf92f5)</li> <li>handle dimensionality of empty outputs (3a88170)</li> <li>improve rich repr support (522db9c)</li> <li>ir: normalize <code>date</code> types (39056b5)</li> <li>ir: normalize timestamps to <code>datetime.datetime</code> values (157efde)</li> <li>make <code>col.day_of_week</code> not an expr (96e1580)</li> <li>mssql: fix integer to timestamp casting (9122eef)</li> <li>mssql: fix ops.TimeFromHMS (d2188e1)</li> <li>mssql: fix ops.TimestampFromUNIX (ec28add)</li> <li>mssql: fix round without argument (52a60ce)</li> <li>mssql: use double-dollar sign to prevent from interpolating a value (b82da5d)</li> <li>mysql: fix mysql <code>startswith</code>/<code>endswith</code> to be case sensitive (d7469cc)</li> <li>mysql: handle out of bounds timestamps and fix milliseconds calculation (1f7649a)</li> <li>mysql: upcast bool agg args (8c5f9a5)</li> <li>pandas/dask now cast int&lt;-&gt;timestamp as seconds since epoch (bbfe998)</li> <li>pandas: drop <code>RowID</code> implementation (05f5016)</li> <li>pandas: make quantile/multiquantile with filter work (6b5abd6)</li> <li>pandas: support <code>substr</code> with no <code>length</code> (b2c2922)</li> <li>pandas: use localized UTC time for <code>now</code> operation (f6d7327)</li> <li>pandas: use the correct context when aggregating over a window (e7fa5c0)</li> <li>polars: fix polars <code>startswith</code> to call the right method (9e6f397)</li> <li>polars: workaround passing <code>pl.Null</code> to the null type (fd9633b)</li> <li>postgres/duckdb: fix negative slicing by copying the trino impl (39e3962)</li> <li>postgres: fix array repeat to work with literals (3c46eb1)</li> <li>postgres: fix array_index operation (63ef892)</li> <li>postgres: make any/all translation rules use <code>reduction</code> helper (78bfd1d)</li> <li>pyspark: handle <code>datetime.datetime</code> literals (4f94abe)</li> <li>remove kerberos extra for impala dialect (6ed3e5f)</li> <li>repr: don't repeat value in repr for literals (974eeb6)</li> <li>repr: fix off by one in repr (322c8dc)</li> <li>s3: fix quoting and autonaming for s3 (ce09266)</li> <li>select: raise error on attempt to select no columns in projection (94ac10e)</li> <li>snowflake: fix extracting query parameter by (75af240)</li> <li>snowflake: fix failing snowflake url extraction functions (2eee50b)</li> <li>snowflake: fix snowflake list_databases (680cd24)</li> <li>snowflake: handle schema when getting table (f6fff5b)</li> <li>snowflake: snowflake now likes Tuesdays (1bf9d7c)</li> <li>sqlalchemy: allow passing pd.DataFrame to create (1a083f6)</li> <li>sqlalchemy: ensure that arbitrary expressions are valid sort keys (cb1a013)</li> <li>sql: avoid generating cartesian products yet again (fdc52a2)</li> <li>sqlite: fix sqlite <code>startswith</code>/<code>endswith</code> to be case sensitive (fd4a88d)</li> <li>standardize list_tables signature everywhere (abafe1b), closes #2877</li> <li>support <code>arbitrary</code> with no arguments (45156f5)</li> <li>support dtype in <code>__array__</code> methods (1294b76)</li> <li>test: ensure that file-based url tests don't expect data to exist (c2b635a)</li> <li>trino: fix integer to timestamp casting (49321a6)</li> <li>trino: make filterable any/all reductions work (992bd18)</li> <li>truncate columns in repr for wide tables (aadcba1)</li> <li>typo: in StringValue helpstr (b2e2093)</li> <li>ux: improve error messages for rlz.comparable failures (5ca41d2)</li> <li>ux: prevent infinite looping when formatting a floating column of all nans (b6afe98)</li> <li>visualize(label_edges=True) works for NodeList ops (a91ceae)</li> <li>visualize: dedup nodes and edges and add <code>verbose</code> argument for debugging (521e188)</li> <li>visualize: handle join predicates in visualize (d63cb57)</li> <li>window: allow window range tuples in preceding or following (77172b3)</li> </ul>"},{"location":"release_notes/#deprecations_2","title":"Deprecations","text":"<ul> <li>deprecate <code>Table.groupby</code> alias in favor of <code>Table.group_by</code> (39cea3b)</li> <li>deprecate <code>Table.sort_by</code> in favor of <code>Table.order_by</code> (7ac7103)</li> </ul>"},{"location":"release_notes/#performance_1","title":"Performance","text":"<ul> <li>add benchmark for known-slow table expression (e9617f0)</li> <li>expr: traverse nodes only once during compilation (69019ed)</li> <li>fix join performance by avoiding Projection construction (ed532bf)</li> <li>node: give <code>Node</code>s the default Python repr (eb26b11)</li> <li> <p>ux: remove pandas import overhead from <code>import ibis</code> (ea452fc)</p> </li> <li> <p>deps: bump duckdb lower bound (4539683)</p> </li> <li>dev-deps: replace flake8 et al with <code>ruff</code> and fix lints (9c1b282)</li> </ul>"},{"location":"release_notes/#refactors_2","title":"Refactors","text":"<ul> <li>add <code>lazy_singledispatch</code> utility (180ecff)</li> <li>add <code>rlz.lazy_instance_of</code> (4e30480)</li> <li>add <code>Temporal</code> base class for temporal data types (694eec4)</li> <li>api: add deprecated Node.op() #4519 (2b0826b)</li> <li>avoid roundtripping to expression for <code>IFF</code> (3068ae2)</li> <li>clean up <code>cot</code> implementations to have one less function call (0f304e5)</li> <li>clean up timezone support in ops.TimestampFromYMDHMS (2e183a9)</li> <li>cleanup str method docstrings (36bd36c)</li> <li>clickhouse: implement sqlglot-based compiler (5cc5d4b)</li> <li>clickhouse: simplify Quantile and MultiQuantile implementation (9e16e9e)</li> <li>common: allow traversal and substitution of tuple and dictionary arguments (60f4806)</li> <li>common: enforce slots definitions for Base subclasses (6c3df91)</li> <li>common: move Parameter and Signature to validators.py (da20537)</li> <li>common: reduce implementation complexity of annotations (27cee71)</li> <li>datafusion: align register API across backends (08046aa)</li> <li>datafusion: get name from expr (fea3e5b)</li> <li>datatypes: remove Enum (145e706)</li> <li>dev-deps: remove unnecessary <code>poetry2nix</code> overrides (5ed95bc)</li> <li>don't sort new columns in mutate (72ec96a)</li> <li>duckdb: use lambda to define backend operations (5d14de6)</li> <li>impala: move impala SQL tests to snapshots (927bf65)</li> <li>impala: replace custom pooling with sqlalchemy QueuePool (626cdca)</li> <li>ir: <code>ops.List</code> -&gt; <code>ops.NodeList</code> (6765bd2)</li> <li>ir: better encapsulate graph traversal logic, schema and datatype objects are not traversable anymore (1a07725)</li> <li>ir: generalize handling and traversal of node sequences (e8bcd0f)</li> <li>ir: make all value operations 'Named' for more consistent naming semantics (f1eb4d2)</li> <li>ir: move random() to api.py (e136f1b)</li> <li>ir: remove <code>ops.DeferredSortKey</code> (e629633)</li> <li>ir: remove <code>ops.TopKNode</code> and <code>ir.TopK</code> (d4dc544)</li> <li>ir: remove Analytic expression's unused type() method (1864bc1)</li> <li>ir: remove DecimalValue.precision(), DecimalValue.scale() method (be975bc)</li> <li>ir: remove DestructValue expressions (762d384)</li> <li>ir: remove duplicated literal creation code (7dfb56f)</li> <li>ir: remove intermediate expressions (c6fb0c0)</li> <li>ir: remove lin.lineage() since it's not used anywhere (120b1d7)</li> <li>ir: remove node.blocks() in favor of more explicit type handling (37d8ce4)</li> <li>ir: remove Node.inputs since it is an implementation detail of the pandas backend (6d2c49c)</li> <li>ir: remove node.root_tables() and unify parent table handling (fbb07c1)</li> <li>ir: remove ops.AggregateSelection in favor of an.simplify_aggregation (ecf6ed3)</li> <li>ir: remove ops.NodeList and ir.List in favor of builtin tuples (a90ce35)</li> <li>ir: remove pydantic dependency and make grounds more composable (9da0f41)</li> <li>ir: remove sch.HasSchema and introduce ops.Projection base class for ops.Selection (c3b0139)</li> <li>ir: remove unnecessary complexity introduced by variadic annotation (698314b)</li> <li>ir: resolve circular imports so operations can be globally imported for types (d2a3919)</li> <li>ir: simplify analysis.substitute_unbound() (a6c7406)</li> <li>ir: simplify SortKey construction using rules (4d63280)</li> <li>ir: simplify switch-case builders (9acf717)</li> <li>ir: split datatypes package into multiple submodules (cce6535)</li> <li>ir: split out table count into <code>CountStar</code> operation (e812e6e)</li> <li>ir: support replacing nodes in the tree (6a0df5a)</li> <li>ir: support variadic annotable arguments and add generic graph traversal routines (5d6a289)</li> <li>ir: unify aggregation construction to use AggregateSelection (c7d6a6f)</li> <li>make <code>quantile</code>, <code>any</code>, and <code>all</code> reductions filterable (1bafc9e)</li> <li>make sure <code>value_counts</code> always has a projection (a70a302)</li> <li>mssql: use lambda to define backend operations (1437cfb)</li> <li>mysql: dedup extract code (d551944)</li> <li>mysql: use lambda to define backend operations (d10bff8)</li> <li>polars: match duckdb registration api (ac59dac)</li> <li>postgres: use lambda to define backend operations (4c85d7b)</li> <li>remove dead <code>compat.py</code> module (eda0fdb)</li> <li>remove deprecated approximate aggregation classes (53fc6cb)</li> <li>remove deprecated functions and classes (be1cdda)</li> <li>remove duplicate <code>_random_identifier</code> calls (26e7942)</li> <li>remove setup.py and related infrastructure (adfcce1)</li> <li>remove the <code>JSONB</code> type (c4fc0ec)</li> <li>rename some infer methods for consistency (a8f5579)</li> <li>replace isinstance dtype checking with <code>is_*</code> methods (386adc2)</li> <li>rework registration / file loading (c60e30d)</li> <li>rules: generalize field referencing using rlz.ref() (0afb8b9)</li> <li>simplify <code>ops.ArrayColumn</code> in postgres backend (f9677cc)</li> <li>simplify histogram implementation by using window functions (41cbc29)</li> <li>simplify ops.ArrayColumn in alchemy backend (28ff4a8)</li> <li>snowflake: use lambda to define backend operations (cb33fce)</li> <li>split up custom nix code; remove unused derivations (57dff10)</li> <li>sqlite: use lambda to define backend operations (b937391)</li> <li>test: make clickhouse tests use <code>pytest-snapshot</code> (413dbd2)</li> <li>tests: move sql output to golden dir (6a6a453)</li> <li>test: sort regex test cases by name instead of posix-ness (0dfb0e7)</li> <li>tests: replace <code>sqlgolden</code> with <code>pytest-snapshot</code> (5700eb0)</li> <li>timestamps: remove <code>timezone</code> argument to <code>to_timestamp</code> API (eb4762e)</li> <li>trino: use lambda to define backend operations (dbd61a5)</li> <li>uncouple <code>MultiQuantile</code> class from <code>Quantile</code> (9c48f8c)</li> <li>use <code>rlz.lazy_instance_of</code> to delay shapely import (d14badc)</li> <li>use lazy dispatch for <code>dt.infer</code> (2e56540)</li> </ul>"},{"location":"release_notes/#documentation_2","title":"Documentation","text":"<ul> <li>add <code>backend_sensitive</code> decorator (836f237)</li> <li>add <code>pip install poetry</code> dev env setup step (69940b1)</li> <li>add bigquery ci data analysis notebook (2b1d4e5)</li> <li>add how to sessionize guide (18989dd)</li> <li>add issue templates (4480c18)</li> <li>add missing argument descriptions (ea757fa)</li> <li>add mssql backend page (63c0f19)</li> <li>added 4.0 release blog post (bcc0eca)</li> <li>added memtable howto guide (5dde9bd)</li> <li>backends: add duckdb and mssql to the backend index page (7b13218)</li> <li>bring back git revision localized date plugin (e4fc2c9)</li> <li>created how to guide for deferred expressions (2a9f6ab)</li> <li>dev: python-duckdb now available for windows with conda (7f76b09)</li> <li>document how to create a table from a pandas dataframe using ibis.memtable (c6521ec)</li> <li>fix backends label in feature request issue form (cf852d3)</li> <li>fix broken docstrings; reduce docstring noise; workaround griffe (bd1c637)</li> <li>fix docs for building docs (23af567)</li> <li>fix feature-request issue template (6fb62f5)</li> <li>fix installation section for conda (7af6ac1)</li> <li>fix landing page links (1879362)</li> <li>fix links to make docs work locally and remotely (13c7810)</li> <li>fix pyarrow batches docstring (dba9594)</li> <li>fix single line docstring summaries (8028201)</li> <li>fix snowflake doc link in readme.md (9aff68e)</li> <li>fix the inline example for ibis.dask.do_connect (6a533f0)</li> <li>fix tutorial link on install page (b34811a)</li> <li>fix typo in first example of the homepage (9a8a25a)</li> <li>formatting and syntax highlighting fixes (50864da)</li> <li>front page rework (24b795a)</li> <li>how-to: use parquet data source for sessionization, fix typos, more deferred usage (974be37)</li> <li>improve the docstring of the generic connect method (ee87802)</li> <li>issue template cleanups (fed37da)</li> <li>list (e331247)</li> <li>polars: add backend docs page (e303b68)</li> <li>remove hrs (4c30de4)</li> <li>renamed how to guides to be more consistent (1bdc5bd)</li> <li>sentence structure in the Notes section (ac20232)</li> <li>show interactive prompt for python (5d7d913)</li> <li>split out geospatial operations in the support matrix docs (0075c28)</li> <li>trino: add backend docs (2f262cd)</li> <li>typo (6bac645)</li> <li>typos headers and formatting (9566cbb)</li> <li>udf: examples in pandas have the incorrect import path (49028b8)</li> <li>update filename (658a296)</li> <li>update line (4edfce0)</li> <li>update readme (19a3f3c)</li> <li>use buf/feat prefix only (2561a29)</li> <li>use components instead of pieces (179ca1e)</li> <li>use heading instead of bulleted bold (99b044e)</li> <li>use library instead of project (fd2d915)</li> <li>use present tense for use cases and \"why\" section (6cc7416)</li> <li>www: fix frontpage example (7db39e8)</li> </ul>"},{"location":"release_notes/#320-2022-09-15","title":"3.2.0 (2022-09-15)","text":""},{"location":"release_notes/#features_3","title":"Features","text":"<ul> <li>add api to get backend entry points (0152f5e)</li> <li>api: add <code>and_</code> and <code>or_</code> helpers (94bd4df)</li> <li>api: add <code>argmax</code> and <code>argmin</code> column methods (b52216a)</li> <li>api: add <code>distinct</code> to <code>Intersection</code> and <code>Difference</code> operations (cd9a34c)</li> <li>api: add <code>ibis.memtable</code> API for constructing in-memory table expressions (0cc6948)</li> <li>api: add <code>ibis.sql</code> to easily get a formatted SQL string (d971cc3)</li> <li>api: add <code>Table.unpack()</code> and <code>StructValue.lift()</code> APIs for projecting struct fields (ced5f53)</li> <li>api: allow transmute-style select method (d5fc364)</li> <li>api: implement all bitwise operators (7fc5073)</li> <li>api: promote <code>psql</code> to a <code>show_sql</code> public API (877a05d)</li> <li>clickhouse: add dataframe external table support for memtables (bc86aa7)</li> <li>clickhouse: add enum, ipaddr, json, lowcardinality to type parser (8f0287f)</li> <li>clickhouse: enable support for working window functions (310a5a8)</li> <li>clickhouse: implement <code>argmin</code> and <code>argmax</code> (ee7c878)</li> <li>clickhouse: implement bitwise operations (348cd08)</li> <li>clickhouse: implement struct scalars (1f3efe9)</li> <li>dask: implement <code>StringReplace</code> execution (1389f4b)</li> <li>dask: implement ungrouped <code>argmin</code> and <code>argmax</code> (854aea7)</li> <li>deps: support duckdb 0.5.0 (47165b2)</li> <li>duckdb: handle query parameters in <code>ibis.connect</code> (fbde95d)</li> <li>duckdb: implement <code>argmin</code> and <code>argmax</code> (abf03f1)</li> <li>duckdb: implement bitwise xor (ca3abed)</li> <li>duckdb: register tables from pandas/pyarrow objects (36e48cc)</li> <li>duckdb: support unsigned integer types (2e67918)</li> <li>impala: implement bitwise operations (c5302ab)</li> <li>implement dropna for SQL backends (8a747fb)</li> <li>log: make BaseSQLBackend._log print by default (12de5bb)</li> <li>mysql: register BLOB types (1e4fb92)</li> <li>pandas: implement <code>argmin</code> and <code>argmax</code> (bf9b948)</li> <li>pandas: implement <code>NotContains</code> on grouped data (976dce7)</li> <li>pandas: implement <code>StringReplace</code> execution (578795f)</li> <li>pandas: implement Contains with a group by (c534848)</li> <li>postgres: implement bitwise xor (9b1ebf5)</li> <li>pyspark: add option to treat nan as null in aggregations (bf47250)</li> <li>pyspark: implement <code>ibis.connect</code> for pyspark (a191744)</li> <li>pyspark: implement <code>Intersection</code> and <code>Difference</code> (9845a3c)</li> <li>pyspark: implement bitwise operators (33cadb1)</li> <li>sqlalchemy: implement bitwise operator translation (bd9f64c)</li> <li>sqlalchemy: make <code>ibis.connect</code> with sqlalchemy backends (b6cefb9)</li> <li>sqlalchemy: properly implement <code>Intersection</code> and <code>Difference</code> (2bc0b69)</li> <li>sql: implement <code>StringReplace</code> translation (29daa32)</li> <li>sqlite: implement bitwise xor and bitwise not (58c42f9)</li> <li>support <code>table.sort_by(ibis.random())</code> (693005d)</li> <li>type-system: infer pandas' string dtype (5f0eb5d)</li> <li>ux: add duckdb as the default backend (8ccb81d)</li> <li>ux: use <code>rich</code> to format <code>Table.info()</code> output (67234c3)</li> <li>ux: use <code>sqlglot</code> for pretty printing SQL (a3c81c5)</li> <li>variadic union, intersect, &amp; difference functions (05aca5a)</li> </ul>"},{"location":"release_notes/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>api: make sure column names that are already inferred are not overwritten (6f1cb16)</li> <li>api: support deferred objects in existing API functions (241ce6a)</li> <li>backend: ensure that chained limits respect prior limits (02a04f5)</li> <li>backends: ensure select after filter works (e58ca73)</li> <li>backends: only recommend installing ibis-foo when foo is a known backend (ac6974a)</li> <li>base-sql: fix String-generating backend string concat implementation (3cf78c1)</li> <li>clickhouse: add IPv4/IPv6 literal inference (0a2f315)</li> <li>clickhouse: cast repeat <code>times</code> argument to <code>UInt64</code> (b643544)</li> <li>clickhouse: fix listing tables from databases with no tables (08900c3)</li> <li>compilers: make sure memtable rows have names in the SQL string compilers (18e7f95)</li> <li>compiler: use <code>repr</code> for SQL string <code>VALUES</code> data (75af658)</li> <li>dask: ensure predicates are computed before projections (5cd70e1)</li> <li>dask: implement timestamp-date binary comparisons (48d5058)</li> <li>dask: set dask upper bound due to large scale test breakage (796c645), closes #9221</li> <li>decimal: add decimal type inference (3fe3fd8)</li> <li>deps: update dependency duckdb-engine to &gt;=0.1.8,&lt;0.4.0 (113dc8f)</li> <li>deps: update dependency duckdb-engine to &gt;=0.1.8,&lt;0.5.0 (ef97c9d)</li> <li>deps: update dependency parsy to v2 (9a06131)</li> <li>deps: update dependency shapely to &gt;=1.6,&lt;1.8.4 (0c787d2)</li> <li>deps: update dependency shapely to &gt;=1.6,&lt;1.8.5 (d08c737)</li> <li>deps: update dependency sqlglot to v5 (f210bb8)</li> <li>deps: update dependency sqlglot to v6 (5ca4533)</li> <li>duckdb: add missing types (59bad07)</li> <li>duckdb: ensure that in-memory connections remain in their creating thread (39bc537)</li> <li>duckdb: use <code>fetch_arrow_table()</code> to be able to handle big timestamps (85a76eb)</li> <li>fix bug in pandas &amp; dask <code>difference</code> implementation (88a78fa)</li> <li>fix dask <code>where</code> implementation (49f8845)</li> <li>impala: add date column dtype to impala to ibis type dict (c59e94e), closes #4449</li> <li>pandas where supports scalar for <code>left</code> (48f6c1e)</li> <li>pandas: fix anti-joins (10a659d)</li> <li>pandas: implement timestamp-date binary comparisons (4fc666d)</li> <li>pandas: properly handle empty groups when aggregating with <code>GroupConcat</code> (6545f4d)</li> <li>pyspark: fix broken <code>StringReplace</code> implementation (22cb297)</li> <li>pyspark: make sure <code>ibis.connect</code> works with pyspark (a7ab107)</li> <li>pyspark: translate predicates before projections (b3d1c80)</li> <li>sqlalchemy: fix float64 type mapping (8782773)</li> <li>sqlalchemy: handle reductions with multiple arguments (5b2039b)</li> <li>sqlalchemy: implement <code>SQLQueryResult</code> translation (786a50f)</li> <li>sql: fix sql compilation after making <code>InMemoryTable</code> a subclass of <code>PhysicalTable</code> (aac9524)</li> <li>squash several bugs in <code>sort_by</code> asc/desc handling (222b2ba)</li> <li>support chained set operations in SQL backends (227aed3)</li> <li>support filters on InMemoryTable exprs (abfaf1f)</li> <li>typo: in BaseSQLBackend.compile docstring (0561b13)</li> </ul>"},{"location":"release_notes/#deprecations_3","title":"Deprecations","text":"<ul> <li><code>right</code> kwarg in <code>union</code>/<code>intersect</code>/<code>difference</code> (719a5a1)</li> <li>duckdb: deprecate <code>path</code> argument in favor of <code>database</code> (fcacc20)</li> <li>sqlite: deprecate <code>path</code> argument in favor of <code>database</code> (0f85919)</li> </ul>"},{"location":"release_notes/#performance_2","title":"Performance","text":"<ul> <li>pandas: remove reexecution of alias children (64efa53)</li> <li>pyspark: ensure that pyspark DDL doesn't use <code>VALUES</code> (422c98d)</li> <li>sqlalchemy: register DataFrames cheaply where possible (ee9f1be)</li> </ul>"},{"location":"release_notes/#documentation_3","title":"Documentation","text":"<ul> <li>add <code>to_sql</code> (e2821a5)</li> <li>add back constraints for transitive doc dependencies and fix docs (350fd43)</li> <li>add coc reporting information (c2355ba)</li> <li>add community guidelines documentation (fd0893f)</li> <li>add HeavyAI to the readme (4c5ca80)</li> <li>add how-to bfill and ffill (ff84027)</li> <li>add how-to for ibis+duckdb register (73a726e)</li> <li>add how-to section to docs (33c4b93)</li> <li>duckdb: add installation note for duckdb &gt;= 0.5.0 (608b1fb)</li> <li>fix <code>memtable</code> docstrings (72bc0f5)</li> <li>fix flake8 line length issues (fb7af75)</li> <li>fix markdown (4ab6b95)</li> <li>fix relative links in tutorial (2bd075f), closes #4064 #4201</li> <li>make attribution style uniform across the blog (05561e0)</li> <li>move the blog out to the top level sidebar for visibility (417ba64)</li> <li>remove underspecified UDF doc page (0eb0ac0)</li> </ul>"},{"location":"release_notes/#310-2022-07-26","title":"3.1.0 (2022-07-26)","text":""},{"location":"release_notes/#features_4","title":"Features","text":"<ul> <li>add <code>__getattr__</code> support to <code>StructValue</code> (75bded1)</li> <li>allow selection subclasses to define new node args (2a7dc41)</li> <li>api: accept <code>Schema</code> objects in public <code>ibis.schema</code> (0daac6c)</li> <li>api: add <code>.tables</code> accessor to <code>BaseBackend</code> (7ad27f0)</li> <li>api: add <code>e</code> function to public API (3a07e70)</li> <li>api: add <code>ops.StructColumn</code> operation (020bfdb)</li> <li>api: add cume_dist operation (6b6b185)</li> <li>api: add toplevel ibis.connect() (e13946b)</li> <li>api: handle literal timestamps with timezone embedded in string (1ae976b)</li> <li>api: ibis.connect() default to duckdb for parquet/csv extensions (ff2f088)</li> <li>api: make struct metadata more convenient to access (3fd9bd8)</li> <li>api: support tab completion for backends (eb75fc5)</li> <li>api: underscore convenience api (81716da)</li> <li>api: unnest (98ecb09)</li> <li>backends: allow column expressions from non-foreign tables on the right side of <code>isin</code>/<code>notin</code> (e1374a4)</li> <li>base-sql: implement trig and math functions (addb2c1)</li> <li>clickhouse: add ability to pass arbitrary kwargs to Clickhouse do_connect (583f599)</li> <li>clickhouse: implement <code>ops.StructColumn</code> operation (0063007)</li> <li>clickhouse: implement array collect (8b2577d)</li> <li>clickhouse: implement ArrayColumn (1301f18)</li> <li>clickhouse: implement bit aggs (f94a5d2)</li> <li>clickhouse: implement clip (12dfe50)</li> <li>clickhouse: implement covariance and correlation (a37c155)</li> <li>clickhouse: implement degrees (7946c0f)</li> <li>clickhouse: implement proper type serialization (80f4ab9)</li> <li>clickhouse: implement radians (c7b7f08)</li> <li>clickhouse: implement strftime (222f2b5)</li> <li>clickhouse: implement struct field access (fff69f3)</li> <li>clickhouse: implement trig and math functions (c56440a)</li> <li>clickhouse: support subsecond timestamp literals (e8698a6)</li> <li>compiler: restore <code>intersect_class</code> and <code>difference_class</code> overrides in base SQL backend (2c46a15)</li> <li>dask: implement trig functions (e4086bb)</li> <li>dask: implement zeroifnull (38487db)</li> <li>datafusion: implement negate (69dd64d)</li> <li>datafusion: implement trig functions (16803e1)</li> <li>duckdb: add register method to duckdb backend to load parquet and csv files (4ccc6fc)</li> <li>duckdb: enable find_in_set test (377023d)</li> <li>duckdb: enable group_concat test (4b9ad6c)</li> <li>duckdb: implement <code>ops.StructColumn</code> operation (211bfab)</li> <li>duckdb: implement approx_count_distinct (03c89ad)</li> <li>duckdb: implement approx_median (894ce90)</li> <li>duckdb: implement arbitrary first and last aggregation (8a500bc)</li> <li>duckdb: implement NthValue (1bf2842)</li> <li>duckdb: implement strftime (aebc252)</li> <li>duckdb: return the <code>ir.Table</code> instance from DuckDB's <code>register</code> API (0d05d41)</li> <li>mysql: implement FindInSet (e55bbbf)</li> <li>mysql: implement StringToTimestamp (169250f)</li> <li>pandas: implement bitwise aggregations (37ff328)</li> <li>pandas: implement degrees (25b4f69)</li> <li>pandas: implement radians (6816b75)</li> <li>pandas: implement trig functions (1fd52d2)</li> <li>pandas: implement zeroifnull (48e8ed1)</li> <li>postgres/duckdb: implement covariance and correlation (464d3ef)</li> <li>postgres: implement ArrayColumn (7b0a506)</li> <li>pyspark: implement approx_count_distinct (1fe1d75)</li> <li>pyspark: implement approx_median (07571a9)</li> <li>pyspark: implement covariance and correlation (ae818fb)</li> <li>pyspark: implement degrees (f478c7c)</li> <li>pyspark: implement nth_value (abb559d)</li> <li>pyspark: implement nullifzero (640234b)</li> <li>pyspark: implement radians (18843c0)</li> <li>pyspark: implement trig functions (fd7621a)</li> <li>pyspark: implement Where (32b9abb)</li> <li>pyspark: implement xor (550b35b)</li> <li>pyspark: implement zeroifnull (db13241)</li> <li>pyspark: topk support (9344591)</li> <li>sqlalchemy: add degrees and radians (8b7415f)</li> <li>sqlalchemy: add xor translation rule (2921664)</li> <li>sqlalchemy: allow non-primitive arrays (4e02918)</li> <li>sqlalchemy: implement approx_count_distinct as count distinct (4e8bcab)</li> <li>sqlalchemy: implement clip (8c02639)</li> <li>sqlalchemy: implement trig functions (34c1514)</li> <li>sqlalchemy: implement Where (7424704)</li> <li>sqlalchemy: implement zeroifnull (4735e9a)</li> <li>sqlite: implement BitAnd, BitOr and BitXor (e478479)</li> <li>sqlite: implement cotangent (01e7ce7)</li> <li>sqlite: implement degrees and radians (2cf9c5e)</li> </ul>"},{"location":"release_notes/#bug-fixes_4","title":"Bug Fixes","text":"<ul> <li>api: bring back null datatype parsing (fc131a1)</li> <li>api: compute the type from both branches of <code>Where</code> expressions (b8f4120)</li> <li>api: ensure that <code>Deferred</code> objects work in aggregations (bbb376c)</li> <li>api: ensure that nulls can be cast to any type to allow caller promotion (fab4393)</li> <li>api: make ExistSubquery and NotExistsSubquery pure boolean operations (dd70024)</li> <li>backends: make execution transactional where possible (d1ea269)</li> <li>clickhouse: cast empty result dataframe (27ae68a)</li> <li>clickhouse: handle empty IN and NOT IN expressions (2c892eb)</li> <li>clickhouse: return null instead of empty string for group_concat when values are filtered out (b826b40)</li> <li>compiler: fix bool bool comparisons (1ac9a9e)</li> <li>dask/pandas: allow limit to be <code>None</code> (9f91d6b)</li> <li>dask: aggregation with multi-key groupby fails on dask backend (4f8bc70)</li> <li>datafusion: handle predicates in aggregates (4725571)</li> <li>deps: update dependency datafusion to &gt;=0.4,&lt;0.7 (f5b244e)</li> <li>deps: update dependency duckdb to &gt;=0.3.2,&lt;0.5.0 (57ee818)</li> <li>deps: update dependency duckdb-engine to &gt;=0.1.8,&lt;0.3.0 (3e379a0)</li> <li>deps: update dependency geoalchemy2 to &gt;=0.6.3,&lt;0.13 (c04a533)</li> <li>deps: update dependency geopandas to &gt;=0.6,&lt;0.12 (b899c37)</li> <li>deps: update dependency Shapely to &gt;=1.6,&lt;1.8.3 (87a49ad)</li> <li>deps: update dependency toolz to &gt;=0.11,&lt;0.13 (258a641)</li> <li>don't mask udf module in init.py (3e567ba)</li> <li>duckdb: ensure that paths with non-extension <code>.</code> chars are parsed correctly (9448fd3)</li> <li>duckdb: fix struct datatype parsing (5124763)</li> <li>duckdb: force string_agg separator to be a constant (21cdf2f)</li> <li>duckdb: handle multiple dotted extensions; quote names; consolidate implementations (1494246)</li> <li>duckdb: remove timezone function invocation (33d38fc)</li> <li>geospatial: ensure that later versions of numpy are compatible with geospatial code (33f0afb)</li> <li>impala: a delimited table explicitly declare stored as textfile (04086a4), closes #4260</li> <li>impala: remove broken nth_value implementation (dbc9cc2)</li> <li>ir: don't attempt fusion when projections aren't exactly equivalent (3482ba2)</li> <li>mysql: cast mysql timestamp literals to ensure correct return type (8116e04)</li> <li>mysql: implement integer to timestamp using <code>from_unixtime</code> (1b43004)</li> <li>pandas/dask: look at pre_execute for has_operation reporting (cb44efc)</li> <li>pandas: execute negate on bool as <code>not</code> (330ab4f)</li> <li>pandas: fix struct inference from dict in the pandas backend (5886a9a)</li> <li>pandas: force backend options registration on trace.enable() calls (8818fe6)</li> <li>pandas: handle empty boolean column casting in Series conversion (f697e3e)</li> <li>pandas: handle struct columns with NA elements (9a7c510)</li> <li>pandas: handle the case of selection from a join when remapping overlapping column names (031c4c6)</li> <li>pandas: perform correct equality comparison (d62e7b9)</li> <li>postgres/duckdb: cast after milliseconds computation instead of after extraction (bdd1d65)</li> <li>pyspark: handle predicates in Aggregation (842c307)</li> <li>pyspark: prevent spark from trying to convert timezone of naive timestamps (dfb4127)</li> <li>pyspark: remove xpassing test for #2453 (c051e28)</li> <li>pyspark: specialize implementation of <code>has_operation</code> (5082346)</li> <li>pyspark: use empty check for collect_list in GroupConcat rule (df66acb)</li> <li>repr: allow DestructValue selections to be formatted by fmt (4b45d87)</li> <li>repr: when formatting DestructValue selections, use struct field names as column names (d01fe42)</li> <li>sqlalchemy: fix parsing and construction of nested array types (e20bcc0)</li> <li>sqlalchemy: remove unused second argument when creating temporary views (8766b40)</li> <li>sqlite: register coversion to isoformat for <code>pandas.Timestamp</code> (fe95dca)</li> <li>sqlite: test case with whitespace at the end of the line (7623ae9)</li> <li>sql: use isoformat for timestamp literals (70d0ba6)</li> <li>type-system: infer null datatype for empty sequence of expressions (f67d5f9)</li> <li>use bounded precision for decimal aggregations (596acfb)</li> </ul>"},{"location":"release_notes/#performance-improvements","title":"Performance Improvements","text":"<ul> <li>analysis: add <code>_projection</code> as cached_property to avoid reconstruction of projections (98510c8)</li> <li>lineage: ensure that expressions are not traversed multiple times in most cases (ff9708c)</li> </ul>"},{"location":"release_notes/#reverts","title":"Reverts","text":"<ul> <li>ci: install sqlite3 on ubuntu (1f2705f)</li> </ul>"},{"location":"release_notes/#302-2022-04-28","title":"3.0.2 (2022-04-28)","text":""},{"location":"release_notes/#bug-fixes_5","title":"Bug Fixes","text":"<ul> <li>docs: fix tempdir location for docs build (dcd1b22)</li> </ul>"},{"location":"release_notes/#301-2022-04-28","title":"3.0.1 (2022-04-28)","text":""},{"location":"release_notes/#bug-fixes_6","title":"Bug Fixes","text":"<ul> <li>build: replace version before exec plugin runs (573139c)</li> </ul>"},{"location":"release_notes/#300-2022-04-25","title":"3.0.0 (2022-04-25)","text":""},{"location":"release_notes/#breaking-changes_2","title":"\u26a0 BREAKING CHANGES","text":"<ul> <li>ir: The following are breaking changes due to simplifying expression internals</li> <li><code>ibis.expr.datatypes.DataType.scalar_type</code> and <code>DataType.column_type</code> factory     methods have been removed, <code>DataType.scalar</code> and <code>DataType.column</code> class     fields can be used to directly construct a corresponding expression instance     (though prefer to use <code>operation.to_expr()</code>)</li> <li><code>ibis.expr.types.ValueExpr._name</code> and <code>ValueExpr._dtype`` fields are not     accassible anymore. While these were not supposed to used directly now</code>ValueExpr.has_name()<code>,</code>ValueExpr.get_name()<code>and</code>ValueExpr.type()` methods     are the only way to retrieve the expression's name and datatype.</li> <li><code>ibis.expr.operations.Node.output_type</code> is a property now not a method,     decorate those methods with <code>@property</code></li> <li><code>ibis.expr.operations.Value</code> subclasses must define <code>output_shape</code> and     <code>output_dtype</code> properties from now on (note the datatype abbreviation <code>dtype</code>     in the property name)</li> <li><code>ibis.expr.rules.cast()</code>, <code>scalar_like()</code> and <code>array_like()</code> rules have been     removed</li> <li>api: Replace <code>t[\"a\"].distinct()</code> with <code>t[[\"a\"]].distinct()</code>.</li> <li>deps: The sqlalchemy lower bound is now 1.4</li> <li>ir: Schema.names and Schema.types attributes now have tuple type rather than list</li> <li>expr: Columns that were added or used in an aggregation or mutation would be alphabetically sorted in compiled SQL outputs.  This was a vestige from when Python dicts didn't preserve insertion order. Now columns will appear in the order in which they were passed to <code>aggregate</code> or <code>mutate</code></li> <li>api: <code>dt.float</code> is now <code>dt.float64</code>; use <code>dt.float32</code> for the previous behavior.</li> <li>ir: Relation-based <code>execute_node</code> dispatch rules must now accept tuples of expressions.</li> <li>ir: removed ibis.expr.lineage.{roots,find_nodes} functions</li> <li>config: Use <code>ibis.options.graphviz_repr = True</code> to enable</li> <li>hdfs: Use <code>fsspec</code> instead of HDFS from ibis</li> <li>udf: Vectorized UDF coercion functions are no longer a public API.</li> <li>The minimum supported Python version is now Python 3.8</li> <li>config: <code>register_option</code> is no longer supported, please submit option requests upstream</li> <li>backends: Read tables with pandas.read_hdf and use the pandas backend</li> <li>The CSV backend is removed. Use Datafusion for CSV execution.</li> <li>backends: Use the datafusion backend to read parquet files</li> <li><code>Expr() -&gt; Expr.pipe()</code></li> <li>coercion functions previously in expr/schema.py are now in udf/vectorized.py</li> <li>api: <code>materialize</code> is removed. Joins with overlapping columns now have suffixes.</li> <li>kudu: use impala instead: https://kudu.apache.org/docs/kudu_impala_integration.html</li> <li>Any code that was relying implicitly on string-y behavior from UUID datatypes will need to add an explicit cast first.</li> </ul>"},{"location":"release_notes/#features_5","title":"Features","text":"<ul> <li>add repr_html for expressions to print as tables in ipython (cd6fa4e)</li> <li>add duckdb backend (667f2d5)</li> <li>allow construction of decimal literals (3d9e865)</li> <li>api: add <code>ibis.asc</code> expression (efe177e), closes #1454</li> <li>api: add has_operation API to the backend (4fab014)</li> <li>api: implement type for SortExpr (ab19bd6)</li> <li>clickhouse: implement string concat for clickhouse (1767205)</li> <li>clickhouse: implement StrRight operation (67749a0)</li> <li>clickhouse: implement table union (e0008d7)</li> <li>clickhouse: implement trim, pad and string predicates (a5b7293)</li> <li>datafusion: implement Count operation (4797a86)</li> <li>datatypes: unbounded decimal type (f7e6f65)</li> <li>date: add ibis.date(y,m,d) functionality (26892b6), closes #386</li> <li>duckdb/postgres/mysql/pyspark: implement <code>.sql</code> on tables for mixing sql and expressions (00e8087)</li> <li>duckdb: add functionality needed to pass integer to interval test (e2119e8)</li> <li>duckdb: implement _get_schema_using_query (93cd730)</li> <li>duckdb: implement now() function (6924f50)</li> <li>duckdb: implement regexp replace and extract (18d16a7)</li> <li>implement <code>force</code> argument in sqlalchemy backend base class (9df7f1b)</li> <li>implement coalesce for the pyspark backend (8183efe)</li> <li>implement semi/anti join for the pandas backend (cb36fc5)</li> <li>implement semi/anti join for the pyspark backend (3e1ba9c)</li> <li>implement the remaining clickhouse joins (b3aa1f0)</li> <li>ir: rewrite and speed up expression repr (45ce9b2)</li> <li>mysql: implement _get_schema_from_query (456cd44)</li> <li>mysql: move string join impl up to alchemy for mysql (77a8eb9)</li> <li>postgres: implement _get_schema_using_query (f2459eb)</li> <li>pyspark: implement Distinct for pyspark (4306ad9)</li> <li>pyspark: implement log base b for pyspark (527af3c)</li> <li>pyspark: implement percent_rank and enable testing (c051617)</li> <li>repr: add interval info to interval repr (df26231)</li> <li>sqlalchemy: implement ilike (43996c0)</li> <li>sqlite: implement date_truncate (3ce4f2a)</li> <li>sqlite: implement ISO week of year (714ff7b)</li> <li>sqlite: implement string join and concat (6f5f353)</li> <li>support of arrays and tuples for clickhouse (db512a8)</li> <li>ver: dynamic version identifiers (408f862)</li> </ul>"},{"location":"release_notes/#bug-fixes_7","title":"Bug Fixes","text":"<ul> <li>added wheel to pyproject toml for venv users (b0b8e5c)</li> <li>allow major version changes in CalVer dependencies (9c3fbe5)</li> <li>annotable: allow optional arguments at any position (778995f), closes #3730</li> <li>api: add ibis.map and .struct (327b342), closes #3118</li> <li>api: map string multiplication with integer to repeat method (b205922)</li> <li>api: thread suffixes parameter to individual join methods (31a9aff)</li> <li>change TimestampType to Timestamp (e0750be)</li> <li>clickhouse: disconnect from clickhouse when computing version (11cbf08)</li> <li>clickhouse: use a context manager for execution (a471225)</li> <li>combine windows during windowization (7fdd851)</li> <li>conform epoch_seconds impls to expression return type (18a70f1)</li> <li>context-adjustment: pass scope when calling adjust_context in pyspark backend (33aad7b), closes #3108</li> <li>dask: fix asof joins for newer version of dask (50711cc)</li> <li>dask: workaround dask bug (a0f3bd9)</li> <li>deps: update dependency atpublic to v3 (3fe8f0d)</li> <li>deps: update dependency datafusion to &gt;=0.4,&lt;0.6 (3fb2194)</li> <li>deps: update dependency geoalchemy2 to &gt;=0.6.3,&lt;0.12 (dc3c361)</li> <li>deps: update dependency graphviz to &gt;=0.16,&lt;0.21 (3014445)</li> <li>duckdb: add casts to literals to fix binding errors (1977a55), closes #3629</li> <li>duckdb: fix array column type discovery on leaf tables and add tests (15e5412)</li> <li>duckdb: fix log with base b impl (4920097)</li> <li>duckdb: support both 0.3.2 and 0.3.3 (a73ccce)</li> <li>enforce the schema's column names in <code>apply_to</code> (b0f334d)</li> <li>expose ops.IfNull for mysql backend (156c2bd)</li> <li>expr: add more binary operators to char list and implement fallback (b88184c)</li> <li>expr: fix formatting of table info using tabulate (b110636)</li> <li>fix float vs real data type detection in sqlalchemy (24e6774)</li> <li>fix list_schemas argument (69c1abf)</li> <li>fix postgres udfs and reenable ci tests (7d480d2)</li> <li>fix tablecolumn execution for filter following join (064595b)</li> <li>format: remove some newlines from formatted expr repr (ed4fa78)</li> <li>histogram: cross_join needs onclause=True (5d36a58), closes #622</li> <li>ibis.expr.signature.Parameter is not pickleable (828fd54)</li> <li>implement coalesce properly in the pandas backend (aca5312)</li> <li>implement count on tables for pyspark (7fe5573), closes #2879</li> <li>infer coalesce types when a non-null expression occurs after the first argument (c5f2906)</li> <li>mutate: do not lift table column that results from mutate (ba4e5e5)</li> <li>pandas: disable range windows with order by (e016664)</li> <li>pandas: don't reassign the same column to silence SettingWithCopyWarning warning (75dc616)</li> <li>pandas: implement percent_rank correctly (d8b83e7)</li> <li>prevent unintentional cross joins in mutate + filter (83eef99)</li> <li>pyspark: fix range windows (a6f2aa8)</li> <li>regression in Selection.sort_by with resolved_keys (c7a69cd)</li> <li>regression in sort_by with resolved_keys (63f1382), closes #3619</li> <li>remove broken csv pre_execute (93b662a)</li> <li>remove importorskip call for backend tests (2f0bcd8)</li> <li>remove incorrect fix for pandas regression (339f544)</li> <li>remove passing schema into register_parquet (bdcbb08)</li> <li>repr: add ops.TimeAdd to repr binop lookup table (fd94275)</li> <li>repr: allow ops.TableNode in fmt_value (6f57003)</li> <li>reverse the predicate pushdown subsitution (f3cd358)</li> <li>sort_index to satisfy pandas 1.4.x (6bac0fc)</li> <li>sqlalchemy: ensure correlated subqueries FROM clauses are rendered (3175321)</li> <li>sqlalchemy: use corresponding_column to prevent spurious cross joins (fdada21)</li> <li>sqlalchemy: use replace selectables to prevent semi/anti join cross join (e8a1a71)</li> <li>sql: retain column names for named ColumnExprs (f1b4b6e), closes #3754</li> <li>sql: walk right join trees and substitute joins with right-side joins with views (0231592)</li> <li>store schema on the pandas backend to allow correct inference (35070be)</li> </ul>"},{"location":"release_notes/#performance-improvements_1","title":"Performance Improvements","text":"<ul> <li>datatypes: speed up str and hash (262d3d7)</li> <li>fast path for simple column selection (d178498)</li> <li>ir: global equality cache (13c2bb2)</li> <li>ir: introduce CachedEqMixin to speed up equality checks (b633925)</li> <li>repr: remove full tree repr from rule validator error message (65885ab)</li> <li>speed up attribute access (89d1c05)</li> <li>use assign instead of concat in projections when possible (985c242)</li> </ul>"},{"location":"release_notes/#miscellaneous-chores","title":"Miscellaneous Chores","text":"<ul> <li>deps: increase sqlalchemy lower bound to 1.4 (560854a)</li> <li>drop support for Python 3.7 (0afd138)</li> </ul>"},{"location":"release_notes/#code-refactoring","title":"Code Refactoring","text":"<ul> <li>api: make primitive types more cohesive (71da8f7)</li> <li>api: remove distinct ColumnExpr API (3f48cb8)</li> <li>api: remove materialize (24285c1)</li> <li>backends: remove the hdf5 backend (ff34f3e)</li> <li>backends: remove the parquet backend (b510473)</li> <li>config: disable graphviz-repr-in-notebook by default (214ad4e)</li> <li>config: remove old config code and port to pydantic (4bb96d1)</li> <li>dt.UUID inherits from DataType, not String (2ba540d)</li> <li>expr: preserve column ordering in aggregations/mutations (668be0f)</li> <li>hdfs: replace HDFS with <code>fsspec</code> (cc6eddb)</li> <li>ir: make Annotable immutable (1f2b3fa)</li> <li>ir: make schema annotable (b980903)</li> <li>ir: remove unused lineage <code>roots</code> and <code>find_nodes</code> functions (d630a77)</li> <li>ir: simplify expressions by not storing dtype and name (e929f85)</li> <li>kudu: remove support for use of kudu through kudu-python (36bd97f)</li> <li>move coercion functions from schema.py to udf (58eea56), closes #3033</li> <li>remove blanket call for Expr (3a71116), closes #2258</li> <li>remove the csv backend (0e3e02e)</li> <li>udf: make coerce functions in ibis.udf.vectorized private (9ba4392)</li> </ul>"},{"location":"release_notes/#211-2022-01-12","title":"2.1.1 (2022-01-12)","text":""},{"location":"release_notes/#bug-fixes_8","title":"Bug Fixes","text":"<ul> <li>setup.py: set the correct version number for 2.1.0 (f3d267b)</li> </ul>"},{"location":"release_notes/#210-2022-01-12","title":"2.1.0 (2022-01-12)","text":""},{"location":"release_notes/#bug-fixes_9","title":"Bug Fixes","text":"<ul> <li>consider all packages' entry points (b495cf6)</li> <li>datatypes: infer bytes literal as binary #2915 (#3124) (887efbd)</li> <li>deps: bump minimum dask version to 2021.10.0 (e6b5c09)</li> <li>deps: constrain numpy to ensure wheels are used on windows (70c308b)</li> <li>deps: update dependency clickhouse-driver to ^0.1 || ^0.2.0 (#3061) (a839d54)</li> <li>deps: update dependency geoalchemy2 to &gt;=0.6,&lt;0.11 (4cede9d)</li> <li>deps: update dependency pyarrow to v6 (#3092) (61e52b5)</li> <li>don't force backends to override do_connect until 3.0.0 (4b46973)</li> <li>execute materialized joins in the pandas and dask backends (#3086) (9ed937a)</li> <li>literal: allow creating ibis literal with uuid (#3131) (b0f4f44)</li> <li>restore the ability to have more than two option levels (#3151) (fb4a944)</li> <li>sqlalchemy: fix correlated subquery compilation (43b9010)</li> <li>sqlite: defer db connection until needed (#3127) (5467afa), closes #64</li> </ul>"},{"location":"release_notes/#features_6","title":"Features","text":"<ul> <li>allow column_of to take a column expression (dbc34bb)</li> <li>ci: More readable workflow job titles  (#3111) (d8fd7d9)</li> <li>datafusion: initial implementation for Arrow Datafusion backend (3a67840), closes #2627</li> <li>datafusion: initial implementation for Arrow Datafusion backend (75876d9), closes #2627</li> <li>make dayofweek impls conform to pandas semantics (#3161) (9297828)</li> </ul>"},{"location":"release_notes/#reverts_1","title":"Reverts","text":"<ul> <li>\"ci: install gdal for fiona\" (8503361)</li> </ul>"},{"location":"release_notes/#200-2021-10-06","title":"2.0.0 (2021-10-06)","text":""},{"location":"release_notes/#features_7","title":"Features","text":"<ul> <li>Serialization-deserialization of Node via pickle is now byte compatible between different processes (#2938)</li> <li>Support joining on different columns in ClickHouse backend (#2916)</li> <li>Support summarization of empty data in Pandas backend (#2908)</li> <li>Unify implementation of fillna and isna in Pyspark backend (#2882)</li> <li>Support binary operation with Timedelta in Pyspark backend (#2873)</li> <li>Add <code>group_concat</code> operation for Clickhouse backend (#2839)</li> <li>Support comparison of ColumnExpr to timestamp literal (#2808)</li> <li>Make op schema a cached property (#2805)</li> <li>Implement <code>.insert()</code> for SQLAlchemy backends (#2613, #2613)</li> <li>Infer categorical and decimal Series to more specific Ibis types in Pandas backend (#2792)</li> <li>Add <code>startswith</code> and <code>endswith</code> operations (#2790)</li> <li>Allow more flexible return type for UDFs (#2776, #2797)</li> <li>Implement Clip in the Pyspark backend (#2779)</li> <li>Use <code>ndarray</code> as array representation in Pandas backend (#2753)</li> <li>Support Spark filter with window operation (#2687)</li> <li>Support context adjustment for udfs for pandas backend (#2646)</li> <li>Add <code>auth_local_webserver</code>, <code>auth_external_data</code>, and <code>auth_cache</code> parameters to BigQuery connect method. Set <code>auth_local_webserver</code> to use a local server instead of copy-pasting an authorization code. Set <code>auth_external_data</code> to true to request additional scopes required to query Google Drive and Sheets. Set <code>auth_cache</code> to <code>reauth</code> or <code>none</code> to force reauthentication. (#2655)</li> <li>Add <code>bit_and</code>, <code>bit_or</code>, and <code>bit_xor</code> integer column aggregates (BigQuery and MySQL backends) (#2641)</li> <li>Backends are defined as entry points (#2379)</li> <li>Add <code>ibis.array</code> for creating array expressions (#2615)</li> <li>Implement Not operation in PySpark backend (#2607)</li> <li>Added support for case/when in PySpark backend (#2610)</li> <li>Add support for np.array as literals for backends that already support lists as literals (#2603)</li> </ul>"},{"location":"release_notes/#bugs","title":"Bugs","text":"<ul> <li>Fix data races in impala connection pool accounting (#2991)</li> <li>Fix null literal compilation in the Clickhouse backend (#2985)</li> <li>Fix order of limit and offset parameters in the Clickhouse backend (#2984)</li> <li>Replace <code>equals</code> operation for geospatial datatype to <code>geo_equals</code> (#2956)</li> <li>Fix .drop(fields). The argument can now be either a list of strings or a string. (#2829)</li> <li>Fix projection on differences and intersections for SQL backends (#2845)</li> <li>Backends are loaded in a lazy way, so third-party backends can import Ibis without circular imports (#2827)</li> <li>Disable aggregation optimization due to N squared performance (#2830)</li> <li>Fix <code>.cast()</code> to array outputting list instead of np.array in Pandas backend (#2821)</li> <li>Fix aggregation with mixed reduction datatypes (array + scalar) on Dask backend (#2820)</li> <li>Fix error when using reduction UDF that returns np.array in a grouped aggregation (#2770)</li> <li>Fix time context trimming error for multi column udfs in pandas backend (#2712)</li> <li>Fix error during compilation of range_window in base_sql backends (:issue:<code>2608</code>) (#2710)</li> <li>Fix wrong row indexing in the result for 'window after filter' for timecontext adjustment (#2696)</li> <li>Fix <code>aggregate</code> exploding the output of Reduction ops that return a list/ndarray (#2702)</li> <li>Fix issues with context adjustment for filter with PySpark backend (#2693)</li> <li>Add temporary struct col in pyspark backend to ensure that UDFs are executed only once (#2657)</li> <li>Fix BigQuery connect bug that ignored project ID parameter (#2588)</li> <li>Fix overwrite logic to account for DestructColumn inside mutate API (#2636)</li> <li>Fix fusion optimization bug that incorrectly changes operation order (#2635)</li> <li>Fixes a NPE issue with substr in PySpark backend (#2610)</li> <li>Fixes binary data type translation into BigQuery bytes data type (#2354)</li> <li>Make StructValue picklable (#2577)</li> </ul>"},{"location":"release_notes/#support","title":"Support","text":"<ul> <li>Improvement of the backend API. The former <code>Client</code> subclasses have been replaced by a <code>Backend</code> class that must subclass <code>ibis.backends.base.BaseBackend</code>. The <code>BaseBackend</code> class contains abstract methods for the minimum subset of methods that backends must implement, and their signatures have been standardized across backends. The Ibis compiler has been refactored, and backends don't need to implement all compiler classes anymore if the default works for them. Only a subclass of <code>ibis.backends.base.sql.compiler.Compiler</code> is now required. Backends now need to register themselves as entry points. (#2678)</li> <li>Deprecate <code>exists_table(table)</code> in favor of <code>table in list_tables()</code> (#2905)</li> <li>Remove handwritten type parser; parsing errors that were previously <code>IbisTypeError</code> are now <code>parsy.ParseError</code>. <code>parsy</code> is now a hard requirement. (#2977)</li> <li>Methods <code>current_database</code> and <code>list_databases</code> raise an exception for backends that do not support databases (#2962)</li> <li>Method <code>set_database</code> has been deprecated, in favor of creating a new connection to a different database (#2913)</li> <li>Removed <code>log</code> method of clients, in favor of <code>verbose_log</code> option (#2914)</li> <li>Output of <code>Client.version</code> returned as a string, instead of a setuptools <code>Version</code> (#2883)</li> <li>Deprecated <code>list_schemas</code> in SQLAlchemy backends in favor of <code>list_databases</code> (#2862)</li> <li>Deprecated <code>ibis.&lt;backend&gt;.verify()</code> in favor of capturing exception in <code>ibis.&lt;backend&gt;.compile()</code> (#2865)</li> <li>Simplification of data fetching. Backends don't need to implement <code>Query</code> anymore (#2789)</li> <li>Move BigQuery backend to a <code>separate repository &lt;https://github.com/ibis-project/ibis-bigquery&gt;</code>_. The backend will be released separately, use <code>pip install ibis-bigquery</code> or <code>conda install ibis-bigquery</code> to install it, and then use as before. (#2665)</li> <li>Supporting SQLAlchemy 1.4, and requiring minimum 1.3 (#2689)</li> <li>Namespace time_col config, fix type check for trim_with_timecontext for pandas window execution (#2680)</li> <li>Remove deprecated <code>ibis.HDFS</code>, <code>ibis.WebHDFS</code> and <code>ibis.hdfs_connect</code> (#2505)</li> </ul>"},{"location":"release_notes/#140-2020-11-07","title":"1.4.0 (2020-11-07)","text":""},{"location":"release_notes/#features_8","title":"Features","text":"<ul> <li>Add Struct.from_dict (#2514)</li> <li>Add hash and hashbytes support for BigQuery backend (#2310)</li> <li>Support reduction UDF without groupby to return multiple columns for Pandas backend (#2511)</li> <li>Support analytic and reduction UDF to return multiple columns for Pandas backend (#2487)</li> <li>Support elementwise UDF to return multiple columns for Pandas and PySpark backend (#2473)</li> <li>FEAT: Support Ibis interval for window in pyspark backend (#2409)</li> <li>Use Scope class for scope in pyspark backend (#2402)</li> <li>Add PySpark support for ReductionVectorizedUDF (#2366)</li> <li>Add time context in <code>scope</code> in execution for pandas backend (#2306)</li> <li>Add <code>start_point</code> and <code>end_point</code> to PostGIS backend. (#2081)</li> <li>Add set difference to general ibis api (#2347)</li> <li>Add <code>rowid</code> expression, supported by SQLite and OmniSciDB (#2251)</li> <li>Add intersection to general ibis api (#2230)</li> <li>Add <code>application_name</code> argument to <code>ibis.bigquery.connect</code> to allow attributing Google API requests to projects that use Ibis. (#2303)</li> <li>Add support for casting category dtype in pandas backend (#2285)</li> <li>Add support for Union in the PySpark backend (#2270)</li> <li>Add support for implementign custom window object for pandas backend (#2260)</li> <li>Implement two level dispatcher for execute_node (#2246)</li> <li>Add ibis.pandas.trace module to log time and call stack information. (#2233)</li> <li>Validate that the output type of a UDF is a single element (#2198)</li> <li>ZeroIfNull and NullIfZero implementation for OmniSciDB (#2186)</li> <li>IsNan implementation for OmniSciDB (#2093)</li> <li>[OmnisciDB] Support add_columns and drop_columns for OmnisciDB table (#2094)</li> <li>Create ExtractQuarter operation and add its support to Clickhouse, CSV, Impala, MySQL, OmniSciDB, Pandas, Parquet, PostgreSQL, PySpark, SQLite and Spark (#2175)</li> <li>Add translation rules for isnull() and notnull() for pyspark backend (#2126)</li> <li>Add window operations support to SQLite (#2232)</li> <li>Implement read_csv for omniscidb backend (#2062)</li> <li>[OmniSciDB] Add support to week extraction (#2171)</li> <li>Date, DateDiff and TimestampDiff implementations for OmniSciDB (#2097)</li> <li>Create ExtractWeekOfYear operation and add its support to Clickhouse, CSV, MySQL, Pandas, Parquet, PostgreSQL, PySpark and Spark (#2177)</li> <li>Add initial support for ibis.random function (#2060)</li> <li>Added epoch_seconds extraction operation to Clickhouse, CSV, Impala, MySQL, OmniSciDB, Pandas, Parquet, PostgreSQL, PySpark, SQLite, Spark and BigQuery :issue:<code>2273</code> (#2178)</li> <li>[OmniSciDB] Add \"method\" parameter to load_data (#2165)</li> <li>Add non-nullable info to schema output (#2117)</li> <li>fillna and nullif implementations for OmnisciDB (#2083)</li> <li>Add load_data to sqlalchemy's backends and fix database parameter for load/create/drop when database parameter is the same than the current database (#1981)</li> <li>[OmniSciDB] Add support for within, d_fully_within and point (#2125)</li> <li>OmniSciDB - Refactor DDL and Client; Add temporary parameter to create_table and \"force\" parameter to drop_view (#2086)</li> <li>Create ExtractDayOfYear operation and add its support to Clickhouse, CSV, MySQL, OmniSciDB, Pandas, Parquet, PostgreSQL, PySpark, SQLite and Spark (#2173)</li> <li>Implementations of Log Log2 Log10 for OmniSciDB backend (#2095)</li> </ul>"},{"location":"release_notes/#bugs_1","title":"Bugs","text":"<ul> <li>Table expressions do not recognize inet datatype (Postgres backend) (#2462)</li> <li>Table expressions do not recognize macaddr datatype (Postgres backend) (#2461)</li> <li>Fix <code>aggcontext.Summarize</code> not always producing scalar (Pandas backend) (#2410)</li> <li>Fix same window op with different window size on table lead to incorrect results for pyspark backend (#2414)</li> <li>Fix same column with multiple aliases not showing properly in repr (#2229)</li> <li>Fix reduction UDFs over ungrouped, bounded windows on Pandas backend (#2395)</li> <li>FEAT: Support rolling window UDF with non numeric inputs for pandas backend. (#2386)</li> <li>Fix scope get to use hashmap lookup instead of list lookup (#2386)</li> <li>Fix equality behavior for Literal ops (#2387)</li> <li>Fix analytic ops over ungrouped and unordered windows on Pandas backend (#2376)</li> <li>Fix the covariance operator in the BigQuery backend. (#2367)</li> <li>Update impala kerberos dependencies (#2342)</li> <li>Added verbose logging to SQL backends (#1320)</li> <li>Fix issue with sql_validate call to OmnisciDB. (#2256)</li> <li>Add missing float types to pandas backend (#2237)</li> <li>Allow group_by and order_by as window operation input in pandas backend (#2252)</li> <li>Fix PySpark compiler error when elementwise UDF output_type is Decimal or Timestamp (#2223)</li> <li>Fix interactive mode returning a expression instead of the value when used in Jupyter (#2157)</li> <li>Fix PySpark error when doing alias after selection (#2127)</li> <li>Fix millisecond issue for OmniSciDB :issue:<code>2167</code>, MySQL :issue:<code>2169</code>, PostgreSQL :issue:<code>2166</code>, Pandas :issue:<code>2168</code>, BigQuery :issue:<code>2273</code> backends (#2170)</li> <li>[OmniSciDB] Fix TopK when used as filter (#2134)</li> </ul>"},{"location":"release_notes/#support_1","title":"Support","text":"<ul> <li>Move <code>ibis.HDFS</code>, <code>ibis.WebHDFS</code> and <code>ibis.hdfs_connect</code> to <code>ibis.impala.*</code> (#2497)</li> <li>Drop support to Python 3.6 (#2288)</li> <li>Simplifying tests directories structure (#2351)</li> <li>Update <code>google-cloud-bigquery</code> dependency minimum version to 1.12.0 (#2304)</li> <li>Remove \"experimental\" mentions for OmniSciDB and Pandas backends (#2234)</li> <li>Use an OmniSciDB image stable on CI (#2244)</li> <li>Added fragment_size to table creation for OmniSciDB (#2107)</li> <li>Added round() support for OmniSciDB (#2096)</li> <li>Enabled cumulative ops support for OmniSciDB (#2113)</li> </ul>"},{"location":"release_notes/#130-2020-02-27","title":"1.3.0 (2020-02-27)","text":""},{"location":"release_notes/#features_9","title":"Features","text":"<ul> <li>Improve many arguments UDF performance in pandas backend. (#2071)</li> <li>Add DenseRank, RowNumber, MinRank, Count, PercentRank/CumeDist window operations to OmniSciDB (#1976)</li> <li>Introduce a top level vectorized UDF module (experimental). Implement element-wise UDF for pandas and PySpark backend. (#2047)</li> <li>Add support for  multi arguments window UDAF for the pandas backend (#2035)</li> <li>Clean up window translation logic in pyspark backend (#2004)</li> <li>Add docstring check to CI for an initial subset files (#1996)</li> <li>Pyspark backend bounded windows (#2001)</li> <li>Add more POSTGIS operations (#1987)</li> <li>SQLAlchemy Default precision and scale to decimal types for PostgreSQL and MySQL (#1969)</li> <li>Add support for array operations in PySpark backend (#1983)</li> <li>Implement sort, if_null, null_if and notin for PySpark backend (#1978)</li> <li>Add support for date/time operations in PySpark backend (#1974)</li> <li>Add support for params, query_schema, and sql in PySpark backend (#1973)</li> <li>Implement join for PySpark backend (#1967)</li> <li>Validate AsOfJoin tolerance and attempt interval unit conversion (#1952)</li> <li>filter for PySpark backend (#1943)</li> <li>window operations for pyspark backend (#1945)</li> <li>Implement IntervalSub for pandas backend (#1951)</li> <li>PySpark backend string and column ops (#1942)</li> <li>PySpark backend (#1913)</li> <li>DDL support for Spark backend (#1908)</li> <li>Support timezone aware arrow timestamps (#1923)</li> <li>Add shapely geometries as input for literals (#1860)</li> <li>Add geopandas as output for omniscidb (#1858)</li> <li>Spark UDFs (#1885)</li> <li>Add support for Postgres UDFs (#1871)</li> <li>Spark tests (#1830)</li> <li>Spark client (#1807)</li> <li>Use pandas rolling apply to implement rows_with_max_lookback (#1868)</li> </ul>"},{"location":"release_notes/#bugs_2","title":"Bugs","text":"<ul> <li>Pin \"clickhouse-driver\" to \"&gt;=0.1.3\" (#2089)</li> <li>Fix load data stage for Linux CI (#2069)</li> <li>Fix datamgr.py fail if IBIS_TEST_OMNISCIDB_DATABASE=omnisci (#2057)</li> <li>Change pymapd connection parameter from \"session_id\" to \"sessionid\" (#2041)</li> <li>Fix pandas backend to treat trailing_window preceding arg as window bound rather than window size (e.g. preceding=0 now indicates current row rather than window size 0) (#2009)</li> <li>Fix handling of Array types in Postgres UDF (#2015)</li> <li>Fix pydocstyle config (#2010)</li> <li>Pinning clickhouse-driver&lt;0.1.2 (#2006)</li> <li>Fix CI log for database (#1984)</li> <li>Fixes explain operation (#1933)</li> <li>Fix incorrect assumptions about attached SQLite databases (#1937)</li> <li>Upgrade to JDK11 (#1938)</li> <li><code>sql</code> method doesn't work when the query uses LIMIT clause (#1903)</li> <li>Fix union implementation (#1910)</li> <li>Fix failing com imports on master (#1912)</li> <li>OmniSci/MapD - Fix reduction for bool (#1901)</li> <li>Pass scope to grouping execution in the pandas backend (#1899)</li> <li>Fix various Spark backend issues (#1888)</li> <li>Make Nodes enforce the proper signature (#1891)</li> <li>Fix according to bug in pd.to_datetime when passing the unit flag (#1893)</li> <li>Fix small formatting buglet in PR merge tool (#1883)</li> <li>Fix the case where we do not have an index when using preceding with intervals (#1876)</li> <li>Fixed issues with geo data (#1872)</li> <li>Remove -x from pytest call in linux CI (#1869)</li> <li>Fix return type of Struct.from_tuples (#1867)</li> </ul>"},{"location":"release_notes/#support_2","title":"Support","text":"<ul> <li>Add support to Python 3.8 (#2066)</li> <li>Pin back version of isort (#2079)</li> <li>Use user-defined port variables for Omnisci and PostgreSQL tests (#2082)</li> <li>Change omniscidb image tag from v5.0.0 to v5.1.0 on docker-compose recipe (#2077)</li> <li>[Omnisci] The same SRIDs for test_geo_spatial_binops (#2051)</li> <li>Unpin rtree version (#2078)</li> <li>Link pandas issues with xfail tests in pandas/tests/test_udf.py (#2074)</li> <li>Disable Postgres tests on Windows CI. (#2075)</li> <li>use conda for installation black and isort tools (#2068)</li> <li>CI: Fix CI builds related to new pandas 1.0 compatibility (#2061)</li> <li>Fix data map for int8 on OmniSciDB backend (#2056)</li> <li>Add possibility to run tests for separate backend via <code>make test BACKENDS=[YOUR BACKEND]</code> (#2052)</li> <li>Fix \"cudf\" import on OmniSciDB backend (#2055)</li> <li>CI: Drop table only if it exists (OmniSciDB) (#2050)</li> <li>Add initial documentation for OmniSciDB, MySQL, PySpark and SparkSQL backends, add initial documentation for geospatial methods and add links to Ibis wiki page (#2034)</li> <li>Implement covariance for bigquery backend (#2044)</li> <li>Add Spark to supported backends list (#2046)</li> <li>Ping dependency of rtree to fix CI failure (#2043)</li> <li>Drop support for Python 3.5 (#2037)</li> <li>HTML escape column names and types in png repr. (#2023)</li> <li>Add geospatial tutorial notebook (#1991)</li> <li>Change omniscidb image tag from v4.7.0 to v5.0.0 on docker-compose recipe (#2031)</li> <li>Pin \"semantic_version\" to \"&lt;2.7\" in the docs build CI, fix \"builddoc\" and \"doc\" section inside \"Makefile\" and skip mysql tzinfo on CI to allow to run MySQL using docker container on a hard disk drive. (#2030)</li> <li>Fixed impala start up issues (#2012)</li> <li>cache all ops in translate() (#1999)</li> <li>Add black step to CI (#1988)</li> <li>Json UUID any (#1962)</li> <li>Add log for database services (#1982)</li> <li>Fix BigQuery backend fixture so batting and awards_players fixture re\u2026 (#1972)</li> <li>Disable BigQuery explicitly in all/test_join.py (#1971)</li> <li>Re-formatting all files using pre-commit hook (#1963)</li> <li>Disable codecov report upload during CI builds (#1961)</li> <li>Developer doc enhancements (#1960)</li> <li>Missing geospatial ops for OmniSciDB (#1958)</li> <li>Remove pandas deprecation warnings (#1950)</li> <li>Add developer docs to get docker setup (#1948)</li> <li>More informative IntegrityError on duplicate columns (#1949)</li> <li>Improve geospatial literals and smoke tests (#1928)</li> <li>PostGIS enhancements (#1925)</li> <li>Rename mapd to omniscidb backend (#1866)</li> <li>Fix failing BigQuery tests (#1926)</li> <li>Added missing null literal op (#1917)</li> <li>Update link to Presto website (#1895)</li> <li>Removing linting from windows (#1896)</li> <li>Fix link to NUMFOCUS CoC (#1884)</li> <li>Added CoC section (#1882)</li> <li>Remove pandas exception for rows_with_max_lookback (#1859)</li> <li>Move CI pipelines to Azure (#1856)</li> </ul>"},{"location":"release_notes/#120-2019-06-24","title":"1.2.0 (2019-06-24)","text":""},{"location":"release_notes/#features_10","title":"Features","text":"<ul> <li>Add new geospatial functions to OmniSciDB backend (#1836)</li> <li>allow pandas timedelta in rows_with_max_lookback (#1838)</li> <li>Accept rows-with-max-lookback as preceding parameter (#1825)</li> <li>PostGIS support (#1787)</li> </ul>"},{"location":"release_notes/#bugs_3","title":"Bugs","text":"<ul> <li>Fix call to psql causing failing CI (#1855)</li> <li>Fix nested array literal repr (#1851)</li> <li>Fix repr of empty schema (#1850)</li> <li>Add max_lookback to window replace and combine functions (#1843)</li> <li>Partially revert #1758 (#1837)</li> </ul>"},{"location":"release_notes/#support_3","title":"Support","text":"<ul> <li>Skip SQLAlchemy backend tests in connect method in backends.py (#1847)</li> <li>Validate order_by when using rows_with_max_lookback window (#1848)</li> <li>Generate release notes from commits (#1845)</li> <li>Raise exception on backends where rows_with_max_lookback can't be implemented (#1844)</li> <li>Tighter version spec for pytest (#1840)</li> <li>Allow passing a branch to ci/feedstock.py (#1826)</li> </ul>"},{"location":"release_notes/#110-2019-06-09","title":"1.1.0 (2019-06-09)","text":""},{"location":"release_notes/#features_11","title":"Features","text":"<ul> <li>Conslidate trailing window functions (#1809)</li> <li>Call to_interval when casting integers to intervals (#1766)</li> <li>Add session feature to mapd client API (#1796)</li> <li>Add min periods parameter to Window (#1792)</li> <li>Allow strings for types in pandas UDFs (#1785)</li> <li>Add missing date operations and struct field operation for the pandas backend (#1790)</li> <li>Add window operations to the OmniSci backend (#1771)</li> <li>Reimplement the pandas backend using topological sort (#1758)</li> <li>Add marker for xfailing specific backends (#1778)</li> <li>Enable window function tests where possible (#1777)</li> <li>is_computable_arg dispatcher (#1743)</li> <li>Added float32 and geospatial types for create table from schema (#1753)</li> </ul>"},{"location":"release_notes/#bugs_4","title":"Bugs","text":"<ul> <li>Fix group_concat test and implementations (#1819)</li> <li>Fix failing strftime tests on Python 3.7 (#1818)</li> <li>Remove unnecessary (and erroneous in some cases) frame clauses (#1757)</li> <li>Chained mutate operations are buggy (#1799)</li> <li>Allow projections from joins to attempt fusion (#1783)</li> <li>Fix Python 3.5 dependency versions (#1798)</li> <li>Fix compatibility and bugs associated with pandas toposort reimplementation (#1789)</li> <li>Fix outer_join generating LEFT join instead of FULL OUTER (#1772)</li> <li>NullIf should enforce that its arguments are castable to a common type (#1782)</li> <li>Fix conda create command in documentation (#1775)</li> <li>Fix preceding and following with <code>None</code> (#1765)</li> <li>PostgreSQL interval type not recognized (#1661)</li> </ul>"},{"location":"release_notes/#support_4","title":"Support","text":"<ul> <li>Remove decorator hacks and add custom markers (#1820)</li> <li>Add development deps to setup.py (#1814)</li> <li>Fix design and developer docs (#1805)</li> <li>Pin sphinx version to 2.0.1 (#1810)</li> <li>Add pep8speaks integration (#1793)</li> <li>Fix typo in UDF signature specification (#1821)</li> <li>Clean up most xpassing tests (#1779)</li> <li>Update omnisci container version (#1781)</li> <li>Constrain PyMapD version to get passing builds (#1776)</li> <li>Remove warnings and clean up some docstrings (#1763)</li> <li>Add StringToTimestamp as unsupported (#1638)</li> <li>Add isort pre-commit hooks (#1759)</li> <li>Add Python 3.5 testing back to CI (#1750)</li> <li>Re-enable CI for building step (#1700)</li> <li>Update README reference to MapD to say OmniSci (#1749)</li> </ul>"},{"location":"release_notes/#100-2019-03-26","title":"1.0.0 (2019-03-26)","text":""},{"location":"release_notes/#features_12","title":"Features","text":"<ul> <li>Add black as a pre-commit hook (#1735)</li> <li>Add support for the arbitrary aggregate in the mapd backend (#1680)</li> <li>Add SQL method for the MapD backend (#1731)</li> <li>Clean up merge PR script and use the actual merge feature of GitHub (#1744)</li> <li>Add cross join to the pandas backend (#1723)</li> <li>Implement default handler for multiple client <code>pre_execute</code> (#1727)</li> <li>Implement BigQuery auth using <code>pydata_google_auth</code> (#1728)</li> <li>Timestamp literal accepts a timezone parameter (#1712)</li> <li>Remove support for passing integers to <code>ibis.timestamp</code> (#1725)</li> <li>Add <code>find_nodes</code> to lineage (#1704)</li> <li>Remove a bunch of deprecated APIs and clean up warnings (#1714)</li> <li>Implement table distinct for the pandas backend (#1716)</li> <li>Implement geospatial functions for MapD (#1678)</li> <li>Implement geospatial types for MapD (#1666)</li> <li>Add pre commit hook (#1685)</li> <li>Getting started with mapd, mysql and pandas (#1686)</li> <li>Support column names with special characters in mapd (#1675)</li> <li>Allow operations to hide arguments from display (#1669)</li> <li>Remove implicit ordering requirements in the PostgreSQL backend (#1636)</li> <li>Add cross join operator to MapD (#1655)</li> <li>Fix UDF bugs and add support for non-aggregate analytic functions (#1637)</li> <li>Support string slicing with other expressions (#1627)</li> <li>Publish the ibis roadmap (#1618)</li> <li>Implement <code>approx_median</code> in BigQuery (#1604)</li> <li>Make ibis node instances hashable (#1611)</li> <li>Add <code>range_window</code> and <code>trailing_range_window</code> to docs (#1608)</li> </ul>"},{"location":"release_notes/#bugs_5","title":"Bugs","text":"<ul> <li>Make <code>dev/merge-pr.py</code> script handle PR branches (#1745)</li> <li>Fix <code>NULLIF</code> implementation for the pandas backend (#1742)</li> <li>Fix casting to float in the MapD backend (#1737)</li> <li>Fix testing for BigQuery after auth flow update (#1741)</li> <li>Fix skipping for new BigQuery auth flow (#1738)</li> <li>Fix bug in <code>TableExpr.drop</code> (#1732)</li> <li>Filter the <code>raw</code> warning from newer pandas to support older pandas (#1729)</li> <li>Fix BigQuery credentials link (#1706)</li> <li>Add Union as an unsuppoted operation for MapD (#1639)</li> <li>Fix visualizing an ibis expression when showing a selection after a table join (#1705)</li> <li>Fix MapD exception for <code>toDateTime</code> (#1659)</li> <li>Use <code>==</code> to compare strings (#1701)</li> <li>Resolves joining with different column names (#1647)</li> <li>Fix map get with compatible types (#1643)</li> <li>Fixed where operator for MapD (#1653)</li> <li>Remove parameters from mapd (#1648)</li> <li>Make sure we cast when NULL is else in CASE expressions (#1651)</li> <li>Fix equality (#1600)</li> </ul>"},{"location":"release_notes/#support_5","title":"Support","text":"<ul> <li>Do not build universal wheels (#1748)</li> <li>Remove tag prefix from versioneer (#1747)</li> <li>Use releases to manage documentation (#1746)</li> <li>Use cudf instead of pygdf (#1694)</li> <li>Fix multiple CI issues (#1696)</li> <li>Update mapd ci to v4.4.1 (#1681)</li> <li>Enabled mysql CI on azure pipelines (#1672)</li> <li>Remove support for Python 2 (#1670)</li> <li>Fix flake8 and many other warnings (#1667)</li> <li>Update README.md for impala and kudu (#1664)</li> <li>Remove defaults as a channel from azure pipelines (#1660)</li> <li>Fixes a very typo in the pandas/core.py docstring (#1658)</li> <li>Unpin clickhouse-driver version (#1657)</li> <li>Add test for reduction returning lists (#1650)</li> <li>Fix Azure VM image name (#1646)</li> <li>Updated MapD server-CI (#1641)</li> <li>Add TableExpr.drop to API documentation (#1645)</li> <li>Fix Azure deployment step (#1642)</li> <li>Set up CI with Azure Pipelines (#1640)</li> <li>Fix conda builds (#1609)</li> </ul>"},{"location":"release_notes/#v0140-2018-08-23","title":"v0.14.0 (2018-08-23)","text":"<p>This release brings refactored, more composable core components and rule system to ibis. We also focused quite heavily on the BigQuery backend this release.</p>"},{"location":"release_notes/#new-features","title":"New Features","text":"<ul> <li>Allow keyword arguments in Node subclasses (#968)</li> <li>Splat args into Node subclasses instead of requiring a list     (#969)</li> <li>Add support for <code>UNION</code> in the BigQuery backend     (#1408, #1409)</li> <li>Support for writing UDFs in BigQuery (#1377). See the BigQuery UDF docs for more details.</li> <li>Support for cross-project expressions in the BigQuery backend.     (#1427, #1428)</li> <li>Add <code>strftime</code> and <code>to_timestamp</code> support for BigQuery     (#1422, #1410)</li> <li>Require <code>google-cloud-bigquery &gt;=1.0</code> (#1424)</li> <li>Limited support for interval arithmetic in the pandas backend     (#1407)</li> <li>Support for subclassing <code>TableExpr</code> (#1439)</li> <li>Fill out pandas backend operations (#1423)</li> <li>Add common DDL APIs to the pandas backend (#1464)</li> <li>Implement the <code>sql</code> method for BigQuery (#1463)</li> <li>Add <code>to_timestamp</code> for BigQuery (#1455)</li> <li>Add the <code>mapd</code> backend (#1419)</li> <li>Implement range windows (#1349)</li> <li>Support for map types in the pandas backend     (#1498)</li> <li>Add <code>mean</code> and <code>sum</code> for <code>boolean</code> types in BigQuery     (#1516)</li> <li>All recent versions of SQLAlchemy are now suppported     (#1384)</li> <li>Add support for <code>NUMERIC</code> types in the BigQuery backend     (#1534)</li> <li>Speed up grouped and rolling operations in the pandas backend     (#1549)</li> <li>Implement <code>TimestampNow</code> for BigQuery and pandas     (#1575)</li> </ul>"},{"location":"release_notes/#bug-fixes_10","title":"Bug Fixes","text":"<ul> <li>Nullable property is now propagated through value types     (#1289)</li> <li>Implicit casting between signed and unsigned integers checks     boundaries</li> <li>Fix precedence of case statement (#1412)</li> <li>Fix handling of large timestamps (#1440)</li> <li>Fix <code>identical_to</code> precedence (#1458)</li> <li>Pandas 0.23 compatibility (#1458)</li> <li>Preserve timezones in timestamp-typed literals     (#1459)</li> <li>Fix incorrect topological ordering of <code>UNION</code> expressions     (#1501)</li> <li>Fix projection fusion bug when attempting to fuse columns of the     same name (#1496)</li> <li>Fix output type for some decimal operations     (#1541)</li> </ul>"},{"location":"release_notes/#api-changes","title":"API Changes","text":"<ul> <li>The previous, private rules API has been rewritten     (#1366)</li> <li>Defining input arguments for operations happens in a more readable     fashion instead of the previous [input_type]{.title-ref} list.</li> <li>Removed support for async query execution (only Impala supported)</li> <li>Remove support for Python 3.4 (#1326)</li> <li>BigQuery division defaults to using <code>IEEE_DIVIDE</code>     (#1390)</li> <li>Add <code>tolerance</code> parameter to <code>asof_join</code> (#1443)</li> </ul>"},{"location":"release_notes/#v0130-2018-03-30","title":"v0.13.0 (2018-03-30)","text":"<p>This release brings new backends, including support for executing against files, MySQL, Pandas user defined scalar and aggregations along with a number of bug fixes and reliability enhancements. We recommend that all users upgrade from earlier versions of Ibis.</p>"},{"location":"release_notes/#new-backends","title":"New Backends","text":"<ul> <li>File Support for CSV &amp; HDF5 (#1165, #1194)</li> <li>File Support for Parquet Format (#1175, #1194)</li> <li>Experimental support for <code>MySQL</code> thanks to \\@kszucs     (#1224)</li> </ul>"},{"location":"release_notes/#new-features_1","title":"New Features","text":"<ul> <li>Support for Unsigned Integer Types (#1194)</li> <li>Support for Interval types and expressions with support for     execution on the Impala and Clickhouse backends     (#1243)</li> <li>Isnan, isinf operations for float and double values     (#1261)</li> <li>Support for an interval with a quarter period     (#1259)</li> <li><code>ibis.pandas.from_dataframe</code> convenience function     (#1155)</li> <li>Remove the restriction on <code>ROW_NUMBER()</code> requiring it to have an     <code>ORDER BY</code> clause (#1371)</li> <li>Add <code>.get()</code> operation on a Map type (#1376)</li> <li>Allow visualization of custom defined expressions</li> <li>Add experimental support for pandas UDFs/UDAFs     (#1277)</li> <li>Functions can be used as groupby keys (#1214, #1215)</li> <li>Generalize the use of the <code>where</code> parameter to reduction operations     (#1220)</li> <li>Support for interval operations thanks to \\@kszucs     (#1243, #1260, #1249)</li> <li>Support for the <code>PARTITIONTIME</code> column in the BigQuery backend     (#1322)</li> <li>Add <code>arbitrary()</code> method for selecting the first non null value in a     column (#1230,     #1309)</li> <li>Windowed <code>MultiQuantile</code> operation in the pandas backend thanks to     \\@DiegoAlbertoTorres (#1343)</li> <li>Rules for validating table expressions thanks to     \\@DiegoAlbertoTorres (#1298)</li> <li>Complete end-to-end testing framework for all supported backends     (#1256)</li> <li><code>contains</code>/<code>not contains</code> now supported in the pandas backend     (#1210, #1211)</li> <li>CI builds are now reproducible locally thanks to \\@kszucs     (#1121, #1237, #1255,     #1311)</li> <li><code>isnan</code>/<code>isinf</code> operations thanks to \\@kszucs     (#1261)</li> <li>Framework for generalized dtype and schema inference, and implicit     casting thanks to \\@kszucs (#1221, #1269)</li> <li>Generic utilities for expression traversal thanks to \\@kszucs     (#1336)</li> <li><code>day_of_week</code> API (#306,     #1047)</li> <li>Design documentation for ibis (#1351)</li> </ul>"},{"location":"release_notes/#bug-fixes_11","title":"Bug Fixes","text":"<ul> <li>Unbound parameters were failing in the simple case of a     <code>ibis.expr.types.TableExpr.mutate</code>     call with no operation (#1378)</li> <li>Fix parameterized subqueries (#1300, #1331,     #1303, #1378)</li> <li>Fix subquery extraction, which wasn\\'t happening in topological     order (#1342)</li> <li>Fix parenthesization if <code>isnull</code> (#1307)</li> <li>Calling drop after mutate did not work (#1296, #1299)</li> <li>SQLAlchemy backends were missing an implementation of     <code>ibis.expr.operations.NotContains</code>.</li> <li>Support <code>REGEX_EXTRACT</code> in PostgreSQL 10 (#1276, #1278)</li> </ul>"},{"location":"release_notes/#api-changes_1","title":"API Changes","text":"<ul> <li>Fixing #1378 required the removal     of the <code>name</code> parameter to the <code>ibis.param</code> function. Use the     <code>ibis.expr.types.Expr.name</code> method     instead.</li> </ul>"},{"location":"release_notes/#v0120-2017-10-28","title":"v0.12.0 (2017-10-28)","text":"<p>This release brings Clickhouse and BigQuery SQL support along with a number of bug fixes and reliability enhancements. We recommend that all users upgrade from earlier versions of Ibis.</p>"},{"location":"release_notes/#new-backends_1","title":"New Backends","text":"<ul> <li>BigQuery backend (#1170), thanks     to \\@tsdlovell.</li> <li>Clickhouse backend (#1127),     thanks to \\@kszucs.</li> </ul>"},{"location":"release_notes/#new-features_2","title":"New Features","text":"<ul> <li>Add support for <code>Binary</code> data type (#1183)</li> <li>Allow users of the BigQuery client to define their own API proxy     classes (#1188)</li> <li>Add support for HAVING in the pandas backend     (#1182)</li> <li>Add struct field tab completion (#1178)</li> <li>Add expressions for Map/Struct types and columns     (#1166)</li> <li>Support Table.asof_join (#1162)</li> <li>Allow right side of arithmetic operations to take over     (#1150)</li> <li>Add a data_preload step in pandas backend (#1142)</li> <li>expressions in join predicates in the pandas backend     (#1138)</li> <li>Scalar parameters (#1075)</li> <li>Limited window function support for pandas (#1083)</li> <li>Implement Time datatype (#1105)</li> <li>Implement array ops for pandas (#1100)</li> <li>support for passing multiple quantiles in <code>.quantile()</code>     (#1094)</li> <li>support for clip and quantile ops on DoubleColumns     (#1090)</li> <li>Enable unary math operations for pandas, sqlite     (#1071)</li> <li>Enable casting from strings to temporal types     (#1076)</li> <li>Allow selection of whole tables in pandas joins     (#1072)</li> <li>Implement comparison for string vs date and timestamp types     (#1065)</li> <li>Implement isnull and notnull for pandas (#1066)</li> <li>Allow like operation to accept a list of conditions to match     (#1061)</li> <li>Add a pre_execute step in pandas backend (#1189)</li> </ul>"},{"location":"release_notes/#bug-fixes_12","title":"Bug Fixes","text":"<ul> <li>Remove global expression caching to ensure repeatable code     generation (#1179,     #1181)</li> <li>Fix <code>ORDER BY</code> generation without a <code>GROUP BY</code>     (#1180, #1181)</li> <li>Ensure that <code>~ibis.expr.datatypes.DataType</code> and subclasses hash properly (#1172)</li> <li>Ensure that the pandas backend can deal with unary operations in     groupby</li> <li>(#1182)</li> <li>Incorrect impala code generated for NOT with complex argument     (#1176)</li> <li>BUG/CLN: Fix predicates on Selections on Joins     (#1149)</li> <li>Don\\'t use SET LOCAL to allow redshift to work     (#1163)</li> <li>Allow empty arrays as arguments (#1154)</li> <li>Fix column renaming in groupby keys (#1151)</li> <li>Ensure that we only cast if timezone is not None     (#1147)</li> <li>Fix location of conftest.py (#1107)</li> <li>TST/Make sure we drop tables during postgres testing     (#1101)</li> <li>Fix misleading join error message (#1086)</li> <li>BUG/TST: Make hdfs an optional dependency (#1082)</li> <li>Memoization should include expression name where available     (#1080)</li> </ul>"},{"location":"release_notes/#performance-enhancements","title":"Performance Enhancements","text":"<ul> <li>Speed up imports (#1074)</li> <li>Fix execution perf of groupby and selection     (#1073)</li> <li>Use normalize for casting to dates in pandas     (#1070)</li> <li>Speed up pandas groupby (#1067)</li> </ul>"},{"location":"release_notes/#contributors","title":"Contributors","text":"<p>The following people contributed to the 0.12.0 release :</p> <pre><code>$ git shortlog -sn --no-merges v0.11.2..v0.12.0\n63  Phillip Cloud\n 8  Jeff Reback\n 2  Kriszti\u00e1n Sz\u0171cs\n 2  Tory Haavik\n 1  Anirudh\n 1  Szucs Krisztian\n 1  dlovell\n 1  kwangin\n</code></pre>"},{"location":"release_notes/#0110-2017-06-28","title":"0.11.0 (2017-06-28)","text":"<p>This release brings initial Pandas backend support along with a number of bug fixes and reliability enhancements. We recommend that all users upgrade from earlier versions of Ibis.</p>"},{"location":"release_notes/#new-features_3","title":"New Features","text":"<ul> <li>Experimental pandas backend to allow execution of ibis expression     against pandas DataFrames</li> <li>Graphviz visualization of ibis expressions. Implements <code>_repr_png_</code>     for Jupyter Notebook functionality</li> <li>Ability to create a partitioned table from an ibis expression</li> <li>Support for missing operations in the SQLite backend: sqrt, power,     variance, and standard deviation, regular expression functions, and     missing power support for PostgreSQL</li> <li>Support for schemas inside databases with the PostgreSQL backend</li> <li>Appveyor testing on core ibis across all supported Python versions</li> <li>Add <code>year</code>/<code>month</code>/<code>day</code> methods to <code>date</code> types</li> <li>Ability to sort, group by and project columns according to     positional index rather than only by name</li> <li>Added a <code>type</code> parameter to <code>ibis.literal</code> to allow user     specification of literal types</li> </ul>"},{"location":"release_notes/#bug-fixes_13","title":"Bug Fixes","text":"<ul> <li>Fix broken conda recipe</li> <li>Fix incorrectly typed fillna operation</li> <li>Fix postgres boolean summary operations</li> <li>Fix kudu support to reflect client API Changes</li> <li>Fix equality of nested types and construction of nested types when     the value type is specified as a string</li> </ul>"},{"location":"release_notes/#api-changes_2","title":"API Changes","text":"<ul> <li>Deprecate passing integer values to the <code>ibis.timestamp</code> literal     constructor, this will be removed in 0.12.0</li> <li>Added the <code>admin_timeout</code> parameter to the kudu client <code>connect</code>     function</li> </ul>"},{"location":"release_notes/#contributors_1","title":"Contributors","text":"<pre><code>$ git shortlog --summary --numbered v0.10.0..v0.11.0\n\n  58 Phillip Cloud\n   1 Greg Rahn\n   1 Marius van Niekerk\n   1 Tarun Gogineni\n   1 Wes McKinney\n</code></pre>"},{"location":"release_notes/#08-2016-05-19","title":"0.8 (2016-05-19)","text":"<p>This release brings initial PostgreSQL backend support along with a number of critical bug fixes and usability improvements. As several correctness bugs with the SQL compiler were fixed, we recommend that all users upgrade from earlier versions of Ibis.</p>"},{"location":"release_notes/#new-features_4","title":"New Features","text":"<ul> <li>Initial PostgreSQL backend contributed by Phillip Cloud.</li> <li>Add <code>groupby</code> as an alias for <code>group_by</code> to table expressions</li> </ul>"},{"location":"release_notes/#bug-fixes_14","title":"Bug Fixes","text":"<ul> <li>Fix an expression error when filtering based on a new field</li> <li>Fix Impala\\'s SQL compilation of using <code>OR</code> with compound filters</li> <li>Various fixes with the <code>having(...)</code> function in grouped table     expressions</li> <li>Fix CTE (<code>WITH</code>) extraction inside <code>UNION ALL</code> expressions.</li> <li>Fix <code>ImportError</code> on Python 2 when <code>mock</code> library not installed</li> </ul>"},{"location":"release_notes/#api-changes_3","title":"API Changes","text":"<ul> <li>The deprecated <code>ibis.impala_connect</code> and <code>ibis.make_client</code> APIs     have been removed</li> </ul>"},{"location":"release_notes/#07-2016-03-16","title":"0.7 (2016-03-16)","text":"<p>This release brings initial Kudu-Impala integration and improved Impala and SQLite support, along with several critical bug fixes.</p>"},{"location":"release_notes/#new-features_5","title":"New Features","text":"<ul> <li>Apache Kudu (incubating) integration for Impala users. Will     add some documentation here when possible.</li> <li>Add <code>use_https</code> option to <code>ibis.hdfs_connect</code> for WebHDFS     connections in secure (Kerberized) clusters without SSL enabled.</li> <li>Correctly compile aggregate expressions involving multiple     subqueries.</li> </ul> <p>To explain this last point in more detail, suppose you had:</p> <pre><code>table = ibis.table([('flag', 'string'),\n                    ('value', 'double')],\n                   'tbl')\n\nflagged = table[table.flag == '1']\nunflagged = table[table.flag == '0']\n\nfv = flagged.value\nuv = unflagged.value\n\nexpr = (fv.mean() / fv.sum()) - (uv.mean() / uv.sum())\n</code></pre> <p>The last expression now generates the correct Impala or SQLite SQL:</p> <pre><code>SELECT t0.`tmp` - t1.`tmp` AS `tmp`\nFROM (\nSELECT avg(`value`) / sum(`value`) AS `tmp`\nFROM tbl\nWHERE `flag` = '1'\n) t0\nCROSS JOIN (\nSELECT avg(`value`) / sum(`value`) AS `tmp`\nFROM tbl\nWHERE `flag` = '0'\n) t1\n</code></pre>"},{"location":"release_notes/#bug-fixes_15","title":"Bug Fixes","text":"<ul> <li><code>CHAR(n)</code> and <code>VARCHAR(n)</code> Impala types now correctly map to Ibis     string expressions</li> <li>Fix inappropriate projection-join-filter expression rewrites     resulting in incorrect generated SQL.</li> <li><code>ImpalaClient.create_table</code> correctly passes <code>STORED AS PARQUET</code> for     <code>format='parquet'</code>.</li> <li>Fixed several issues with Ibis dependencies (impyla, thriftpy, sasl,     thrift_sasl), especially for secure clusters. Upgrading will pull in     these new dependencies.</li> <li>Do not fail in <code>ibis.impala.connect</code> when trying to create the     temporary Ibis database if no HDFS connection passed.</li> <li>Fix join predicate evaluation bug when column names overlap with     table attributes.</li> <li>Fix handling of fully-materialized joins (aka <code>select *</code> joins) in     SQLAlchemy / SQLite.</li> </ul>"},{"location":"release_notes/#contributors_2","title":"Contributors","text":"<p>Thank you to all who contributed patches to this release.</p> <pre><code>$ git log v0.6.0..v0.7.0 --pretty=format:%aN | sort | uniq -c | sort -rn\n    21 Wes McKinney\n     1 Uri Laserson\n     1 Kristopher Overholt\n</code></pre>"},{"location":"release_notes/#06-2015-12-01","title":"0.6 (2015-12-01)","text":"<p>This release brings expanded pandas and Impala integration, including support for managing partitioned tables in Impala. See the new <code>Ibis for Impala Users</code> guide for more on using Ibis with Impala.</p> <p>The <code>Ibis for SQL Programmers</code> guide also was written since the 0.5 release.</p> <p>This release also includes bug fixes affecting generated SQL correctness. All users should upgrade as soon as possible.</p>"},{"location":"release_notes/#new-features_6","title":"New Features","text":"<ul> <li>New integrated Impala functionality. See <code>Ibis for Impala Users</code> for more details on     these things.<ul> <li>Improved Impala-pandas integration. Create tables or insert into     existing tables from pandas <code>DataFrame</code> objects.</li> <li>Partitioned table metadata management API. Add, drop, alter, and     insert into table partitions.</li> <li>Add <code>is_partitioned</code> property to <code>ImpalaTable</code>.</li> <li>Added support for <code>LOAD DATA</code> DDL using the <code>load_data</code>     function, also supporting partitioned tables.</li> <li>Modify table metadata (location, format, SerDe properties etc.)     using <code>ImpalaTable.alter</code></li> <li>Interrupting Impala expression execution with Control-C will     attempt to cancel the running query with the server.</li> <li>Set the compression codec (e.g. snappy) used with     <code>ImpalaClient.set_compression_codec</code>.</li> <li>Get and set query options for a client session with     <code>ImpalaClient.get_options</code> and <code>ImpalaClient.set_options</code>.</li> <li>Add <code>ImpalaTable.metadata</code> method that parses the output of the     <code>DESCRIBE FORMATTED</code> DDL to simplify table metadata inspection.</li> <li>Add <code>ImpalaTable.stats</code> and <code>ImpalaTable.column_stats</code> to see     computed table and partition statistics.</li> <li>Add <code>CHAR</code> and <code>VARCHAR</code> handling</li> <li>Add <code>refresh</code>, <code>invalidate_metadata</code> DDL options and add     <code>incremental</code> option to <code>compute_stats</code> for     <code>COMPUTE INCREMENTAL STATS</code>.</li> </ul> </li> <li>Add <code>substitute</code> method for performing multiple value substitutions     in an array or scalar expression.</li> <li>Division is by default true division like Python 3 for all numeric     data. This means for SQL systems that use C-style division     semantics, the appropriate <code>CAST</code> will be automatically inserted in     the generated SQL.</li> <li>Easier joins on tables with overlapping column names. See <code>Ibis for SQL Programmers</code>.</li> <li>Expressions like <code>string_expr[:3]</code> now work as expected.</li> <li>Add <code>coalesce</code> instance method to all value expressions.</li> <li>Passing <code>limit=None</code> to the <code>execute</code> method on expressions disables     any default row limits.</li> </ul>"},{"location":"release_notes/#api-changes_4","title":"API Changes","text":"<ul> <li><code>ImpalaTable.rename</code> no longer mutates the calling table expression.</li> </ul>"},{"location":"release_notes/#contributors_3","title":"Contributors","text":"<pre><code>$ git log v0.5.0..v0.6.0 --pretty=format:%aN | sort | uniq -c | sort -rn\n46 Wes McKinney\n 3 Uri Laserson\n 1 Phillip Cloud\n 1 mariusvniekerk\n 1 Kristopher Overholt\n</code></pre>"},{"location":"release_notes/#05-2015-09-10","title":"0.5 (2015-09-10)","text":"<p>Highlights in this release are the SQLite, Python 3, Impala UDA support, and an asynchronous execution API. There are also many usability improvements, bug fixes, and other new features.</p>"},{"location":"release_notes/#new-features_7","title":"New Features","text":"<ul> <li>SQLite client and built-in function support</li> <li>Ibis now supports Python 3.4 as well as 2.6 and 2.7</li> <li>Ibis can utilize Impala user-defined aggregate (UDA) functions</li> <li>SQLAlchemy-based translation toolchain to enable more SQL engines     having SQLAlchemy dialects to be supported</li> <li>Many window function usability improvements (nested analytic     functions and deferred binding conveniences)</li> <li>More convenient aggregation with keyword arguments in <code>aggregate</code>     functions</li> <li>Built preliminary wrapper API for MADLib-on-Impala</li> <li>Add <code>var</code> and <code>std</code> aggregation methods and support in Impala</li> <li>Add <code>nullifzero</code> numeric method for all SQL engines</li> <li>Add <code>rename</code> method to Impala tables (for renaming tables in the     Hive metastore)</li> <li>Add <code>close</code> method to <code>ImpalaClient</code> for session cleanup (#533)</li> <li>Add <code>relabel</code> method to table expressions</li> <li>Add <code>insert</code> method to Impala tables</li> <li>Add <code>compile</code> and <code>verify</code> methods to all expressions to test     compilation and ability to compile (since many operations are     unavailable in SQLite, for example)</li> </ul>"},{"location":"release_notes/#api-changes_5","title":"API Changes","text":"<ul> <li>Impala Ibis client creation now uses only <code>ibis.impala.connect</code>, and     <code>ibis.make_client</code> has been deprecated</li> </ul>"},{"location":"release_notes/#contributors_4","title":"Contributors","text":"<pre><code>$ git log v0.4.0..v0.5.0 --pretty=format:%aN | sort | uniq -c | sort -rn\n      55 Wes McKinney\n      9 Uri Laserson\n      1 Kristopher Overholt\n</code></pre>"},{"location":"release_notes/#04-2015-08-14","title":"0.4 (2015-08-14)","text":""},{"location":"release_notes/#new-features_8","title":"New Features","text":"<ul> <li>Add tooling to use Impala C++ scalar UDFs within Ibis (#262, #195)</li> <li>Support and testing for Kerberos-enabled secure HDFS clusters</li> <li>Many table functions can now accept functions as parameters (invoked     on the calling table) to enhance composability and emulate     late-binding semantics of languages (like R) that have non-standard     evaluation (#460)</li> <li>Add <code>any</code>, <code>all</code>, <code>notany</code>, and <code>notall</code> reductions on boolean     arrays, as well as <code>cumany</code> and <code>cumall</code></li> <li>Using <code>topk</code> now produces an analytic expression that is executable     (as an aggregation) but can also be used as a filter as before     (#392, #91)</li> <li>Added experimental database object \\\"usability layer\\\", see     <code>ImpalaClient.database</code>.</li> <li>Add <code>TableExpr.info</code></li> <li>Add <code>compute_stats</code> API to table expressions referencing physical     Impala tables</li> <li>Add <code>explain</code> method to <code>ImpalaClient</code> to show query plan for an     expression</li> <li>Add <code>chmod</code> and <code>chown</code> APIs to <code>HDFS</code> interface for superusers</li> <li>Add <code>convert_base</code> method to strings and integer types</li> <li>Add option to <code>ImpalaClient.create_table</code> to create empty     partitioned tables</li> <li><code>ibis.cross_join</code> can now join more than 2 tables at once</li> <li>Add <code>ImpalaClient.raw_sql</code> method for running naked SQL queries</li> <li><code>ImpalaClient.insert</code> now validates schemas locally prior to sending     query to cluster, for better usability.</li> <li>Add conda installation recipes</li> </ul>"},{"location":"release_notes/#contributors_5","title":"Contributors","text":"<pre><code>$ git log v0.3.0..v0.4.0 --pretty=format:%aN | sort | uniq -c | sort -rn\n     38 Wes McKinney\n      9 Uri Laserson\n      2 Meghana Vuyyuru\n      2 Kristopher Overholt\n      1 Marius van Niekerk\n</code></pre>"},{"location":"release_notes/#03-2015-07-20","title":"0.3 (2015-07-20)","text":"<p>First public release. See https://ibis-project.org for more.</p>"},{"location":"release_notes/#new-features_9","title":"New Features","text":"<ul> <li>Implement window / analytic function support</li> <li>Enable non-equijoins (join clauses with operations other than <code>==</code>).</li> <li>Add remaining <code>string functions</code> supported by Impala.</li> <li>Add <code>pipe</code> method to tables (hat-tip to the pandas dev team).</li> <li>Add <code>mutate</code> convenience method to tables.</li> <li>Fleshed out <code>WebHDFS</code> implementations: get/put directories, move     files, etc. See the <code>full HDFS API</code>.</li> <li>Add <code>truncate</code> method for timestamp values</li> <li><code>ImpalaClient</code> can execute scalar expressions not involving any     table.</li> <li>Can also create internal Impala tables with a specific HDFS path.</li> <li>Make Ibis\\'s temporary Impala database and HDFS paths configurable     (see <code>ibis.options</code>).</li> <li>Add <code>truncate_table</code> function to client (if the user\\'s Impala     cluster supports it).</li> <li>Python 2.6 compatibility</li> <li>Enable Ibis to execute concurrent queries in multithreaded     applications (earlier versions were not thread-safe).</li> <li>Test data load script in <code>scripts/load_test_data.py</code></li> <li>Add an internal operation type signature API to enhance developer     productivity.</li> </ul>"},{"location":"release_notes/#contributors_6","title":"Contributors","text":"<pre><code>$ git log v0.2.0..v0.3.0 --pretty=format:%aN | sort | uniq -c | sort -rn\n     59 Wes McKinney\n     29 Uri Laserson\n      4 Isaac Hodes\n      2 Meghana Vuyyuru\n</code></pre>"},{"location":"release_notes/#02-2015-06-16","title":"0.2 (2015-06-16)","text":""},{"location":"release_notes/#new-features_10","title":"New Features","text":"<ul> <li><code>insert</code> method on Ibis client for inserting data into existing     tables.</li> <li><code>parquet_file</code>, <code>delimited_file</code>, and <code>avro_file</code> client methods for     querying datasets not yet available in Impala</li> <li>New <code>ibis.hdfs_connect</code> method and <code>HDFS</code> client API for WebHDFS for     writing files and directories to HDFS</li> <li>New timedelta API and improved timestamp data support</li> <li>New <code>bucket</code> and <code>histogram</code> methods on numeric expressions</li> <li>New <code>category</code> logical datatype for handling bucketed data, among     other things</li> <li>Add <code>summary</code> API to numeric expressions</li> <li>Add <code>value_counts</code> convenience API to array expressions</li> <li>New string methods <code>like</code>, <code>rlike</code>, and <code>contains</code> for fuzzy and     regex searching</li> <li>Add <code>options.verbose</code> option and configurable <code>options.verbose_log</code>     callback function for improved query logging and visibility</li> <li>Support for new SQL built-in functions<ul> <li><code>ibis.coalesce</code></li> <li><code>ibis.greatest</code> and <code>ibis.least</code></li> <li><code>ibis.where</code> for conditional logic (see also <code>ibis.case</code> and     <code>ibis.cases</code>)</li> <li><code>nullif</code> method on value expressions</li> <li><code>ibis.now</code></li> </ul> </li> <li>New aggregate functions: <code>approx_median</code>, <code>approx_nunique</code>, and     <code>group_concat</code></li> <li><code>where</code> argument in aggregate functions</li> <li>Add <code>having</code> method to <code>group_by</code> intermediate object</li> <li>Added group-by convenience     <code>table.group_by(exprs).COLUMN_NAME.agg_function()</code></li> <li>Add default expression names to most aggregate functions</li> <li>New Impala database client helper methods<ul> <li><code>create_database</code></li> <li><code>drop_database</code></li> <li><code>exists_database</code></li> <li><code>list_databases</code></li> <li><code>set_database</code></li> </ul> </li> <li>Client <code>list_tables</code> searching / listing method</li> <li>Add <code>add</code>, <code>sub</code>, and other explicit arithmetic methods to value     expressions</li> </ul>"},{"location":"release_notes/#api-changes_6","title":"API Changes","text":"<ul> <li>New Ibis client and Impala connection workflow. Client now combined     from an Impala connection and an optional HDFS connection</li> </ul>"},{"location":"release_notes/#bug-fixes_16","title":"Bug Fixes","text":"<ul> <li>Numerous expression API bug fixes and rough edges fixed</li> </ul>"},{"location":"release_notes/#contributors_7","title":"Contributors","text":"<pre><code>$ git log v0.1.0..v0.2.0 --pretty=format:%aN | sort | uniq -c | sort -rn\n     71 Wes McKinney\n      1 Juliet Hougland\n      1 Isaac Hodes\n</code></pre>"},{"location":"release_notes/#01-2015-03-26","title":"0.1 (2015-03-26)","text":"<p>First Ibis release.</p> <ul> <li>Expression DSL design and type system</li> <li>Expression to ImpalaSQL compiler toolchain</li> <li> <p>Impala built-in function wrappers</p> <p>$ git log 84d0435..v0.1.0 --pretty=format:%aN | sort | uniq -c | sort -rn     78 Wes McKinney      1 srus      1 Henry Robinson</p> </li> </ul>"},{"location":"api/config/","title":"Configuration Options","text":""},{"location":"api/config/#ibis.config.Options","title":"<code>Options</code>","text":"<p>Ibis configuration options.</p> <p>Attributes:</p> Name Type Description <code>interactive</code> <code>bool</code> <p>Show the first few rows of computing an expression when in a repl.</p> <code>repr</code> <code>Repr</code> <p>Options controlling expression printing.</p> <code>verbose</code> <code>bool</code> <p>Run in verbose mode if <code>True</code></p> <code>verbose_log</code> <code>Callable[[str], None] | None</code> <p>A callable to use when logging.</p> <code>graphviz_repr</code> <code>bool</code> <p>Render expressions as GraphViz PNGs when running in a Jupyter notebook.</p> <code>default_backend</code> <code>Optional[ibis.backends.base.BaseBackend], default None</code> <p>The default backend to use for execution, defaults to DuckDB if not set.</p> <code>context_adjustment</code> <code>ContextAdjustment</code> <p>Options related to time context adjustment.</p> <code>sql</code> <code>SQL</code> <p>SQL-related options.</p> <code>clickhouse</code> <code>Config | None</code> <p>Clickhouse specific options.</p> <code>dask</code> <code>Config | None</code> <p>Dask specific options.</p> <code>impala</code> <code>Config | None</code> <p>Impala specific options.</p> <code>pandas</code> <code>Config | None</code> <p>Pandas specific options.</p> <code>pyspark</code> <code>Config | None</code> <p>PySpark specific options.</p>"},{"location":"api/config/#ibis.config.Repr","title":"<code>Repr</code>","text":"<p>Expression printing options.</p> <p>Attributes:</p> Name Type Description <code>depth</code> <code>int</code> <p>The maximum number of expression nodes to print when repring.</p> <code>table_columns</code> <code>int</code> <p>The number of columns to show in leaf table expressions.</p> <code>query_text_length</code> <code>int</code> <p>The maximum number of characters to show in the <code>query</code> field repr of SQLQueryResult operations.</p> <code>show_types</code> <code>bool</code> <p>Show the inferred type of value expressions in the repr.</p> <code>interactive</code> <code>bool</code> <p>Options controlling the interactive repr.</p>"},{"location":"api/config/#ibis.config.SQL","title":"<code>SQL</code>","text":"<p>SQL-related options.</p> <p>Attributes:</p> Name Type Description <code>default_limit</code> <code>int | None</code> <p>Number of rows to be retrieved for a table expression without an explicit limit. <code>None</code> means no limit.</p> <code>default_dialect</code> <code>str</code> <p>Dialect to use for printing SQL when the backend cannot be determined.</p>"},{"location":"api/config/#ibis.config.ContextAdjustment","title":"<code>ContextAdjustment</code>","text":"<p>Options related to time context adjustment.</p> <p>Attributes:</p> Name Type Description <code>time_col</code> <code>str</code> <p>Name of the timestamp column for execution with a <code>timecontext</code>. See <code>ibis/expr/timecontext.py</code> for details.</p>"},{"location":"api/datatypes/","title":"Data Types","text":"<p>This module contains classes for handling the different logical types that occur in databases.</p> <p>All data type constructors take a <code>nullable: bool</code> parameter whose default value is <code>True</code>.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core","title":"<code>core</code>","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core-classes","title":"Classes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.Array","title":"<code>Array</code>","text":"<p>         Bases: <code>Variadic</code>, <code>Parametric</code></p> <p>Array values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Binary","title":"<code>Binary</code>","text":"<p>         Bases: <code>Variadic</code>, <code>Singleton</code></p> <p>A type representing a sequence of bytes.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Binary--notes","title":"Notes","text":"<p>Some databases treat strings and blobs of equally, and some do not.</p> <p>For example, Impala doesn't make a distinction between string and binary types but PostgreSQL has a <code>TEXT</code> type and a <code>BYTEA</code> type which are distinct types that have different behavior.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Boolean","title":"<code>Boolean</code>","text":"<p>         Bases: <code>Primitive</code></p> <p><code>True</code> or <code>False</code> values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Bounds","title":"<code>Bounds</code>","text":"<p>         Bases: <code>NamedTuple</code></p> <p>The lower and upper bound of a fixed-size value.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.DataType","title":"<code>DataType</code>","text":"<p>         Bases: <code>Concrete</code></p> <p>Base class for all data types.</p> <p><code>DataType</code> instances are immutable.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.DataType-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.DataType.name","title":"<code>name: str</code>  <code>property</code>","text":"<p>Return the name of the data type.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.DataType-functions","title":"Functions","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.DataType.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Return the equivalent pandas datatype.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.DataType.to_pyarrow","title":"<code>to_pyarrow()</code>","text":"<p>Return the equivalent pyarrow datatype.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Date","title":"<code>Date</code>","text":"<p>         Bases: <code>Temporal</code>, <code>Primitive</code></p> <p>Date values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Decimal","title":"<code>Decimal</code>","text":"<p>         Bases: <code>Numeric</code>, <code>Parametric</code></p> <p>Fixed-precision decimal values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Decimal-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.Decimal.largest","title":"<code>largest</code>  <code>property</code>","text":"<p>Return the largest type of decimal.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Decimal.precision","title":"<code>precision = optional(instance_of(int))</code>  <code>class-attribute</code>","text":"<p>The number of decimal places values of this type can hold.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Decimal.scale","title":"<code>scale = optional(instance_of(int))</code>  <code>class-attribute</code>","text":"<p>The number of values after the decimal point.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Float16","title":"<code>Float16</code>","text":"<p>         Bases: <code>Floating</code></p> <p>16-bit floating point numbers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Float32","title":"<code>Float32</code>","text":"<p>         Bases: <code>Floating</code></p> <p>32-bit floating point numbers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Float64","title":"<code>Float64</code>","text":"<p>         Bases: <code>Floating</code></p> <p>64-bit floating point numbers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Floating","title":"<code>Floating</code>","text":"<p>         Bases: <code>Primitive</code>, <code>Numeric</code></p> <p>Floating point values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Floating-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.Floating.largest","title":"<code>largest</code>  <code>property</code>","text":"<p>Return the largest type of floating point values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.GeoSpatial","title":"<code>GeoSpatial</code>","text":"<p>         Bases: <code>DataType</code></p> <p>Geospatial values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.GeoSpatial-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.GeoSpatial.geotype","title":"<code>geotype = optional(isin({'geography', 'geometry'}))</code>  <code>class-attribute</code>","text":"<p>The specific geospatial type.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.GeoSpatial.srid","title":"<code>srid = optional(instance_of(int))</code>  <code>class-attribute</code>","text":"<p>The spatial reference identifier.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.INET","title":"<code>INET</code>","text":"<p>         Bases: <code>String</code></p> <p>IP addresses.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Int16","title":"<code>Int16</code>","text":"<p>         Bases: <code>SignedInteger</code></p> <p>Signed 16-bit integers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Int32","title":"<code>Int32</code>","text":"<p>         Bases: <code>SignedInteger</code></p> <p>Signed 32-bit integers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Int64","title":"<code>Int64</code>","text":"<p>         Bases: <code>SignedInteger</code></p> <p>Signed 64-bit integers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Int8","title":"<code>Int8</code>","text":"<p>         Bases: <code>SignedInteger</code></p> <p>Signed 8-bit integers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Integer","title":"<code>Integer</code>","text":"<p>         Bases: <code>Primitive</code>, <code>Numeric</code></p> <p>Integer values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Integer-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.Integer.nbytes","title":"<code>nbytes: int</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Return the number of bytes used to store values of this type.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Interval","title":"<code>Interval</code>","text":"<p>         Bases: <code>Parametric</code></p> <p>Interval values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Interval-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.Interval.resolution","title":"<code>resolution</code>  <code>property</code>","text":"<p>The interval unit's name.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Interval.unit","title":"<code>unit = optional(map_to(__valid_units__), default='s')</code>  <code>class-attribute</code>","text":"<p>The time unit of the interval.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Interval.value_type","title":"<code>value_type = optional(all_of([datatype, instance_of(Integer)]), default=Int32())</code>  <code>class-attribute</code>","text":"<p>The underlying type of the stored values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.JSON","title":"<code>JSON</code>","text":"<p>         Bases: <code>Variadic</code></p> <p>JSON values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.LineString","title":"<code>LineString</code>","text":"<p>         Bases: <code>GeoSpatial</code></p> <p>A sequence of 2 or more points.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.MACADDR","title":"<code>MACADDR</code>","text":"<p>         Bases: <code>String</code></p> <p>Media Access Control (MAC) address of a network interface.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Map","title":"<code>Map</code>","text":"<p>         Bases: <code>Variadic</code>, <code>Parametric</code></p> <p>Associative array values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.MultiLineString","title":"<code>MultiLineString</code>","text":"<p>         Bases: <code>GeoSpatial</code></p> <p>A set of one or more line strings.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.MultiPoint","title":"<code>MultiPoint</code>","text":"<p>         Bases: <code>GeoSpatial</code></p> <p>A set of one or more points.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.MultiPolygon","title":"<code>MultiPolygon</code>","text":"<p>         Bases: <code>GeoSpatial</code></p> <p>A set of one or more polygons.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Null","title":"<code>Null</code>","text":"<p>         Bases: <code>Primitive</code></p> <p>Null values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Numeric","title":"<code>Numeric</code>","text":"<p>         Bases: <code>DataType</code></p> <p>Numeric types.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Parametric","title":"<code>Parametric</code>","text":"<p>         Bases: <code>DataType</code></p> <p>Types that can be parameterized.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Point","title":"<code>Point</code>","text":"<p>         Bases: <code>GeoSpatial</code></p> <p>A point described by two coordinates.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Polygon","title":"<code>Polygon</code>","text":"<p>         Bases: <code>GeoSpatial</code></p> <p>A set of one or more closed line strings.</p> <p>The first line string represents the shape (external ring) and the rest represent holes in that shape (internal rings).</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Primitive","title":"<code>Primitive</code>","text":"<p>         Bases: <code>DataType</code>, <code>Singleton</code></p> <p>Values with known size.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Set","title":"<code>Set</code>","text":"<p>         Bases: <code>Variadic</code>, <code>Parametric</code></p> <p>Set values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.SignedInteger","title":"<code>SignedInteger</code>","text":"<p>         Bases: <code>Integer</code></p> <p>Signed integer values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.SignedInteger-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.SignedInteger.largest","title":"<code>largest</code>  <code>property</code>","text":"<p>Return the largest type of signed integer.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.String","title":"<code>String</code>","text":"<p>         Bases: <code>Variadic</code>, <code>Singleton</code></p> <p>A type representing a string.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.String--notes","title":"Notes","text":"<p>Because of differences in the way different backends handle strings, we cannot assume that strings are UTF-8 encoded.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Struct","title":"<code>Struct</code>","text":"<p>         Bases: <code>Parametric</code>, <code>MapSet</code></p> <p>Structured values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Struct-functions","title":"Functions","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.Struct.from_tuples","title":"<code>from_tuples(pairs, nullable=True)</code>  <code>classmethod</code>","text":"<p>Construct a <code>Struct</code> type from pairs.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>Iterable[tuple[str, str | DataType]]</code> <p>An iterable of pairs of field name and type</p> required <code>nullable</code> <code>bool</code> <p>Whether the type is nullable</p> <code>True</code> <p>Returns:</p> Type Description <code>Struct</code> <p>Struct data type instance</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Struct.names","title":"<code>names()</code>","text":"<p>Return the names of the struct's fields.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Struct.types","title":"<code>types()</code>","text":"<p>Return the types of the struct's fields.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Temporal","title":"<code>Temporal</code>","text":"<p>         Bases: <code>DataType</code></p> <p>Data types related to time.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Time","title":"<code>Time</code>","text":"<p>         Bases: <code>Temporal</code>, <code>Primitive</code></p> <p>Time values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Timestamp","title":"<code>Timestamp</code>","text":"<p>         Bases: <code>Temporal</code>, <code>Parametric</code></p> <p>Timestamp values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Timestamp-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.Timestamp.scale","title":"<code>scale = optional(isin(range(10)))</code>  <code>class-attribute</code>","text":"<p>The scale of the timestamp if known.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Timestamp.timezone","title":"<code>timezone = optional(instance_of(str))</code>  <code>class-attribute</code>","text":"<p>The timezone of values of this type.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.UInt16","title":"<code>UInt16</code>","text":"<p>         Bases: <code>UnsignedInteger</code></p> <p>Unsigned 16-bit integers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.UInt32","title":"<code>UInt32</code>","text":"<p>         Bases: <code>UnsignedInteger</code></p> <p>Unsigned 32-bit integers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.UInt64","title":"<code>UInt64</code>","text":"<p>         Bases: <code>UnsignedInteger</code></p> <p>Unsigned 64-bit integers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.UInt8","title":"<code>UInt8</code>","text":"<p>         Bases: <code>UnsignedInteger</code></p> <p>Unsigned 8-bit integers.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.UUID","title":"<code>UUID</code>","text":"<p>         Bases: <code>DataType</code></p> <p>A 128-bit number used to identify information in computer systems.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.UnsignedInteger","title":"<code>UnsignedInteger</code>","text":"<p>         Bases: <code>Integer</code></p> <p>Unsigned integer values.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.UnsignedInteger-attributes","title":"Attributes","text":""},{"location":"api/datatypes/#ibis.expr.datatypes.core.UnsignedInteger.largest","title":"<code>largest</code>  <code>property</code>","text":"<p>Return the largest type of unsigned integer.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core.Variadic","title":"<code>Variadic</code>","text":"<p>         Bases: <code>DataType</code></p> <p>Values with unknown size.</p>"},{"location":"api/datatypes/#ibis.expr.datatypes.core-functions","title":"Functions","text":""},{"location":"api/schemas/","title":"Schemas","text":"<p>This module contains APIs for interacting with table schemas.</p>"},{"location":"api/schemas/#ibis.expr.schema.Schema","title":"<code>Schema</code>","text":"<p>         Bases: <code>Concrete</code>, <code>Coercible</code>, <code>MapSet</code></p> <p>An object for holding table schema information.</p>"},{"location":"api/schemas/#ibis.expr.schema.Schema-attributes","title":"Attributes","text":""},{"location":"api/schemas/#ibis.expr.schema.Schema.fields","title":"<code>fields = frozendict_of(instance_of(str), datatype)</code>  <code>class-attribute</code>","text":"<p>A mapping of <code>str</code> to <code>DataType</code> objects representing the type of each column.</p>"},{"location":"api/schemas/#ibis.expr.schema.Schema-functions","title":"Functions","text":""},{"location":"api/schemas/#ibis.expr.schema.Schema.apply_to","title":"<code>apply_to(df)</code>","text":"<p>Apply the schema <code>self</code> to a pandas <code>DataFrame</code>.</p> <p>This method mutates the input <code>DataFrame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>Input DataFrame</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Type-converted DataFrame</p> <p>Examples:</p> <p>Import the necessary modules</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.datatypes as dt\n</code></pre> <p>Construct a DataFrame with string timestamps and an <code>int8</code> column that we're going to upcast.</p> <pre><code>&gt;&gt;&gt; data = dict(\n...     times=[\n...         \"2022-01-01 12:00:00\",\n...         \"2022-01-01 13:00:01\",\n...         \"2022-01-01 14:00:02\",\n...     ],\n...     x=np.array([-1, 0, 1], dtype=\"int8\")\n... )\n&gt;&gt;&gt; df = pd.DataFrame(data)\n&gt;&gt;&gt; df\n                 times  x\n0  2022-01-01 12:00:00 -1\n1  2022-01-01 13:00:01  0\n2  2022-01-01 14:00:02  1\n&gt;&gt;&gt; df.dtypes\ntimes    object\nx          int8\ndtype: object\n</code></pre> <p>Construct an ibis Schema that we want to cast to.</p> <pre><code>&gt;&gt;&gt; sch = ibis.schema({\"times\": dt.timestamp, \"x\": \"int16\"})\n&gt;&gt;&gt; sch\nibis.Schema {\n  times  timestamp\n  x      int16\n}\n</code></pre> <p>Apply the schema</p> <pre><code>&gt;&gt;&gt; sch.apply_to(df)\n                times  x\n0 2022-01-01 12:00:00 -1\n1 2022-01-01 13:00:01  0\n2 2022-01-01 14:00:02  1\n&gt;&gt;&gt; df.dtypes  # `df` is mutated by the method\ntimes    datetime64[ns]\nx                 int16\ndtype: object\n</code></pre>"},{"location":"api/schemas/#ibis.expr.schema.Schema.equals","title":"<code>equals(other)</code>","text":"<p>Return whether <code>other</code> is equal to <code>self</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Schema</code> <p>Schema to compare <code>self</code> to.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; first = ibis.schema({\"a\": \"int\"})\n&gt;&gt;&gt; second = ibis.schema({\"a\": \"int\"})\n&gt;&gt;&gt; assert first.equals(second)\n&gt;&gt;&gt; third = ibis.schema({\"a\": \"array&lt;int&gt;\"})\n&gt;&gt;&gt; assert not first.equals(third)\n</code></pre>"},{"location":"api/schemas/#ibis.expr.schema.Schema.from_tuples","title":"<code>from_tuples(values)</code>  <code>classmethod</code>","text":"<p>Construct a <code>Schema</code> from an iterable of pairs.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Iterable[tuple[str, str | dt.DataType]]</code> <p>An iterable of pairs of name and type.</p> required <p>Returns:</p> Type Description <code>Schema</code> <p>A new schema</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.Schema.from_tuples([(\"a\", \"int\"), (\"b\", \"string\")])\nibis.Schema {\n  a  int64\n  b  string\n}\n</code></pre>"},{"location":"api/schemas/#ibis.expr.schema.Schema.merge","title":"<code>merge(other)</code>","text":"<p>Merge <code>other</code> to <code>self</code>.</p> <p>Raise an <code>IntegrityError</code> if there are duplicate column names.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Schema</code> <p>Schema instance to append to <code>self</code>.</p> required <p>Returns:</p> Type Description <code>Schema</code> <p>A new schema appended with <code>schema</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; first = ibis.Schema({\"a\": \"int\", \"b\": \"string\"})\n&gt;&gt;&gt; second = ibis.Schema({\"c\": \"float\", \"d\": \"int16\"})\n&gt;&gt;&gt; first.merge(second)\nibis.Schema {\n  a  int64\n  b  string\n  c  float64\n  d  int16\n}\n</code></pre>"},{"location":"api/schemas/#ibis.expr.schema.Schema.name_at_position","title":"<code>name_at_position(i)</code>","text":"<p>Return the name of a schema column at position <code>i</code>.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>The position of the column</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the column in the schema at position <code>i</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; sch = ibis.Schema({\"a\": \"int\", \"b\": \"string\"})\n&gt;&gt;&gt; sch.name_at_position(0)\n'a'\n&gt;&gt;&gt; sch.name_at_position(1)\n'b'\n</code></pre>"},{"location":"api/schemas/#ibis.expr.schema.Schema.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Return the equivalent pandas datatypes.</p>"},{"location":"api/schemas/#ibis.expr.schema.Schema.to_pyarrow","title":"<code>to_pyarrow()</code>","text":"<p>Return the equivalent pyarrow schema.</p>"},{"location":"api/selectors/","title":"Column Selectors","text":""},{"location":"api/selectors/#ibis.expr.selectors","title":"<code>selectors</code>","text":"<p>Convenient column selectors.</p>"},{"location":"api/selectors/#ibis.expr.selectors--rationale","title":"Rationale","text":"<p>Column selectors are convenience functions for selecting columns that share some property.</p>"},{"location":"api/selectors/#ibis.expr.selectors--discussion","title":"Discussion","text":"<p>For example, a common task is to be able to select all numeric columns for a subsequent computation.</p> <p>Without selectors this becomes quite verbose and tedious to write:</p> <pre><code>&gt;&gt;&gt; t.select([t[c] for c in t.columns if t[c].type().is_numeric()])  # doctest: +SKIP\n</code></pre> <p>Compare that to the <code>numeric</code> selector:</p> <pre><code>&gt;&gt;&gt; t.select(s.numeric())  # doctest: +SKIP\n</code></pre> <p>When there are multiple properties to check it gets worse:</p> <pre><code>&gt;&gt;&gt; t.select(  # doctest: +SKIP\n...     [\n...         t[c] for c in t.columns\n...         if t[c].type().is_numeric()\n...         if (\"a\" in c.get_name() or \"cd\" in c.get_name())\n...     ]\n... )\n</code></pre> <p>Using a composition of selectors this is much less tiresome:</p> <pre><code>&gt;&gt;&gt; t.select(s.numeric() &amp; s.contains((\"a\", \"cd\")))  # doctest: +SKIP\n</code></pre>"},{"location":"api/selectors/#ibis.expr.selectors-classes","title":"Classes","text":""},{"location":"api/selectors/#ibis.expr.selectors.Predicate","title":"<code>Predicate</code>","text":"<p>         Bases: <code>Selector</code></p>"},{"location":"api/selectors/#ibis.expr.selectors.Predicate-functions","title":"Functions","text":""},{"location":"api/selectors/#ibis.expr.selectors.Predicate.__and__","title":"<code>__and__(other)</code>","text":"<p>Compute the conjunction of two <code>Selectors</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Selector</code> <p>Another selector</p> required"},{"location":"api/selectors/#ibis.expr.selectors.Predicate.__invert__","title":"<code>__invert__()</code>","text":"<p>Compute the logical negation of two <code>Selectors</code>.</p>"},{"location":"api/selectors/#ibis.expr.selectors.Predicate.__or__","title":"<code>__or__(other)</code>","text":"<p>Compute the disjunction of two <code>Selectors</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Selector</code> <p>Another selector</p> required"},{"location":"api/selectors/#ibis.expr.selectors.Predicate.expand","title":"<code>expand(table)</code>","text":"<p>Evaluate <code>self.predicate</code> on every column of <code>table</code>.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>ir.Table</code> <p>An ibis table expression</p> required"},{"location":"api/selectors/#ibis.expr.selectors-functions","title":"Functions","text":""},{"location":"api/selectors/#ibis.expr.selectors.all","title":"<code>all()</code>","text":"<p>Return every column from a table.</p>"},{"location":"api/selectors/#ibis.expr.selectors.all_of","title":"<code>all_of(*predicates)</code>","text":"<p>Include columns satisfying all of <code>predicates</code>.</p>"},{"location":"api/selectors/#ibis.expr.selectors.any_of","title":"<code>any_of(*predicates)</code>","text":"<p>Include columns satisfying any of <code>predicates</code>.</p>"},{"location":"api/selectors/#ibis.expr.selectors.c","title":"<code>c(*names)</code>","text":"<p>Select specific column names.</p>"},{"location":"api/selectors/#ibis.expr.selectors.contains","title":"<code>contains(needles, how=any)</code>","text":"<p>Return columns whose name contains <code>needles</code>.</p> <p>Parameters:</p> Name Type Description Default <code>needles</code> <code>str | tuple[str, ...]</code> <p>One or more strings to search for in column names</p> required <code>how</code> <code>Callable[[Iterable[bool]], bool]</code> <p>A boolean reduction to allow the configuration of how <code>needles</code> are summarized.</p> <code>any</code> <p>Examples:</p> <p>Select columns that contain either <code>\"a\"</code> or <code>\"b\"</code></p> <pre><code>&gt;&gt;&gt; t.select(s.contains((\"a\", \"b\")))\n</code></pre> <p>Select columns that contain all of <code>\"a\"</code> and <code>\"b\"</code></p> <pre><code>&gt;&gt;&gt; t.select(s.contains((\"a\", \"b\"), how=all))\n</code></pre>"},{"location":"api/selectors/#ibis.expr.selectors.contains--see-also","title":"See Also","text":"<p><code>matches</code></p>"},{"location":"api/selectors/#ibis.expr.selectors.endswith","title":"<code>endswith(suffixes)</code>","text":"<p>Select columns whose name ends with one of <code>suffixes</code>.</p> <p>Parameters:</p> Name Type Description Default <code>suffixes</code> <code>str | tuple[str, ...]</code> <p>Suffixes to compare column names against</p> required"},{"location":"api/selectors/#ibis.expr.selectors.endswith--see-also","title":"See Also","text":"<p><code>startswith</code></p>"},{"location":"api/selectors/#ibis.expr.selectors.first","title":"<code>first()</code>","text":"<p>Return the first column of a table.</p>"},{"location":"api/selectors/#ibis.expr.selectors.last","title":"<code>last()</code>","text":"<p>Return the last column of a table.</p>"},{"location":"api/selectors/#ibis.expr.selectors.matches","title":"<code>matches(regex)</code>","text":"<p>Return columns whose name matches the regular expression <code>regex</code>.</p> <p>Parameters:</p> Name Type Description Default <code>regex</code> <code>str | re.Pattern</code> <p>A string or <code>re.Pattern</code> object</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; t.select(s.matches(r\"ab+\"))\n</code></pre>"},{"location":"api/selectors/#ibis.expr.selectors.matches--see-also","title":"See Also","text":"<p><code>contains</code></p>"},{"location":"api/selectors/#ibis.expr.selectors.numeric","title":"<code>numeric()</code>","text":"<p>Return numeric columns.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; t = ibis.table(dict(a=\"int\", b=\"string\", c=\"array&lt;string&gt;\"), name=\"t\")\n&gt;&gt;&gt; t\nUnboundTable: t\n  a int64\n  b string\n  c array&lt;string&gt;\n&gt;&gt;&gt; expr = t.select(s.numeric())  # `a` has integer type, so it's numeric\n&gt;&gt;&gt; expr.columns\n['a']\n</code></pre>"},{"location":"api/selectors/#ibis.expr.selectors.numeric--see-also","title":"See Also","text":"<p><code>of_type</code></p>"},{"location":"api/selectors/#ibis.expr.selectors.of_type","title":"<code>of_type(dtype)</code>","text":"<p>Select columns of type <code>dtype</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>dt.DataType | str | type[dt.DataType]</code> <p><code>DataType</code> instance, <code>str</code> or <code>DataType</code> class</p> required <p>Examples:</p> <p>Select according to a specific <code>DataType</code> instance</p> <pre><code>&gt;&gt;&gt; t.select(s.of_type(dt.Array(dt.string)))\n</code></pre> <p>Strings are also accepted</p> <pre><code>&gt;&gt;&gt; t.select(s.of_type(\"map&lt;string, float&gt;\"))\n</code></pre> <p>Select by category of <code>DataType</code> by passing the <code>DataType</code> class</p> <pre><code>&gt;&gt;&gt; t.select(s.of_type(dt.Struct))\n</code></pre>"},{"location":"api/selectors/#ibis.expr.selectors.of_type--see-also","title":"See Also","text":"<p><code>numeric</code></p>"},{"location":"api/selectors/#ibis.expr.selectors.startswith","title":"<code>startswith(prefixes)</code>","text":"<p>Select columns whose name starts with one of <code>prefixes</code>.</p> <p>Parameters:</p> Name Type Description Default <code>prefixes</code> <code>str | tuple[str, ...]</code> <p>Prefixes to compare column names against</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; t = ibis.table(dict(apples=\"int\", oranges=\"float\", bananas=\"bool\"), name=\"t\")\n&gt;&gt;&gt; expr = t.select(s.startswith((\"a\", \"b\")))\n&gt;&gt;&gt; expr.columns\n['apples', 'bananas']\n</code></pre>"},{"location":"api/selectors/#ibis.expr.selectors.startswith--see-also","title":"See Also","text":"<p><code>endswith</code></p>"},{"location":"api/selectors/#ibis.expr.selectors.where","title":"<code>where(predicate)</code>","text":"<p>Return columns that satisfy <code>predicate</code>.</p> <p>Use this selector when one of the other selectors does not meet your needs.</p> <p>Parameters:</p> Name Type Description Default <code>predicate</code> <code>Callable[[ir.Value], bool]</code> <p>A callable that accepts an ibis value expression and returns a <code>bool</code></p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; t = ibis.table(dict(a=\"float32\"), name=\"t\")\n&gt;&gt;&gt; expr = t.select(s.where(lambda col: col.get_name() == \"a\"))\n&gt;&gt;&gt; expr.columns\n['a']\n</code></pre>"},{"location":"api/backends/base/","title":"Backend Base Classes","text":""},{"location":"api/backends/base/#ibis.backends.base.BaseBackend","title":"<code>BaseBackend</code>","text":"<p>         Bases: <code>abc.ABC</code>, <code>_FileIOHandler</code></p> <p>Base backend class.</p> <p>All Ibis backends must subclass this class and implement all the required methods.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend-attributes","title":"Attributes","text":""},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.current_database","title":"<code>current_database: str | None</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Return the name of the current database.</p> <p>Backends that don't support different databases will return None.</p> <p>Returns:</p> Type Description <code>str | None</code> <p>Name of the current database.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.db_identity","title":"<code>db_identity: str</code>  <code>property</code> <code>cached</code>","text":"<p>Return the identity of the database.</p> <p>Multiple connections to the same database will return the same value for <code>db_identity</code>.</p> <p>The default implementation assumes connection parameters uniquely specify the database.</p> <p>Returns:</p> Type Description <code>Hashable</code> <p>Database identity</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.tables","title":"<code>tables</code>  <code>property</code> <code>cached</code>","text":"<p>An accessor for tables in the database.</p> <p>Tables may be accessed by name using either index or attribute access:</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; con = ibis.sqlite.connect(\"example.db\")\n&gt;&gt;&gt; people = con.tables['people']  # access via index\n&gt;&gt;&gt; people = con.tables.people  # access via attribute\n</code></pre>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.version","title":"<code>version: str</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Return the version of the backend engine.</p> <p>For database servers, return the server version.</p> <p>For others such as SQLite and pandas return the version of the underlying library or application.</p> <p>Returns:</p> Type Description <code>str</code> <p>The backend version</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend-functions","title":"Functions","text":""},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.add_operation","title":"<code>add_operation(operation)</code>","text":"<p>Add a translation function to the backend for a specific operation.</p> <p>Operations are defined in <code>ibis.expr.operations</code>, and a translation function receives the translator object and an expression as parameters, and returns a value depending on the backend. For example, in SQL backends, a NullLiteral operation could be translated to the string <code>\"NULL\"</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @ibis.sqlite.add_operation(ibis.expr.operations.NullLiteral)\n... def _null_literal(translator, expression):\n...     return 'NULL'\n</code></pre>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.compile","title":"<code>compile(expr, params=None)</code>","text":"<p>Compile an expression.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.connect","title":"<code>connect(*args, **kwargs)</code>","text":"<p>Connect to the database.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>Mandatory connection parameters, see the docstring of <code>do_connect</code> for details.</p> <code>()</code> <code>**kwargs</code> <p>Extra connection parameters, see the docstring of <code>do_connect</code> for details.</p> <code>{}</code>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.connect--notes","title":"Notes","text":"<p>This creates a new backend instance with saved <code>args</code> and <code>kwargs</code>, then calls <code>reconnect</code> and finally returns the newly created and connected backend instance.</p> <p>Returns:</p> Type Description <code>BaseBackend</code> <p>An instance of the backend</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.create_database","title":"<code>create_database(name, force=False)</code>","text":"<p>Create a new database.</p> <p>Not all backends implement this method.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the new database.</p> required <code>force</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the database already exists.</p> <code>False</code>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.create_table","title":"<code>create_table(name, obj=None, *, schema=None, database=None, temp=False, overwrite=False)</code>  <code>abstractmethod</code>","text":"<p>Create a new table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the new table.</p> required <code>obj</code> <code>pd.DataFrame | ir.Table | None</code> <p>An Ibis table expression or pandas table that will be used to extract the schema and the data of the new table. If not provided, <code>schema</code> must be given.</p> <code>None</code> <code>schema</code> <code>ibis.Schema | None</code> <p>The schema for the new table. Only one of <code>schema</code> or <code>obj</code> can be provided.</p> <code>None</code> <code>database</code> <code>str | None</code> <p>Name of the database where the table will be created, if not the default.</p> <code>None</code> <code>temp</code> <code>bool</code> <p>Whether a table is temporary or not</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to clobber existing data</p> <code>False</code> <p>Returns:</p> Type Description <code>Table</code> <p>The table that was created.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.create_view","title":"<code>create_view(name, obj, *, database=None, overwrite=False)</code>  <code>abstractmethod</code>","text":"<p>Create a new view from an expression.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the new view.</p> required <code>obj</code> <code>ir.Table</code> <p>An Ibis table expression that will be used to create the view.</p> required <code>database</code> <code>str | None</code> <p>Name of the database where the view will be created, if not provided the database's default is used.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Whether to clobber an existing view with the same name</p> <code>False</code> <p>Returns:</p> Type Description <code>Table</code> <p>The view that was created.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.database","title":"<code>database(name=None)</code>","text":"<p>Return a <code>Database</code> object for the <code>name</code> database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Name of the database to return the object for.</p> <code>None</code> <p>Returns:</p> Type Description <code>Database</code> <p>A database object for the specified database.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.drop_table","title":"<code>drop_table(name, *, database=None, force=False)</code>  <code>abstractmethod</code>","text":"<p>Drop a table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the table to drop.</p> required <code>database</code> <code>str | None</code> <p>Name of the database where the table exists, if not the default.</p> <code>None</code> <code>force</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the table does not exist.</p> <code>False</code>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.drop_view","title":"<code>drop_view(name, *, database=None, force=False)</code>  <code>abstractmethod</code>","text":"<p>Drop a view.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the view to drop.</p> required <code>database</code> <code>str | None</code> <p>Name of the database where the view exists, if not the default.</p> <code>None</code> <code>force</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the view does not exist.</p> <code>False</code>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.execute","title":"<code>execute(expr)</code>","text":"<p>Execute an expression.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.has_operation","title":"<code>has_operation(operation)</code>  <code>classmethod</code>","text":"<p>Return whether the backend implements support for <code>operation</code>.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>type[ops.Value]</code> <p>A class corresponding to an operation.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the backend implements the operation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.operations as ops\n&gt;&gt;&gt; ibis.sqlite.has_operation(ops.ArrayIndex)\nFalse\n&gt;&gt;&gt; ibis.postgres.has_operation(ops.ArrayIndex)\nTrue\n</code></pre>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.list_databases","title":"<code>list_databases(like=None)</code>  <code>abstractmethod</code>","text":"<p>List existing databases in the current connection.</p> <p>Parameters:</p> Name Type Description Default <code>like</code> <code>str</code> <p>A pattern in Python's regex format to filter returned database names.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>The database names that exist in the current connection, that match the <code>like</code> pattern if provided.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.list_tables","title":"<code>list_tables(like=None, database=None)</code>  <code>abstractmethod</code>","text":"<p>Return the list of table names in the current database.</p> <p>For some backends, the tables may be files in a directory, or other equivalent entities in a SQL database.</p> <p>Parameters:</p> Name Type Description Default <code>like</code> <code>str, optional</code> <p>A pattern in Python's regex format.</p> <code>None</code> <code>database</code> <code>str, optional</code> <p>The database to list tables of, if not the current one.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>The list of the table names that match the pattern <code>like</code>.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.register_options","title":"<code>register_options()</code>  <code>classmethod</code>","text":"<p>Register custom backend options.</p>"},{"location":"api/backends/base/#ibis.backends.base.BaseBackend.table","title":"<code>table(name, database=None)</code>  <code>abstractmethod</code>","text":"<p>Construct a table expression.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"api/backends/pandas/","title":"Pandas-like Backend Base Classes","text":"<p>These base classes underlie the pandas-based backends.</p>"},{"location":"api/backends/pandas/#ibis.backends.pandas.BasePandasBackend","title":"<code>BasePandasBackend</code>","text":"<p>         Bases: <code>BaseBackend</code></p> <p>Base class for backends based on pandas.</p>"},{"location":"api/backends/pandas/#ibis.backends.pandas.BasePandasBackend-functions","title":"Functions","text":""},{"location":"api/backends/pandas/#ibis.backends.pandas.BasePandasBackend.create_table","title":"<code>create_table(name, obj=None, *, schema=None, database=None, temp=None, overwrite=False)</code>","text":"<p>Create a table.</p>"},{"location":"api/backends/pandas/#ibis.backends.pandas.BasePandasBackend.from_dataframe","title":"<code>from_dataframe(df, name='df', client=None)</code>","text":"<p>Construct an ibis table from a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>A pandas DataFrame</p> required <code>name</code> <code>str</code> <p>The name of the pandas DataFrame</p> <code>'df'</code> <code>client</code> <code>BasePandasBackend | None</code> <p>Client dictionary will be mutated with the name of the DataFrame, if not provided a new client is created</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>A table expression</p>"},{"location":"api/backends/sql/","title":"SQL Backend Base Classes","text":""},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend","title":"<code>BaseSQLBackend</code>","text":"<p>         Bases: <code>BaseBackend</code></p> <p>Base backend class for backends that compile to SQL.</p>"},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend-functions","title":"Functions","text":""},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend.compile","title":"<code>compile(expr, limit=None, params=None, timecontext=None)</code>","text":"<p>Compile an Ibis expression.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Expr</code> <p>Ibis expression</p> required <code>limit</code> <code>str | None</code> <p>For expressions yielding result sets; retrieve at most this number of values/rows. Overrides any limit already set on the expression.</p> <code>None</code> <code>params</code> <code>Mapping[ir.Expr, Any] | None</code> <p>Named unbound parameters</p> <code>None</code> <code>timecontext</code> <code>tuple[pd.Timestamp, pd.Timestamp] | None</code> <p>Additional information about data source time boundaries</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The output of compilation. The type of this value depends on the backend.</p>"},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend.execute","title":"<code>execute(expr, params=None, limit='default', **kwargs)</code>","text":"<p>Compile and execute an Ibis expression.</p> <p>Compile and execute Ibis expression using this backend client interface, returning results in-memory in the appropriate object type</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Expr</code> <p>Ibis expression</p> required <code>limit</code> <code>str</code> <p>For expressions yielding result sets; retrieve at most this number of values/rows. Overrides any limit already set on the expression.</p> <code>'default'</code> <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Named unbound parameters</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Backend specific arguments. For example, the clickhouse backend uses this to receive <code>external_tables</code> as a dictionary of pandas DataFrames.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame | Series | Scalar</code> <ul> <li><code>Table</code>: pandas.DataFrame</li> <li><code>Column</code>: pandas.Series</li> <li><code>Scalar</code>: Python scalar value</li> </ul>"},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend.explain","title":"<code>explain(expr, params=None)</code>","text":"<p>Explain an expression.</p> <p>Return the query plan associated with the indicated expression or SQL query.</p> <p>Returns:</p> Type Description <code>str</code> <p>Query plan</p>"},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend.raw_sql","title":"<code>raw_sql(query)</code>","text":"<p>Execute a query string.</p> <p>The returned cursor object must be manually released if results are returned.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>DDL or DML statement</p> required"},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend.sql","title":"<code>sql(query, schema=None)</code>","text":"<p>Convert a SQL query to an Ibis table expression.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL string</p> required <code>schema</code> <code>sch.Schema | None</code> <p>The expected schema for this query. If not provided, will be inferred automatically if possible.</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend.table","title":"<code>table(name, database=None)</code>","text":"<p>Construct a table expression.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"api/backends/sql/#ibis.backends.base.sql.BaseSQLBackend.to_pyarrow_batches","title":"<code>to_pyarrow_batches(expr, *, params=None, limit=None, chunk_size=1000000, **_)</code>","text":"<p>Execute expression and return an iterator of pyarrow record batches.</p> <p>This method is eager and will execute the associated expression immediately.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Expr</code> <p>Ibis expression to export to pyarrow</p> required <code>limit</code> <code>int | str | None</code> <p>An integer to effect a specific row limit. A value of <code>None</code> means \"no limit\". The default is in <code>ibis/config.py</code>.</p> <code>None</code> <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Mapping of scalar parameter expressions to value.</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>Maximum number of rows in each returned record batch.</p> <code>1000000</code> <p>Returns:</p> Type Description <code>RecordBatchReader</code> <p>Collection of pyarrow <code>RecordBatch</code>s.</p>"},{"location":"api/backends/sqlalchemy/","title":"SQLAlchemy Backend Base Classes","text":""},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend","title":"<code>BaseAlchemyBackend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p> <p>Backend class for backends that compile to SQLAlchemy expressions.</p>"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend-attributes","title":"Attributes","text":""},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.current_database","title":"<code>current_database: str</code>  <code>property</code>","text":"<p>The name of the current database this client is connected to.</p>"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend-functions","title":"Functions","text":""},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.create_table","title":"<code>create_table(name, obj=None, *, schema=None, database=None, temp=False, overwrite=False)</code>","text":"<p>Create a table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the new table.</p> required <code>obj</code> <code>pd.DataFrame | ir.Table | None</code> <p>An Ibis table expression or pandas table that will be used to extract the schema and the data of the new table. If not provided, <code>schema</code> must be given.</p> <code>None</code> <code>schema</code> <code>sch.Schema | None</code> <p>The schema for the new table. Only one of <code>schema</code> or <code>obj</code> can be provided.</p> <code>None</code> <code>database</code> <code>str | None</code> <p>Name of the database where the table will be created, if not the default.</p> <code>None</code> <code>temp</code> <code>bool</code> <p>Should the table be temporary for the session.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Clobber existing data</p> <code>False</code> <p>Returns:</p> Type Description <code>Table</code> <p>The table that was created.</p>"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.drop_table","title":"<code>drop_table(name, *, database=None, force=False)</code>","text":"<p>Drop a table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table to drop</p> required <code>database</code> <code>str | None</code> <p>Database to drop table from</p> <code>None</code> <code>force</code> <code>bool</code> <p>Check for existence before dropping</p> <code>False</code>"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.insert","title":"<code>insert(table_name, obj, database=None, overwrite=False)</code>","text":"<p>Insert data into a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to which data needs will be inserted</p> required <code>obj</code> <code>pd.DataFrame | ir.Table | list | dict</code> <p>The source data or expression to insert</p> required <code>database</code> <code>str | None</code> <p>Name of the attached database that the table is located in.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>If <code>True</code> then replace existing contents of table</p> <code>False</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If inserting data from a different database</p> <code>ValueError</code> <p>If the type of <code>obj</code> isn't supported</p>"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.list_databases","title":"<code>list_databases(like=None)</code>","text":"<p>List databases in the current server.</p>"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.load_data","title":"<code>load_data(table_name, data, database=None, if_exists='fail')</code>","text":"<p>Load data from a dataframe to the backend.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table in which to load data</p> required <code>data</code> <code>pd.DataFrame</code> <p>Pandas DataFrame</p> required <code>database</code> <code>str | None</code> <p>Database in which the table exists</p> <code>None</code> <code>if_exists</code> <code>Literal['fail', 'replace', 'append']</code> <p>What to do when data in <code>name</code> already exists</p> <code>'fail'</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Loading data to a table from a different database is not yet implemented</p>"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.raw_sql","title":"<code>raw_sql(query)</code>","text":"<p>Execute a query string.</p> <p>The returned cursor object must be manually released.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>DDL or DML statement</p> required"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.schema","title":"<code>schema(name)</code>","text":"<p>Get an ibis schema from the current database for the table <code>name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <p>Returns:</p> Type Description <code>Schema</code> <p>The ibis schema of <code>name</code></p>"},{"location":"api/backends/sqlalchemy/#ibis.backends.base.sql.alchemy.BaseAlchemyBackend.table","title":"<code>table(name, database=None, schema=None)</code>","text":"<p>Create a table expression from a table in the database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>The database the table resides in</p> <code>None</code> <code>schema</code> <code>str | None</code> <p>The schema inside <code>database</code> where the table resides.</p> <p><code>schema</code> refers to database organization</p> <p>The <code>schema</code> parameter does not refer to the column names and types of <code>table</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"api/expressions/","title":"Base Expression Types","text":"<p>These APIs are shared by both table and column expressions.</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr","title":"<code>Expr</code>","text":"<p>         Bases: <code>Immutable</code></p> <p>Base expression class.</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr-functions","title":"Functions","text":""},{"location":"api/expressions/#ibis.expr.types.core.Expr.as_table","title":"<code>as_table()</code>","text":"<p>Convert an expression to a table.</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.compile","title":"<code>compile(limit=None, timecontext=None, params=None)</code>","text":"<p>Compile to an execution target.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int | None</code> <p>An integer to effect a specific row limit. A value of <code>None</code> means \"no limit\". The default is in <code>ibis/config.py</code>.</p> <code>None</code> <code>timecontext</code> <code>TimeContext | None</code> <p>Defines a time range of <code>(begin, end)</code>. When defined, the execution will only compute result for data inside the time range. The time range is inclusive of both endpoints. This is conceptually same as a time filter. The time column must be named <code>'time'</code> and should preserve across the expression. For example, if that column is dropped then execute will result in an error.</p> <code>None</code> <code>params</code> <code>Mapping[ir.Value, Any] | None</code> <p>Mapping of scalar parameter expressions to value</p> <code>None</code>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.equals","title":"<code>equals(other)</code>","text":"<p>Return whether this expression is structurally equivalent to <code>other</code>.</p> <p>If you want to produce an equality expression, use <code>==</code> syntax.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another expression</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t1 = ibis.table(dict(a=\"int\"), name=\"t\")\n&gt;&gt;&gt; t2 = ibis.table(dict(a=\"int\"), name=\"t\")\n&gt;&gt;&gt; t1.equals(t2)\nTrue\n&gt;&gt;&gt; v = ibis.table(dict(a=\"string\"), name=\"v\")\n&gt;&gt;&gt; t1.equals(v)\nFalse\n</code></pre>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.execute","title":"<code>execute(limit='default', timecontext=None, params=None, **kwargs)</code>","text":"<p>Execute an expression against its backend if one exists.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int | str | None</code> <p>An integer to effect a specific row limit. A value of <code>None</code> means \"no limit\". The default is in <code>ibis/config.py</code>.</p> <code>'default'</code> <code>timecontext</code> <code>TimeContext | None</code> <p>Defines a time range of <code>(begin, end)</code>. When defined, the execution will only compute result for data inside the time range. The time range is inclusive of both endpoints. This is conceptually same as a time filter. The time column must be named <code>'time'</code> and should preserve across the expression. For example, if that column is dropped then execute will result in an error.</p> <code>None</code> <code>params</code> <code>Mapping[ir.Value, Any] | None</code> <p>Mapping of scalar parameter expressions to value</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Keyword arguments</p> <code>{}</code>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.get_name","title":"<code>get_name()</code>","text":"<p>Return the name of this expression.</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.has_name","title":"<code>has_name()</code>","text":"<p>Check whether this expression has an explicit name.</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.pipe","title":"<code>pipe(f, *args, **kwargs)</code>","text":"<p>Compose <code>f</code> with <code>self</code>.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>If the expression needs to be passed as anything other than the first argument to the function, pass a tuple with the argument name. For example, (f, 'data') if the function f expects a 'data' keyword</p> required <code>args</code> <code>Any</code> <p>Positional arguments to <code>f</code></p> <code>()</code> <code>kwargs</code> <code>Any</code> <p>Keyword arguments to <code>f</code></p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t = ibis.table([('a', 'int64'), ('b', 'string')], name='t')\n&gt;&gt;&gt; f = lambda a: (a + 1).name('a')\n&gt;&gt;&gt; g = lambda a: (a * 2).name('a')\n&gt;&gt;&gt; result1 = t.a.pipe(f).pipe(g)\n&gt;&gt;&gt; result1\nr0 := UnboundTable: t\n  a int64\n  b string\na: r0.a + 1 * 2\n</code></pre> <pre><code>&gt;&gt;&gt; result2 = g(f(t.a))  # equivalent to the above\n&gt;&gt;&gt; result1.equals(result2)\nTrue\n</code></pre> <p>Returns:</p> Type Description <code>Expr</code> <p>Result type of passed function</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.to_csv","title":"<code>to_csv(path, *, params=None, **kwargs)</code>","text":"<p>Write the results of executing the given expression to a CSV file</p> <p>This method is eager and will execute the associated expression immediately.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The data source. A string or Path to the CSV file.</p> required <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Mapping of scalar parameter expressions to value.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to pyarrow.csv.CSVWriter</p> <code>{}</code>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.to_parquet","title":"<code>to_parquet(path, *, params=None, **kwargs)</code>","text":"<p>Write the results of executing the given expression to a parquet file</p> <p>This method is eager and will execute the associated expression immediately.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The data source. A string or Path to the parquet file.</p> required <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Mapping of scalar parameter expressions to value.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to pyarrow.parquet.ParquetWriter</p> <code>{}</code> <p>Examples:</p> <p>Write out an expression to a single parquet file.</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; penguins = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; penguins.to_parquet(\"penguins.parquet\")\n</code></pre> <p>Write out an expression to a hive-partitioned parquet file.</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; penguins = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; # partition on single column\n&gt;&gt;&gt; penguins.to_parquet(\"penguins_hive_dir\", partition_by=\"year\")\n&gt;&gt;&gt; # partition on multiple columns\n&gt;&gt;&gt; penguins.to_parquet(\"penguins_hive_dir\", partition_by=(\"year\", \"island\"))\n</code></pre> <p>Hive-partitioned output is currently only supported when using DuckDB</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.to_pyarrow","title":"<code>to_pyarrow(*, params=None, limit=None, **kwargs)</code>","text":"<p>Execute expression and return results in as a pyarrow table.</p> <p>This method is eager and will execute the associated expression immediately.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Mapping of scalar parameter expressions to value.</p> <code>None</code> <code>limit</code> <code>int | str | None</code> <p>An integer to effect a specific row limit. A value of <code>None</code> means \"no limit\". The default is in <code>ibis/config.py</code>.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Keyword arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>Table</code> <p>A pyarrow table holding the results of the executed expression.</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.to_pyarrow_batches","title":"<code>to_pyarrow_batches(*, limit=None, params=None, chunk_size=1000000, **kwargs)</code>","text":"<p>Execute expression and return a RecordBatchReader.</p> <p>This method is eager and will execute the associated expression immediately.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int | str | None</code> <p>An integer to effect a specific row limit. A value of <code>None</code> means \"no limit\". The default is in <code>ibis/config.py</code>.</p> <code>None</code> <code>params</code> <code>Mapping[ir.Value, Any] | None</code> <p>Mapping of scalar parameter expressions to value.</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>Maximum number of rows in each returned record batch.</p> <code>1000000</code> <code>kwargs</code> <code>Any</code> <p>Keyword arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>results</code> <p>RecordBatchReader</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.unbind","title":"<code>unbind()</code>","text":"<p>Return an expression built on <code>UnboundTable</code> instead of backend-specific objects.</p>"},{"location":"api/expressions/#ibis.expr.types.core.Expr.visualize","title":"<code>visualize(format='svg', *, label_edges=False, verbose=False)</code>","text":"<p>Visualize an expression as a GraphViz graph in the browser.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Image output format. These are specified by the <code>graphviz</code> Python library.</p> <code>'svg'</code> <code>label_edges</code> <code>bool</code> <p>Show operation input names as edge labels</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Print the graphviz DOT code to stderr if <code>True</code></p> <code>False</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If <code>graphviz</code> is not installed.</p>"},{"location":"api/expressions/collections/","title":"Complex Type Expressions","text":"<p>These APIs are available on arrays, maps and structs.</p>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue","title":"<code>ArrayValue</code>","text":"<p>         Bases: <code>Value</code></p>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue-functions","title":"Functions","text":""},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.__add__","title":"<code>__add__(other)</code>","text":"<p>Concatenate this array with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ArrayValue</code> <p>Array to concat with <code>self</code></p> required <p>Returns:</p> Type Description <code>ArrayValue</code> <p><code>self</code> concatenated with <code>other</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[7], [3] , None]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7]                  \u2502\n\u2502 [3]                  \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.a + t.a\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayConcat(a, a)    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7, 7]               \u2502\n\u2502 [3, 3]               \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.a + [4]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayConcat(a, (4,)) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7, 4]               \u2502\n\u2502 [3, 4]               \u2502\n\u2502 [4]                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Extract one or more elements of <code>self</code>.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int | ir.IntegerValue | slice</code> <p>Index into <code>array</code></p> required <p>Returns:</p> Type Description <code>Value</code> <ul> <li>If <code>index</code> is an <code>int</code> or <code>IntegerValue</code> then the return type is the element type of <code>self</code>.</li> <li>If <code>index</code> is a <code>slice</code> then the return type is the same type as the input.</li> </ul> <p>Examples:</p> <p>Extract a single element</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[7, 42], [3], None]})\n&gt;&gt;&gt; t.a[0]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayIndex(a, 0) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int8             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                7 \u2502\n\u2502                3 \u2502\n\u2502                \u2205 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Extract a range of elements</p> <pre><code>&gt;&gt;&gt; t = ibis.memtable({\"a\": [[7, 42, 72], [3] * 5, None]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7, 42, ... +1]      \u2502\n\u2502 [3, 3, ... +3]       \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.a[1:2]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArraySlice(a, 1, 2)  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [42]                 \u2502\n\u2502 [3]                  \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.__mul__","title":"<code>__mul__(n)</code>","text":"<p>Repeat this array <code>n</code> times.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | ir.IntegerValue</code> <p>Number of times to repeat <code>self</code>.</p> required <p>Returns:</p> Type Description <code>ArrayValue</code> <p><code>self</code> repeated <code>n</code> times</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[7], [3] , None]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7]                  \u2502\n\u2502 [3]                  \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.a * 2\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayRepeat(a, 2)    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7, 7]               \u2502\n\u2502 [3, 3]               \u2502\n\u2502 []                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.__radd__","title":"<code>__radd__(other)</code>","text":"<p>Concatenate this array with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ArrayValue</code> <p>Array to concat with <code>self</code></p> required <p>Returns:</p> Type Description <code>ArrayValue</code> <p><code>self</code> concatenated with <code>other</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[7], [3] , None]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7]                  \u2502\n\u2502 [3]                  \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; [4] + t.a\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayConcat((4,), a) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [4, 7]               \u2502\n\u2502 [4, 3]               \u2502\n\u2502 [4]                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.__rmul__","title":"<code>__rmul__(n)</code>","text":"<p>Repeat this array <code>n</code> times.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | ir.IntegerValue</code> <p>Number of times to repeat <code>self</code>.</p> required <p>Returns:</p> Type Description <code>ArrayValue</code> <p><code>self</code> repeated <code>n</code> times</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[7], [3] , None]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7]                  \u2502\n\u2502 [3]                  \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; 2 * t.a\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayRepeat(a, 2)    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7, 7]               \u2502\n\u2502 [3, 3]               \u2502\n\u2502 []                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.filter","title":"<code>filter(predicate)</code>","text":"<p>Filter array elements using <code>predicate</code>.</p> <p>Parameters:</p> Name Type Description Default <code>predicate</code> <code>Callable[[ir.Value], ir.BooleanValue]</code> <p>Function to use to filter array elements</p> required <p>Returns:</p> Type Description <code>ArrayValue</code> <p>Array elements filtered using <code>predicate</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[1, None, 2], [4], []]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [1, None, ... +1]    \u2502\n\u2502 [4]                  \u2502\n\u2502 []                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.a.filter(lambda x: x &gt; 1)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayFilter(a)       \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [2]                  \u2502\n\u2502 [4]                  \u2502\n\u2502 []                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.join","title":"<code>join(sep)</code>","text":"<p>Join the elements of this array expression with <code>sep</code>.</p> <p>Parameters:</p> Name Type Description Default <code>sep</code> <code>str | ir.StringValue</code> <p>Separator to use for joining array elements</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Elements of <code>self</code> joined with <code>sep</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"arr\": [[\"a\", \"b\", \"c\"], None, [], [\"b\", None]]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 arr                  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;string&gt;        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ['a', 'b', ... +1]   \u2502\n\u2502 \u2205                    \u2502\n\u2502 []                   \u2502\n\u2502 ['b', None]          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.arr.join(\"|\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayStringJoin('|', arr) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a|b|c                     \u2502\n\u2502 \u2205                         \u2502\n\u2502 \u2205                         \u2502\n\u2502 b                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.join--see-also","title":"See Also","text":"<p><code>StringValue.join</code></p>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.length","title":"<code>length()</code>","text":"<p>Compute the length of an array.</p> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>The integer length of each element of <code>self</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[7, 42], [3], None]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7, 42]              \u2502\n\u2502 [3]                  \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.a.length()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayLength(a) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502              2 \u2502\n\u2502              1 \u2502\n\u2502              \u2205 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.map","title":"<code>map(func)</code>","text":"<p>Apply a callable <code>func</code> to each element of this array expression.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[[ir.Value], ir.Value]</code> <p>Function to apply to each element of this array</p> required <p>Returns:</p> Type Description <code>ArrayValue</code> <p><code>func</code> applied to every element of this array expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[1, None, 2], [4], []]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [1, None, ... +1]    \u2502\n\u2502 [4]                  \u2502\n\u2502 []                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.a.map(lambda x: (x + 100).cast(\"float\"))\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayMap(a)           \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;float64&gt;        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [101.0, None, ... +1] \u2502\n\u2502 [104.0]               \u2502\n\u2502 []                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.arrays.ArrayValue.unnest","title":"<code>unnest()</code>","text":"<p>Flatten an array into a column.</p> <p>This operation changes the cardinality of the result</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [[7, 42], [3, 3] , None]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;int8&gt;          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [7, 42]              \u2502\n\u2502 [3, 3]               \u2502\n\u2502 \u2205                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.a.unnest()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int8 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    7 \u2502\n\u2502   42 \u2502\n\u2502    3 \u2502\n\u2502    3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Returns:</p> Type Description <code>ir.Value</code> <p>Unnested array</p>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue","title":"<code>StructValue</code>","text":"<p>         Bases: <code>Value</code></p>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue-attributes","title":"Attributes","text":""},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue.fields","title":"<code>fields: Mapping[str, dt.DataType]</code>  <code>property</code>","text":"<p>Return a mapping from field name to field type of the struct.</p>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue.names","title":"<code>names: Sequence[str]</code>  <code>property</code>","text":"<p>Return the field names of the struct.</p>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue.types","title":"<code>types: Sequence[dt.DataType]</code>  <code>property</code>","text":"<p>Return the field types of the struct.</p>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue-functions","title":"Functions","text":""},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue.__getattr__","title":"<code>__getattr__(name)</code>","text":"<p>Extract the <code>name</code> field from this struct.</p>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue.__getitem__","title":"<code>__getitem__(name)</code>","text":"<p>Extract the <code>name</code> field from this struct.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the field to access.</p> required <p>Returns:</p> Type Description <code>Value</code> <p>An expression with the type of the field being accessed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; s = ibis.struct(dict(fruit=\"pear\", weight=0))\n&gt;&gt;&gt; s['fruit']\nfruit: StructField(...)\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue.destructure","title":"<code>destructure()</code>","text":"<p>Destructure a <code>StructValue</code> into the corresponding struct fields.</p> <p>When assigned, a destruct value will be destructured and assigned to multiple columns.</p> <p>Returns:</p> Type Description <code>list[AnyValue]</code> <p>Value expressions corresponding to the struct fields.</p>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue.lift","title":"<code>lift()</code>","text":"<p>Project the fields of <code>self</code> into a table.</p> <p>This method is useful when analyzing data that has deeply nested structs or arrays of structs. <code>lift</code> can be chained to avoid repeating column names and table references.</p> <p>Returns:</p> Type Description <code>Table</code> <p>A projection with this struct expression's fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; lines = '''\n...     {\"pos\": {\"lat\": 10.1, \"lon\": 30.3}}\n...     {\"pos\": {\"lat\": 10.2, \"lon\": 30.2}}\n...     {\"pos\": {\"lat\": 10.3, \"lon\": 30.1}}\n... '''\n&gt;&gt;&gt; with open(\"/tmp/lines.json\", \"w\") as f:\n...     _ = f.write(lines)\n&gt;&gt;&gt; t = ibis.read_json(\"/tmp/lines.json\")\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 pos                                \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 struct&lt;lat: float64, lon: float64&gt; \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 {'lat': 10.1, 'lon': 30.3}         \u2502\n\u2502 {'lat': 10.2, 'lon': 30.2}         \u2502\n\u2502 {'lat': 10.3, 'lon': 30.1}         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.pos.lift()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 lat     \u2503 lon     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64 \u2502 float64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    10.1 \u2502    30.3 \u2502\n\u2502    10.2 \u2502    30.2 \u2502\n\u2502    10.3 \u2502    30.1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.structs.StructValue.lift--see-also","title":"See Also","text":"<p><code>Table.unpack</code>.</p>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue","title":"<code>MapValue</code>","text":"<p>         Bases: <code>Value</code></p>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue-functions","title":"Functions","text":""},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue.__add__","title":"<code>__add__(other)</code>","text":"<p>Concatenate this map with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>MapValue</code> <p>Map to concatenate with <code>self</code></p> required <p>Returns:</p> Type Description <code>MapValue</code> <p><code>self</code> concatenated with <code>other</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; m1 = ibis.map({\"a\": 1, \"b\": 2})\n&gt;&gt;&gt; m2 = ibis.map({\"c\": 3, \"d\": 4})\n&gt;&gt;&gt; m1 + m2\nMapMerge(...)\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the value for a given map <code>key</code>.</p> <p>This operation may have different semantics depending on the backend.</p> <p>Some backends return <code>NULL</code> when a key is missing, others may fail the query.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>ir.Value</code> <p>A map key</p> required <p>Returns:</p> Type Description <code>Value</code> <p>An element with the value type of the map</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; m = ibis.map({\"a\": 1, \"b\": 2})\n&gt;&gt;&gt; m[\"a\"]\nMapGet(...)\n&gt;&gt;&gt; m[\"c\"]  # note that this does not fail on construction\nMapGet(...)\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue.__radd__","title":"<code>__radd__(other)</code>","text":"<p>Concatenate this map with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>MapValue</code> <p>Map to concatenate with <code>self</code></p> required <p>Returns:</p> Type Description <code>MapValue</code> <p><code>self</code> concatenated with <code>other</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; m1 = ibis.map({\"a\": 1, \"b\": 2})\n&gt;&gt;&gt; m2 = ibis.map({\"c\": 3, \"d\": 4})\n&gt;&gt;&gt; m1 + m2\nMapMerge(...)\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue.contains","title":"<code>contains(key)</code>","text":"<p>Return whether the map contains <code>key</code>.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int | str | ir.IntegerValue | ir.StringValue</code> <p>Mapping key for which to check</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Boolean indicating the presence of <code>key</code> in the map expression</p>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue.get","title":"<code>get(key, default=None)</code>","text":"<p>Return the value for <code>key</code> from <code>expr</code>.</p> <p>Return <code>default</code> if <code>key</code> is not in the map.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>ir.Value</code> <p>Expression to use for key</p> required <code>default</code> <code>ir.Value | None</code> <p>Expression to return if <code>key</code> is not a key in <code>expr</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Value</code> <p>The element type of <code>self</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; m = ibis.map({\"a\": 1, \"b\": 2})\n&gt;&gt;&gt; m.get(\"a\")\nMapGet(...)\n&gt;&gt;&gt; m.get(\"c\", 3)\nMapGet(...)\n&gt;&gt;&gt; m.get(\"d\")\nMapGet(...)\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue.keys","title":"<code>keys()</code>","text":"<p>Extract the keys of a map.</p> <p>Returns:</p> Type Description <code>ArrayValue</code> <p>The keys of <code>self</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; m = ibis.map({\"a\": 1, \"b\": 2})\n&gt;&gt;&gt; m.keys()\nMapKeys(...)\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue.length","title":"<code>length()</code>","text":"<p>Return the number of key-value pairs in the map.</p> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>The number of elements in <code>self</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; m = ibis.map({\"a\": 1, \"b\": 2})\n&gt;&gt;&gt; m.length()\nMapLength(...)\n</code></pre>"},{"location":"api/expressions/collections/#ibis.expr.types.maps.MapValue.values","title":"<code>values()</code>","text":"<p>Extract the values of a map.</p> <p>Returns:</p> Type Description <code>ArrayValue</code> <p>The values of <code>self</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; m = ibis.map({\"a\": 1, \"b\": 2})\n&gt;&gt;&gt; m.values()\nMapValues(...)\n</code></pre>"},{"location":"api/expressions/generic/","title":"Generic Expression APIs","text":"<p>These expressions are available on scalars and columns of any element type.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value","title":"<code>Value</code>","text":"<p>         Bases: <code>Expr</code></p> <p>Base class for a data generating expression having a known type.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value-functions","title":"Functions","text":""},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.as_table","title":"<code>as_table()</code>","text":"<p>Promote the expression to a table.</p> <p>Returns:</p> Type Description <code>Table</code> <p>A table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t = ibis.table(dict(a=\"str\"), name=\"t\")\n&gt;&gt;&gt; expr = t.a.length().name(\"len\").as_table()\n&gt;&gt;&gt; expected = t.select(len=t.a.length())\n&gt;&gt;&gt; expr.equals(expected)\nTrue\n</code></pre>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.asc","title":"<code>asc()</code>","text":"<p>Sort an expression ascending.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.between","title":"<code>between(lower, upper)</code>","text":"<p>Check if this expression is between <code>lower</code> and <code>upper</code>, inclusive.</p> <p>Parameters:</p> Name Type Description Default <code>lower</code> <code>Value</code> <p>Lower bound</p> required <code>upper</code> <code>Value</code> <p>Upper bound</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Expression indicating membership in the provided range</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.case","title":"<code>case()</code>","text":"<p>Create a SimpleCaseBuilder to chain multiple if-else statements.</p> <p>Add new search expressions with the <code>.when()</code> method. These must be comparable with this column expression. Conclude by calling <code>.end()</code></p> <p>Returns:</p> Type Description <code>SimpleCaseBuilder</code> <p>A case builder</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t = ibis.table([('string_col', 'string')], name='t')\n&gt;&gt;&gt; expr = t.string_col\n&gt;&gt;&gt; case_expr = (expr.case()\n...              .when('a', 'an a')\n...              .when('b', 'a b')\n...              .else_('null or (not a and not b)')\n...              .end())\n&gt;&gt;&gt; case_expr\nr0 := UnboundTable: t\n  string_col string\nSimpleCase(...)\n</code></pre>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.cases","title":"<code>cases(case_result_pairs, default=None)</code>","text":"<p>Create a case expression in one shot.</p> <p>Parameters:</p> Name Type Description Default <code>case_result_pairs</code> <code>Iterable[tuple[ir.BooleanValue, Value]]</code> <p>Conditional-result pairs</p> required <code>default</code> <code>Value | None</code> <p>Value to return if none of the case conditions are true</p> <code>None</code> <p>Returns:</p> Type Description <code>Value</code> <p>Value expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.cast","title":"<code>cast(target_type)</code>","text":"<p>Cast expression to indicated data type.</p> <p>Parameters:</p> Name Type Description Default <code>target_type</code> <code>dt.DataType</code> <p>Type to cast to</p> required <p>Returns:</p> Type Description <code>Value</code> <p>Casted expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.coalesce","title":"<code>coalesce(*args)</code>","text":"<p>Return the first non-null value from <code>args</code>.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Value</code> <p>Arguments from which to choose the first non-null value</p> <code>()</code> <p>Returns:</p> Type Description <code>Value</code> <p>Coalesced expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.coalesce(None, 4, 5).name(\"x\")\nx: Coalesce(...)\n</code></pre>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.collect","title":"<code>collect(where=None)</code>","text":"<p>Aggregate this expression's elements into an array.</p> <p>This function is called <code>array_agg</code>, <code>list_agg</code>, or <code>list</code> in other systems.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter to apply before aggregation</p> <code>None</code> <p>Returns:</p> Type Description <code>ArrayScalar</code> <p>Collected array</p> <p>Examples:</p> <p>Basic collect usage</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"key\": list(\"aaabb\"), \"value\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 key    \u2503 value \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502     1 \u2502\n\u2502 a      \u2502     2 \u2502\n\u2502 a      \u2502     3 \u2502\n\u2502 b      \u2502     4 \u2502\n\u2502 b      \u2502     5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.value.collect()\n[1, 2, 3, 4, 5]\n&gt;&gt;&gt; type(t.value.collect())\n&lt;class 'ibis.expr.types.arrays.ArrayScalar'&gt;\n</code></pre> <p>Collect elements per group</p> <pre><code>&gt;&gt;&gt; t.group_by(\"key\").agg(v=lambda t: t.value.collect())\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 key    \u2503 v                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 array&lt;int64&gt;         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502 [1, 2, ... +1]       \u2502\n\u2502 b      \u2502 [4, 5]               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Collect elements per group using a filter</p> <pre><code>&gt;&gt;&gt; t.group_by(\"key\").agg(v=lambda t: t.value.collect(where=t.value &gt; 1))\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 key    \u2503 v                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 array&lt;int64&gt;         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502 [2, 3]               \u2502\n\u2502 b      \u2502 [4, 5]               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.desc","title":"<code>desc()</code>","text":"<p>Sort an expression descending.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.fillna","title":"<code>fillna(fill_value)</code>","text":"<p>Replace any null values with the indicated fill value.</p> <p>Parameters:</p> Name Type Description Default <code>fill_value</code> <code>Scalar</code> <p>Value with which to replace <code>NA</code> values in <code>self</code></p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t.sex\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sex    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 male   \u2502\n\u2502 female \u2502\n\u2502 female \u2502\n\u2502 \u2205      \u2502\n\u2502 female \u2502\n\u2502 male   \u2502\n\u2502 female \u2502\n\u2502 male   \u2502\n\u2502 \u2205      \u2502\n\u2502 \u2205      \u2502\n\u2502 \u2026      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.sex.fillna(\"unrecorded\").name(\"sex\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sex        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 male       \u2502\n\u2502 female     \u2502\n\u2502 female     \u2502\n\u2502 unrecorded \u2502\n\u2502 female     \u2502\n\u2502 male       \u2502\n\u2502 female     \u2502\n\u2502 male       \u2502\n\u2502 unrecorded \u2502\n\u2502 unrecorded \u2502\n\u2502 \u2026          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Returns:</p> Type Description <code>Value</code> <p><code>self</code> filled with <code>fill_value</code> where it is <code>NA</code></p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.greatest","title":"<code>greatest(*args)</code>","text":"<p>Compute the largest value among the supplied arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>ir.Value</code> <p>Arguments to choose from</p> <code>()</code> <p>Returns:</p> Type Description <code>Value</code> <p>Maximum of the passed arguments</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.group_concat","title":"<code>group_concat(sep=',', where=None)</code>","text":"<p>Concatenate values using the indicated separator to produce a string.</p> <p>Parameters:</p> Name Type Description Default <code>sep</code> <code>str</code> <p>Separator will be used to join strings</p> <code>','</code> <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter expression</p> <code>None</code> <p>Returns:</p> Type Description <code>StringScalar</code> <p>Concatenated string expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.hash","title":"<code>hash(how='fnv')</code>","text":"<p>Compute an integer hash value.</p> <p>Parameters:</p> Name Type Description Default <code>how</code> <code>str</code> <p>Hash algorithm to use</p> <code>'fnv'</code> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>The hash value of <code>self</code></p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.identical_to","title":"<code>identical_to(other)</code>","text":"<p>Return whether this expression is identical to other.</p> <p>Corresponds to <code>IS NOT DISTINCT FROM</code> in SQL.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Value</code> <p>Expression to compare to</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether this expression is not distinct from <code>other</code></p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.isin","title":"<code>isin(values)</code>","text":"<p>Check whether this expression's values are in <code>values</code>.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Value | Sequence[Value]</code> <p>Values or expression to check for membership</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Expression indicating membership</p> <p>Examples:</p> <p>Check whether a column's values are contained in a sequence</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; table = ibis.table(dict(string_col='string'), name=\"t\")\n&gt;&gt;&gt; table.string_col.isin(['foo', 'bar', 'baz'])\nr0 := UnboundTable: t\n  string_col string\nContains(string_col): Contains(...)\n</code></pre> <p>Check whether a column's values are contained in another table's column</p> <pre><code>&gt;&gt;&gt; table2 = ibis.table(dict(other_string_col='string'), name=\"t2\")\n&gt;&gt;&gt; table.string_col.isin(table2.other_string_col)\nr0 := UnboundTable: t\n  string_col string\nr1 := UnboundTable: t2\n  other_string_col string\nContains(string_col, other_string_col): Contains(...)\n</code></pre>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.isnull","title":"<code>isnull()</code>","text":"<p>Return whether this expression is NULL.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.least","title":"<code>least(*args)</code>","text":"<p>Compute the smallest value among the supplied arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>ir.Value</code> <p>Arguments to choose from</p> <code>()</code> <p>Returns:</p> Type Description <code>Value</code> <p>Minimum of the passed arguments</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.name","title":"<code>name(name)</code>","text":"<p>Rename an expression to <code>name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>The new name of the expression</p> required <p>Returns:</p> Type Description <code>Value</code> <p><code>self</code> with name <code>name</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t = ibis.table(dict(a=\"int64\"), name=\"t\")\n&gt;&gt;&gt; t.a.name(\"b\")\nr0 := UnboundTable: t\n  a int64\nb: r0.a\n</code></pre>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.notin","title":"<code>notin(values)</code>","text":"<p>Check whether this expression's values are not in <code>values</code>.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Value | Sequence[Value]</code> <p>Values or expression to check for lack of membership</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code>'s values are not contained in <code>values</code></p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.notnull","title":"<code>notnull()</code>","text":"<p>Return whether this expression is not NULL.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.nullif","title":"<code>nullif(null_if_expr)</code>","text":"<p>Set values to null if they equal the values <code>null_if_expr</code>.</p> <p>Commonly use to avoid divide-by-zero problems by replacing zero with <code>NULL</code> in the divisor.</p> <p>Parameters:</p> Name Type Description Default <code>null_if_expr</code> <code>Value</code> <p>Expression indicating what values should be NULL</p> required <p>Returns:</p> Type Description <code>Value</code> <p>Value expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.over","title":"<code>over(window=None, *, rows=None, range=None, group_by=None, order_by=None)</code>","text":"<p>Construct a window expression.</p> <p>Parameters:</p> Name Type Description Default <code>window</code> <p>Window specification</p> <code>None</code> <code>rows</code> <p>Whether to use the <code>ROWS</code> window clause</p> <code>None</code> <code>range</code> <p>Whether to use the <code>RANGE</code> window clause</p> <code>None</code> <code>group_by</code> <p>Grouping key</p> <code>None</code> <code>order_by</code> <p>Ordering key</p> <code>None</code> <p>Returns:</p> Type Description <code>Value</code> <p>A window function expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.substitute","title":"<code>substitute(value, replacement=None, else_=None)</code>","text":"<p>Replace values given in <code>values</code> with <code>replacement</code>.</p> <p>This is similar to the pandas <code>replace</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Value | dict</code> <p>Expression or dict.</p> required <code>replacement</code> <code>Value | None</code> <p>If an expression is passed to value, this must be passed.</p> <code>None</code> <code>else_</code> <code>Value | None</code> <p>If an original value does not match <code>value</code>, then <code>else_</code> is used. The default of <code>None</code> means leave the original value unchanged.</p> <code>None</code> <p>Returns:</p> Type Description <code>Value</code> <p>Replaced values</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.to_pandas","title":"<code>to_pandas(**kwargs)</code>","text":"<p>Convert a column expression to a pandas Series or scalar object.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>Same as keyword arguments to <code>execute</code></p> <code>{}</code>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.type","title":"<code>type()</code>","text":"<p>Return the [DataType] of this expression.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Value.typeof","title":"<code>typeof()</code>","text":"<p>Return the data type of the expression.</p> <p>The values of the returned strings are necessarily backend dependent.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>A string indicating the type of the value</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column","title":"<code>Column</code>","text":"<p>         Bases: <code>Value</code>, <code>_FixedTextJupyterMixin</code></p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column-functions","title":"Functions","text":""},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.approx_median","title":"<code>approx_median(where=None)</code>","text":"<p>Return an approximate of the median of <code>self</code>.</p> <p>The result may or may not be exact</p> <p>Whether the result is an approximation depends on the backend.</p> <p>Do not depend on the results being exact</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter in values when <code>where</code> is <code>True</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Scalar</code> <p>An approximation of the median of <code>self</code></p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.approx_nunique","title":"<code>approx_nunique(where=None)</code>","text":"<p>Return the approximate number of distinct elements in <code>self</code>.</p> <p>The result may or may not be exact</p> <p>Whether the result is an approximation depends on the backend.</p> <p>Do not depend on the results being exact</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter in values when <code>where</code> is <code>True</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Scalar</code> <p>An approximate count of the distinct elements of <code>self</code></p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.arbitrary","title":"<code>arbitrary(where=None, how='first')</code>","text":"<p>Select an arbitrary value in a column.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>A filter expression</p> <code>None</code> <code>how</code> <code>Literal['first', 'last', 'heavy']</code> <p>The method to use for selecting the element.</p> <ul> <li><code>\"first\"</code>: Select the first non-<code>NULL</code> element</li> <li><code>\"last\"</code>: Select the last non-<code>NULL</code> element</li> <li><code>\"heavy\"</code>: Select a frequently occurring value using the heavy hitters algorithm. <code>\"heavy\"</code> is only supported by Clickhouse backend.</li> </ul> <code>'first'</code> <p>Returns:</p> Type Description <code>Scalar</code> <p>An expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.argmax","title":"<code>argmax(key, where=None)</code>","text":"<p>Return the value of <code>self</code> that maximizes <code>key</code>.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.argmin","title":"<code>argmin(key, where=None)</code>","text":"<p>Return the value of <code>self</code> that minimizes <code>key</code>.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.count","title":"<code>count(where=None)</code>","text":"<p>Compute the number of rows in an expression.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter expression</p> <code>None</code> <p>Returns:</p> Type Description <code>IntegerScalar</code> <p>Number of elements in an expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.cume_dist","title":"<code>cume_dist()</code>","text":"<p>Return the cumulative distribution over a window.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.cummax","title":"<code>cummax()</code>","text":"<p>Return the cumulative max over a window.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.cummin","title":"<code>cummin()</code>","text":"<p>Return the cumulative min over a window.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.dense_rank","title":"<code>dense_rank()</code>","text":"<p>Position of first element within each group of equal values.</p> <p>Values are returned in sorted order and duplicate values are ignored.</p> <p>Equivalent to SQL's <code>DENSE_RANK()</code>.</p> <p>Examples:</p> <p>values   ranks 1        0 1        0 2        1 2        1 2        1 3        2</p> <p>Returns:</p> Type Description <code>IntegerColumn</code> <p>The rank</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.first","title":"<code>first()</code>","text":"<p>Return the first value of a column.</p> <p>Equivalent to SQL's <code>FIRST_VALUE</code> window function.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.lag","title":"<code>lag(offset=None, default=None)</code>","text":"<p>Return the row located at <code>offset</code> rows before the current row.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>int | ir.IntegerValue | None</code> <p>Index of row to select</p> <code>None</code> <code>default</code> <code>Value | None</code> <p>Value used if no row exists at <code>offset</code></p> <code>None</code>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.last","title":"<code>last()</code>","text":"<p>Return the last value of a column.</p> <p>Equivalent to SQL's <code>LAST_VALUE</code> window function.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.lead","title":"<code>lead(offset=None, default=None)</code>","text":"<p>Return the row located at <code>offset</code> rows after the current row.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>int | ir.IntegerValue | None</code> <p>Index of row to select</p> <code>None</code> <code>default</code> <code>Value | None</code> <p>Value used if no row exists at <code>offset</code></p> <code>None</code>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.max","title":"<code>max(where=None)</code>","text":"<p>Return the maximum of a column.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.min","title":"<code>min(where=None)</code>","text":"<p>Return the minimum of a column.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.mode","title":"<code>mode(where=None)</code>","text":"<p>Return the mode of a column.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.nth","title":"<code>nth(n)</code>","text":"<p>Return the <code>n</code>th value over a window.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | ir.IntegerValue</code> <p>Desired rank value</p> required <p>Returns:</p> Type Description <code>Column</code> <p>The nth value over a window</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.ntile","title":"<code>ntile(buckets)</code>","text":"<p>Return the integer number of a partitioning of the column values.</p> <p>Parameters:</p> Name Type Description Default <code>buckets</code> <code>int | ir.IntegerValue</code> <p>Number of buckets to partition into</p> required"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.nunique","title":"<code>nunique(where=None)</code>","text":"<p>Compute the number of distinct rows in an expression.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter expression</p> <code>None</code> <p>Returns:</p> Type Description <code>IntegerScalar</code> <p>Number of distinct elements in an expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.percent_rank","title":"<code>percent_rank()</code>","text":"<p>Return the relative rank of the values in the column.</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.rank","title":"<code>rank()</code>","text":"<p>Compute position of first element within each equal-value group in sorted order.</p> <p>Equivalent to SQL's <code>RANK()</code> window function.</p> <p>Examples:</p> <p>values   ranks 1        0 1        0 2        2 2        2 2        2 3        5</p> <p>Returns:</p> Type Description <code>Int64Column</code> <p>The min rank</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.summary","title":"<code>summary(exact_nunique=False, prefix='', suffix='')</code>","text":"<p>Compute a set of summary metrics.</p> <p>Parameters:</p> Name Type Description Default <code>exact_nunique</code> <code>bool</code> <p>Compute the exact number of distinct values. Typically slower if <code>True</code>.</p> <code>False</code> <code>prefix</code> <code>str</code> <p>String prefix for metric names</p> <code>''</code> <code>suffix</code> <code>str</code> <p>String suffix for metric names</p> <code>''</code> <p>Returns:</p> Type Description <code>list[NumericScalar]</code> <p>Metrics list</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.topk","title":"<code>topk(k, by=None)</code>","text":"<p>Return a \"top k\" expression.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>Return this number of rows</p> required <code>by</code> <code>ir.Value | None</code> <p>An expression. Defaults to <code>count</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>TableExpr</code> <p>A top-k expression</p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Column.value_counts","title":"<code>value_counts()</code>","text":"<p>Compute a frequency table.</p> <p>Returns:</p> Type Description <code>Table</code> <p>Frequency table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"chars\": char} for char in \"aabcddd\")\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 chars  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502\n\u2502 a      \u2502\n\u2502 b      \u2502\n\u2502 c      \u2502\n\u2502 d      \u2502\n\u2502 d      \u2502\n\u2502 d      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.chars.value_counts()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 chars  \u2503 chars_count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502           2 \u2502\n\u2502 b      \u2502           1 \u2502\n\u2502 c      \u2502           1 \u2502\n\u2502 d      \u2502           3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Scalar","title":"<code>Scalar</code>","text":"<p>         Bases: <code>Value</code></p>"},{"location":"api/expressions/generic/#ibis.expr.types.generic.Scalar-functions","title":"Functions","text":""},{"location":"api/expressions/generic/#ibis.expr.types.generic.Scalar.as_table","title":"<code>as_table()</code>","text":"<p>Promote the scalar expression to a table.</p> <p>Returns:</p> Type Description <code>Table</code> <p>A table expression</p> <p>Examples:</p> <p>Promote an aggregation to a table</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.types as ir\n&gt;&gt;&gt; t = ibis.table(dict(a=\"str\"), name=\"t\")\n&gt;&gt;&gt; expr = t.a.length().sum().name(\"len\").as_table()\n&gt;&gt;&gt; isinstance(expr, ir.Table)\nTrue\n</code></pre> <p>Promote a literal value to a table</p> <pre><code>&gt;&gt;&gt; import ibis.expr.types as ir\n&gt;&gt;&gt; lit = ibis.literal(1).name(\"a\").as_table()\n&gt;&gt;&gt; isinstance(lit, ir.Table)\nTrue\n</code></pre>"},{"location":"api/expressions/geospatial/","title":"Geospatial Expressions","text":"<p>Ibis supports the following geospatial expression APIs</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue","title":"<code>GeoSpatialValue</code>","text":"<p>         Bases: <code>NumericValue</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue-functions","title":"Functions","text":""},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.area","title":"<code>area()</code>","text":"<p>Compute the area of a geospatial value.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>The area of <code>self</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.as_binary","title":"<code>as_binary()</code>","text":"<p>Get the geometry as well-known bytes (WKB) without the SRID data.</p> <p>Returns:</p> Type Description <code>BinaryValue</code> <p>Binary value</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.as_ewkb","title":"<code>as_ewkb()</code>","text":"<p>Get the geometry as well-known bytes (WKB) with the SRID data.</p> <p>Returns:</p> Type Description <code>BinaryValue</code> <p>WKB value</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.as_ewkt","title":"<code>as_ewkt()</code>","text":"<p>Get the geometry as well-known text (WKT) with the SRID data.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>String value</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.as_text","title":"<code>as_text()</code>","text":"<p>Get the geometry as well-known text (WKT) without the SRID data.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>String value</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.azimuth","title":"<code>azimuth(right)</code>","text":"<p>Return the angle in radians from the horizontal of the vector defined by the inputs.</p> <p>Angle is computed clockwise from down-to-up on the clock: 12=0; 3=PI/2; 6=PI; 9=3PI/2.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>FloatingValue</code> <p>azimuth</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.buffer","title":"<code>buffer(radius)</code>","text":"<p>Return all points whose distance from this geometry is less than or equal to <code>radius</code>.</p> <p>Calculations are in the Spatial Reference System of this Geometry.</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <code>float | ir.FloatingValue</code> <p>Floating expression</p> required <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p>Geometry expression</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.centroid","title":"<code>centroid()</code>","text":"<p>Returns the centroid of the geometry.</p> <p>Returns:</p> Type Description <code>PointValue</code> <p>The centroid</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.contains","title":"<code>contains(right)</code>","text":"<p>Check if the geometry contains the <code>right</code>.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> contains <code>right</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.contains_properly","title":"<code>contains_properly(right)</code>","text":"<p>Check if the first geometry contains the second one.</p> <p>Excludes common border points.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether self contains right excluding border points.</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.covered_by","title":"<code>covered_by(right)</code>","text":"<p>Check if the first geometry is covered by the second one.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> is covered by <code>right</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.covers","title":"<code>covers(right)</code>","text":"<p>Check if the first geometry covers the second one.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> covers <code>right</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.crosses","title":"<code>crosses(right)</code>","text":"<p>Check if the geometries have at least one interior point in common.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> and <code>right</code> have at least one common interior point.</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.d_fully_within","title":"<code>d_fully_within(right, distance)</code>","text":"<p>Check if <code>self</code> is entirely within <code>distance</code> from <code>right</code>.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <code>distance</code> <code>ir.FloatingValue</code> <p>Distance to check</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> is within a specified distance from <code>right</code>.</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.d_within","title":"<code>d_within(right, distance)</code>","text":"<p>Check if <code>self</code> is partially within <code>distance</code> from <code>right</code>.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <code>distance</code> <code>ir.FloatingValue</code> <p>Distance to check</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> is partially within <code>distance</code> from <code>right</code>.</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.difference","title":"<code>difference(right)</code>","text":"<p>Return the difference of two geometries.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p>Difference of <code>self</code> and <code>right</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.disjoint","title":"<code>disjoint(right)</code>","text":"<p>Check if the geometries have no points in common.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> and <code>right</code> are disjoint</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.distance","title":"<code>distance(right)</code>","text":"<p>Compute the distance between two geospatial expressions.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry or geography</p> required <p>Returns:</p> Type Description <code>FloatingValue</code> <p>Distance between <code>self</code> and <code>right</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.end_point","title":"<code>end_point()</code>","text":"<p>Return the last point of a <code>LINESTRING</code> geometry as a <code>POINT</code>.</p> <p>Return <code>NULL</code> if the input parameter is not a <code>LINESTRING</code></p> <p>Returns:</p> Type Description <code>PointValue</code> <p>End point</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.envelope","title":"<code>envelope()</code>","text":"<p>Returns a geometry representing the bounding box of <code>self</code>.</p> <p>Returns:</p> Type Description <code>PolygonValue</code> <p>A polygon</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.geo_equals","title":"<code>geo_equals(right)</code>","text":"<p>Check if the geometries are equal.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> equals <code>right</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.geometry_n","title":"<code>geometry_n(n)</code>","text":"<p>Get the 1-based Nth geometry of a multi geometry.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | ir.IntegerValue</code> <p>Nth geometry index</p> required <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p>Geometry value</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.geometry_type","title":"<code>geometry_type()</code>","text":"<p>Get the type of a geometry.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>String representing the type of <code>self</code>.</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.intersection","title":"<code>intersection(right)</code>","text":"<p>Return the intersection of two geometries.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p>Intersection of <code>self</code> and <code>right</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.intersects","title":"<code>intersects(right)</code>","text":"<p>Check if the geometries share any points.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> intersects <code>right</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.is_valid","title":"<code>is_valid()</code>","text":"<p>Check if the geometry is valid.</p> <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> is valid</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.length","title":"<code>length()</code>","text":"<p>Compute the length of a geospatial expression.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>Length of <code>self</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.line_locate_point","title":"<code>line_locate_point(right)</code>","text":"<p>Locate the distance a point falls along the length of a line.</p> <p>Returns a float between zero and one representing the location of the closest point on the linestring to the given point, as a fraction of the total 2d line length.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>PointValue</code> <p>Point geometry</p> required <p>Returns:</p> Type Description <code>FloatingValue</code> <p>Fraction of the total line length</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.line_merge","title":"<code>line_merge()</code>","text":"<p>Merge a <code>MultiLineString</code> into a <code>LineString</code>.</p> <p>Returns a (set of) LineString(s) formed by sewing together the constituent line work of a MultiLineString. If a geometry other than a LineString or MultiLineString is given, this will return an empty geometry collection.</p> <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p>Merged linestrings</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.line_substring","title":"<code>line_substring(start, end)</code>","text":"<p>Clip a substring from a LineString.</p> <p>Returns a linestring that is a substring of the input one, starting and ending at the given fractions of the total 2d length. The second and third arguments are floating point values between zero and one. This only works with linestrings.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>ir.FloatingValue</code> <p>Start value</p> required <code>end</code> <code>ir.FloatingValue</code> <p>End value</p> required <p>Returns:</p> Type Description <code>LineStringValue</code> <p>Clipped linestring</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.max_distance","title":"<code>max_distance(right)</code>","text":"<p>Returns the 2-dimensional max distance between two geometries in projected units.</p> <p>If <code>self</code> and <code>right</code> are the same geometry the function will return the distance between the two vertices most far from each other in that geometry.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>FloatingValue</code> <p>Maximum distance</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.n_points","title":"<code>n_points()</code>","text":"<p>Return the number of points in a geometry. Works for all geometries.</p> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>Number of points</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.n_rings","title":"<code>n_rings()</code>","text":"<p>Return the number of rings for polygons and multipolygons.</p> <p>Outer rings are counted as well.</p> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>Number of rings</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.ordering_equals","title":"<code>ordering_equals(right)</code>","text":"<p>Check if two geometries are equal and have the same point ordering.</p> <p>Returns true if the two geometries are equal and the coordinates are in the same order.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether points and orderings are equal.</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.overlaps","title":"<code>overlaps(right)</code>","text":"<p>Check if the geometries share space, have the same dimension, and are not completely contained by each other.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Overlaps indicator</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.perimeter","title":"<code>perimeter()</code>","text":"<p>Compute the perimeter of a geospatial expression.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>Perimeter of <code>self</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.point_n","title":"<code>point_n(n)</code>","text":"<p>Return the Nth point in a single linestring in the geometry.</p> <p>Negative values are counted backwards from the end of the LineString, so that -1 is the last point. Returns NULL if there is no linestring in the geometry.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>ir.IntegerValue</code> <p>Nth point index</p> required <p>Returns:</p> Type Description <code>PointValue</code> <p>Nth point in <code>self</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.set_srid","title":"<code>set_srid(srid)</code>","text":"<p>Set the spatial reference identifier for the <code>ST_Geometry</code>.</p> <p>Parameters:</p> Name Type Description Default <code>srid</code> <code>ir.IntegerValue</code> <p>SRID integer value</p> required <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p><code>self</code> with SRID set to <code>srid</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.simplify","title":"<code>simplify(tolerance, preserve_collapsed)</code>","text":"<p>Simplify a given geometry.</p> <p>Parameters:</p> Name Type Description Default <code>tolerance</code> <code>ir.FloatingValue</code> <p>Tolerance</p> required <code>preserve_collapsed</code> <code>ir.BooleanValue</code> <p>Whether to preserve collapsed geometries</p> required <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p>Simplified geometry</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.srid","title":"<code>srid()</code>","text":"<p>Return the spatial reference identifier for the ST_Geometry.</p> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>SRID</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.start_point","title":"<code>start_point()</code>","text":"<p>Return the first point of a <code>LINESTRING</code> geometry as a <code>POINT</code>.</p> <p>Return <code>NULL</code> if the input parameter is not a <code>LINESTRING</code></p> <p>Returns:</p> Type Description <code>PointValue</code> <p>Start point</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.touches","title":"<code>touches(right)</code>","text":"<p>Check if the geometries have at least one point in common, but do not intersect.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether self and right are touching</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.transform","title":"<code>transform(srid)</code>","text":"<p>Transform a geometry into a new SRID.</p> <p>Parameters:</p> Name Type Description Default <code>srid</code> <code>ir.IntegerValue</code> <p>Integer expression</p> required <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p>Transformed geometry</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.union","title":"<code>union(right)</code>","text":"<p>Merge two geometries into a union geometry.</p> <p>Returns the pointwise union of the two geometries. This corresponds to the non-aggregate version the PostGIS ST_Union.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>GeoSpatialValue</code> <p>Union of geometries</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.within","title":"<code>within(right)</code>","text":"<p>Check if the first geometry is completely inside of the second.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>GeoSpatialValue</code> <p>Right geometry</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Whether <code>self</code> is in <code>right</code>.</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.x","title":"<code>x()</code>","text":"<p>Return the X coordinate of <code>self</code>, or NULL if not available.</p> <p>Input must be a point.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>X coordinate of <code>self</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.x_max","title":"<code>x_max()</code>","text":"<p>Return the X maxima of a geometry.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>X maxima</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.x_min","title":"<code>x_min()</code>","text":"<p>Return the X minima of a geometry.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>X minima</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.y","title":"<code>y()</code>","text":"<p>Return the Y coordinate of <code>self</code>, or NULL if not available.</p> <p>Input must be a point.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>Y coordinate of <code>self</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.y_max","title":"<code>y_max()</code>","text":"<p>Return the Y maxima of a geometry.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>Y maxima</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialValue.y_min","title":"<code>y_min()</code>","text":"<p>Return the Y minima of a geometry.</p> <p>Returns:</p> Type Description <code>FloatingValue</code> <p>Y minima</p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialColumn","title":"<code>GeoSpatialColumn</code>","text":"<p>         Bases: <code>NumericColumn</code>, <code>GeoSpatialValue</code></p>"},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialColumn-functions","title":"Functions","text":""},{"location":"api/expressions/geospatial/#ibis.expr.types.geospatial.GeoSpatialColumn.unary_union","title":"<code>unary_union()</code>","text":"<p>Aggregate a set of geometries into a union.</p> <p>This corresponds to the aggregate version of the PostGIS ST_Union. We give it a different name (following the corresponding method in GeoPandas) to avoid name conflicts with the non-aggregate version.</p> <p>Returns:</p> Type Description <code>GeoSpatialScalar</code> <p>Union of geometries</p>"},{"location":"api/expressions/numeric/","title":"Numeric and Boolean Expressions","text":"<p>These APIs are available on numeric and boolean expressions.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue","title":"<code>NumericValue</code>","text":"<p>         Bases: <code>Value</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue-functions","title":"Functions","text":""},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__add__","title":"<code>__add__(other)</code>","text":"<p>Add <code>self</code> with <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__floordiv__","title":"<code>__floordiv__(other)</code>","text":"<p>Floor divide <code>self</code> by <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__mod__","title":"<code>__mod__(other)</code>","text":"<p>Compute <code>self</code> modulo <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiply <code>self</code> and <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__neg__","title":"<code>__neg__()</code>","text":"<p>Negate <code>self</code>.</p> <p>Returns:</p> Type Description <code>NumericValue</code> <p><code>self</code> negated</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__pow__","title":"<code>__pow__(other)</code>","text":"<p>Raise <code>self</code> to the <code>other</code>th power.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__rfloordiv__","title":"<code>__rfloordiv__(other)</code>","text":"<p>Floor divide <code>other</code> by <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__rmod__","title":"<code>__rmod__(other)</code>","text":"<p>Compute <code>other</code> modulo <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__rpow__","title":"<code>__rpow__(other)</code>","text":"<p>Raise <code>other</code> to the <code>self</code>th power.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__rsub__","title":"<code>__rsub__(other)</code>","text":"<p>Substract <code>self</code> from <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__rtruediv__","title":"<code>__rtruediv__(other)</code>","text":"<p>Divide <code>other</code> by <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Substract <code>other</code> from <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.__truediv__","title":"<code>__truediv__(other)</code>","text":"<p>Divide <code>self</code> by <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.abs","title":"<code>abs()</code>","text":"<p>Return the absolute value of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.acos","title":"<code>acos()</code>","text":"<p>Compute the arc cosine of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.asin","title":"<code>asin()</code>","text":"<p>Compute the arc sine of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.atan","title":"<code>atan()</code>","text":"<p>Compute the arc tangent of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.atan2","title":"<code>atan2(other)</code>","text":"<p>Compute the two-argument version of arc tangent.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.ceil","title":"<code>ceil()</code>","text":"<p>Return the ceiling of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.clip","title":"<code>clip(lower=None, upper=None)</code>","text":"<p>Trim values outside of <code>lower</code> and <code>upper</code> bounds.</p> <p>Parameters:</p> Name Type Description Default <code>lower</code> <code>NumericValue | None</code> <p>Lower bound</p> <code>None</code> <code>upper</code> <code>NumericValue | None</code> <p>Upper bound</p> <code>None</code> <p>Returns:</p> Type Description <code>NumericValue</code> <p>Clipped input</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.cos","title":"<code>cos()</code>","text":"<p>Compute the cosine of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.cot","title":"<code>cot()</code>","text":"<p>Compute the cotangent of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.degrees","title":"<code>degrees()</code>","text":"<p>Compute the degrees of <code>self</code> radians.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.exp","title":"<code>exp()</code>","text":"<p>Compute \\(e^\\texttt{self}\\).</p> <p>Returns:</p> Type Description <code>NumericValue</code> <p>\\(e^\\texttt{self}\\)</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.floor","title":"<code>floor()</code>","text":"<p>Return the floor of an expression.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.ln","title":"<code>ln()</code>","text":"<p>Compute \\(\\ln\\left(\\texttt{self}\\right)\\).</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.log","title":"<code>log(base=None)</code>","text":"<p>Return the logarithm using a specified base.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>NumericValue | None</code> <p>The base of the logarithm. If <code>None</code>, base <code>e</code> is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>NumericValue</code> <p>Logarithm of <code>arg</code> with base <code>base</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.log10","title":"<code>log10()</code>","text":"<p>Compute \\(\\log_{10}\\left(\\texttt{self}\\right)\\).</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.log2","title":"<code>log2()</code>","text":"<p>Compute \\(\\log_{2}\\left(\\texttt{self}\\right)\\).</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.negate","title":"<code>negate()</code>","text":"<p>Negate a numeric expression.</p> <p>Returns:</p> Type Description <code>NumericValue</code> <p>A numeric value expression</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.nullifzero","title":"<code>nullifzero()</code>","text":"<p>Return <code>NULL</code> if an expression is zero.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.point","title":"<code>point(right)</code>","text":"<p>Return a point constructed from the coordinate values.</p> <p>Constant coordinates result in construction of a <code>POINT</code> literal or column.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>int | float | NumericValue</code> <p>Y coordinate</p> required <p>Returns:</p> Type Description <code>PointValue</code> <p>Points</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.radians","title":"<code>radians()</code>","text":"<p>Compute radians from <code>self</code> degrees.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.round","title":"<code>round(digits=None)</code>","text":"<p>Round values to an indicated number of decimal places.</p> <p>Parameters:</p> Name Type Description Default <code>digits</code> <code>int | IntegerValue | None</code> <p>The number of digits to round to.</p> <p>Here's how the <code>digits</code> parameter affects the expression output type:</p> <code>digits</code> <code>self.type()</code> Output <code>None</code> or <code>0</code> <code>decimal</code> <code>decimal</code> Nonzero <code>decimal</code> <code>decimal</code> <code>None</code> or <code>0</code> Floating <code>int64</code> Nonzero Floating <code>float64</code> <code>None</code> <p>Returns:</p> Type Description <code>NumericValue</code> <p>The rounded expression</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.sign","title":"<code>sign()</code>","text":"<p>Return the sign of the input.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.sin","title":"<code>sin()</code>","text":"<p>Compute the sine of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.sqrt","title":"<code>sqrt()</code>","text":"<p>Compute the square root of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.tan","title":"<code>tan()</code>","text":"<p>Compute the tangent of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericValue.zeroifnull","title":"<code>zeroifnull()</code>","text":"<p>Return zero if an expression is <code>NULL</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn","title":"<code>NumericColumn</code>","text":"<p>         Bases: <code>Column</code>, <code>NumericValue</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn-functions","title":"Functions","text":""},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.bucket","title":"<code>bucket(buckets, closed='left', close_extreme=True, include_under=False, include_over=False)</code>","text":"<p>Compute a discrete binning of a numeric array.</p> <p>Parameters:</p> Name Type Description Default <code>buckets</code> <code>Sequence[int]</code> <p>List of buckets</p> required <code>closed</code> <code>Literal['left', 'right']</code> <p>Which side of each interval is closed. For example:</p> <pre><code>buckets = [0, 100, 200]\nclosed = \"left\"  # 100 falls in 2nd bucket\nclosed = \"right\"  # 100 falls in 1st bucket\n</code></pre> <code>'left'</code> <code>close_extreme</code> <code>bool</code> <p>Whether the extreme values fall in the last bucket</p> <code>True</code> <code>include_over</code> <code>bool</code> <p>Include values greater than the last bucket in the last bucket</p> <code>False</code> <code>include_under</code> <code>bool</code> <p>Include values less than the first bucket in the first bucket</p> <code>False</code> <p>Returns:</p> Type Description <code>IntegerColumn</code> <p>A categorical column expression</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.corr","title":"<code>corr(right, where=None, how='sample')</code>","text":"<p>Return the correlation of two numeric columns.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>NumericColumn</code> <p>Numeric column</p> required <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter</p> <code>None</code> <code>how</code> <code>Literal['sample', 'pop']</code> <p>Population or sample correlation</p> <code>'sample'</code> <p>Returns:</p> Type Description <code>NumericScalar</code> <p>The correlation of <code>left</code> and <code>right</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.cov","title":"<code>cov(right, where=None, how='sample')</code>","text":"<p>Return the covariance of two numeric columns.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <code>NumericColumn</code> <p>Numeric column</p> required <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter</p> <code>None</code> <code>how</code> <code>Literal['sample', 'pop']</code> <p>Population or sample covariance</p> <code>'sample'</code> <p>Returns:</p> Type Description <code>NumericScalar</code> <p>The covariance of <code>self</code> and <code>right</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.cummean","title":"<code>cummean()</code>","text":"<p>Return the cumulative mean of the input.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.cumsum","title":"<code>cumsum()</code>","text":"<p>Return the cumulative sum of the input.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.histogram","title":"<code>histogram(nbins=None, binwidth=None, base=None, eps=1e-13)</code>","text":"<p>Compute a histogram with fixed width bins.</p> <p>Parameters:</p> Name Type Description Default <code>nbins</code> <code>int | None</code> <p>If supplied, will be used to compute the binwidth</p> <code>None</code> <code>binwidth</code> <code>float | None</code> <p>If not supplied, computed from the data (actual max and min values)</p> <code>None</code> <code>base</code> <code>float | None</code> <p>The value of the first histogram bin. Defaults to the minimum value of <code>column</code>.</p> <code>None</code> <code>eps</code> <code>float</code> <p>Allowed floating point epsilon for histogram base</p> <code>1e-13</code> <p>Returns:</p> Type Description <code>Column</code> <p>Bucketed column</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.mean","title":"<code>mean(where=None)</code>","text":"<p>Return the mean of a numeric column.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter</p> <code>None</code> <p>Returns:</p> Type Description <code>NumericScalar</code> <p>The mean of the input expression</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.quantile","title":"<code>quantile(quantile, interpolation=None, where=None)</code>","text":"<p>Return value at the given quantile.</p> <p>Parameters:</p> Name Type Description Default <code>quantile</code> <code>Sequence[NumericValue | float]</code> <p><code>0 &lt;= quantile &lt;= 1</code>, the quantile(s) to compute</p> required <code>interpolation</code> <code>Literal['linear', 'lower', 'higher', 'midpoint', 'nearest'] | None</code> <p>This parameter is backend dependent and may have no effect</p> <p>This parameter specifies the interpolation method to use, when the desired quantile lies between two data points <code>i</code> and <code>j</code>:</p> <ul> <li>linear: <code>i + (j - i) * fraction</code>, where <code>fraction</code> is the fractional part of the index surrounded by <code>i</code> and <code>j</code>.</li> <li>lower: <code>i</code>.</li> <li>higher: <code>j</code>.</li> <li>nearest: <code>i</code> or <code>j</code> whichever is nearest.</li> <li>midpoint: (<code>i</code> + <code>j</code>) / 2.</li> </ul> <code>None</code> <code>where</code> <code>ir.BooleanValue | None</code> <p>Boolean filter for input values</p> <code>None</code> <p>Returns:</p> Type Description <code>NumericScalar</code> <p>Quantile of the input</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.std","title":"<code>std(where=None, how='sample')</code>","text":"<p>Return the standard deviation of a numeric column.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter</p> <code>None</code> <code>how</code> <code>Literal['sample', 'pop']</code> <p>Sample or population standard deviation</p> <code>'sample'</code> <p>Returns:</p> Type Description <code>NumericScalar</code> <p>Standard deviation of <code>arg</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.sum","title":"<code>sum(where=None)</code>","text":"<p>Return the sum of a numeric column.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter</p> <code>None</code> <p>Returns:</p> Type Description <code>NumericScalar</code> <p>The sum of the input expression</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.summary","title":"<code>summary(exact_nunique=False, prefix='', suffix='')</code>","text":"<p>Compute summary metrics from the input numeric expression.</p> <p>Parameters:</p> Name Type Description Default <code>exact_nunique</code> <code>bool</code> <p>Compute the exact number of distinct values. Typically slower if <code>True</code>.</p> <code>False</code> <code>prefix</code> <code>str</code> <p>String prefix for metric names</p> <code>''</code> <code>suffix</code> <code>str</code> <p>String suffix for metric names</p> <code>''</code> <p>Returns:</p> Type Description <code>list[NumericScalar]</code> <p>Metrics list</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.NumericColumn.var","title":"<code>var(where=None, how='sample')</code>","text":"<p>Return the variance of a numeric column.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Filter</p> <code>None</code> <code>how</code> <code>Literal['sample', 'pop']</code> <p>Sample or population variance</p> <code>'sample'</code> <p>Returns:</p> Type Description <code>NumericScalar</code> <p>Standard deviation of <code>arg</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue","title":"<code>IntegerValue</code>","text":"<p>         Bases: <code>NumericValue</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue-functions","title":"Functions","text":""},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.__and__","title":"<code>__and__(other)</code>","text":"<p>Bitwise and <code>self</code> with <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.__invert__","title":"<code>__invert__()</code>","text":"<p>Bitwise not of <code>self</code>.</p> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>Inverted bits of <code>self</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.__lshift__","title":"<code>__lshift__(other)</code>","text":"<p>Bitwise left shift <code>self</code> with <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.__or__","title":"<code>__or__(other)</code>","text":"<p>Bitwise or <code>self</code> with <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.__rlshift__","title":"<code>__rlshift__(other)</code>","text":"<p>Bitwise left shift <code>self</code> with <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.__rrshift__","title":"<code>__rrshift__(other)</code>","text":"<p>Bitwise right shift <code>self</code> with <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.__rshift__","title":"<code>__rshift__(other)</code>","text":"<p>Bitwise right shift <code>self</code> with <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.__xor__","title":"<code>__xor__(other)</code>","text":"<p>Bitwise xor <code>self</code> with <code>other</code>.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.convert_base","title":"<code>convert_base(from_base, to_base)</code>","text":"<p>Convert an integer from one base to another.</p> <p>Parameters:</p> Name Type Description Default <code>from_base</code> <code>IntegerValue</code> <p>Numeric base of expression</p> required <code>to_base</code> <code>IntegerValue</code> <p>New base</p> required <p>Returns:</p> Type Description <code>IntegerValue</code> <p>Converted expression</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.label","title":"<code>label(labels, nulls=None)</code>","text":"<p>Label a set of integer values with strings.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Iterable[str]</code> <p>An iterable of string labels. Each integer value in <code>self</code> will be mapped to a value in <code>labels</code>.</p> required <code>nulls</code> <code>str | None</code> <p>String label to use for <code>NULL</code> values</p> <code>None</code> <p>Returns:</p> Type Description <code>StringValue</code> <p><code>self</code> labeled with <code>labels</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [0, 1, 0, 2]})\n&gt;&gt;&gt; t.select(t.a, labeled=t.a.label([\"a\", \"b\", \"c\"]))\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 labeled \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     0 \u2502 a       \u2502\n\u2502     1 \u2502 b       \u2502\n\u2502     0 \u2502 a       \u2502\n\u2502     2 \u2502 c       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.to_interval","title":"<code>to_interval(unit='s')</code>","text":"<p>Convert an integer to an interval.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>Literal['Y', 'M', 'W', 'D', 'h', 'm', 's', 'ms', 'us', 'ns']</code> <p>Unit for the resulting interval</p> <code>'s'</code> <p>Returns:</p> Type Description <code>IntervalValue</code> <p>An interval in units of <code>unit</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerValue.to_timestamp","title":"<code>to_timestamp(unit='s')</code>","text":"<p>Convert an integral UNIX timestamp to a timestamp expression.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>Literal['s', 'ms', 'us']</code> <p>The resolution of <code>arg</code></p> <code>'s'</code> <p>Returns:</p> Type Description <code>TimestampValue</code> <p><code>self</code> converted to a timestamp</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerColumn","title":"<code>IntegerColumn</code>","text":"<p>         Bases: <code>NumericColumn</code>, <code>IntegerValue</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerColumn-functions","title":"Functions","text":""},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerColumn.bit_and","title":"<code>bit_and(where=None)</code>","text":"<p>Aggregate the column using the bitwise and operator.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerColumn.bit_or","title":"<code>bit_or(where=None)</code>","text":"<p>Aggregate the column using the bitwise or operator.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.IntegerColumn.bit_xor","title":"<code>bit_xor(where=None)</code>","text":"<p>Aggregate the column using the bitwise exclusive or operator.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.FloatingValue","title":"<code>FloatingValue</code>","text":"<p>         Bases: <code>NumericValue</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.FloatingValue-functions","title":"Functions","text":""},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.FloatingValue.isinf","title":"<code>isinf()</code>","text":"<p>Return whether the value is infinity.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.FloatingValue.isnan","title":"<code>isnan()</code>","text":"<p>Return whether the value is NaN.</p>"},{"location":"api/expressions/numeric/#ibis.expr.types.numeric.DecimalValue","title":"<code>DecimalValue</code>","text":"<p>         Bases: <code>NumericValue</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.logical.BooleanValue","title":"<code>BooleanValue</code>","text":"<p>         Bases: <code>NumericValue</code></p>"},{"location":"api/expressions/numeric/#ibis.expr.types.logical.BooleanValue-functions","title":"Functions","text":""},{"location":"api/expressions/numeric/#ibis.expr.types.logical.BooleanValue.ifelse","title":"<code>ifelse(true_expr, false_expr)</code>","text":"<p>Construct a ternary conditional expression.</p> <p>Parameters:</p> Name Type Description Default <code>true_expr</code> <code>ir.Value</code> <p>Expression to return if <code>self</code> evaluates to <code>True</code></p> required <code>false_expr</code> <code>ir.Value</code> <p>Expression to return if <code>self</code> evaluates to <code>False</code></p> required <p>Returns:</p> Type Description <code>Value</code> <p>The value of <code>true_expr</code> if <code>arg</code> is <code>True</code> else <code>false_expr</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t = ibis.table([(\"is_person\", \"boolean\")], name=\"t\")\n&gt;&gt;&gt; expr = t.is_person.ifelse(\"yes\", \"no\")\n&gt;&gt;&gt; print(ibis.impala.compile(expr.name(\"tmp\")))\nSELECT if(t0.`is_person`, 'yes', 'no') AS `tmp`\nFROM t t0\n</code></pre>"},{"location":"api/expressions/strings/","title":"String Expressions","text":"<p>All string operations are valid for both scalars and columns.</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue","title":"<code>StringValue</code>","text":"<p>         Bases: <code>Value</code></p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue-functions","title":"Functions","text":""},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.__add__","title":"<code>__add__(other)</code>","text":"<p>Concatenate strings.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>str | StringValue</code> <p>String to concatenate</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>All strings concatenated</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"bac\", \"bca\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 s      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 abc    \u2502\n\u2502 bac    \u2502\n\u2502 bca    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s + \"z\"\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringConcat() \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 abcz           \u2502\n\u2502 bacz           \u2502\n\u2502 bcaz           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s + t.s\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringConcat() \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 abcabc         \u2502\n\u2502 bacbac         \u2502\n\u2502 bcabca         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Index or slice a string expression.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>slice | int | ir.IntegerScalar</code> <p><code>int</code>, <code>slice</code> or integer scalar expression</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Indexed or sliced string value</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"food\": [\"bread\", \"cheese\", \"rice\"], \"idx\": [1, 2, 4]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 food   \u2503 idx   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bread  \u2502     1 \u2502\n\u2502 cheese \u2502     2 \u2502\n\u2502 rice   \u2502     4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.food[0]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Substring(food, 0, 1) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 b                     \u2502\n\u2502 c                     \u2502\n\u2502 r                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.food[:3]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Substring(food, 0, 3) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bre                   \u2502\n\u2502 che                   \u2502\n\u2502 ric                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.food[3:5]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Substring(food, 3, 2) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ad                    \u2502\n\u2502 es                    \u2502\n\u2502 e                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.food[7]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Substring(food, 7, 1) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ~                     \u2502\n\u2502 ~                     \u2502\n\u2502 ~                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.__radd__","title":"<code>__radd__(other)</code>","text":"<p>Concatenate strings.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>str | StringValue</code> <p>String to concatenate</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>All strings concatenated</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"bac\", \"bca\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 s      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 abc    \u2502\n\u2502 bac    \u2502\n\u2502 bca    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; \"z\" + t.s\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringConcat() \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 zabc           \u2502\n\u2502 zbac           \u2502\n\u2502 zbca           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.ascii_str","title":"<code>ascii_str()</code>","text":"<p>Return the numeric ASCII code of the first character of a string.</p> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>ASCII code of the first character of the input</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"def\", \"ghi\"]})\n&gt;&gt;&gt; t.s.ascii_str()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringAscii(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int32          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502             97 \u2502\n\u2502            100 \u2502\n\u2502            103 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.authority","title":"<code>authority()</code>","text":"<p>Parse a URL and extract authority.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; url = ibis.literal(\"https://user:pass@example.com:80/docs/books\")\n&gt;&gt;&gt; result = url.authority()  # user:pass@example.com:80\n</code></pre> <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted string value</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.capitalize","title":"<code>capitalize()</code>","text":"<p>Capitalize the input string.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>Capitalized string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"def\", \"ghi\"]})\n&gt;&gt;&gt; t.s.capitalize()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Capitalize(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Abc           \u2502\n\u2502 Def           \u2502\n\u2502 Ghi           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.concat","title":"<code>concat(other, *args)</code>","text":"<p>Concatenate strings.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>str | StringValue</code> <p>String to concatenate</p> required <code>args</code> <code>str | StringValue</code> <p>Additional strings to concatenate</p> <code>()</code> <p>Returns:</p> Type Description <code>StringValue</code> <p>All strings concatenated</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"bac\", \"bca\"]})\n&gt;&gt;&gt; t.s.concat(\"xyz\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringConcat() \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 abcxyz         \u2502\n\u2502 bacxyz         \u2502\n\u2502 bcaxyz         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.contains","title":"<code>contains(substr)</code>","text":"<p>Return whether the expression contains <code>substr</code>.</p> <p>Parameters:</p> Name Type Description Default <code>substr</code> <code>str | StringValue</code> <p>Substring for which to check</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Boolean indicating the presence of <code>substr</code> in the expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"bab\", \"ddd\", \"eaf\"]})\n&gt;&gt;&gt; t.s.contains(\"a\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringContains(s, 'a') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 True                   \u2502\n\u2502 False                  \u2502\n\u2502 True                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.convert_base","title":"<code>convert_base(from_base, to_base)</code>","text":"<p>Convert a string representing an integer from one base to another.</p> <p>Parameters:</p> Name Type Description Default <code>from_base</code> <code>int | ir.IntegerValue</code> <p>Numeric base of the expression</p> required <code>to_base</code> <code>int | ir.IntegerValue</code> <p>New base</p> required <p>Returns:</p> Type Description <code>IntegerValue</code> <p>Converted expression</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.endswith","title":"<code>endswith(end)</code>","text":"<p>Determine if <code>self</code> ends with <code>end</code>.</p> <p>Parameters:</p> Name Type Description Default <code>end</code> <code>str | StringValue</code> <p>Suffix to check for</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Boolean indicating whether <code>self</code> ends with <code>end</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"Ibis project\", \"GitHub\"]})\n&gt;&gt;&gt; t.s.endswith(\"project\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 EndsWith(s, 'project') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 True                   \u2502\n\u2502 False                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.file","title":"<code>file()</code>","text":"<p>Parse a URL and extract file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; url = ibis.literal(\"https://example.com:80/docs/books/tutorial/index.html?name=networking\")\n&gt;&gt;&gt; result = url.authority()  # docs/books/tutorial/index.html?name=networking\n</code></pre> <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted string value</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.find","title":"<code>find(substr, start=None, end=None)</code>","text":"<p>Return the position of the first occurence of substring.</p> <p>Parameters:</p> Name Type Description Default <code>substr</code> <code>str | StringValue</code> <p>Substring to search for</p> required <code>start</code> <code>int | ir.IntegerValue | None</code> <p>Zero based index of where to start the search</p> <code>None</code> <code>end</code> <code>int | ir.IntegerValue | None</code> <p>Zero based index of where to stop the search. Currently not implemented.</p> <code>None</code> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>Position of <code>substr</code> in <code>arg</code> starting from <code>start</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"bac\", \"bca\"]})\n&gt;&gt;&gt; t.s.find(\"a\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringFind(s, 'a') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                  0 \u2502\n\u2502                  1 \u2502\n\u2502                  2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s.find(\"z\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringFind(s, 'z') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                 -1 \u2502\n\u2502                 -1 \u2502\n\u2502                 -1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.find_in_set","title":"<code>find_in_set(str_list)</code>","text":"<p>Find the first occurence of <code>str_list</code> within a list of strings.</p> <p>No string in <code>str_list</code> can have a comma.</p> <p>Parameters:</p> Name Type Description Default <code>str_list</code> <code>Sequence[str]</code> <p>Sequence of strings</p> required <p>Returns:</p> Type Description <code>IntegerValue</code> <p>Position of <code>str_list</code> in <code>self</code>. Returns -1 if <code>self</code> isn't found or if <code>self</code> contains <code>','</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; table = ibis.table(dict(string_col='string'))\n&gt;&gt;&gt; result = table.string_col.find_in_set(['a', 'b'])\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.fragment","title":"<code>fragment()</code>","text":"<p>Parse a URL and extract fragment identifier.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; url = ibis.literal(\"https://example.com:80/docs/#DOWNLOADING\")\n&gt;&gt;&gt; result = url.fragment()  # DOWNLOADING\n</code></pre> <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted string value</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.hashbytes","title":"<code>hashbytes(how='sha256')</code>","text":"<p>Compute the binary hash value of the input.</p> <p>Parameters:</p> Name Type Description Default <code>how</code> <code>Literal['md5', 'sha1', 'sha256', 'sha512']</code> <p>Hash algorithm to use</p> <code>'sha256'</code> <p>Returns:</p> Type Description <code>BinaryValue</code> <p>Binary expression</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.host","title":"<code>host()</code>","text":"<p>Parse a URL and extract host.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; url = ibis.literal(\"https://user:pass@example.com:80/docs/books\")\n&gt;&gt;&gt; result = url.authority()  # example.com\n</code></pre> <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted string value</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.ilike","title":"<code>ilike(patterns)</code>","text":"<p>Match <code>patterns</code> against <code>self</code>, case-insensitive.</p> <p>This function is modeled after SQL's <code>ILIKE</code> directive. Use <code>%</code> as a multiple-character wildcard or <code>_</code> as a single-character wildcard.</p> <p>Use <code>re_search</code> or <code>rlike</code> for regular expression-based matching.</p> <p>Parameters:</p> Name Type Description Default <code>patterns</code> <code>str | StringValue | Iterable[str | StringValue]</code> <p>If <code>pattern</code> is a list, then if any pattern matches the input then the corresponding row in the output is <code>True</code>.</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Column indicating matches</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"Ibis project\", \"GitHub\"]})\n&gt;&gt;&gt; t.s.ilike(\"%PROJect\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringSQLILike(s, '%PROJect') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 True                          \u2502\n\u2502 False                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.join","title":"<code>join(strings)</code>","text":"<p>Join a list of strings using <code>self</code> as the separator.</p> <p>Parameters:</p> Name Type Description Default <code>strings</code> <code>Sequence[str | StringValue] | ir.ArrayValue</code> <p>Strings to join with <code>arg</code></p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Joined string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"arr\": [[\"a\", \"b\", \"c\"], None, [], [\"b\", None]]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 arr                  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;string&gt;        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ['a', 'b', ... +1]   \u2502\n\u2502 \u2205                    \u2502\n\u2502 []                   \u2502\n\u2502 ['b', None]          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; ibis.literal(\"|\").join(t.arr)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ArrayStringJoin('|', arr) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a|b|c                     \u2502\n\u2502 \u2205                         \u2502\n\u2502 \u2205                         \u2502\n\u2502 b                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.join--see-also","title":"See Also","text":"<p><code>ArrayValue.join</code></p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.left","title":"<code>left(nchars)</code>","text":"<p>Return the <code>nchars</code> left-most characters.</p> <p>Parameters:</p> Name Type Description Default <code>nchars</code> <code>int | ir.IntegerValue</code> <p>Maximum number of characters to return</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Characters from the start</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"defg\", \"hijlk\"]})\n&gt;&gt;&gt; t.s.left(2)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Substring(s, 0, 2) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ab                 \u2502\n\u2502 de                 \u2502\n\u2502 hi                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.length","title":"<code>length()</code>","text":"<p>Compute the length of a string.</p> <p>Returns:</p> Type Description <code>IntegerValue</code> <p>The length of each string in the expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"aaa\", \"a\", \"aa\"]})\n&gt;&gt;&gt; t.s.length()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringLength(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int32           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502               3 \u2502\n\u2502               1 \u2502\n\u2502               2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.like","title":"<code>like(patterns)</code>","text":"<p>Match <code>patterns</code> against <code>self</code>, case-sensitive.</p> <p>This function is modeled after the SQL <code>LIKE</code> directive. Use <code>%</code> as a multiple-character wildcard or <code>_</code> as a single-character wildcard.</p> <p>Use <code>re_search</code> or <code>rlike</code> for regular expression-based matching.</p> <p>Parameters:</p> Name Type Description Default <code>patterns</code> <code>str | StringValue | Iterable[str | StringValue]</code> <p>If <code>pattern</code> is a list, then if any pattern matches the input then the corresponding row in the output is <code>True</code>.</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Column indicating matches</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"Ibis project\", \"GitHub\"]})\n&gt;&gt;&gt; t.s.like(\"%project\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringSQLLike(s, '%project') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 True                         \u2502\n\u2502 False                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.lower","title":"<code>lower()</code>","text":"<p>Convert string to all lowercase.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>Lowercase string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"AAA\", \"a\", \"AA\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 s      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 AAA    \u2502\n\u2502 a      \u2502\n\u2502 AA     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s.lower()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Lowercase(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 aaa          \u2502\n\u2502 a            \u2502\n\u2502 aa           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.lpad","title":"<code>lpad(length, pad=' ')</code>","text":"<p>Pad <code>arg</code> by truncating on the right or padding on the left.</p> <p>Parameters:</p> Name Type Description Default <code>length</code> <code>int | ir.IntegerValue</code> <p>Length of output string</p> required <code>pad</code> <code>str | StringValue</code> <p>Pad character</p> <code>' '</code> <p>Returns:</p> Type Description <code>StringValue</code> <p>Left-padded string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"def\", \"ghij\"]})\n&gt;&gt;&gt; t.s.lpad(5, \"-\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 LPad(s, 5, '-') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 --abc           \u2502\n\u2502 --def           \u2502\n\u2502 -ghij           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.lstrip","title":"<code>lstrip()</code>","text":"<p>Remove whitespace from the left side of string.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>Left-stripped string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"\\ta\\t\", \"\\nb\\n\", \"\\vc\\t\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 s      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \\ta\\t  \u2502\n\u2502 \\nb\\n  \u2502\n\u2502 \\vc\\t  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s.lstrip()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 LStrip(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a\\t       \u2502\n\u2502 b\\n       \u2502\n\u2502 c\\t       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.path","title":"<code>path()</code>","text":"<p>Parse a URL and extract path.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; url = ibis.literal(\"https://example.com:80/docs/books/tutorial/index.html?name=networking\")\n&gt;&gt;&gt; result = url.authority()  # docs/books/tutorial/index.html\n</code></pre> <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted string value</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.protocol","title":"<code>protocol()</code>","text":"<p>Parse a URL and extract protocol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; url = ibis.literal(\"https://user:pass@example.com:80/docs/books\")\n&gt;&gt;&gt; result = url.protocol()  # https\n</code></pre> <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted string value</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.query","title":"<code>query(key=None)</code>","text":"<p>Parse a URL and returns query strring or query string parameter.</p> <p>If key is passed, return the value of the query string parameter named. If key is absent, return the query string.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | StringValue | None</code> <p>Query component to extract</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; url = ibis.literal(\"https://example.com:80/docs/books/tutorial/index.html?name=networking\")\n&gt;&gt;&gt; result = url.query()  # name=networking\n&gt;&gt;&gt; query_name = url.query('name')  # networking\n</code></pre> <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted string value</p>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.re_extract","title":"<code>re_extract(pattern, index)</code>","text":"<p>Return the specified match at <code>index</code> from a regex <code>pattern</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str | StringValue</code> <p>Reguar expression pattern string</p> required <code>index</code> <code>int | ir.IntegerValue</code> <p>The index of the match group to return.</p> <p>The behavior of this function follows the behavior of Python's <code>re.match</code>: when <code>index</code> is zero and there's a match, return the entire string, otherwise return the content of the <code>index</code>-th match group.</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted match or whole string if <code>index</code> is zero</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"bac\", \"bca\"]})\n</code></pre> <p>Extract a specific group</p> <pre><code>&gt;&gt;&gt; t.s.re_extract(r\"^(a)bc\", 1)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 RegexExtract(s, '^(a)bc', 1) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a                            \u2502\n\u2502 ~                            \u2502\n\u2502 ~                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Extract the entire match</p> <pre><code>&gt;&gt;&gt; t.s.re_extract(r\"^(a)bc\", 0)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 RegexExtract(s, '^(a)bc', 0) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 abc                          \u2502\n\u2502 ~                            \u2502\n\u2502 ~                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.re_replace","title":"<code>re_replace(pattern, replacement)</code>","text":"<p>Replace match found by regex <code>pattern</code> with <code>replacement</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str | StringValue</code> <p>Regular expression string</p> required <code>replacement</code> <code>str | StringValue</code> <p>Replacement string or regular expression</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Modified string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"bac\", \"bca\"]})\n&gt;&gt;&gt; t.s.re_replace(\"^(a)\", \"b\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 RegexReplace(s, '^(a)', 'b') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bbc                          \u2502\n\u2502 bac                          \u2502\n\u2502 bca                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.re_search","title":"<code>re_search(pattern)</code>","text":"<p>Return whether the values match <code>pattern</code>.</p> <p>Returns <code>True</code> if the regex matches a string and <code>False</code> otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str | StringValue</code> <p>Regular expression use for searching</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Indicator of matches</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"Ibis project\", \"GitHub\"]})\n&gt;&gt;&gt; t.s.re_search(\".+Hub\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 RegexSearch(s, '.+Hub') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 False                   \u2502\n\u2502 True                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.repeat","title":"<code>repeat(n)</code>","text":"<p>Repeat a string <code>n</code> times.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | ir.IntegerValue</code> <p>Number of repetitions</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Repeated string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"a\", \"bb\", \"c\"]})\n&gt;&gt;&gt; t.s.repeat(5)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Repeat(s, 5) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 aaaaa        \u2502\n\u2502 bbbbbbbbbb   \u2502\n\u2502 ccccc        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.replace","title":"<code>replace(pattern, replacement)</code>","text":"<p>Replace each exact match of <code>pattern</code> with <code>replacement</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>StringValue</code> <p>String pattern</p> required <code>replacement</code> <code>StringValue</code> <p>String replacement</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Replaced string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"bac\", \"bca\"]})\n&gt;&gt;&gt; t.s.replace(\"b\", \"z\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringReplace(s, 'b', 'z') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 azc                        \u2502\n\u2502 zac                        \u2502\n\u2502 zca                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.reverse","title":"<code>reverse()</code>","text":"<p>Reverse the characters of a string.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>Reversed string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"def\", \"ghi\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 s      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 abc    \u2502\n\u2502 def    \u2502\n\u2502 ghi    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s.reverse()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Reverse(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 cba        \u2502\n\u2502 fed        \u2502\n\u2502 ihg        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.right","title":"<code>right(nchars)</code>","text":"<p>Return up to <code>nchars</code> from the end of each string.</p> <p>Parameters:</p> Name Type Description Default <code>nchars</code> <code>int | ir.IntegerValue</code> <p>Maximum number of characters to return</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Characters from the end</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"defg\", \"hijlk\"]})\n&gt;&gt;&gt; t.s.right(2)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StrRight(s, 2) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bc             \u2502\n\u2502 fg             \u2502\n\u2502 lk             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.rpad","title":"<code>rpad(length, pad=' ')</code>","text":"<p>Pad <code>self</code> by truncating or padding on the right.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <p>String to pad</p> required <code>length</code> <code>int | ir.IntegerValue</code> <p>Length of output string</p> required <code>pad</code> <code>str | StringValue</code> <p>Pad character</p> <code>' '</code> <p>Returns:</p> Type Description <code>StringValue</code> <p>Right-padded string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"def\", \"ghij\"]})\n&gt;&gt;&gt; t.s.rpad(5, \"-\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 RPad(s, 5, '-') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 abc--           \u2502\n\u2502 def--           \u2502\n\u2502 ghij-           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.rstrip","title":"<code>rstrip()</code>","text":"<p>Remove whitespace from the right side of string.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>Right-stripped string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"\\ta\\t\", \"\\nb\\n\", \"\\vc\\t\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 s      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \\ta\\t  \u2502\n\u2502 \\nb\\n  \u2502\n\u2502 \\vc\\t  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s.rstrip()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 RStrip(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \\ta       \u2502\n\u2502 \\nb       \u2502\n\u2502 \\vc       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.split","title":"<code>split(delimiter)</code>","text":"<p>Split as string on <code>delimiter</code>.</p> <p>This API only works on backends with array support.</p> <p>Parameters:</p> Name Type Description Default <code>delimiter</code> <code>str | StringValue</code> <p>Value to split by</p> required <p>Returns:</p> Type Description <code>ArrayValue</code> <p>The string split by <code>delimiter</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"col\": [\"a,b,c\", \"d,e\", \"f\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 col    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a,b,c  \u2502\n\u2502 d,e    \u2502\n\u2502 f      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.col.split(\",\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringSplit(col, ',') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 array&lt;string&gt;         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ['a', 'b', ... +1]    \u2502\n\u2502 ['d', 'e']            \u2502\n\u2502 ['f']                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.startswith","title":"<code>startswith(start)</code>","text":"<p>Determine whether <code>self</code> starts with <code>end</code>.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>str | StringValue</code> <p>prefix to check for</p> required <p>Returns:</p> Type Description <code>BooleanValue</code> <p>Boolean indicating whether <code>self</code> starts with <code>start</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"Ibis project\", \"GitHub\"]})\n&gt;&gt;&gt; t.s.startswith(\"Ibis\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StartsWith(s, 'Ibis') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 boolean               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 True                  \u2502\n\u2502 False                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.strip","title":"<code>strip()</code>","text":"<p>Remove whitespace from left and right sides of a string.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>Stripped string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"\\ta\\t\", \"\\nb\\n\", \"\\vc\\t\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 s      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \\ta\\t  \u2502\n\u2502 \\nb\\n  \u2502\n\u2502 \\vc\\t  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s.strip()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Strip(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a        \u2502\n\u2502 b        \u2502\n\u2502 c        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.substr","title":"<code>substr(start, length=None)</code>","text":"<p>Extract a substring.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>int | ir.IntegerValue</code> <p>First character to start splitting, indices start at 0</p> required <code>length</code> <code>int | ir.IntegerValue | None</code> <p>Maximum length of each substring. If not supplied, searches the entire string</p> <code>None</code> <p>Returns:</p> Type Description <code>StringValue</code> <p>Found substring</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"abc\", \"defg\", \"hijlk\"]})\n&gt;&gt;&gt; t.s.substr(2)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Substring(s, 2) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 c               \u2502\n\u2502 fg              \u2502\n\u2502 jlk             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.to_timestamp","title":"<code>to_timestamp(format_str)</code>","text":"<p>Parse a string and return a timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>format_str</code> <code>str</code> <p>Format string in <code>strptime</code> format</p> required <p>Returns:</p> Type Description <code>TimestampValue</code> <p>Parsed timestamp value</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"ts\": [\"20170206\"]})\n&gt;&gt;&gt; t.ts.to_timestamp(\"%Y%m%d\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 StringToTimestamp(ts, '%Y%m%d') \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 timestamp('UTC')                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2017-02-06 00:00:00+00:00       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.translate","title":"<code>translate(from_str, to_str)</code>","text":"<p>Replace <code>from_str</code> characters in <code>self</code> characters in <code>to_str</code>.</p> <p>To avoid unexpected behavior, <code>from_str</code> should be shorter than <code>to_str</code>.</p> <p>Parameters:</p> Name Type Description Default <code>from_str</code> <code>StringValue</code> <p>Characters in <code>arg</code> to replace</p> required <code>to_str</code> <code>StringValue</code> <p>Characters to use for replacement</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Translated string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; table = ibis.table(dict(string_col='string'))\n&gt;&gt;&gt; result = table.string_col.translate('a', 'b')\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.upper","title":"<code>upper()</code>","text":"<p>Convert string to all uppercase.</p> <p>Returns:</p> Type Description <code>StringValue</code> <p>Uppercase string</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"s\": [\"aaa\", \"A\", \"aa\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 s      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 aaa    \u2502\n\u2502 A      \u2502\n\u2502 aa     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.s.upper()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Uppercase(s) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 AAA          \u2502\n\u2502 A            \u2502\n\u2502 AA           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/strings/#ibis.expr.types.strings.StringValue.userinfo","title":"<code>userinfo()</code>","text":"<p>Parse a URL and extract user info.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; url = ibis.literal(\"https://user:pass@example.com:80/docs/books\")\n&gt;&gt;&gt; result = url.authority()  # user:pass\n</code></pre> <p>Returns:</p> Type Description <code>StringValue</code> <p>Extracted string value</p>"},{"location":"api/expressions/tables/","title":"Table Expressions","text":"<p>Table expressions form the basis for most Ibis expressions.</p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table","title":"<code>Table</code>","text":"<p>         Bases: <code>Expr</code>, <code>_FixedTextJupyterMixin</code></p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table-attributes","title":"Attributes","text":""},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.columns","title":"<code>columns: list[str]</code>  <code>property</code>","text":"<p>The list of columns in this table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.starwars.fetch()\n&gt;&gt;&gt; t.columns\n['name',\n 'height',\n 'mass',\n 'hair_color',\n 'skin_color',\n 'eye_color',\n 'birth_year',\n 'sex',\n 'gender',\n 'homeworld',\n 'species',\n 'films',\n 'vehicles',\n 'starships']\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table-functions","title":"Functions","text":""},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.__contains__","title":"<code>__contains__(name)</code>","text":"<p>Return whether <code>name</code> is a column in the table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Possible column name</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether <code>name</code> is a column in <code>self</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t = ibis.table(dict(a=\"string\", b=\"float\"), name=\"t\")\n&gt;&gt;&gt; \"a\" in t\nTrue\n&gt;&gt;&gt; \"c\" in t\nFalse\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.__getattr__","title":"<code>__getattr__(key)</code>","text":"<p>Return the column name of a table.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Column name</p> required <p>Returns:</p> Type Description <code>Column</code> <p>Column expression with name <code>key</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t.island\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 \u2026         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.__getitem__","title":"<code>__getitem__(what)</code>","text":"<p>Select items from a table expression.</p> <p>This method implements square bracket syntax for table expressions, including various forms of projection and filtering.</p> <p>Parameters:</p> Name Type Description Default <code>what</code> <p>Selection object. This can be a variety of types including strings, ints, lists.</p> required <p>Returns:</p> Type Description <code>Table | Column</code> <p>The return type depends on the input. For a single string or int input a column is returned, otherwise a table is returned.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502 \u2026 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Return a column by name</p> <pre><code>&gt;&gt;&gt; t[\"island\"]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 \u2026         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Return the second column, starting from index 0</p> <pre><code>&gt;&gt;&gt; t.columns[1]\n'island'\n&gt;&gt;&gt; t[1]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 Torgersen \u2502\n\u2502 \u2026         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Extract a range of rows</p> <pre><code>&gt;&gt;&gt; t[:2]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t[:5]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t[2:5]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Select columns</p> <pre><code>&gt;&gt;&gt; t[[\"island\", \"bill_length_mm\"]].head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 bill_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 float64        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502           39.1 \u2502\n\u2502 Torgersen \u2502           39.5 \u2502\n\u2502 Torgersen \u2502           40.3 \u2502\n\u2502 Torgersen \u2502            nan \u2502\n\u2502 Torgersen \u2502           36.7 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t[\"island\", \"bill_length_mm\"].head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 bill_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 float64        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502           39.1 \u2502\n\u2502 Torgersen \u2502           39.5 \u2502\n\u2502 Torgersen \u2502           40.3 \u2502\n\u2502 Torgersen \u2502            nan \u2502\n\u2502 Torgersen \u2502           36.7 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t[_.island, _.bill_length_mm].head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 bill_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 float64        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502           39.1 \u2502\n\u2502 Torgersen \u2502           39.5 \u2502\n\u2502 Torgersen \u2502           40.3 \u2502\n\u2502 Torgersen \u2502            nan \u2502\n\u2502 Torgersen \u2502           36.7 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Filtering</p> <pre><code>&gt;&gt;&gt; t[t.island.lower() != \"torgersen\"].head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Biscoe \u2502           37.8 \u2502          18.3 \u2502               174 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Biscoe \u2502           37.7 \u2502          18.7 \u2502               180 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Biscoe \u2502           35.9 \u2502          19.2 \u2502               189 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Biscoe \u2502           38.2 \u2502          18.1 \u2502               185 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Biscoe \u2502           38.8 \u2502          17.2 \u2502               180 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Selectors</p> <pre><code>&gt;&gt;&gt; t[~s.numeric() | (s.numeric() &amp; ~s.c(\"year\"))].head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t[s.r[\"bill_length_mm\":\"body_mass_g\"]].head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64        \u2502 float64       \u2502 int64             \u2502 int64       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502           39.1 \u2502          18.7 \u2502               181 \u2502        3750 \u2502\n\u2502           39.5 \u2502          17.4 \u2502               186 \u2502        3800 \u2502\n\u2502           40.3 \u2502          18.0 \u2502               195 \u2502        3250 \u2502\n\u2502            nan \u2502           nan \u2502                 \u2205 \u2502           \u2205 \u2502\n\u2502           36.7 \u2502          19.3 \u2502               193 \u2502        3450 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.aggregate","title":"<code>aggregate(metrics=None, by=None, having=None, **kwargs)</code>","text":"<p>Aggregate a table with a given set of reductions grouping by <code>by</code>.</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>Sequence[ir.Scalar] | None</code> <p>Aggregate expressions</p> <code>None</code> <code>by</code> <code>Sequence[ir.Value] | None</code> <p>Grouping expressions</p> <code>None</code> <code>having</code> <code>Sequence[ir.BooleanValue] | None</code> <p>Post-aggregation filters</p> <code>None</code> <code>kwargs</code> <code>ir.Value</code> <p>Named aggregate expressions</p> <code>{}</code> <p>Returns:</p> Type Description <code>Table</code> <p>An aggregate table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"fruit\": [\"apple\", \"apple\", \"banana\", \"orange\"], \"price\": [0.5, 0.5, 0.25, 0.33]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 fruit  \u2503 price   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 float64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 apple  \u2502    0.50 \u2502\n\u2502 apple  \u2502    0.50 \u2502\n\u2502 banana \u2502    0.25 \u2502\n\u2502 orange \u2502    0.33 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.aggregate(by=[\"fruit\"], total_cost=_.price.sum(), avg_cost=_.price.mean(), having=_.price.sum() &lt; 0.5)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 fruit  \u2503 total_cost \u2503 avg_cost \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 float64    \u2502 float64  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 banana \u2502       0.25 \u2502     0.25 \u2502\n\u2502 orange \u2502       0.33 \u2502     0.33 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.alias","title":"<code>alias(alias)</code>","text":"<p>Create a table expression with a specific name <code>alias</code>.</p> <p>This method is useful for exposing an ibis expression to the underlying backend for use in the <code>Table.sql</code> method.</p> <p><code>.alias</code> will create a temporary view</p> <p><code>.alias</code> creates a temporary view in the database.</p> <p>This side effect will be removed in a future version of ibis and is not part of the public API.</p> <p>Parameters:</p> Name Type Description Default <code>alias</code> <code>str</code> <p>Name of the child expression</p> required <p>Returns:</p> Type Description <code>Table</code> <p>An table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; expr = t.alias(\"ping\u00fcinos\").sql('SELECT * FROM \"ping\u00fcinos\" LIMIT 5')\n&gt;&gt;&gt; expr\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.as_table","title":"<code>as_table()</code>","text":"<p>Promote the expression to a table.</p> <p>This method is a no-op for table expressions.</p> <p>Returns:</p> Type Description <code>Table</code> <p>A table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t = ibis.table(dict(a=\"int\"), name=\"t\")\n&gt;&gt;&gt; s = t.as_table()\n&gt;&gt;&gt; t is s\nTrue\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.asof_join","title":"<code>asof_join(left, right, predicates=(), by=(), tolerance=None, *, suffixes=('_x', '_y'))</code>","text":"<p>Perform an \"as-of\" join between <code>left</code> and <code>right</code>.</p> <p>Similar to a left join except that the match is done on nearest key rather than equal keys.</p> <p>Optionally, match keys with <code>by</code> before joining with <code>predicates</code>.</p> <p>Parameters:</p> Name Type Description Default <code>left</code> <code>Table</code> <p>Table expression</p> required <code>right</code> <code>Table</code> <p>Table expression</p> required <code>predicates</code> <code>str | ir.BooleanColumn | Sequence[str | ir.BooleanColumn]</code> <p>Join expressions</p> <code>()</code> <code>by</code> <code>str | ir.Column | Sequence[str | ir.Column]</code> <p>column to group by before joining</p> <code>()</code> <code>tolerance</code> <code>str | ir.IntervalScalar | None</code> <p>Amount of time to look behind when joining</p> <code>None</code> <code>suffixes</code> <code>tuple[str, str]</code> <p>Left and right suffixes that will be used to rename overlapping columns.</p> <code>('_x', '_y')</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.cache","title":"<code>cache()</code>","text":"<p>Cache the provided expression.</p> <p>All subsequent operations on the returned expression will be performed on the cached data. Use the <code>with</code> statement to limit the lifetime of a cached table.</p> <p>This method is idempotent: calling it multiple times in succession will return the same value as the first call.</p> <p>This method eagerly evaluates the expression prior to caching</p> <p>Subsequent evaluations will not recompute the expression so method chaining will not incur the overhead of caching more than once.</p> <p>Returns:</p> Type Description <code>Table</code> <p>Cached table</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch(table_name=\"penguins\")\n&gt;&gt;&gt; cached_penguins = t.mutate(computation=\"Heavy Computation\").cache()\n&gt;&gt;&gt; cached_penguins\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502 \u2026 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Explicit cache cleanup</p> <pre><code>&gt;&gt;&gt; with t.mutate(computation=\"Heavy Computation\").cache() as cached_penguins:\n...     cached_penguins\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502 \u2026 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.cast","title":"<code>cast(schema)</code>","text":"<p>Cast the columns of a table.</p> <p>If you need to cast columns to a single type, use selectors.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>SupportsSchema</code> <p>Mapping, schema or iterable of pairs to use for casting</p> required <p>Returns:</p> Type Description <code>Table</code> <p>Casted table</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t.schema()\nibis.Schema {\n  species            string\n  island             string\n  bill_length_mm     float64\n  bill_depth_mm      float64\n  flipper_length_mm  int64\n  body_mass_g        int64\n  sex                string\n  year               int64\n}\n&gt;&gt;&gt; cols = [\"body_mass_g\", \"bill_length_mm\"]\n&gt;&gt;&gt; t[cols].head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 body_mass_g \u2503 bill_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64       \u2502 float64        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502        3750 \u2502           39.1 \u2502\n\u2502        3800 \u2502           39.5 \u2502\n\u2502        3250 \u2502           40.3 \u2502\n\u2502           \u2205 \u2502            nan \u2502\n\u2502        3450 \u2502           36.7 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Columns not present in the input schema will be passed through unchanged</p> <pre><code>&gt;&gt;&gt; t.columns\n['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex', 'year']\n&gt;&gt;&gt; expr = t.cast({\"body_mass_g\": \"float64\", \"bill_length_mm\": \"int\"})\n&gt;&gt;&gt; expr.select(*cols).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 body_mass_g \u2503 bill_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64     \u2502 int64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      3750.0 \u2502             39 \u2502\n\u2502      3800.0 \u2502             40 \u2502\n\u2502      3250.0 \u2502             40 \u2502\n\u2502         nan \u2502              \u2205 \u2502\n\u2502      3450.0 \u2502             37 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Columns that are in the input <code>schema</code> but not in the table raise an error</p> <pre><code>&gt;&gt;&gt; t.cast({\"foo\": \"string\"})\nTraceback (most recent call last):\n...\nibis.common.exceptions.IbisError: Cast schema has fields that are not in the table: ['foo']\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.count","title":"<code>count(where=None)</code>","text":"<p>Compute the number of rows in the table.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>ir.BooleanValue | None</code> <p>Optional boolean expression to filter rows when counting.</p> <code>None</code> <p>Returns:</p> Type Description <code>IntegerScalar</code> <p>Number of rows in the table</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [\"foo\", \"bar\", \"baz\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 foo    \u2502\n\u2502 bar    \u2502\n\u2502 baz    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.count()\n3\n&gt;&gt;&gt; t.count(t.a != \"foo\")\n2\n&gt;&gt;&gt; type(t.count())\n&lt;class 'ibis.expr.types.numeric.IntegerScalar'&gt;\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.cross_join","title":"<code>cross_join(left, right, *rest, suffixes=('_x', '_y'))</code>","text":"<p>Compute the cross join of a sequence of tables.</p> <p>Parameters:</p> Name Type Description Default <code>left</code> <code>Table</code> <p>Left table</p> required <code>right</code> <code>Table</code> <p>Right table</p> required <code>rest</code> <code>Table</code> <p>Additional tables to cross join</p> <code>()</code> <code>suffixes</code> <code>tuple[str, str]</code> <p>Left and right suffixes that will be used to rename overlapping columns.</p> <code>('_x', '_y')</code> <p>Returns:</p> Type Description <code>Table</code> <p>Cross join of <code>left</code>, <code>right</code> and <code>rest</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; agg = t.drop(\"year\").agg(s.across(s.numeric(), _.mean()))\n&gt;&gt;&gt; expr = t.cross_join(agg)\n&gt;&gt;&gt; expr\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm_x \u2503 bill_depth_mm_x \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64          \u2502 float64         \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502             39.1 \u2502            18.7 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502             39.5 \u2502            17.4 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502             40.3 \u2502            18.0 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502              nan \u2502             nan \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502             36.7 \u2502            19.3 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502             39.3 \u2502            20.6 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502             38.9 \u2502            17.8 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502             39.2 \u2502            19.6 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502             34.1 \u2502            18.1 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502             42.0 \u2502            20.2 \u2502 \u2026 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502                \u2026 \u2502               \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; from pprint import pprint\n&gt;&gt;&gt; pprint(expr.columns)\n['species',\n 'island',\n 'bill_length_mm_x',\n 'bill_depth_mm_x',\n 'flipper_length_mm_x',\n 'body_mass_g_x',\n 'sex',\n 'year',\n 'bill_length_mm_y',\n 'bill_depth_mm_y',\n 'flipper_length_mm_y',\n 'body_mass_g_y']\n&gt;&gt;&gt; expr.count()\n344\n&gt;&gt;&gt; t.count()\n344\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.difference","title":"<code>difference(*tables, distinct=True)</code>","text":"<p>Compute the set difference of multiple table expressions.</p> <p>The input tables must have identical schemas.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>Table</code> <p>One or more table expressions</p> <code>()</code> <code>distinct</code> <code>bool</code> <p>Only diff distinct rows not occurring in the calling table</p> <code>True</code>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.difference--see-also","title":"See Also","text":"<p><code>ibis.difference</code></p> <p>Returns:</p> Type Description <code>Table</code> <p>The rows present in <code>self</code> that are not present in <code>tables</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t1 = ibis.memtable({\"a\": [1, 2]})\n&gt;&gt;&gt; t1\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t2 = ibis.memtable({\"a\": [2, 3]})\n&gt;&gt;&gt; t2\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     2 \u2502\n\u2502     3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.difference(t2)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Passing no arguments to <code>difference</code> returns the table expression</p> <p>This can be useful when you have a sequence of tables to process, and you don't know the length prior to running your program (for example, user input).</p> <pre><code>&gt;&gt;&gt; t1\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.difference()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.difference().equals(t1)\nTrue\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.distinct","title":"<code>distinct()</code>","text":"<p>Compute the unique rows in <code>self</code>.</p> <p>Returns:</p> Type Description <code>Table</code> <p>Unique rows of <code>self</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [1, 1, 2], \"b\": [\"c\", \"a\", \"a\"]})\n&gt;&gt;&gt; t[[\"a\"]].distinct()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.distinct()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 b      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 c      \u2502\n\u2502     1 \u2502 a      \u2502\n\u2502     2 \u2502 a      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.drop","title":"<code>drop(*fields)</code>","text":"<p>Remove fields from a table.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>str | Selector</code> <p>Fields to drop. Strings and selectors are accepted.</p> <code>()</code> <p>Returns:</p> Type Description <code>Table</code> <p>A table with all columns matching <code>fields</code> removed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502 \u2026 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Drop one or more columns</p> <pre><code>&gt;&gt;&gt; t.drop(\"species\").head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.drop(\"species\", \"bill_length_mm\").head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 float64       \u2502 int64             \u2502 int64       \u2502 string \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502          18.7 \u2502               181 \u2502        3750 \u2502 male   \u2502 \u2026 \u2502\n\u2502 Torgersen \u2502          17.4 \u2502               186 \u2502        3800 \u2502 female \u2502 \u2026 \u2502\n\u2502 Torgersen \u2502          18.0 \u2502               195 \u2502        3250 \u2502 female \u2502 \u2026 \u2502\n\u2502 Torgersen \u2502           nan \u2502                 \u2205 \u2502           \u2205 \u2502 \u2205      \u2502 \u2026 \u2502\n\u2502 Torgersen \u2502          19.3 \u2502               193 \u2502        3450 \u2502 female \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Drop with selectors, mix and match</p> <pre><code>&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; t.drop(\"species\", s.startswith(\"bill_\")).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 int64             \u2502 int64       \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502               181 \u2502        3750 \u2502 male   \u2502  2007 \u2502\n\u2502 Torgersen \u2502               186 \u2502        3800 \u2502 female \u2502  2007 \u2502\n\u2502 Torgersen \u2502               195 \u2502        3250 \u2502 female \u2502  2007 \u2502\n\u2502 Torgersen \u2502                 \u2205 \u2502           \u2205 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 Torgersen \u2502               193 \u2502        3450 \u2502 female \u2502  2007 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.dropna","title":"<code>dropna(subset=None, how='any')</code>","text":"<p>Remove rows with null values from the table.</p> <p>Parameters:</p> Name Type Description Default <code>subset</code> <code>Sequence[str] | None</code> <p>Columns names to consider when dropping nulls. By default all columns are considered.</p> <code>None</code> <code>how</code> <code>Literal['any', 'all']</code> <p>Determine whether a row is removed if there is at least one null value in the row (<code>'any'</code>), or if all row values are null (<code>'all'</code>).</p> <code>'any'</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502 \u2026 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.count()\n344\n&gt;&gt;&gt; t.dropna([\"bill_length_mm\", \"body_mass_g\"]).count()\n342\n&gt;&gt;&gt; t.dropna(how=\"all\").count()  # no rows where all columns are null\n344\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.fillna","title":"<code>fillna(replacements)</code>","text":"<p>Fill null values in a table expression.</p> <p>There is potential lack of type stability with the <code>fillna</code> API</p> <p>For example, different library versions may impact whether a given backend promotes integer replacement values to floats.</p> <p>Parameters:</p> Name Type Description Default <code>replacements</code> <code>ir.Scalar | Mapping[str, ir.Scalar]</code> <p>Value with which to fill nulls. If <code>replacements</code> is a mapping, the keys are column names that map to their replacement value. If passed as a scalar all columns are filled with that value.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t.sex\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sex    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 male   \u2502\n\u2502 female \u2502\n\u2502 female \u2502\n\u2502 \u2205      \u2502\n\u2502 female \u2502\n\u2502 male   \u2502\n\u2502 female \u2502\n\u2502 male   \u2502\n\u2502 \u2205      \u2502\n\u2502 \u2205      \u2502\n\u2502 \u2026      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.fillna({\"sex\": \"unrecorded\"}).sex\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sex        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 male       \u2502\n\u2502 female     \u2502\n\u2502 female     \u2502\n\u2502 unrecorded \u2502\n\u2502 female     \u2502\n\u2502 male       \u2502\n\u2502 female     \u2502\n\u2502 male       \u2502\n\u2502 unrecorded \u2502\n\u2502 unrecorded \u2502\n\u2502 \u2026          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.filter","title":"<code>filter(predicates)</code>","text":"<p>Select rows from <code>table</code> based on <code>predicates</code>.</p> <p>Parameters:</p> Name Type Description Default <code>predicates</code> <code>ir.BooleanValue | Sequence[ir.BooleanValue] | IfAnyAll</code> <p>Boolean value expressions used to select rows in <code>table</code>.</p> required <p>Returns:</p> Type Description <code>Table</code> <p>Filtered table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502 \u2026 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.filter([t.species == \"Adelie\", t.body_mass_g &gt; 3500]).sex.value_counts().dropna(\"sex\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 sex    \u2503 sex_count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 male   \u2502        68 \u2502\n\u2502 female \u2502        22 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.group_by","title":"<code>group_by(by=None, **key_exprs)</code>","text":"<p>Create a grouped table expression.</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>str | ir.Value | Iterable[str] | Iterable[ir.Value] | None</code> <p>Grouping expressions</p> <code>None</code> <code>key_exprs</code> <code>str | ir.Value | Iterable[str] | Iterable[ir.Value]</code> <p>Named grouping expressions</p> <code>{}</code> <p>Returns:</p> Type Description <code>GroupedTable</code> <p>A grouped table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"fruit\": [\"apple\", \"apple\", \"banana\", \"orange\"], \"price\": [0.5, 0.5, 0.25, 0.33]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 fruit  \u2503 price   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 float64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 apple  \u2502    0.50 \u2502\n\u2502 apple  \u2502    0.50 \u2502\n\u2502 banana \u2502    0.25 \u2502\n\u2502 orange \u2502    0.33 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.group_by(\"fruit\").agg(total_cost=_.price.sum(), avg_cost=_.price.mean())\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 fruit  \u2503 total_cost \u2503 avg_cost \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 float64    \u2502 float64  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 apple  \u2502       1.00 \u2502     0.50 \u2502\n\u2502 banana \u2502       0.25 \u2502     0.25 \u2502\n\u2502 orange \u2502       0.33 \u2502     0.33 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.head","title":"<code>head(n=5)</code>","text":"<p>Select the first <code>n</code> rows of a table.</p> <p>The result set is not deterministic without a call to <code>order_by</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to include</p> <code>5</code> <p>Returns:</p> Type Description <code>Table</code> <p><code>self</code> limited to <code>n</code> rows</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [1, 1, 2], \"b\": [\"c\", \"a\", \"a\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 b      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 c      \u2502\n\u2502     1 \u2502 a      \u2502\n\u2502     2 \u2502 a      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.head(2)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 b      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 c      \u2502\n\u2502     1 \u2502 a      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.head--see-also","title":"See Also","text":"<p><code>Table.limit</code> <code>Table.order_by</code></p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.info","title":"<code>info()</code>","text":"<p>Return summary information about a table.</p> <p>Returns:</p> Type Description <code>Table</code> <p>Summary of <code>self</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch(table_name=\"penguins\")\n&gt;&gt;&gt; t.info()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 name              \u2503 type    \u2503 nullable \u2503 nulls \u2503 non_nulls \u2503 null_frac \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string            \u2502 string  \u2502 boolean  \u2502 int64 \u2502 int64     \u2502 float64   \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 species           \u2502 string  \u2502 True     \u2502     0 \u2502       344 \u2502  0.000000 \u2502 \u2026 \u2502\n\u2502 island            \u2502 string  \u2502 True     \u2502     0 \u2502       344 \u2502  0.000000 \u2502 \u2026 \u2502\n\u2502 bill_length_mm    \u2502 float64 \u2502 True     \u2502     2 \u2502       342 \u2502  0.005814 \u2502 \u2026 \u2502\n\u2502 bill_depth_mm     \u2502 float64 \u2502 True     \u2502     2 \u2502       342 \u2502  0.005814 \u2502 \u2026 \u2502\n\u2502 flipper_length_mm \u2502 int64   \u2502 True     \u2502     2 \u2502       342 \u2502  0.005814 \u2502 \u2026 \u2502\n\u2502 body_mass_g       \u2502 int64   \u2502 True     \u2502     2 \u2502       342 \u2502  0.005814 \u2502 \u2026 \u2502\n\u2502 sex               \u2502 string  \u2502 True     \u2502    11 \u2502       333 \u2502  0.031977 \u2502 \u2026 \u2502\n\u2502 year              \u2502 int64   \u2502 True     \u2502     0 \u2502       344 \u2502  0.000000 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.intersect","title":"<code>intersect(*tables, distinct=True)</code>","text":"<p>Compute the set intersection of multiple table expressions.</p> <p>The input tables must have identical schemas.</p> <p>Parameters:</p> Name Type Description Default <code>*tables</code> <code>Table</code> <p>One or more table expressions</p> <code>()</code> <code>distinct</code> <code>bool</code> <p>Only return distinct rows</p> <code>True</code> <p>Returns:</p> Type Description <code>Table</code> <p>A new table containing the intersection of all input tables.</p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.intersect--see-also","title":"See Also","text":"<p><code>ibis.intersect</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t1 = ibis.memtable({\"a\": [1, 2]})\n&gt;&gt;&gt; t1\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t2 = ibis.memtable({\"a\": [2, 3]})\n&gt;&gt;&gt; t2\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     2 \u2502\n\u2502     3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.intersect(t2)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Passing no arguments to <code>intersect</code> returns the table expression.</p> <p>This can be useful when you have a sequence of tables to process, and you don't know the length prior to running your program (for example, user input).</p> <pre><code>&gt;&gt;&gt; t1\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.intersect()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.intersect().equals(t1)\nTrue\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.join","title":"<code>join(left, right, predicates=(), how='inner', *, suffixes=('_x', '_y'))</code>","text":"<p>Perform a join between two tables.</p> <p>Parameters:</p> Name Type Description Default <code>left</code> <code>Table</code> <p>Left table to join</p> required <code>right</code> <code>Table</code> <p>Right table to join</p> required <code>predicates</code> <code>str | Sequence[str | tuple[str | ir.Column, str | ir.Column] | ir.BooleanColumn]</code> <p>Boolean or column names to join on</p> <code>()</code> <code>how</code> <code>Literal['inner', 'left', 'outer', 'right', 'semi', 'anti', 'any_inner', 'any_left', 'left_semi']</code> <p>Join method</p> <code>'inner'</code> <code>suffixes</code> <code>tuple[str, str]</code> <p>Left and right suffixes that will be used to rename overlapping columns.</p> <code>('_x', '_y')</code>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.limit","title":"<code>limit(n, offset=0)</code>","text":"<p>Select <code>n</code> rows from <code>self</code> starting at <code>offset</code>.</p> <p>The result set is not deterministic without a call to <code>order_by</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to include</p> required <code>offset</code> <code>int</code> <p>Number of rows to skip first</p> <code>0</code> <p>Returns:</p> Type Description <code>Table</code> <p>The first <code>n</code> rows of <code>self</code> starting at <code>offset</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [1, 1, 2], \"b\": [\"c\", \"a\", \"a\"]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 b      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 c      \u2502\n\u2502     1 \u2502 a      \u2502\n\u2502     2 \u2502 a      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.limit(2)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 b      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 c      \u2502\n\u2502     1 \u2502 a      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.limit--see-also","title":"See Also","text":"<p><code>Table.order_by</code></p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.mutate","title":"<code>mutate(exprs=None, **mutations)</code>","text":"<p>Add columns to a table expression.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>Sequence[ir.Expr] | None</code> <p>List of named expressions to add as columns</p> <code>None</code> <code>mutations</code> <code>ir.Value</code> <p>Named expressions using keyword arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression with additional columns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch().select(\"species\", \"year\", \"bill_length_mm\")\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 year  \u2503 bill_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 int64 \u2502 float64        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502  2007 \u2502           39.1 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           39.5 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           40.3 \u2502\n\u2502 Adelie  \u2502  2007 \u2502            nan \u2502\n\u2502 Adelie  \u2502  2007 \u2502           36.7 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           39.3 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           38.9 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           39.2 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           34.1 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           42.0 \u2502\n\u2502 \u2026       \u2502     \u2026 \u2502              \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Add a new column from a per-element expression</p> <pre><code>&gt;&gt;&gt; t.mutate(next_year=_.year + 1).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 year  \u2503 bill_length_mm \u2503 next_year \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 int64 \u2502 float64        \u2502 int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502  2007 \u2502           39.1 \u2502      2008 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           39.5 \u2502      2008 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           40.3 \u2502      2008 \u2502\n\u2502 Adelie  \u2502  2007 \u2502            nan \u2502      2008 \u2502\n\u2502 Adelie  \u2502  2007 \u2502           36.7 \u2502      2008 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Add a new column based on an aggregation. Note the automatic broadcasting.</p> <pre><code>&gt;&gt;&gt; t.select(\"species\", bill_demean=_.bill_length_mm - _.bill_length_mm.mean()).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 bill_demean \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 float64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502    -4.82193 \u2502\n\u2502 Adelie  \u2502    -4.42193 \u2502\n\u2502 Adelie  \u2502    -3.62193 \u2502\n\u2502 Adelie  \u2502         nan \u2502\n\u2502 Adelie  \u2502    -7.22193 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Mutate across multiple columns</p> <pre><code>&gt;&gt;&gt; t.mutate(s.across(s.numeric() &amp; ~s.c(\"year\"), _ - _.mean())).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 year  \u2503 bill_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 int64 \u2502 float64        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502  2007 \u2502       -4.82193 \u2502\n\u2502 Adelie  \u2502  2007 \u2502       -4.42193 \u2502\n\u2502 Adelie  \u2502  2007 \u2502       -3.62193 \u2502\n\u2502 Adelie  \u2502  2007 \u2502            nan \u2502\n\u2502 Adelie  \u2502  2007 \u2502       -7.22193 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.order_by","title":"<code>order_by(by)</code>","text":"<p>Sort a table by one or more expressions.</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>str | ir.Column | tuple[str | ir.Column, bool] | Sequence[str] | Sequence[ir.Column] | Sequence[tuple[str | ir.Column, bool]] | None</code> <p>Expressions to sort the table by.</p> required <p>Returns:</p> Type Description <code>Table</code> <p>Sorted table</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.memtable({\"a\": [1, 2, 3], \"b\": [\"c\", \"b\", \"a\"], \"c\": [4, 6, 5]})\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 b      \u2503 c     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 c      \u2502     4 \u2502\n\u2502     2 \u2502 b      \u2502     6 \u2502\n\u2502     3 \u2502 a      \u2502     5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.order_by(\"b\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 b      \u2503 c     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     3 \u2502 a      \u2502     5 \u2502\n\u2502     2 \u2502 b      \u2502     6 \u2502\n\u2502     1 \u2502 c      \u2502     4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.order_by(ibis.desc(\"c\"))\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503 b      \u2503 c     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     2 \u2502 b      \u2502     6 \u2502\n\u2502     3 \u2502 a      \u2502     5 \u2502\n\u2502     1 \u2502 c      \u2502     4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.pivot_longer","title":"<code>pivot_longer(cols, *, names_to='name', names_pattern='(.+)', names_transform=None, values_to='value', values_transform=None)</code>","text":"<p>Transform a table from wider to longer.</p> <p>Parameters:</p> Name Type Description Default <code>cols</code> <code>str | s.Selector</code> <p>String column names or selectors.</p> required <code>names_to</code> <code>str | Iterable[str]</code> <p>A string or iterable of strings indicating how to name the new pivoted columns.</p> <code>'name'</code> <code>names_pattern</code> <code>str | re.Pattern</code> <p>Pattern to use to extract column names from the input. By default the entire column name is extracted.</p> <code>'(.+)'</code> <code>names_transform</code> <code>Callable[[str], ir.Value] | Mapping[str, Callable[[str], ir.Value]] | None</code> <p>Function or mapping of a name in <code>names_to</code> to a function to transform a column name to a value.</p> <code>None</code> <code>values_to</code> <code>str</code> <p>Name of the pivoted value column.</p> <code>'value'</code> <code>values_transform</code> <code>Callable[[ir.Value], ir.Value] | Deferred | None</code> <p>Apply a function to the value column. This can be a lambda or deferred expression.</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Pivoted table</p> <p>Examples:</p> <p>Basic usage</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; relig_income = ibis.examples.relig_income_raw.fetch()\n&gt;&gt;&gt; relig_income\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 religion                \u2503 &lt;$10k \u2503 $10-20k \u2503 $20-30k \u2503 $30-40k \u2503 $40-50k \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string                  \u2502 int64 \u2502 int64   \u2502 int64   \u2502 int64   \u2502 int64   \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Agnostic                \u2502    27 \u2502      34 \u2502      60 \u2502      81 \u2502      76 \u2502 \u2026 \u2502\n\u2502 Atheist                 \u2502    12 \u2502      27 \u2502      37 \u2502      52 \u2502      35 \u2502 \u2026 \u2502\n\u2502 Buddhist                \u2502    27 \u2502      21 \u2502      30 \u2502      34 \u2502      33 \u2502 \u2026 \u2502\n\u2502 Catholic                \u2502   418 \u2502     617 \u2502     732 \u2502     670 \u2502     638 \u2502 \u2026 \u2502\n\u2502 Don\u2019t know/refused      \u2502    15 \u2502      14 \u2502      15 \u2502      11 \u2502      10 \u2502 \u2026 \u2502\n\u2502 Evangelical Prot        \u2502   575 \u2502     869 \u2502    1064 \u2502     982 \u2502     881 \u2502 \u2026 \u2502\n\u2502 Hindu                   \u2502     1 \u2502       9 \u2502       7 \u2502       9 \u2502      11 \u2502 \u2026 \u2502\n\u2502 Historically Black Prot \u2502   228 \u2502     244 \u2502     236 \u2502     238 \u2502     197 \u2502 \u2026 \u2502\n\u2502 Jehovah's Witness       \u2502    20 \u2502      27 \u2502      24 \u2502      24 \u2502      21 \u2502 \u2026 \u2502\n\u2502 Jewish                  \u2502    19 \u2502      19 \u2502      25 \u2502      25 \u2502      30 \u2502 \u2026 \u2502\n\u2502 \u2026                       \u2502     \u2026 \u2502       \u2026 \u2502       \u2026 \u2502       \u2026 \u2502       \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Here we convert column names not matching the selector for the <code>religion</code> column and convert those names into values</p> <pre><code>&gt;&gt;&gt; relig_income.pivot_longer(~s.c(\"religion\"), names_to=\"income\", values_to=\"count\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 religion \u2503 income             \u2503 count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string   \u2502 string             \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Agnostic \u2502 &lt;$10k              \u2502    27 \u2502\n\u2502 Agnostic \u2502 $10-20k            \u2502    34 \u2502\n\u2502 Agnostic \u2502 $20-30k            \u2502    60 \u2502\n\u2502 Agnostic \u2502 $30-40k            \u2502    81 \u2502\n\u2502 Agnostic \u2502 $40-50k            \u2502    76 \u2502\n\u2502 Agnostic \u2502 $50-75k            \u2502   137 \u2502\n\u2502 Agnostic \u2502 $75-100k           \u2502   122 \u2502\n\u2502 Agnostic \u2502 $100-150k          \u2502   109 \u2502\n\u2502 Agnostic \u2502 &gt;150k              \u2502    84 \u2502\n\u2502 Agnostic \u2502 Don't know/refused \u2502    96 \u2502\n\u2502 \u2026        \u2502 \u2026                  \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Simliarly for a different example dataset, we convert names to values but using a different selector and the default <code>values_to</code> value.</p> <pre><code>&gt;&gt;&gt; world_bank_pop = ibis.examples.world_bank_pop_raw.fetch(header=1)\n&gt;&gt;&gt; world_bank_pop.head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 country \u2503 indicator   \u2503 2000         \u2503 2001         \u2503 2002         \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string      \u2502 float64      \u2502 float64      \u2502 float64      \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 ABW     \u2502 SP.URB.TOTL \u2502 4.244400e+04 \u2502 4.304800e+04 \u2502 4.367000e+04 \u2502 \u2026 \u2502\n\u2502 ABW     \u2502 SP.URB.GROW \u2502 1.182632e+00 \u2502 1.413021e+00 \u2502 1.434560e+00 \u2502 \u2026 \u2502\n\u2502 ABW     \u2502 SP.POP.TOTL \u2502 9.085300e+04 \u2502 9.289800e+04 \u2502 9.499200e+04 \u2502 \u2026 \u2502\n\u2502 ABW     \u2502 SP.POP.GROW \u2502 2.055027e+00 \u2502 2.225930e+00 \u2502 2.229056e+00 \u2502 \u2026 \u2502\n\u2502 AFG     \u2502 SP.URB.TOTL \u2502 4.436299e+06 \u2502 4.648055e+06 \u2502 4.892951e+06 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; world_bank_pop.pivot_longer(s.matches(r\"\\d{4}\"), names_to=\"year\").head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 country \u2503 indicator   \u2503 year   \u2503 value   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string      \u2502 string \u2502 float64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ABW     \u2502 SP.URB.TOTL \u2502 2000   \u2502 42444.0 \u2502\n\u2502 ABW     \u2502 SP.URB.TOTL \u2502 2001   \u2502 43048.0 \u2502\n\u2502 ABW     \u2502 SP.URB.TOTL \u2502 2002   \u2502 43670.0 \u2502\n\u2502 ABW     \u2502 SP.URB.TOTL \u2502 2003   \u2502 44246.0 \u2502\n\u2502 ABW     \u2502 SP.URB.TOTL \u2502 2004   \u2502 44669.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p><code>pivot_longer</code> has some preprocessing capabiltiies like stripping a prefix and applying a function to column names</p> <pre><code>&gt;&gt;&gt; billboard = ibis.examples.billboard.fetch()\n&gt;&gt;&gt; billboard\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 artist         \u2503 track                   \u2503 date_entered \u2503 wk1   \u2503 wk2   \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string         \u2502 string                  \u2502 date         \u2502 int64 \u2502 int64 \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 2 Pac          \u2502 Baby Don't Cry (Keep... \u2502 2000-02-26   \u2502    87 \u2502    82 \u2502 \u2026 \u2502\n\u2502 2Ge+her        \u2502 The Hardest Part Of ... \u2502 2000-09-02   \u2502    91 \u2502    87 \u2502 \u2026 \u2502\n\u2502 3 Doors Down   \u2502 Kryptonite              \u2502 2000-04-08   \u2502    81 \u2502    70 \u2502 \u2026 \u2502\n\u2502 3 Doors Down   \u2502 Loser                   \u2502 2000-10-21   \u2502    76 \u2502    76 \u2502 \u2026 \u2502\n\u2502 504 Boyz       \u2502 Wobble Wobble           \u2502 2000-04-15   \u2502    57 \u2502    34 \u2502 \u2026 \u2502\n\u2502 98^0           \u2502 Give Me Just One Nig... \u2502 2000-08-19   \u2502    51 \u2502    39 \u2502 \u2026 \u2502\n\u2502 A*Teens        \u2502 Dancing Queen           \u2502 2000-07-08   \u2502    97 \u2502    97 \u2502 \u2026 \u2502\n\u2502 Aaliyah        \u2502 I Don't Wanna           \u2502 2000-01-29   \u2502    84 \u2502    62 \u2502 \u2026 \u2502\n\u2502 Aaliyah        \u2502 Try Again               \u2502 2000-03-18   \u2502    59 \u2502    53 \u2502 \u2026 \u2502\n\u2502 Adams, Yolanda \u2502 Open My Heart           \u2502 2000-08-26   \u2502    76 \u2502    76 \u2502 \u2026 \u2502\n\u2502 \u2026              \u2502 \u2026                       \u2502 \u2026            \u2502     \u2026 \u2502     \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; billboard.pivot_longer(\n...     s.startswith(\"wk\"),\n...     names_to=\"week\",\n...     names_pattern=r\"wk(.+)\",\n...     names_transform=int,\n...     values_to=\"rank\",\n...     values_transform=_.cast(\"int\"),\n... ).dropna(\"rank\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 artist  \u2503 track                   \u2503 date_entered \u2503 week \u2503 rank  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string                  \u2502 date         \u2502 int8 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2 Pac   \u2502 Baby Don't Cry (Keep... \u2502 2000-02-26   \u2502    1 \u2502    87 \u2502\n\u2502 2 Pac   \u2502 Baby Don't Cry (Keep... \u2502 2000-02-26   \u2502    2 \u2502    82 \u2502\n\u2502 2 Pac   \u2502 Baby Don't Cry (Keep... \u2502 2000-02-26   \u2502    3 \u2502    72 \u2502\n\u2502 2 Pac   \u2502 Baby Don't Cry (Keep... \u2502 2000-02-26   \u2502    4 \u2502    77 \u2502\n\u2502 2 Pac   \u2502 Baby Don't Cry (Keep... \u2502 2000-02-26   \u2502    5 \u2502    87 \u2502\n\u2502 2 Pac   \u2502 Baby Don't Cry (Keep... \u2502 2000-02-26   \u2502    6 \u2502    94 \u2502\n\u2502 2 Pac   \u2502 Baby Don't Cry (Keep... \u2502 2000-02-26   \u2502    7 \u2502    99 \u2502\n\u2502 2Ge+her \u2502 The Hardest Part Of ... \u2502 2000-09-02   \u2502    1 \u2502    91 \u2502\n\u2502 2Ge+her \u2502 The Hardest Part Of ... \u2502 2000-09-02   \u2502    2 \u2502    87 \u2502\n\u2502 2Ge+her \u2502 The Hardest Part Of ... \u2502 2000-09-02   \u2502    3 \u2502    92 \u2502\n\u2502 \u2026       \u2502 \u2026                       \u2502 \u2026            \u2502    \u2026 \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can use regular expression capture groups to extract multiple variables stored in column names</p> <pre><code>&gt;&gt;&gt; who = ibis.examples.who.fetch()\n&gt;&gt;&gt; who\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 country     \u2503 iso2   \u2503 iso3   \u2503 year  \u2503 new_sp_m014 \u2503 new_sp_m1524 \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string      \u2502 string \u2502 string \u2502 int64 \u2502 int64       \u2502 int64        \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1981 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1982 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1983 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1984 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1985 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1986 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1987 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1988 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1989 \u2502           \u2205 \u2502            \u2205 \u2502 \u2026 \u2502\n\u2502 \u2026           \u2502 \u2026      \u2502 \u2026      \u2502     \u2026 \u2502           \u2026 \u2502            \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; len(who.columns)\n60\n&gt;&gt;&gt; who.pivot_longer(\n...     s.r[\"new_sp_m014\":\"newrel_f65\"],\n...     names_to=[\"diagnosis\", \"gender\", \"age\"],\n...     names_pattern=\"new_?(.*)_(.)(.*)\",\n...     values_to=\"count\",\n... )\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 country     \u2503 iso2   \u2503 iso3   \u2503 year  \u2503 diagnosis \u2503 gender \u2503 age    \u2503 count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string      \u2502 string \u2502 string \u2502 int64 \u2502 string    \u2502 string \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 m      \u2502 014    \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 m      \u2502 1524   \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 m      \u2502 2534   \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 m      \u2502 3544   \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 m      \u2502 4554   \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 m      \u2502 5564   \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 m      \u2502 65     \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 f      \u2502 014    \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 f      \u2502 1524   \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502 f      \u2502 2534   \u2502     \u2205 \u2502\n\u2502 \u2026           \u2502 \u2026      \u2502 \u2026      \u2502     \u2026 \u2502 \u2026         \u2502 \u2026      \u2502 \u2026      \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p><code>names_transform</code> is flexible, and can be:</p> <pre><code>1. A mapping of one or more names in `names_to` to callable\n2. A callable that will be applied to every name\n</code></pre> <p>Let's recode gender and age to numeric values using a mapping</p> <pre><code>&gt;&gt;&gt; who.pivot_longer(\n...     s.r[\"new_sp_m014\":\"newrel_f65\"],\n...     names_to=[\"diagnosis\", \"gender\", \"age\"],\n...     names_pattern=\"new_?(.*)_(.)(.*)\",\n...     names_transform=dict(\n...         gender={\"m\": 1, \"f\": 2}.get,\n...         age=dict(zip([\"014\", \"1524\", \"2534\", \"3544\", \"4554\", \"5564\", \"65\"], range(7))).get,\n...     ),\n...     values_to=\"count\",\n... )\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 country     \u2503 iso2   \u2503 iso3   \u2503 year  \u2503 diagnosis \u2503 gender \u2503 age  \u2503 count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string      \u2502 string \u2502 string \u2502 int64 \u2502 string    \u2502 int8   \u2502 int8 \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      1 \u2502    0 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      1 \u2502    1 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      1 \u2502    2 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      1 \u2502    3 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      1 \u2502    4 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      1 \u2502    5 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      1 \u2502    6 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      2 \u2502    0 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      2 \u2502    1 \u2502     \u2205 \u2502\n\u2502 Afghanistan \u2502 AF     \u2502 AFG    \u2502  1980 \u2502 sp        \u2502      2 \u2502    2 \u2502     \u2205 \u2502\n\u2502 \u2026           \u2502 \u2026      \u2502 \u2026      \u2502     \u2026 \u2502 \u2026         \u2502      \u2026 \u2502    \u2026 \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The number of match groups in <code>names_pattern</code> must match the length of <code>names_to</code></p> <pre><code>&gt;&gt;&gt; who.pivot_longer(\n...     s.r[\"new_sp_m014\":\"newrel_f65\"],\n...     names_to=[\"diagnosis\", \"gender\", \"age\"],\n...     names_pattern=\"new_?(.*)_.(.*)\",\n... )\nTraceback (most recent call last):\n...\nibis.common.exceptions.IbisInputError: Number of match groups in `names_pattern` ...\n</code></pre> <p><code>names_transform</code> must be a mapping or callable</p> <pre><code>&gt;&gt;&gt; who.pivot_longer(s.r[\"new_sp_m014\":\"newrel_f65\"], names_transform=\"upper\")\nTraceback (most recent call last):\n...\nibis.common.exceptions.IbisTypeError: ... Got &lt;class 'str'&gt;\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.relabel","title":"<code>relabel(substitutions)</code>","text":"<p>Rename columns in the table.</p> <p>Parameters:</p> Name Type Description Default <code>substitutions</code> <code>Mapping[str, str] | Callable[[str], str | None] | Literal['snake_case']</code> <p>A mapping or function from old to new column names. If a column isn't in the mapping (or if the callable returns None) it is left with its original name. May also pass the string <code>\"snake_case\"</code>, which will relabel all columns to use a <code>snake_case</code> naming convention.</p> required <p>Returns:</p> Type Description <code>Table</code> <p>A relabeled table expressi</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; first3 = s.r[:3]  # first 3 columns\n&gt;&gt;&gt; t = ibis.examples.penguins_raw_raw.fetch().select(first3)\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 studyName \u2503 Sample Number \u2503 Species                             \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 int64         \u2502 string                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PAL0708   \u2502             1 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502             2 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502             3 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502             4 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502             5 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502             6 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502             7 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502             8 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502             9 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 PAL0708   \u2502            10 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2502 \u2026         \u2502             \u2026 \u2502 \u2026                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Relabel column names using a mapping from old name to new name</p> <pre><code>&gt;&gt;&gt; t.relabel({\"studyName\": \"study_name\"}).head(1)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 study_name \u2503 Sample Number \u2503 Species                             \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string     \u2502 int64         \u2502 string                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PAL0708    \u2502             1 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Relabel column names using a snake_case convention</p> <pre><code>&gt;&gt;&gt; t.relabel(\"snake_case\").head(1)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 study_name \u2503 sample_number \u2503 species                             \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string     \u2502 int64         \u2502 string                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PAL0708    \u2502             1 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Relabel column names using a callable</p> <pre><code>&gt;&gt;&gt; t.relabel(str.upper).head(1)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 STUDYNAME \u2503 SAMPLE NUMBER \u2503 SPECIES                             \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 int64         \u2502 string                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PAL0708   \u2502             1 \u2502 Adelie Penguin (Pygoscelis adeliae) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.rowid","title":"<code>rowid()</code>","text":"<p>A unique integer per row.</p> <p>This operation is only valid on physical tables</p> <p>Any further meaning behind this expression is backend dependent. Generally this corresponds to some index into the database storage (for example, sqlite or duckdb's <code>rowid</code>).</p> <p>For a monotonically increasing row number, see <code>ibis.row_number</code>.</p> <p>Returns:</p> Type Description <code>IntegerColumn</code> <p>An integer column</p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.schema","title":"<code>schema()</code>","text":"<p>Return the schema for this table.</p> <p>Returns:</p> Type Description <code>Schema</code> <p>The table's schema.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.starwars.fetch()\n&gt;&gt;&gt; t.schema()\nibis.Schema {\n  name        string\n  height      int64\n  mass        float64\n  hair_color  string\n  skin_color  string\n  eye_color   string\n  birth_year  float64\n  sex         string\n  gender      string\n  homeworld   string\n  species     string\n  films       string\n  vehicles    string\n  starships   string\n}\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.select","title":"<code>select(*exprs, **named_exprs)</code>","text":"<p>Compute a new table expression using <code>exprs</code> and <code>named_exprs</code>.</p> <p>Passing an aggregate function to this method will broadcast the aggregate's value over the number of rows in the table and automatically constructs a window function expression. See the examples section for more details.</p> <p>For backwards compatibility the keyword argument <code>exprs</code> is reserved and cannot be used to name an expression. This behavior will be removed in v4.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>ir.Value | str | Iterable[ir.Value | str]</code> <p>Column expression, string, or list of column expressions and strings.</p> <code>()</code> <code>named_exprs</code> <code>ir.Value | str</code> <p>Column expressions</p> <code>{}</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502 \u2026 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502 \u2026 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Simple projection</p> <pre><code>&gt;&gt;&gt; t.select(\"island\", \"bill_length_mm\").head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 bill_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 float64        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502           39.1 \u2502\n\u2502 Torgersen \u2502           39.5 \u2502\n\u2502 Torgersen \u2502           40.3 \u2502\n\u2502 Torgersen \u2502            nan \u2502\n\u2502 Torgersen \u2502           36.7 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Projection by zero-indexed column position</p> <pre><code>&gt;&gt;&gt; t.select(0, 4).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 flipper_length_mm \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 int64             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502               181 \u2502\n\u2502 Adelie  \u2502               186 \u2502\n\u2502 Adelie  \u2502               195 \u2502\n\u2502 Adelie  \u2502                 \u2205 \u2502\n\u2502 Adelie  \u2502               193 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Projection with renaming and compute in one call</p> <pre><code>&gt;&gt;&gt; t.select(next_year=t.year + 1).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 next_year \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      2008 \u2502\n\u2502      2008 \u2502\n\u2502      2008 \u2502\n\u2502      2008 \u2502\n\u2502      2008 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Projection with aggregation expressions</p> <pre><code>&gt;&gt;&gt; t.select(\"island\", bill_mean=t.bill_length_mm.mean()).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 bill_mean \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 float64   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Torgersen \u2502  43.92193 \u2502\n\u2502 Torgersen \u2502  43.92193 \u2502\n\u2502 Torgersen \u2502  43.92193 \u2502\n\u2502 Torgersen \u2502  43.92193 \u2502\n\u2502 Torgersen \u2502  43.92193 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Projection with a selector</p> <pre><code>&gt;&gt;&gt; import ibis.expr.selectors as s\n&gt;&gt;&gt; t.select(s.numeric() &amp; ~s.c(\"year\")).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64        \u2502 float64       \u2502 int64             \u2502 int64       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502           39.1 \u2502          18.7 \u2502               181 \u2502        3750 \u2502\n\u2502           39.5 \u2502          17.4 \u2502               186 \u2502        3800 \u2502\n\u2502           40.3 \u2502          18.0 \u2502               195 \u2502        3250 \u2502\n\u2502            nan \u2502           nan \u2502                 \u2205 \u2502           \u2205 \u2502\n\u2502           36.7 \u2502          19.3 \u2502               193 \u2502        3450 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Projection + aggregation across multiple columns</p> <pre><code>&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; t.select(s.across(s.numeric() &amp; ~s.c(\"year\"), _.mean())).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64        \u2502 float64       \u2502 float64           \u2502 float64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502       43.92193 \u2502      17.15117 \u2502        200.915205 \u2502 4201.754386 \u2502\n\u2502       43.92193 \u2502      17.15117 \u2502        200.915205 \u2502 4201.754386 \u2502\n\u2502       43.92193 \u2502      17.15117 \u2502        200.915205 \u2502 4201.754386 \u2502\n\u2502       43.92193 \u2502      17.15117 \u2502        200.915205 \u2502 4201.754386 \u2502\n\u2502       43.92193 \u2502      17.15117 \u2502        200.915205 \u2502 4201.754386 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.set_column","title":"<code>set_column(name, expr)</code>","text":"<p>Replace an existing column with a new expression.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Column name to replace</p> required <code>expr</code> <code>ir.Value</code> <p>New data for column</p> required <p>Returns:</p> Type Description <code>Table</code> <p>Table expression with new columns</p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.sql","title":"<code>sql(query)</code>","text":"<p>Run a SQL query against a table expression.</p> <p>The SQL string is backend specific</p> <p><code>query</code> must be valid SQL for the execution backend the expression will run against.</p> <p>This restriction may be lifted in a future version of ibis.</p> <p>See <code>Table.alias</code> for details on using named table expressions in a SQL string.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query string</p> required <p>Returns:</p> Type Description <code>Table</code> <p>An opaque table expression</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch(table_name=\"penguins\")\n&gt;&gt;&gt; expr = t.sql(\"SELECT island, mean(bill_length_mm) FROM penguins GROUP BY 1 ORDER BY 2 DESC\")\n&gt;&gt;&gt; expr\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 island    \u2503 mean(bill_length_mm) \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 float64              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Biscoe    \u2502            45.257485 \u2502\n\u2502 Dream     \u2502            44.167742 \u2502\n\u2502 Torgersen \u2502            38.950980 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.to_array","title":"<code>to_array()</code>","text":"<p>View a single column table as an array.</p> <p>Returns:</p> Type Description <code>Value</code> <p>A single column view of a table</p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.to_pandas","title":"<code>to_pandas(**kwargs)</code>","text":"<p>Convert a table expression to a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>Same as keyword arguments to <code>execute</code></p> <code>{}</code>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.union","title":"<code>union(*tables, distinct=False)</code>","text":"<p>Compute the set union of multiple table expressions.</p> <p>The input tables must have identical schemas.</p> <p>Parameters:</p> Name Type Description Default <code>*tables</code> <code>Table</code> <p>One or more table expressions</p> <code>()</code> <code>distinct</code> <code>bool</code> <p>Only return distinct rows</p> <code>False</code> <p>Returns:</p> Type Description <code>Table</code> <p>A new table containing the union of all input tables.</p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.union--see-also","title":"See Also","text":"<p><code>ibis.union</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t1 = ibis.memtable({\"a\": [1, 2]})\n&gt;&gt;&gt; t1\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t2 = ibis.memtable({\"a\": [2, 3]})\n&gt;&gt;&gt; t2\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     2 \u2502\n\u2502     3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.union(t2)  # union all by default\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2502     2 \u2502\n\u2502     3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.union(t2, distinct=True).order_by(\"a\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2502     3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Passing no arguments to <code>union</code> returns the table expression</p> <p>This can be useful when you have a sequence of tables to process, and you don't know the length prior to running your program (for example, user input).</p> <pre><code>&gt;&gt;&gt; t1\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.union()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 a     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502\n\u2502     2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t1.union().equals(t1)\nTrue\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.unpack","title":"<code>unpack(*columns)</code>","text":"<p>Project the struct fields of each of <code>columns</code> into <code>self</code>.</p> <p>Existing fields are retained in the projection.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str</code> <p>String column names to project into <code>self</code>.</p> <code>()</code> <p>Returns:</p> Type Description <code>Table</code> <p>The child table with struct fields of each of <code>columns</code> projected.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; lines = '''\n...     {\"name\": \"a\", \"pos\": {\"lat\": 10.1, \"lon\": 30.3}}\n...     {\"name\": \"b\", \"pos\": {\"lat\": 10.2, \"lon\": 30.2}}\n...     {\"name\": \"c\", \"pos\": {\"lat\": 10.3, \"lon\": 30.1}}\n... '''\n&gt;&gt;&gt; with open(\"/tmp/lines.json\", \"w\") as f:\n...     _ = f.write(lines)\n&gt;&gt;&gt; t = ibis.read_json(\"/tmp/lines.json\")\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 name   \u2503 pos                                \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 struct&lt;lat: float64, lon: float64&gt; \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502 {'lat': 10.1, 'lon': 30.3}         \u2502\n\u2502 b      \u2502 {'lat': 10.2, 'lon': 30.2}         \u2502\n\u2502 c      \u2502 {'lat': 10.3, 'lon': 30.1}         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; t.unpack(\"pos\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 name   \u2503 lat     \u2503 lon     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string \u2502 float64 \u2502 float64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a      \u2502    10.1 \u2502    30.3 \u2502\n\u2502 b      \u2502    10.2 \u2502    30.2 \u2502\n\u2502 c      \u2502    10.3 \u2502    30.1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.unpack--see-also","title":"See Also","text":"<p><code>StructValue.lift</code></p>"},{"location":"api/expressions/tables/#ibis.expr.types.relations.Table.view","title":"<code>view()</code>","text":"<p>Create a new table expression distinct from the current one.</p> <p>Use this API for any self-referencing operations like a self-join.</p> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable","title":"<code>GroupedTable</code>","text":"<p>An intermediate table expression to hold grouping information.</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable-functions","title":"Functions","text":""},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.aggregate","title":"<code>aggregate(metrics=None, **kwds)</code>","text":"<p>Compute aggregates over a group by.</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.count","title":"<code>count(metric_name='count')</code>","text":"<p>Computing the number of rows per group.</p> <p>Parameters:</p> Name Type Description Default <code>metric_name</code> <code>str</code> <p>Name to use for the row count metric</p> <code>'count'</code> <p>Returns:</p> Type Description <code>Table</code> <p>The aggregated table</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.having","title":"<code>having(expr)</code>","text":"<p>Add a post-aggregation result filter <code>expr</code>.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.BooleanScalar</code> <p>An expression that filters based on an aggregate value.</p> required <p>Returns:</p> Type Description <code>GroupedTable</code> <p>A grouped table expression</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.mutate","title":"<code>mutate(*exprs, **kwexprs)</code>","text":"<p>Return a table projection with window functions applied.</p> <p>Any arguments can be functions.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>ir.Value | Sequence[ir.Value]</code> <p>List of expressions</p> <code>()</code> <code>kwexprs</code> <code>ir.Value</code> <p>Expressions</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t = ibis.table([\n...     ('foo', 'string'),\n...     ('bar', 'string'),\n...     ('baz', 'double'),\n... ], name='t')\n&gt;&gt;&gt; t\nUnboundTable: t\n  foo string\n  bar string\n  baz float64\n&gt;&gt;&gt; expr = (t.group_by('foo')\n...          .order_by(ibis.desc('bar'))\n...          .mutate(qux=lambda x: x.baz.lag(), qux2=t.baz.lead()))\n&gt;&gt;&gt; print(expr)\nr0 := UnboundTable: t\n  foo string\n  bar string\n  baz float64\nSelection[r0]\n  selections:\n    r0\n    qux:  WindowFunction(...)\n    qux2: WindowFunction(...)\n</code></pre> <p>Returns:</p> Type Description <code>Table</code> <p>A table expression with window functions applied</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.order_by","title":"<code>order_by(expr)</code>","text":"<p>Sort a grouped table expression by <code>expr</code>.</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.order_by--notes","title":"Notes","text":"<p>This API call is ignored in aggregations.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Value | Iterable[ir.Value]</code> <p>Expressions to order the results by</p> required <p>Returns:</p> Type Description <code>GroupedTable</code> <p>A sorted grouped GroupedTable</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.over","title":"<code>over(window=None, *, rows=None, range=None, group_by=None, order_by=None)</code>","text":"<p>Apply a window over the input expressions.</p> <p>Parameters:</p> Name Type Description Default <code>window</code> <p>Window to add to the input</p> <code>None</code> <code>rows</code> <p>Whether to use the <code>ROWS</code> window clause</p> <code>None</code> <code>range</code> <p>Whether to use the <code>RANGE</code> window clause</p> <code>None</code> <code>group_by</code> <p>Grouping key</p> <code>None</code> <code>order_by</code> <p>Ordering key</p> <code>None</code> <p>Returns:</p> Type Description <code>GroupedTable</code> <p>A new grouped table expression</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.select","title":"<code>select(*exprs, **kwexprs)</code>","text":"<p>Project new columns out of the grouped table.</p>"},{"location":"api/expressions/tables/#ibis.expr.types.groupby.GroupedTable.select--see-also","title":"See Also","text":"<p><code>GroupedTable.mutate</code></p>"},{"location":"api/expressions/timestamps/","title":"Temporal Expression APIs","text":"<p>All temporal operations are valid for both scalars and columns.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TemporalValue","title":"<code>TemporalValue</code>","text":"<p>         Bases: <code>Value</code></p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TemporalValue-functions","title":"Functions","text":""},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TemporalValue.strftime","title":"<code>strftime(format_str)</code>","text":"<p>Format timestamp according to <code>format_str</code>.</p> <p>Format string may depend on the backend, but we try to conform to ANSI <code>strftime</code>.</p> <p>Parameters:</p> Name Type Description Default <code>format_str</code> <code>str</code> <p><code>strftime</code> format string</p> required <p>Returns:</p> Type Description <code>StringValue</code> <p>Formatted version of <code>arg</code></p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimestampValue","title":"<code>TimestampValue</code>","text":"<p>         Bases: <code>_DateComponentMixin</code>, <code>_TimeComponentMixin</code>, <code>TemporalValue</code></p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimestampValue-functions","title":"Functions","text":""},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimestampValue.__add__","title":"<code>__add__(other)</code>","text":"<p>Add an interval to a timestamp.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimestampValue.__rsub__","title":"<code>__rsub__(other)</code>","text":"<p>Subtract a timestamp or an interval from a timestamp.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimestampValue.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtract a timestamp or an interval from a timestamp.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimestampValue.date","title":"<code>date()</code>","text":"<p>Return the date component of the expression.</p> <p>Returns:</p> Type Description <code>DateValue</code> <p>The date component of <code>self</code></p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimestampValue.truncate","title":"<code>truncate(unit)</code>","text":"<p>Truncate timestamp expression to units of <code>unit</code>.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>Literal['Y', 'Q', 'M', 'W', 'D', 'h', 'm', 's', 'ms', 'us', 'ns']</code> <p>Unit to truncate to</p> required <p>Returns:</p> Type Description <code>TimestampValue</code> <p>Truncated timestamp expression</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.DateValue","title":"<code>DateValue</code>","text":"<p>         Bases: <code>TemporalValue</code>, <code>_DateComponentMixin</code></p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.DateValue-functions","title":"Functions","text":""},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.DateValue.__add__","title":"<code>__add__(other)</code>","text":"<p>Add an interval to a date.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.DateValue.__rsub__","title":"<code>__rsub__(other)</code>","text":"<p>Subtract a date or an interval from a date.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.DateValue.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtract a date or an interval from a date.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.DateValue.truncate","title":"<code>truncate(unit)</code>","text":"<p>Truncate date expression to units of <code>unit</code>.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>Literal['Y', 'Q', 'M', 'W', 'D']</code> <p>Unit to truncate <code>arg</code> to</p> required <p>Returns:</p> Type Description <code>DateValue</code> <p>Truncated date value expression</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimeValue","title":"<code>TimeValue</code>","text":"<p>         Bases: <code>_TimeComponentMixin</code>, <code>TemporalValue</code></p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimeValue-functions","title":"Functions","text":""},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimeValue.__add__","title":"<code>__add__(other)</code>","text":"<p>Add an interval to a time expression.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimeValue.__rsub__","title":"<code>__rsub__(other)</code>","text":"<p>Subtract a time or an interval from a time expression.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimeValue.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtract a time or an interval from a time expression.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.TimeValue.truncate","title":"<code>truncate(unit)</code>","text":"<p>Truncate the expression to a time expression in units of <code>unit</code>.</p> <p>Commonly used for time series resampling.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>Literal['h', 'm', 's', 'ms', 'us', 'ns']</code> <p>The unit to truncate to</p> required <p>Returns:</p> Type Description <code>TimeValue</code> <p><code>self</code> truncated to <code>unit</code></p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue","title":"<code>IntervalValue</code>","text":"<p>         Bases: <code>Value</code></p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue-attributes","title":"Attributes","text":""},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.days","title":"<code>days: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of days from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.hours","title":"<code>hours: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of hours from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.microseconds","title":"<code>microseconds: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of microseconds from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.milliseconds","title":"<code>milliseconds: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of milliseconds from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.minutes","title":"<code>minutes: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of minutes from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.months","title":"<code>months: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of months from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.nanoseconds","title":"<code>nanoseconds: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of nanoseconds from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.quarters","title":"<code>quarters: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of quarters from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.seconds","title":"<code>seconds: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of seconds from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.weeks","title":"<code>weeks: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of weeks from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.years","title":"<code>years: ir.IntegerValue</code>  <code>property</code>","text":"<p>Extract the number of years from an interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue-functions","title":"Functions","text":""},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.__add__","title":"<code>__add__(other)</code>","text":"<p>Add this interval to <code>other</code>.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.__floordiv__","title":"<code>__floordiv__(other)</code>","text":"<p>Floor-divide this interval by <code>other</code>.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiply this interval by <code>other</code>.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.__rsub__","title":"<code>__rsub__(other)</code>","text":"<p>Subtract <code>other</code> from this interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtract <code>other</code> from this interval.</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.negate","title":"<code>negate()</code>","text":"<p>Negate an interval expression.</p> <p>Returns:</p> Type Description <code>IntervalValue</code> <p>A negated interval value expression</p>"},{"location":"api/expressions/timestamps/#ibis.expr.types.temporal.IntervalValue.to_unit","title":"<code>to_unit(target_unit)</code>","text":"<p>Convert this interval to units of <code>target_unit</code>.</p>"},{"location":"api/expressions/top_level/","title":"Top-level APIs","text":"<p>These methods and objects are available directly in the <code>ibis</code> module.</p>"},{"location":"api/expressions/top_level/#na","title":"<code>NA</code>","text":"<p><code>NA</code> is the null scalar.</p>"},{"location":"api/expressions/top_level/#ibis.and_","title":"<code>and_(*predicates)</code>","text":"<p>Combine multiple predicates using <code>&amp;</code>.</p> <p>Parameters:</p> Name Type Description Default <code>predicates</code> <code>ir.BooleanValue</code> <p>Boolean value expressions</p> <code>()</code> <p>Returns:</p> Type Description <code>BooleanValue</code> <p>A new predicate that evaluates to True if all composing predicates are True. If no predicates were provided, returns True.</p>"},{"location":"api/expressions/top_level/#ibis.array","title":"<code>array(values, type=None)</code>","text":"<p>Create an array expression.</p> <p>If the input expressions are all column expressions, then the output will be an <code>ArrayColumn</code>. The input columns will be concatenated row-wise to produce each array in the output array column. Each array will have length n, where n is the number of input columns. All input columns should be of the same datatype.</p> <p>If the input expressions are Python literals, then the output will be a single <code>ArrayScalar</code> of length n, where n is the number of input values. This is equivalent to</p> <pre><code>values = [1, 2, 3]\nibis.literal(values)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Iterable[V]</code> <p>An iterable of Ibis expressions or a list of Python literals</p> required <code>type</code> <code>str | dt.DataType | None</code> <p>An instance of <code>ibis.expr.datatypes.DataType</code> or a string indicating the ibis type of <code>value</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>ArrayValue</code> <p>An array column (if the inputs are column expressions), or an array scalar (if the inputs are Python literals)</p> <p>Examples:</p> <p>Create an array column from column expressions</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t = ibis.table([('a', 'int64'), ('b', 'int64')], name='t')\n&gt;&gt;&gt; result = ibis.array([t.a, t.b])\n</code></pre> <p>Create an array scalar from Python literals</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; result = ibis.array([1.0, 2.0, 3.0])\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.asc","title":"<code>asc(expr)</code>","text":"<p>Create a ascending sort key from <code>asc</code> or column name.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Column | str</code> <p>The expression or column name to use for sorting</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t[[\"species\", \"year\"]].order_by(ibis.asc(\"year\")).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502  2007 \u2502\n\u2502 Adelie  \u2502  2007 \u2502\n\u2502 Adelie  \u2502  2007 \u2502\n\u2502 Adelie  \u2502  2007 \u2502\n\u2502 Adelie  \u2502  2007 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Returns:</p> Type Description <code>ir.ValueExpr</code> <p>An expression</p>"},{"location":"api/expressions/top_level/#ibis.case","title":"<code>case()</code>","text":"<p>Begin constructing a case expression.</p> <p>Use the <code>.when</code> method on the resulting object followed by <code>.end</code> to create a complete case.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; cond1 = ibis.literal(1) == 1\n&gt;&gt;&gt; cond2 = ibis.literal(2) == 1\n&gt;&gt;&gt; expr = ibis.case().when(cond1, 3).when(cond2, 4).end()\n&gt;&gt;&gt; expr\nSearchedCase(...)\n</code></pre> <p>Returns:</p> Type Description <code>SearchedCaseBuilder</code> <p>A builder object to use for constructing a case expression.</p>"},{"location":"api/expressions/top_level/#ibis.coalesce","title":"<code>coalesce = _deferred(ir.Value.coalesce)</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.cumulative_window","title":"<code>cumulative_window(group_by=None, order_by=None)</code>","text":"<p>Create a cumulative window for use with window functions.</p> <p>All window frames / ranges are inclusive.</p> <p>Parameters:</p> Name Type Description Default <code>group_by</code> <p>Grouping key</p> <code>None</code> <code>order_by</code> <p>Ordering key</p> <code>None</code> <p>Returns:</p> Type Description <code>Window</code> <p>A window frame</p>"},{"location":"api/expressions/top_level/#ibis.date","title":"<code>date(value)</code>","text":"<p>Return a date literal if <code>value</code> is coercible to a date.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>Date string</p> required <p>Returns:</p> Type Description <code>DateScalar</code> <p>A date expression</p>"},{"location":"api/expressions/top_level/#ibis.deferred","title":"<code>deferred = Deferred()</code>  <code>module-attribute</code>","text":"<p>Deferred expression object.</p> <p>Use this object to refer to a previous table expression in a chain of expressions.</p> <p><code>_</code> may conflict with other idioms in Python</p> <p>See ibis-project/ibis#4704 for details.</p> <p>Use <code>from ibis import deferred as &lt;NAME&gt;</code> to assign a different name to the deferred object builder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; t = ibis.table(dict(key=\"int\", value=\"float\"), name=\"t\")\n&gt;&gt;&gt; expr = t.group_by(key=_.key - 1).agg(total=_.value.sum())\n&gt;&gt;&gt; expr.schema()\nibis.Schema {\n  key    int64\n  total  float64\n}\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.desc","title":"<code>desc(expr)</code>","text":"<p>Create a descending sort key from <code>expr</code> or column name.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Column | str</code> <p>The expression or column name to use for sorting</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; t[[\"species\", \"year\"]].order_by(ibis.desc(\"year\")).head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502  2009 \u2502\n\u2502 Adelie  \u2502  2009 \u2502\n\u2502 Adelie  \u2502  2009 \u2502\n\u2502 Adelie  \u2502  2009 \u2502\n\u2502 Adelie  \u2502  2009 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Returns:</p> Type Description <code>ir.ValueExpr</code> <p>An expression</p>"},{"location":"api/expressions/top_level/#ibis.difference","title":"<code>difference = ir.Table.difference</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.get_backend","title":"<code>get_backend(expr=None)</code>","text":"<p>Get the current Ibis backend to use for a given expression.</p> <p>expr     An expression to get the backend from. If not passed, the default     backend is returned.</p> <p>Returns:</p> Type Description <code>BaseBackend</code> <p>The Ibis backend.</p>"},{"location":"api/expressions/top_level/#ibis.greatest","title":"<code>greatest = _deferred(ir.Value.greatest)</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.ifelse","title":"<code>ifelse = _deferred(ir.BooleanValue.ifelse)</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.intersect","title":"<code>intersect = ir.Table.intersect</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.interval","title":"<code>interval(value=None, unit='s', years=None, quarters=None, months=None, weeks=None, days=None, hours=None, minutes=None, seconds=None, milliseconds=None, microseconds=None, nanoseconds=None)</code>","text":"<p>Return an interval literal expression.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int | datetime.timedelta | None</code> <p>Interval value. If passed, must be combined with <code>unit</code>.</p> <code>None</code> <code>unit</code> <code>str</code> <p>Unit of <code>value</code></p> <code>'s'</code> <code>years</code> <code>int | None</code> <p>Number of years</p> <code>None</code> <code>quarters</code> <code>int | None</code> <p>Number of quarters</p> <code>None</code> <code>months</code> <code>int | None</code> <p>Number of months</p> <code>None</code> <code>weeks</code> <code>int | None</code> <p>Number of weeks</p> <code>None</code> <code>days</code> <code>int | None</code> <p>Number of days</p> <code>None</code> <code>hours</code> <code>int | None</code> <p>Number of hours</p> <code>None</code> <code>minutes</code> <code>int | None</code> <p>Number of minutes</p> <code>None</code> <code>seconds</code> <code>int | None</code> <p>Number of seconds</p> <code>None</code> <code>milliseconds</code> <code>int | None</code> <p>Number of milliseconds</p> <code>None</code> <code>microseconds</code> <code>int | None</code> <p>Number of microseconds</p> <code>None</code> <code>nanoseconds</code> <code>int | None</code> <p>Number of nanoseconds</p> <code>None</code> <p>Returns:</p> Type Description <code>IntervalScalar</code> <p>An interval expression</p>"},{"location":"api/expressions/top_level/#ibis.least","title":"<code>least = _deferred(ir.Value.least)</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.literal","title":"<code>literal(value, type=None)</code>","text":"<p>Create a scalar expression from a Python value.</p> <p>Use specific functions for arrays, structs and maps</p> <p>Ibis supports literal construction of arrays using the following functions:</p> <ol> <li><code>ibis.array</code></li> <li><code>ibis.struct</code></li> <li><code>ibis.map</code></li> </ol> <p>Constructing these types using <code>literal</code> will be deprecated in a future release.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>A Python value</p> required <code>type</code> <code>dt.DataType | str | None</code> <p>An instance of <code>DataType</code> or a string indicating the ibis type of <code>value</code>. This parameter can be used in cases where ibis's type inference isn't sufficient for discovering the type of <code>value</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Scalar</code> <p>An expression representing a literal value</p> <p>Examples:</p> <p>Construct an integer literal</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; x = ibis.literal(42)\n&gt;&gt;&gt; x.type()\nInt8(nullable=True)\n</code></pre> <p>Construct a <code>float64</code> literal from an <code>int</code></p> <pre><code>&gt;&gt;&gt; y = ibis.literal(42, type='double')\n&gt;&gt;&gt; y.type()\nFloat64(nullable=True)\n</code></pre> <p>Ibis checks for invalid types</p> <pre><code>&gt;&gt;&gt; ibis.literal('foobar', type='int64')\nTraceback (most recent call last):\n...\nTypeError: Value 'foobar' cannot be safely coerced to int64\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.map","title":"<code>map(keys, values=None)</code>","text":"<p>Create a map literal from a <code>dict</code>, other mapping or two sequences.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <p>Keys of the map or <code>Mapping</code>. If <code>keys</code> is a <code>Mapping</code>, <code>values</code> must be <code>None</code>.</p> required <code>values</code> <p>Values of the map or <code>None</code>. If <code>None</code>, the <code>keys</code> argument must be a <code>Mapping</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>MapValue</code> <p>An expression representing either a map column or literal (associative array with key/value pairs of fixed types)</p> <p>Examples:</p> <p>Create a map literal from a dict with the type inferred</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t = ibis.map(dict(a=1, b=2))\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.negate","title":"<code>negate = ir.NumericValue.negate</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.now","title":"<code>now()</code>","text":"<p>Return an expression that will compute the current timestamp.</p> <p>Returns:</p> Type Description <code>TimestampScalar</code> <p>An expression representing the current timestamp.</p>"},{"location":"api/expressions/top_level/#ibis.null","title":"<code>null()</code>","text":"<p>Create a NULL/NA scalar.</p>"},{"location":"api/expressions/top_level/#ibis.or_","title":"<code>or_(*predicates)</code>","text":"<p>Combine multiple predicates using <code>|</code>.</p> <p>Parameters:</p> Name Type Description Default <code>predicates</code> <code>ir.BooleanValue</code> <p>Boolean value expressions</p> <code>()</code> <p>Returns:</p> Type Description <code>BooleanValue</code> <p>A new predicate that evaluates to True if any composing predicates are True. If no predicates were provided, returns False.</p>"},{"location":"api/expressions/top_level/#ibis.param","title":"<code>param(type)</code>","text":"<p>Create a deferred parameter of a given type.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>dt.DataType</code> <p>The type of the unbound parameter, e.g., double, int64, date, etc.</p> required <p>Returns:</p> Type Description <code>Scalar</code> <p>A scalar expression backend by a parameter</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; start = ibis.param('date')\n&gt;&gt;&gt; end = ibis.param('date')\n&gt;&gt;&gt; schema = dict(timestamp_col='timestamp', value='double')\n&gt;&gt;&gt; t = ibis.table(schema, name='t')\n&gt;&gt;&gt; predicates = [t.timestamp_col &gt;= start, t.timestamp_col &lt;= end]\n&gt;&gt;&gt; t.filter(predicates).value.sum()\nr0 := UnboundTable: t\n  timestamp_col timestamp\n  value         float64\nr1 := Selection[r0]\n  predicates:\n    r0.timestamp_col &gt;= $(date)\n    r0.timestamp_col &lt;= $(date)\nSum(value): Sum(r1.value)\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.show_sql","title":"<code>show_sql(expr, dialect=None, file=None)</code>","text":"<p>Pretty-print the compiled SQL string of an expression.</p> <p>If a dialect cannot be inferred and one was not passed, duckdb will be used as the dialect</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Expr</code> <p>Ibis expression whose SQL will be printed</p> required <code>dialect</code> <code>str | None</code> <p>String dialect. This is typically not required, but can be useful if ibis cannot infer the backend dialect.</p> <code>None</code> <code>file</code> <code>IO[str] | None</code> <p>File to write output to</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; from ibis import _\n&gt;&gt;&gt; t = ibis.table(dict(a=\"int\"), name=\"t\")\n&gt;&gt;&gt; expr = t.select(c=_.a * 2)\n&gt;&gt;&gt; ibis.show_sql(expr)  # duckdb dialect by default\nSELECT\n  t0.a * CAST(2 AS SMALLINT) AS c\nFROM t AS t0\n&gt;&gt;&gt; ibis.show_sql(expr, dialect=\"mysql\")\nSELECT\n  t0.a * 2 AS c\nFROM t AS t0\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.to_sql","title":"<code>to_sql(expr, dialect=None, **kwargs)</code>","text":"<p>Return the formatted SQL string for an expression.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Expr</code> <p>Ibis expression.</p> required <code>dialect</code> <code>str | None</code> <p>SQL dialect to use for compilation.</p> <code>None</code> <code>kwargs</code> <p>Scalar parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted SQL string</p>"},{"location":"api/expressions/top_level/#ibis.random","title":"<code>random()</code>","text":"<p>Return a random floating point number in the range [0.0, 1.0).</p> <p>Similar to <code>random.random</code> in the Python standard library.</p> <p>Returns:</p> Type Description <code>FloatingScalar</code> <p>Random float value expression</p>"},{"location":"api/expressions/top_level/#ibis.range_window","title":"<code>range_window(preceding=None, following=None, group_by=None, order_by=None)</code>","text":"<p>Create a range-based window clause for use with window functions.</p> <p>This RANGE window clause aggregates rows based upon differences in the value of the order-by expression.</p> <p>All window frames / ranges are inclusive.</p> <p>Parameters:</p> Name Type Description Default <code>preceding</code> <p>Number of preceding rows in the window</p> <code>None</code> <code>following</code> <p>Number of following rows in the window</p> <code>None</code> <code>group_by</code> <p>Grouping key</p> <code>None</code> <code>order_by</code> <p>Ordering key</p> <code>None</code> <p>Returns:</p> Type Description <code>Window</code> <p>A window frame</p>"},{"location":"api/expressions/top_level/#ibis.read_csv","title":"<code>read_csv(sources, **kwargs)</code>","text":"<p>Lazily load a CSV or set of CSVs.</p> <p>This function delegates to the <code>read_csv</code> method on the current default backend (DuckDB or <code>ibis.config.default_backend</code>).</p> <p>Parameters:</p> Name Type Description Default <code>sources</code> <code>str | Path | Sequence[str | Path]</code> <p>A filesystem path or URL or list of same.  Supports CSV and TSV files.</p> required <code>kwargs</code> <code>Any</code> <p>Backend-specific keyword arguments for the file type. For the DuckDB backend used by default, please refer to:</p> <ul> <li>CSV/TSV: https://duckdb.org/docs/data/csv#parameters.</li> </ul> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>Table expression representing a file</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.Batting_raw.fetch()\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 playerID  \u2503 yearID \u2503 stint \u2503 teamID \u2503 lgID   \u2503 G     \u2503 AB    \u2503 R     \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 int64  \u2502 int64 \u2502 string \u2502 string \u2502 int64 \u2502 int64 \u2502 int64 \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 abercda01 \u2502   1871 \u2502     1 \u2502 TRO    \u2502 NA     \u2502     1 \u2502     4 \u2502     0 \u2502 \u2026 \u2502\n\u2502 addybo01  \u2502   1871 \u2502     1 \u2502 RC1    \u2502 NA     \u2502    25 \u2502   118 \u2502    30 \u2502 \u2026 \u2502\n\u2502 allisar01 \u2502   1871 \u2502     1 \u2502 CL1    \u2502 NA     \u2502    29 \u2502   137 \u2502    28 \u2502 \u2026 \u2502\n\u2502 allisdo01 \u2502   1871 \u2502     1 \u2502 WS3    \u2502 NA     \u2502    27 \u2502   133 \u2502    28 \u2502 \u2026 \u2502\n\u2502 ansonca01 \u2502   1871 \u2502     1 \u2502 RC1    \u2502 NA     \u2502    25 \u2502   120 \u2502    29 \u2502 \u2026 \u2502\n\u2502 armstbo01 \u2502   1871 \u2502     1 \u2502 FW1    \u2502 NA     \u2502    12 \u2502    49 \u2502     9 \u2502 \u2026 \u2502\n\u2502 barkeal01 \u2502   1871 \u2502     1 \u2502 RC1    \u2502 NA     \u2502     1 \u2502     4 \u2502     0 \u2502 \u2026 \u2502\n\u2502 barnero01 \u2502   1871 \u2502     1 \u2502 BS1    \u2502 NA     \u2502    31 \u2502   157 \u2502    66 \u2502 \u2026 \u2502\n\u2502 barrebi01 \u2502   1871 \u2502     1 \u2502 FW1    \u2502 NA     \u2502     1 \u2502     5 \u2502     1 \u2502 \u2026 \u2502\n\u2502 barrofr01 \u2502   1871 \u2502     1 \u2502 BS1    \u2502 NA     \u2502    18 \u2502    86 \u2502    13 \u2502 \u2026 \u2502\n\u2502 \u2026         \u2502      \u2026 \u2502     \u2026 \u2502 \u2026      \u2502 \u2026      \u2502     \u2026 \u2502     \u2026 \u2502     \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.read_parquet","title":"<code>read_parquet(sources, **kwargs)</code>","text":"<p>Lazily load a parquet file or set of parquet files.</p> <p>This function delegates to the <code>read_parquet</code> method on the current default backend (DuckDB or <code>ibis.config.default_backend</code>).</p> <p>Parameters:</p> Name Type Description Default <code>sources</code> <code>str | Path | Sequence[str | Path]</code> <p>A filesystem path or URL or list of same.</p> required <code>kwargs</code> <code>Any</code> <p>Backend-specific keyword arguments for the file type. For the DuckDB backend used by default, please refer to:</p> <ul> <li>Parquet: https://duckdb.org/docs/data/parquet</li> </ul> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>Table expression representing a file</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; t = ibis.examples.Batting_raw.fetch()\n&gt;&gt;&gt; t\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 playerID  \u2503 yearID \u2503 stint \u2503 teamID \u2503 lgID   \u2503 G     \u2503 AB    \u2503 R     \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 int64  \u2502 int64 \u2502 string \u2502 string \u2502 int64 \u2502 int64 \u2502 int64 \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 abercda01 \u2502   1871 \u2502     1 \u2502 TRO    \u2502 NA     \u2502     1 \u2502     4 \u2502     0 \u2502 \u2026 \u2502\n\u2502 addybo01  \u2502   1871 \u2502     1 \u2502 RC1    \u2502 NA     \u2502    25 \u2502   118 \u2502    30 \u2502 \u2026 \u2502\n\u2502 allisar01 \u2502   1871 \u2502     1 \u2502 CL1    \u2502 NA     \u2502    29 \u2502   137 \u2502    28 \u2502 \u2026 \u2502\n\u2502 allisdo01 \u2502   1871 \u2502     1 \u2502 WS3    \u2502 NA     \u2502    27 \u2502   133 \u2502    28 \u2502 \u2026 \u2502\n\u2502 ansonca01 \u2502   1871 \u2502     1 \u2502 RC1    \u2502 NA     \u2502    25 \u2502   120 \u2502    29 \u2502 \u2026 \u2502\n\u2502 armstbo01 \u2502   1871 \u2502     1 \u2502 FW1    \u2502 NA     \u2502    12 \u2502    49 \u2502     9 \u2502 \u2026 \u2502\n\u2502 barkeal01 \u2502   1871 \u2502     1 \u2502 RC1    \u2502 NA     \u2502     1 \u2502     4 \u2502     0 \u2502 \u2026 \u2502\n\u2502 barnero01 \u2502   1871 \u2502     1 \u2502 BS1    \u2502 NA     \u2502    31 \u2502   157 \u2502    66 \u2502 \u2026 \u2502\n\u2502 barrebi01 \u2502   1871 \u2502     1 \u2502 FW1    \u2502 NA     \u2502     1 \u2502     5 \u2502     1 \u2502 \u2026 \u2502\n\u2502 barrofr01 \u2502   1871 \u2502     1 \u2502 BS1    \u2502 NA     \u2502    18 \u2502    86 \u2502    13 \u2502 \u2026 \u2502\n\u2502 \u2026         \u2502      \u2026 \u2502     \u2026 \u2502 \u2026      \u2502 \u2026      \u2502     \u2026 \u2502     \u2026 \u2502     \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.row_number","title":"<code>row_number()</code>","text":"<p>Return an analytic function expression for the current row number.</p> <p>Returns:</p> Type Description <code>IntegerColumn</code> <p>A column expression enumerating rows</p>"},{"location":"api/expressions/top_level/#ibis.schema","title":"<code>schema(pairs=None, names=None, types=None)</code>","text":"<p>Validate and return a <code>Schema</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>SupportsSchema | None</code> <p>List or dictionary of name, type pairs. Mutually exclusive with <code>names</code> and <code>types</code> arguments.</p> <code>None</code> <code>names</code> <code>Iterable[str] | None</code> <p>Field names. Mutually exclusive with <code>pairs</code>.</p> <code>None</code> <code>types</code> <code>Iterable[str | dt.DataType] | None</code> <p>Field types. Mutually exclusive with <code>pairs</code>.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from ibis import schema, Schema\n&gt;&gt;&gt; sc = schema([('foo', 'string'),\n...              ('bar', 'int64'),\n...              ('baz', 'boolean')])\n&gt;&gt;&gt; sc = schema(names=['foo', 'bar', 'baz'],\n...             types=['string', 'int64', 'boolean'])\n&gt;&gt;&gt; sc = schema(dict(foo=\"string\"))\n&gt;&gt;&gt; sc = schema(Schema(dict(foo=\"string\")))  # no-op\n</code></pre> <p>Returns:</p> Type Description <code>Schema</code> <p>An ibis schema</p>"},{"location":"api/expressions/top_level/#ibis.set_backend","title":"<code>set_backend(backend)</code>","text":"<p>Set the default Ibis backend.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str | BaseBackend</code> <p>May be a backend name or URL, or an existing backend instance.</p> required <p>Examples:</p> <p>You can pass the backend as a name:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.set_backend(\"polars\")\n</code></pre> <p>Or as a URI</p> <pre><code>&gt;&gt;&gt; ibis.set_backend(\"postgres://user:password@hostname:5432\")\n</code></pre> <p>Or as an existing backend instance</p> <pre><code>&gt;&gt;&gt; ibis.set_backend(ibis.duckdb.connect())\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.struct","title":"<code>struct(value, type=None)</code>","text":"<p>Create a struct literal from a <code>dict</code> or other mapping.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Iterable[tuple[str, V]] | Mapping[str, V]</code> <p>The underlying data for literal struct value</p> required <code>type</code> <code>str | dt.DataType | None</code> <p>An instance of <code>ibis.expr.datatypes.DataType</code> or a string indicating the ibis type of <code>value</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>StructScalar</code> <p>An expression representing a literal struct (compound type with fields of fixed types)</p> <p>Examples:</p> <p>Create a struct literal from a <code>dict</code> with the type inferred</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; t = ibis.struct(dict(a=1, b='foo'))\n</code></pre> <p>Create a struct literal from a <code>dict</code> with a specified type</p> <pre><code>&gt;&gt;&gt; t = ibis.struct(dict(a=1, b='foo'), type='struct&lt;a: float, b: string&gt;')\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.table","title":"<code>table(schema=None, name=None)</code>","text":"<p>Create a table literal or an abstract table without data.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>SupportsSchema | None</code> <p>A schema for the table</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Name for the table. One is generated if this value is <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>A table expression</p> <p>Examples:</p> <p>Create a table with no data backing it</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive\nFalse\n&gt;&gt;&gt; t = ibis.table(schema=dict(a=\"int\", b=\"string\"), name=\"t\")\n&gt;&gt;&gt; t\nUnboundTable: t\n  a int64\n  b string\n</code></pre>"},{"location":"api/expressions/top_level/#ibis.time","title":"<code>time(value)</code>","text":""},{"location":"api/expressions/top_level/#ibis.timestamp","title":"<code>timestamp(value, *args, timezone=None)</code>","text":"<p>Construct a timestamp literal if <code>value</code> is coercible to a timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>The value to use for constructing the timestamp</p> required <code>args</code> <p>Additional arguments used when constructing a timestamp</p> <code>()</code> <code>timezone</code> <code>str | None</code> <p>The timezone of the timestamp</p> <code>None</code> <p>Returns:</p> Type Description <code>TimestampScalar</code> <p>A timestamp expression</p>"},{"location":"api/expressions/top_level/#ibis.trailing_range_window","title":"<code>trailing_range_window(preceding, order_by, group_by=None)</code>","text":"<p>Create a trailing range window for use with window functions.</p> <p>Parameters:</p> Name Type Description Default <code>preceding</code> <p>A value expression</p> required <code>order_by</code> <p>Ordering key</p> required <code>group_by</code> <p>Grouping key</p> <code>None</code> <p>Returns:</p> Type Description <code>Window</code> <p>A window frame</p>"},{"location":"api/expressions/top_level/#ibis.trailing_window","title":"<code>trailing_window(preceding, group_by=None, order_by=None)</code>","text":"<p>Create a trailing window for use with window functions.</p> <p>Parameters:</p> Name Type Description Default <code>preceding</code> <p>The number of preceding rows</p> required <code>group_by</code> <p>Grouping key</p> <code>None</code> <code>order_by</code> <p>Ordering key</p> <code>None</code> <p>Returns:</p> Type Description <code>Window</code> <p>A window frame</p>"},{"location":"api/expressions/top_level/#ibis.union","title":"<code>union = ir.Table.union</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.where","title":"<code>where = _deferred(ir.BooleanValue.ifelse)</code>  <code>module-attribute</code>","text":""},{"location":"api/expressions/top_level/#ibis.window","title":"<code>window(preceding=None, following=None, order_by=None, group_by=None, *, rows=None, range=None, between=None)</code>","text":"<p>Create a window clause for use with window functions.</p> <p>The <code>ROWS</code> window clause includes peer rows based on differences in row number whereas <code>RANGE</code> includes rows based on the differences in row value of a single <code>order_by</code> expression.</p> <p>All window frame bounds are inclusive.</p> <p>Parameters:</p> Name Type Description Default <code>preceding</code> <p>Number of preceding rows in the window</p> <code>None</code> <code>following</code> <p>Number of following rows in the window</p> <code>None</code> <code>group_by</code> <p>Grouping key</p> <code>None</code> <code>order_by</code> <p>Ordering key</p> <code>None</code> <code>rows</code> <p>Whether to use the <code>ROWS</code> window clause</p> <code>None</code> <code>range</code> <p>Whether to use the <code>RANGE</code> window clause</p> <code>None</code> <code>between</code> <p>Automatically infer the window kind based on the boundaries</p> <code>None</code> <p>Returns:</p> Type Description <code>Window</code> <p>A window frame</p>"},{"location":"backends/","title":"Backends","text":"<p>See the configuration guide to inspect or reconfigure the backend used by default.</p>"},{"location":"backends/#string-generating-backends","title":"String Generating Backends","text":"<p>The first category of backend translate Ibis expressions into string queries.</p> <p>The compiler turns each expression into a string query and passes that query to the database through a driver API for execution.</p> <ul> <li>Apache Impala</li> <li>ClickHouse</li> <li>Google BigQuery</li> <li>HeavyAI</li> </ul>"},{"location":"backends/#expression-generating-backends","title":"Expression Generating Backends","text":"<p>The next category of backends translates ibis expressions into another system's expressions, for example, SQLAlchemy.</p> <p>Instead of generating strings for each expression these backends produce another kind of expression and typically have high-level APIs for execution.</p> <ul> <li>Apache Arrow Datafusion</li> <li>Apache Druid</li> <li>Apache PySpark</li> <li>Dask</li> <li>DuckDB</li> <li>MS SQL Server</li> <li>MySQL</li> <li>Polars</li> <li>PostgreSQL</li> <li>SQLite</li> <li>Snowflake</li> <li>Trino</li> </ul>"},{"location":"backends/#direct-execution-backends","title":"Direct Execution Backends","text":"<p>The pandas backend is the only direct execution backend. A full description of the implementation can be found in the module docstring of the pandas backend located in <code>ibis/backends/pandas/core.py</code>.</p> <ul> <li>Pandas</li> </ul>"},{"location":"backends/BigQuery/","title":"Google BigQuery","text":""},{"location":"backends/BigQuery/#install","title":"Install","text":"<p>Install ibis and dependencies for the Google BigQuery backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[bigquery]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-bigquery\n</code></pre> <pre><code>mamba install -c conda-forge ibis-bigquery\n</code></pre>"},{"location":"backends/BigQuery/#connect","title":"Connect","text":""},{"location":"backends/BigQuery/#api","title":"API","text":"<p>Create a client by passing in connection parameters to <code>ibis.bigquery.connect</code>.</p> <p>See <code>ibis.backends.bigquery.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.bigquery.connect</code> is a thin wrapper around <code>ibis.backends.bigquery.Backend.do_connect</code>.</p>"},{"location":"backends/BigQuery/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/BigQuery/#ibis.backends.bigquery.Backend.do_connect","title":"<code>do_connect(project_id=None, dataset_id='', credentials=None, application_name=None, auth_local_webserver=True, auth_external_data=False, auth_cache='default', partition_column='PARTITIONTIME')</code>","text":"<p>Create a :class:<code>Backend</code> for use with Ibis.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>str | None</code> <p>A BigQuery project id.</p> <code>None</code> <code>dataset_id</code> <code>str</code> <p>A dataset id that lives inside of the project indicated by <code>project_id</code>.</p> <code>''</code> <code>credentials</code> <code>google.auth.credentials.Credentials | None</code> <p>Optional credentials.</p> <code>None</code> <code>application_name</code> <code>str | None</code> <p>A string identifying your application to Google API endpoints.</p> <code>None</code> <code>auth_local_webserver</code> <code>bool</code> <p>Use a local webserver for the user authentication.  Binds a webserver to an open port on localhost between 8080 and 8089, inclusive, to receive authentication token. If not set, defaults to False, which requests a token via the console.</p> <code>True</code> <code>auth_external_data</code> <code>bool</code> <p>Authenticate using additional scopes required to <code>query external data sources &lt;https://cloud.google.com/bigquery/external-data-sources&gt;</code>_, such as Google Sheets, files in Google Cloud Storage, or files in Google Drive. If not set, defaults to False, which requests the default BigQuery scopes.</p> <code>False</code> <code>auth_cache</code> <code>str</code> <p>Selects the behavior of the credentials cache.</p> <p><code>'default'</code> Reads credentials from disk if available, otherwise authenticates and caches credentials to disk.</p> <p><code>'reauth'</code> Authenticates and caches credentials to disk.</p> <p><code>'none'</code> Authenticates and does not cache credentials.</p> <p>Defaults to <code>'default'</code>.</p> <code>'default'</code> <code>partition_column</code> <code>str | None</code> <p>Identifier to use instead of default <code>_PARTITIONTIME</code> partition column. Defaults to <code>'PARTITIONTIME'</code>.</p> <code>'PARTITIONTIME'</code> <p>Returns:</p> Type Description <code>Backend</code> <p>An instance of the BigQuery backend.</p>"},{"location":"backends/BigQuery/#backend-api","title":"Backend API","text":""},{"location":"backends/BigQuery/#ibis.backends.bigquery.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/BigQuery/#ibis.backends.bigquery.Backend-functions","title":"Functions","text":""},{"location":"backends/BigQuery/#ibis.backends.bigquery.Backend.execute","title":"<code>execute(expr, params=None, limit='default', **kwargs)</code>","text":"<p>Compile and execute the given Ibis expression.</p> <p>Compile and execute Ibis expression using this backend client interface, returning results in-memory in the appropriate object type</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <p>Ibis expression to execute</p> required <code>limit</code> <p>Retrieve at most this number of values/rows. Overrides any limit already set on the expression.</p> <code>'default'</code> <code>params</code> <p>Query parameters</p> <code>None</code> <code>kwargs</code> <p>Extra arguments specific to the backend</p> <code>{}</code> <p>Returns:</p> Type Description <code>pd.DataFrame | pd.Series | scalar</code> <p>Output from execution</p>"},{"location":"backends/BigQuery/#ibis.backends.bigquery.Backend.exists_database","title":"<code>exists_database(name)</code>","text":"<p>Return whether a database name exists in the current connection.</p> <p>Deprecated in Ibis 2.0. Use <code>name in client.list_databases()</code> instead.</p>"},{"location":"backends/BigQuery/#ibis.backends.bigquery.Backend.exists_table","title":"<code>exists_table(name, database=None)</code>","text":"<p>Return whether a table name exists in the database.</p> <p>Deprecated in Ibis 2.0. Use <code>name in client.list_tables()</code> instead.</p>"},{"location":"backends/ClickHouse/","title":"ClickHouse","text":""},{"location":"backends/ClickHouse/#install","title":"Install","text":"<p>Install ibis and dependencies for the ClickHouse backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[clickhouse]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-clickhouse\n</code></pre> <pre><code>mamba install -c conda-forge ibis-clickhouse\n</code></pre>"},{"location":"backends/ClickHouse/#connect","title":"Connect","text":""},{"location":"backends/ClickHouse/#api","title":"API","text":"<p>Create a client by passing in connection parameters to <code>ibis.clickhouse.connect</code>.</p> <p>See <code>ibis.backends.clickhouse.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.clickhouse.connect</code> is a thin wrapper around <code>ibis.backends.clickhouse.Backend.do_connect</code>.</p>"},{"location":"backends/ClickHouse/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend.do_connect","title":"<code>do_connect(host='localhost', port=9000, database='default', user='default', password='', client_name='ibis', compression=_default_compression, external_tables=None, **kwargs)</code>","text":"<p>Create a ClickHouse client for use with Ibis.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host name of the clickhouse server</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Clickhouse server's  port</p> <code>9000</code> <code>database</code> <code>str</code> <p>Default database when executing queries</p> <code>'default'</code> <code>user</code> <code>str</code> <p>User to authenticate with</p> <code>'default'</code> <code>password</code> <code>str</code> <p>Password to authenticate with</p> <code>''</code> <code>client_name</code> <code>str</code> <p>Name of client that wil appear in clickhouse server logs</p> <code>'ibis'</code> <code>compression</code> <code>Literal['lz4', 'lz4hc', 'quicklz', 'zstd'] | bool</code> <p>Whether or not to use compression. Default is <code>'lz4'</code> if installed else False. True is equivalent to <code>'lz4'</code>.</p> <code>_default_compression</code> <code>external_tables</code> <p>External tables that can be used in a query.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Client specific keyword arguments</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; clickhouse_host = os.environ.get('IBIS_TEST_CLICKHOUSE_HOST', 'localhost')\n&gt;&gt;&gt; clickhouse_port = int(os.environ.get('IBIS_TEST_CLICKHOUSE_PORT', 9000))\n&gt;&gt;&gt; client = ibis.clickhouse.connect(host=clickhouse_host,  port=clickhouse_port)\n&gt;&gt;&gt; client\n&lt;ibis.clickhouse.client.ClickhouseClient object at 0x...&gt;\n</code></pre>"},{"location":"backends/ClickHouse/#backend-api","title":"Backend API","text":""},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseBackend</code></p>"},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend-classes","title":"Classes","text":""},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend.Options","title":"<code>Options</code>","text":"<p>         Bases: <code>ibis.config.Config</code></p> <p>Clickhouse options.</p> <p>Attributes:</p> Name Type Description <code>temp_db</code> <code>str</code> <p>Database to use for temporary objects.</p> <code>bool_type</code> <code>str</code> <p>Type to use for boolean columns</p>"},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend-functions","title":"Functions","text":""},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend.close","title":"<code>close()</code>","text":"<p>Close Clickhouse connection and drop any temporary objects.</p>"},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend.execute","title":"<code>execute(expr, limit='default', external_tables=None, **kwargs)</code>","text":"<p>Execute an expression.</p>"},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend.raw_sql","title":"<code>raw_sql(query, external_tables=None, **_)</code>","text":"<p>Execute a SQL string <code>query</code> against the database.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Raw SQL string</p> required <code>external_tables</code> <code>Mapping[str, pd.DataFrame] | None</code> <p>Mapping of table name to pandas DataFrames providing external datasources for the query</p> <code>None</code> <p>Returns:</p> Type Description <code>Cursor</code> <p>Clickhouse cursor</p>"},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend.table","title":"<code>table(name, database=None)</code>","text":"<p>Construct a table expression.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"backends/ClickHouse/#ibis.backends.clickhouse.Backend.to_pyarrow_batches","title":"<code>to_pyarrow_batches(expr, *, params=None, limit=None, chunk_size=1000000, **_)</code>","text":"<p>Execute expression and return an iterator of pyarrow record batches.</p> <p>This method is eager and will execute the associated expression immediately.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Expr</code> <p>Ibis expression to export to pyarrow</p> required <code>limit</code> <code>int | str | None</code> <p>An integer to effect a specific row limit. A value of <code>None</code> means \"no limit\". The default is in <code>ibis/config.py</code>.</p> <code>None</code> <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Mapping of scalar parameter expressions to value.</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>Maximum number of rows in each returned record batch.</p> <code>1000000</code> <p>Returns:</p> Type Description <code>results</code> <p>RecordBatchReader</p>"},{"location":"backends/Dask/","title":"Dask","text":""},{"location":"backends/Dask/#install","title":"Install","text":"<p>Install ibis and dependencies for the Dask backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[dask]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-dask\n</code></pre> <pre><code>mamba install -c conda-forge ibis-dask\n</code></pre>"},{"location":"backends/Dask/#connect","title":"Connect","text":""},{"location":"backends/Dask/#api","title":"API","text":"<p>Create a client by passing in a dictionary of paths to <code>ibis.dask.connect</code>.</p> <p>See <code>ibis.backends.dask.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.dask.connect</code> is a thin wrapper around <code>ibis.backends.dask.Backend.do_connect</code>.</p>"},{"location":"backends/Dask/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/Dask/#ibis.backends.dask.Backend.do_connect","title":"<code>do_connect(dictionary=None)</code>","text":"<p>Construct a Dask backend client from a dictionary of data sources.</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>MutableMapping[str, dd.DataFrame] | None</code> <p>An optional mapping from <code>str</code> table names to Dask DataFrames.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; data = {\n...     \"t\": dd.read_parquet(\"path/to/file.parquet\"),\n...     \"s\": dd.read_csv(\"path/to/file.csv\"),\n... }\n&gt;&gt;&gt; ibis.dask.connect(data)\n</code></pre>"},{"location":"backends/Dask/#backend-api","title":"Backend API","text":""},{"location":"backends/Dask/#ibis.backends.dask.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BasePandasBackend</code></p>"},{"location":"backends/Dask/#ibis.backends.dask.Backend-functions","title":"Functions","text":""},{"location":"backends/Dask/#ibis.backends.dask.Backend.compile","title":"<code>compile(query, params=None, **kwargs)</code>","text":"<p>Compile <code>expr</code>.</p> <p>Returns:</p> Type Description <code>dask.dataframe.core.DataFrame | dask.dataframe.core.Series | das.dataframe.core.Scalar</code> <p>Dask graph.</p>"},{"location":"backends/Datafusion/","title":"Datafusion","text":"<p>Introduced in v2.1</p>"},{"location":"backends/Datafusion/#install","title":"Install","text":"<p>Install ibis and dependencies for the Datafusion backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[datafusion]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-datafusion\n</code></pre> <pre><code>mamba install -c conda-forge ibis-datafusion\n</code></pre>"},{"location":"backends/Datafusion/#connect","title":"Connect","text":""},{"location":"backends/Datafusion/#api","title":"API","text":"<p>Create a client by passing in a dictionary of paths to <code>ibis.datafusion.connect</code>.</p> <p>See <code>ibis.backends.datafusion.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.datafusion.connect</code> is a thin wrapper around <code>ibis.backends.datafusion.Backend.do_connect</code>.</p>"},{"location":"backends/Datafusion/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/Datafusion/#ibis.backends.datafusion.Backend.do_connect","title":"<code>do_connect(config=None)</code>","text":"<p>Create a Datafusion backend for use with Ibis.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Mapping[str, str | Path] | SessionContext | None</code> <p>Mapping of table names to files.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; config = {\"t\": \"path/to/file.parquet\", \"s\": \"path/to/file.csv\"}\n&gt;&gt;&gt; ibis.datafusion.connect(config)\n</code></pre>"},{"location":"backends/Datafusion/#backend-api","title":"Backend API","text":""},{"location":"backends/Datafusion/#ibis.backends.datafusion.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseBackend</code></p>"},{"location":"backends/Datafusion/#ibis.backends.datafusion.Backend-functions","title":"Functions","text":""},{"location":"backends/Datafusion/#ibis.backends.datafusion.Backend.list_tables","title":"<code>list_tables(like=None, database=None)</code>","text":"<p>List the available tables.</p>"},{"location":"backends/Datafusion/#ibis.backends.datafusion.Backend.read_csv","title":"<code>read_csv(path, table_name=None, **kwargs)</code>","text":"<p>Register a CSV file as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The data source. A string or Path to the CSV file.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to Datafusion loading function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/Datafusion/#ibis.backends.datafusion.Backend.read_parquet","title":"<code>read_parquet(path, table_name=None, **kwargs)</code>","text":"<p>Register a parquet file as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The data source.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to Datafusion loading function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/Datafusion/#ibis.backends.datafusion.Backend.register","title":"<code>register(source, table_name=None, **kwargs)</code>","text":"<p>Register a CSV or Parquet file with <code>table_name</code> located at <code>source</code>.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | Path</code> <p>The path to the file</p> required <code>table_name</code> <code>str | None</code> <p>The name of the table</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Datafusion-specific keyword arguments</p> <code>{}</code>"},{"location":"backends/Datafusion/#ibis.backends.datafusion.Backend.table","title":"<code>table(name, schema=None)</code>","text":"<p>Get an ibis expression representing a DataFusion table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the table to retreive</p> required <code>schema</code> <code>sch.Schema | None</code> <p>An optional schema for the table</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>A table expression</p>"},{"location":"backends/Druid/","title":"Druid","text":"<p>Introduced in v5.0</p> <p>The Druid backend is experimental and is subject to backwards incompatible changes.</p>"},{"location":"backends/Druid/#install","title":"Install","text":"<p>Install ibis and dependencies for the Druid backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[druid]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-druid\n</code></pre> <pre><code>mamba install -c conda-forge ibis-druid\n</code></pre>"},{"location":"backends/Druid/#connect","title":"Connect","text":""},{"location":"backends/Druid/#api","title":"API","text":"<p>Create a client by passing in a SQLAlchemy connection string to <code>ibis.druid.connect</code>.</p> <p>See <code>ibis.backends.druid.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.druid.connect</code> is a thin wrapper around <code>ibis.backends.druid.Backend.do_connect</code>.</p>"},{"location":"backends/Druid/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/Druid/#ibis.backends.druid.Backend.do_connect","title":"<code>do_connect(host='localhost', port=8082, database='druid/v2/sql', **_)</code>","text":"<p>Create an Ibis client using the passed connection parameters.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Hostname</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Port</p> <code>8082</code> <code>database</code> <code>str | None</code> <p>Database to connect to</p> <code>'druid/v2/sql'</code>"},{"location":"backends/Druid/#backend-api","title":"Backend API","text":""},{"location":"backends/Druid/#ibis.backends.druid.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseAlchemyBackend</code></p>"},{"location":"backends/DuckDB/","title":"DuckDB","text":"<p>Introduced in v3.0</p> <p><code>duckdb</code> &gt;= 0.5.0 requires <code>duckdb-engine</code> &gt;= 0.6.2</p> <p>If you encounter problems when using <code>duckdb</code> &gt;= 0.5.0 you may need to upgrade <code>duckdb-engine</code> to at least version 0.6.2.</p> <p>See this issue for more details.</p>"},{"location":"backends/DuckDB/#install","title":"Install","text":"<p>Install ibis and dependencies for the DuckDB backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[duckdb]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-duckdb\n</code></pre> <pre><code>mamba install -c conda-forge ibis-duckdb\n</code></pre>"},{"location":"backends/DuckDB/#connect","title":"Connect","text":""},{"location":"backends/DuckDB/#api","title":"API","text":"<p>Create a client by passing in a path to a DuckDB database to <code>ibis.duckdb.connect</code>.</p> <p>See <code>ibis.backends.duckdb.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.duckdb.connect</code> is a thin wrapper around <code>ibis.backends.duckdb.Backend.do_connect</code>.</p>"},{"location":"backends/DuckDB/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.do_connect","title":"<code>do_connect(database=':memory:', path=None, read_only=False, temp_directory=None, **config)</code>","text":"<p>Create an Ibis client connected to a DuckDB database.</p> <p>Parameters:</p> Name Type Description Default <code>database</code> <code>str | Path</code> <p>Path to a duckdb database.</p> <code>':memory:'</code> <code>path</code> <code>str | Path</code> <p>Deprecated, use <code>database</code> instead.</p> <code>None</code> <code>read_only</code> <code>bool</code> <p>Whether the database is read-only.</p> <code>False</code> <code>temp_directory</code> <code>Path | str | None</code> <p>Directory to use for spilling to disk. Only set by default for in-memory connections.</p> <code>None</code> <code>config</code> <code>Any</code> <p>DuckDB configuration parameters. See the DuckDB configuration documentation for possible configuration values.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.duckdb.connect(\"database.ddb\", threads=4, memory_limit=\"1GB\")\n&lt;ibis.backends.duckdb.Backend object at ...&gt;\n</code></pre>"},{"location":"backends/DuckDB/#backend-api","title":"Backend API","text":""},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseAlchemyBackend</code></p>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend-functions","title":"Functions","text":""},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.read_csv","title":"<code>read_csv(source_list, table_name=None, **kwargs)</code>","text":"<p>Register a CSV file as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>source_list</code> <code>str | list[str] | tuple[str]</code> <p>The data source(s). May be a path to a file or directory of CSV files, or an iterable of CSV files.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to DuckDB loading function. See https://duckdb.org/docs/data/csv for more information.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.read_in_memory","title":"<code>read_in_memory(dataframe, table_name=None)</code>","text":"<p>Register a Pandas DataFrame or pyarrow Table as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>pd.DataFrame | pa.Table</code> <p>The data source.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.read_json","title":"<code>read_json(source_list, table_name=None, **kwargs)</code>","text":"<p>Read newline-delimited JSON into an ibis table.</p> <p>This feature requires duckdb&gt;=0.7.0</p> <p>Parameters:</p> Name Type Description Default <code>source_list</code> <code>str | list[str] | tuple[str]</code> <p>File or list of files</p> required <code>table_name</code> <code>str | None</code> <p>Optional table name</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments passed to DuckDB's <code>read_json_auto</code> function</p> <code>{}</code> <p>Returns:</p> Type Description <code>Table</code> <p>An ibis table expression</p>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.read_parquet","title":"<code>read_parquet(source_list, table_name=None, **kwargs)</code>","text":"<p>Register a parquet file as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>source_list</code> <code>str | Iterable[str]</code> <p>The data source(s). May be a path to a file, an iterable of files, or directory of parquet files.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to DuckDB loading function. See https://duckdb.org/docs/data/parquet for more information.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.read_postgres","title":"<code>read_postgres(uri, table_name=None, schema='public')</code>","text":"<p>Register a table from a postgres instance into a DuckDB table.</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <p>The postgres URI in form 'postgres://user:password@host:port'</p> required <code>table_name</code> <code>str | None</code> <p>The table to read</p> <code>None</code> <code>schema</code> <code>str</code> <p>PostgreSQL schema where <code>table_name</code> resides</p> <code>'public'</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table.</p>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.read_sqlite","title":"<code>read_sqlite(path, table_name=None)</code>","text":"<p>Register a table from a SQLite database into a DuckDB table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The path to the SQLite database</p> required <code>table_name</code> <code>str | None</code> <p>The table to read</p> <code>None</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; con = ibis.connect(\"duckdb://\")\n&gt;&gt;&gt; t = con.read_sqlite(\"ci/ibis-testing-data/ibis_testing.db\", table_name=\"diamonds\")\n&gt;&gt;&gt; t.head().execute()\n        carat      cut color clarity  depth  table  price     x     y     z\n    0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n    1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n    2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n    3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n    4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n</code></pre>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.register","title":"<code>register(source, table_name=None, **kwargs)</code>","text":"<p>Register a data source as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | Path | Any</code> <p>The data source(s). May be a path to a file or directory of parquet/csv files, an iterable of parquet or CSV files, a pandas dataframe, a pyarrow table or dataset, or a postgres URI.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to the filename if a path (with hyphens replaced with underscores), or sequentially generated name otherwise.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to DuckDB loading functions for CSV or parquet.  See https://duckdb.org/docs/data/csv and https://duckdb.org/docs/data/parquet for more information.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.to_csv","title":"<code>to_csv(expr, path, *, params=None, header=True, **kwargs)</code>","text":"<p>Write the results of executing the given expression to a CSV file.</p> <p>This method is eager and will execute the associated expression immediately.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Table</code> <p>The ibis expression to execute and persist to CSV.</p> required <code>path</code> <code>str | Path</code> <p>The data source. A string or Path to the CSV file.</p> required <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Mapping of scalar parameter expressions to value.</p> <code>None</code> <code>header</code> <code>bool</code> <p>Whether to write the column names as the first line of the CSV file.</p> <code>True</code> <code>kwargs</code> <code>Any</code> <p>DuckDB CSV writer arguments. https://duckdb.org/docs/data/csv.html#parameters</p> <code>{}</code>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.to_parquet","title":"<code>to_parquet(expr, path, *, params=None, **kwargs)</code>","text":"<p>Write the results of executing the given expression to a parquet file.</p> <p>This method is eager and will execute the associated expression immediately.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Table</code> <p>The ibis expression to execute and persist to parquet.</p> required <code>path</code> <code>str | Path</code> <p>The data source. A string or Path to the parquet file.</p> required <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Mapping of scalar parameter expressions to value.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>DuckDB Parquet writer arguments. See https://duckdb.org/docs/data/parquet#writing-to-parquet-files for details</p> <code>{}</code> <p>Examples:</p> <p>Write out an expression to a single parquet file.</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; penguins = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; con = ibis.get_backend(penguins)\n&gt;&gt;&gt; con.to_parquet(penguins, \"penguins.parquet\")\n</code></pre> <p>Write out an expression to a hive-partitioned parquet file.</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; penguins = ibis.examples.penguins.fetch()\n&gt;&gt;&gt; con = ibis.get_backend(penguins)\n&gt;&gt;&gt; con.to_parquet(penguins, \"penguins_hive_dir\", partition_by=\"year\")\n&gt;&gt;&gt; # partition on multiple columns\n&gt;&gt;&gt; con.to_parquet(penguins, \"penguins_hive_dir\", partition_by=(\"year\", \"island\"))\n</code></pre>"},{"location":"backends/DuckDB/#ibis.backends.duckdb.Backend.to_pyarrow_batches","title":"<code>to_pyarrow_batches(expr, *, params=None, limit=None, chunk_size=1000000, **_)</code>","text":"<p>Return a stream of record batches.</p> <p>The returned <code>RecordBatchReader</code> contains a cursor with an unbounded lifetime.</p> <p>For analytics use cases this is usually nothing to fret about. In some cases you may need to explicit release the cursor.</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>ir.Expr</code> <p>Ibis expression</p> required <code>params</code> <code>Mapping[ir.Scalar, Any] | None</code> <p>Bound parameters</p> <code>None</code> <code>limit</code> <code>int | str | None</code> <p>Limit the result to this number of rows</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>DuckDB returns 1024 size batches regardless of what argument is passed.</p> <code>1000000</code>"},{"location":"backends/Impala/","title":"Impala","text":"<p>One goal of Ibis is to provide an integrated Python API for an Impala cluster without requiring you to switch back and forth between Python code and the Impala shell.</p>"},{"location":"backends/Impala/#install","title":"Install","text":"<p>Install ibis and dependencies for the Impala backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[impala]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-impala\n</code></pre> <pre><code>mamba install -c conda-forge ibis-impala\n</code></pre>"},{"location":"backends/Impala/#connect","title":"Connect","text":""},{"location":"backends/Impala/#api","title":"API","text":"<p>Create a client by passing in connection parameters to <code>ibis.impala.connect</code>.</p> <p>See <code>ibis.backends.impala.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.impala.connect</code> is a thin wrapper around <code>ibis.backends.impala.Backend.do_connect</code>.</p>"},{"location":"backends/Impala/#connection-parameters","title":"Connection Parameters","text":"<p>Both method calls can take <code>auth_mechanism='GSSAPI'</code> or <code>auth_mechanism='LDAP'</code> to connect to Kerberos clusters. Depending on your cluster setup, this may also include SSL. See the <code>API reference</code> for more, along with the Impala shell reference, as the connection semantics are identical.</p> <p>These methods are available on the Impala client object after connecting to your HDFS cluster (<code>ibis.impala.hdfs_connect</code>) and connecting to Impala with <code>ibis.impala.connect</code>. See <code>backends.impala</code> for a tutorial on using this backend.</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.do_connect","title":"<code>do_connect(host='localhost', port=21050, database='default', timeout=45, use_ssl=False, ca_cert=None, user=None, password=None, auth_mechanism='NOSASL', kerberos_service_name='impala', pool_size=8, hdfs_client=None)</code>","text":"<p>Create an Impala Backend for use with Ibis.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host name of the impalad or HiveServer2 in Hive</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Impala's HiveServer2 port</p> <code>21050</code> <code>database</code> <code>str</code> <p>Default database when obtaining new cursors</p> <code>'default'</code> <code>timeout</code> <code>int</code> <p>Connection timeout in seconds when communicating with HiveServer2</p> <code>45</code> <code>use_ssl</code> <code>bool</code> <p>Use SSL when connecting to HiveServer2</p> <code>False</code> <code>ca_cert</code> <code>str | Path | None</code> <p>Local path to 3rd party CA certificate or copy of server certificate for self-signed certificates. If SSL is enabled, but this argument is <code>None</code>, then certificate validation is skipped.</p> <code>None</code> <code>user</code> <code>str | None</code> <p>LDAP user to authenticate</p> <code>None</code> <code>password</code> <code>str | None</code> <p>LDAP password to authenticate</p> <code>None</code> <code>auth_mechanism</code> <code>Literal['NOSASL', 'PLAIN', 'GSSAPI', 'LDAP']</code> Value Meaning <code>'NOSASL'</code> insecure Impala connections <code>'PLAIN'</code> insecure Hive clusters <code>'LDAP'</code> LDAP authenticated connections <code>'GSSAPI'</code> Kerberos-secured clusters <code>'NOSASL'</code> <code>kerberos_service_name</code> <code>str</code> <p>Specify a particular <code>impalad</code> service principal.</p> <code>'impala'</code> <code>pool_size</code> <code>int</code> <p>Size of the connection pool. Typically this is not necessary to configure.</p> <code>8</code> <code>hdfs_client</code> <code>fsspec.spec.AbstractFileSystem | None</code> <p>An existing HDFS client.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; hdfs_host = os.environ.get('IBIS_TEST_NN_HOST', 'localhost')\n&gt;&gt;&gt; hdfs_port = int(os.environ.get('IBIS_TEST_NN_PORT', 50070))\n&gt;&gt;&gt; impala_host = os.environ.get('IBIS_TEST_IMPALA_HOST', 'localhost')\n&gt;&gt;&gt; impala_port = int(os.environ.get('IBIS_TEST_IMPALA_PORT', 21050))\n&gt;&gt;&gt; hdfs = ibis.impala.hdfs_connect(host=hdfs_host, port=hdfs_port)\n&gt;&gt;&gt; client = ibis.impala.connect(\n...     host=impala_host,\n...     port=impala_port,\n...     hdfs_client=hdfs,\n... )\n&gt;&gt;&gt; client\n&lt;ibis.backends.impala.Backend object at 0x...&gt;\n</code></pre>"},{"location":"backends/Impala/#database-methods","title":"Database methods","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.create_database","title":"<code>create_database(name, path=None, force=False)</code>","text":"<p>Create a new Impala database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Database name</p> required <code>path</code> <p>HDFS path where to store the database data; otherwise uses Impala default</p> <code>None</code> <code>force</code> <p>Forcibly create the database</p> <code>False</code>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.drop_database","title":"<code>drop_database(name, force=False)</code>","text":"<p>Drop an Impala database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Database name</p> required <code>force</code> <p>If False and there are any tables in this database, raises an IntegrityError</p> <code>False</code>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.list_databases","title":"<code>list_databases(like=None)</code>","text":""},{"location":"backends/Impala/#table-methods","title":"Table methods","text":"<p>The <code>Backend</code> object itself has many helper utility methods. You'll find the most methods on <code>ImpalaTable</code>.</p> <p>The best way to interact with a single table is through the <code>ImpalaTable</code> object you get back from <code>Backend.table</code>.</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.list_tables","title":"<code>list_tables(like=None, database=None)</code>","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.drop_table","title":"<code>drop_table(name, *, database=None, force=False)</code>","text":"<p>Drop an Impala table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <code>force</code> <code>bool</code> <p>Database may throw exception if table does not exist</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; table = 'my_table'\n&gt;&gt;&gt; db = 'operations'\n&gt;&gt;&gt; con.drop_table(table, database=db, force=True)\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.create_table","title":"<code>create_table(name, obj=None, *, schema=None, database=None, temp=None, overwrite=False, external=False, format='parquet', location=None, partition=None, like_parquet=None)</code>","text":"<p>Create a new table in Impala using an Ibis table expression.</p> <p>This is currently designed for tables whose data is stored in HDFS.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>obj</code> <code>ir.Table | None</code> <p>If passed, creates table from select statement results</p> <code>None</code> <code>schema</code> <p>Mutually exclusive with obj, creates an empty table with a particular schema</p> <code>None</code> <code>database</code> <p>Database name</p> <code>None</code> <code>temp</code> <code>bool | None</code> <p>Whether a table is temporary</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Do not create table if table with indicated name already exists</p> <code>False</code> <code>external</code> <code>bool</code> <p>Create an external table; Impala will not delete the underlying data when the table is dropped</p> <code>False</code> <code>format</code> <p>File format</p> <code>'parquet'</code> <code>location</code> <p>Specify the directory location where Impala reads and writes files for the table</p> <code>None</code> <code>partition</code> <p>Must pass a schema to use this. Cannot partition from an expression.</p> <code>None</code> <code>like_parquet</code> <p>Can specify instead of a schema</p> <code>None</code>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.insert","title":"<code>insert(table_name, obj=None, database=None, overwrite=False, partition=None, values=None, validate=True)</code>","text":"<p>Insert data into an existing table.</p> <p>See <code>ImpalaTable.insert</code> for parameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; table = 'my_table'\n&gt;&gt;&gt; con.insert(table, table_expr)\n</code></pre> <p>Completely overwrite contents</p> <pre><code>&gt;&gt;&gt; con.insert(table, table_expr, overwrite=True)\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.invalidate_metadata","title":"<code>invalidate_metadata(name=None, database=None)</code>","text":"<p>Issue an <code>INVALIDATE METADATA</code> command.</p> <p>Optionally this applies to a specific table. See Impala documentation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Table name. Can be fully qualified (with database)</p> <code>None</code> <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.truncate_table","title":"<code>truncate_table(name, database=None)</code>","text":"<p>Delete all rows from an existing table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.get_schema","title":"<code>get_schema(table_name, database=None)</code>","text":"<p>Return a Schema object for the indicated table and database.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <p>Returns:</p> Type Description <code>Schema</code> <p>Ibis schema</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.cache_table","title":"<code>cache_table(table_name, *, database=None, pool='default')</code>","text":"<p>Caches a table in cluster memory in the given pool.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <p>Table name</p> required <code>database</code> <p>Database name</p> <code>None</code> <code>pool</code> <p>The name of the pool in which to cache the table</p> <code>'default'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; table = 'my_table'\n&gt;&gt;&gt; db = 'operations'\n&gt;&gt;&gt; pool = 'op_4GB_pool'\n&gt;&gt;&gt; con.cache_table('my_table', database=db, pool=pool)\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.load_data","title":"<code>load_data(table_name, path, database=None, overwrite=False, partition=None)</code>","text":"<p>Loads data into an Impala table by physically moving data files.</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.get_options","title":"<code>get_options()</code>","text":"<p>Return current query options for the Impala session.</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.set_options","title":"<code>set_options(options)</code>","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.set_compression_codec","title":"<code>set_compression_codec(codec)</code>","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-attributes","title":"Attributes","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.describe_formatted","title":"<code>describe_formatted = metadata</code>  <code>class-attribute</code>","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.is_partitioned","title":"<code>is_partitioned</code>  <code>property</code>","text":"<p>True if the table is partitioned.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.add_partition","title":"<code>add_partition(spec, location=None)</code>","text":"<p>Add a new table partition.</p> <p>This API creates any necessary new directories in HDFS.</p> <p>Partition parameters can be set in a single DDL statement or you can use <code>alter_partition</code> to set them after the fact.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.alter","title":"<code>alter(location=None, format=None, tbl_properties=None, serde_properties=None)</code>","text":"<p>Change settings and parameters of the table.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <p>For partitioned tables, you may want the alter_partition function</p> <code>None</code> <code>format</code> <p>Table format</p> <code>None</code> <code>tbl_properties</code> <p>Table properties</p> <code>None</code> <code>serde_properties</code> <p>Serialization/deserialization properties</p> <code>None</code>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.alter_partition","title":"<code>alter_partition(spec, location=None, format=None, tbl_properties=None, serde_properties=None)</code>","text":"<p>Change settings and parameters of an existing partition.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <p>The partition keys for the partition being modified</p> required <code>location</code> <p>Location of the partition</p> <code>None</code> <code>format</code> <p>Table format</p> <code>None</code> <code>tbl_properties</code> <p>Table properties</p> <code>None</code> <code>serde_properties</code> <p>Serialization/deserialization properties</p> <code>None</code>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.column_stats","title":"<code>column_stats()</code>","text":"<p>Return results of <code>SHOW COLUMN STATS</code>.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Column statistics</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.compute_stats","title":"<code>compute_stats(incremental=False)</code>","text":"<p>Invoke Impala COMPUTE STATS command on the table.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.drop","title":"<code>drop()</code>","text":"<p>Drop the table from the database.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.drop_partition","title":"<code>drop_partition(spec)</code>","text":"<p>Drop an existing table partition.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.files","title":"<code>files()</code>","text":"<p>Return results of SHOW FILES statement.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.insert","title":"<code>insert(obj=None, overwrite=False, partition=None, values=None, validate=True)</code>","text":"<p>Insert into an Impala table.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>Table expression or DataFrame</p> <code>None</code> <code>overwrite</code> <p>If True, will replace existing contents of table</p> <code>False</code> <code>partition</code> <p>For partitioned tables, indicate the partition that's being inserted into, either with an ordered list of partition keys or a dict of partition field name to value. For example for the partition (year=2007, month=7), this can be either (2007, 7) or {'year': 2007, 'month': 7}.</p> <code>None</code> <code>values</code> <p>Unsupported and unused</p> <code>None</code> <code>validate</code> <p>If True, do more rigorous validation that schema of table being inserted is compatible with the existing table</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t.insert(table_expr)\n</code></pre> <p>Completely overwrite contents</p> <pre><code>&gt;&gt;&gt; t.insert(table_expr, overwrite=True)\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.invalidate_metadata","title":"<code>invalidate_metadata()</code>","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.load_data","title":"<code>load_data(path, overwrite=False, partition=None)</code>","text":"<p>Load data into an Impala table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>Data to load</p> required <code>overwrite</code> <p>Overwrite the existing data in the entire table or indicated partition</p> <code>False</code> <code>partition</code> <p>If specified, the partition must already exist</p> <code>None</code>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.metadata","title":"<code>metadata()</code>","text":"<p>Return results of <code>DESCRIBE FORMATTED</code> statement.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.partition_schema","title":"<code>partition_schema()</code>","text":"<p>Return the schema for the partition columns.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.partitions","title":"<code>partitions()</code>","text":"<p>Return information about the table's partitions.</p> <p>Raises an exception if the table is not partitioned.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.refresh","title":"<code>refresh()</code>","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.rename","title":"<code>rename(new_name, database=None)</code>","text":"<p>Rename table inside Impala.</p> <p>References to the old table are no longer valid.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.stats","title":"<code>stats()</code>","text":"<p>Return results of <code>SHOW TABLE STATS</code>.</p> <p>If not partitioned, contains only one row.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Table statistics</p>"},{"location":"backends/Impala/#creating-views","title":"Creating views","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.drop_table_or_view","title":"<code>drop_table_or_view(name, *, database=None, force=False)</code>","text":"<p>Drop view or table.</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.create_view","title":"<code>create_view(name, obj, *, database=None, overwrite=False)</code>","text":""},{"location":"backends/Impala/#accessing-data-formats-in-hdfs","title":"Accessing data formats in HDFS","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.delimited_file","title":"<code>delimited_file(hdfs_dir, schema, name=None, database=None, delimiter=',', na_rep=None, escapechar=None, lineterminator=None, external=True, persist=False)</code>","text":"<p>Interpret delimited text files as an Ibis table expression.</p> <p>See the <code>parquet_file</code> method for more details on what happens under the hood.</p> <p>Parameters:</p> Name Type Description Default <code>hdfs_dir</code> <p>HDFS directory containing delimited text files</p> required <code>schema</code> <p>Ibis schema</p> required <code>name</code> <p>Name for temporary or persistent table; otherwise random names are generated</p> <code>None</code> <code>database</code> <p>Database to create the table in</p> <code>None</code> <code>delimiter</code> <p>Character used to delimit columns</p> <code>','</code> <code>na_rep</code> <p>Character used to represent NULL values</p> <code>None</code> <code>escapechar</code> <p>Character used to escape special characters</p> <code>None</code> <code>lineterminator</code> <p>Character used to delimit lines</p> <code>None</code> <code>external</code> <p>Create table as EXTERNAL (data will not be deleted on drop). Not that if persist=False and external=False, whatever data you reference will be deleted</p> <code>True</code> <code>persist</code> <p>If True, do not delete the table upon garbage collection of ibis table object</p> <code>False</code> <p>Returns:</p> Type Description <code>ImpalaTable</code> <p>Impala table expression</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.parquet_file","title":"<code>parquet_file(hdfs_dir, schema=None, name=None, database=None, external=True, like_file=None, like_table=None, persist=False)</code>","text":"<p>Make indicated parquet file in HDFS available as an Ibis table.</p> <p>The table created can be optionally named and persisted, otherwise a unique name will be generated. Temporarily, for any non-persistent external table created by Ibis we will attempt to drop it when the underlying object is garbage collected (or the Python interpreter shuts down normally).</p> <p>Parameters:</p> Name Type Description Default <code>hdfs_dir</code> <p>Path in HDFS</p> required <code>schema</code> <p>If no schema provided, and neither of the like_* argument is passed, one will be inferred from one of the parquet files in the directory.</p> <code>None</code> <code>like_file</code> <p>Absolute path to Parquet file in HDFS to use for schema definitions. An alternative to having to supply an explicit schema</p> <code>None</code> <code>like_table</code> <p>Fully scoped and escaped string to an Impala table whose schema we will use for the newly created table.</p> <code>None</code> <code>name</code> <p>Random unique name generated otherwise</p> <code>None</code> <code>database</code> <p>Database to create the (possibly temporary) table in</p> <code>None</code> <code>external</code> <p>If a table is external, the referenced data will not be deleted when the table is dropped in Impala. Otherwise (external=False) Impala takes ownership of the Parquet file.</p> <code>True</code> <code>persist</code> <p>Do not drop the table during garbage collection</p> <code>False</code> <p>Returns:</p> Type Description <code>ImpalaTable</code> <p>Impala table expression</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.avro_file","title":"<code>avro_file(hdfs_dir, avro_schema, name=None, database=None, external=True, persist=False)</code>","text":"<p>Create a table to read a collection of Avro data.</p> <p>Parameters:</p> Name Type Description Default <code>hdfs_dir</code> <p>Absolute HDFS path to directory containing avro files</p> required <code>avro_schema</code> <p>The Avro schema for the data as a Python dict</p> required <code>name</code> <p>Table name</p> <code>None</code> <code>database</code> <p>Database name</p> <code>None</code> <code>external</code> <p>Whether the table is external</p> <code>True</code> <code>persist</code> <p>Persist the table</p> <code>False</code> <p>Returns:</p> Type Description <code>ImpalaTable</code> <p>Impala table expression</p>"},{"location":"backends/Impala/#hdfs-interaction","title":"HDFS Interaction","text":"<p>Ibis delegates all HDFS interaction to the <code>fsspec</code> library.</p>"},{"location":"backends/Impala/#the-impala-client-object","title":"The Impala client object","text":"<p>To use Ibis with Impala, you first must connect to a cluster using the <code>ibis.impala.connect</code> function, optionally supplying an HDFS connection:</p> <pre><code>import ibis\n\nhdfs = ibis.impala.hdfs_connect(host=webhdfs_host, port=webhdfs_port)\nclient = ibis.impala.connect(host=impala_host, port=impala_port, hdfs_client=hdfs)\n</code></pre> <p>All examples here use the following block of code to connect to impala using docker:</p> <pre><code>import ibis\n\nhdfs = ibis.impala.hdfs_connect(host=\"localhost\", port=50070)\nclient = ibis.impala.connect(host=host, hdfs_client=hdfs)\n</code></pre> <p>You can accomplish many tasks directly through the client object, but we additionally provide APIs to streamline tasks involving a single Impala table or database.</p>"},{"location":"backends/Impala/#table-objects","title":"Table objects","text":"<p>The client's <code>table</code> method allows you to create an Ibis table expression referencing a physical Impala table:</p> <pre><code>table = client.table('functional_alltypes', database='ibis_testing')\n</code></pre> <p><code>ImpalaTable</code> is a Python subclass of the more general Ibis <code>Table</code> that has additional Impala-specific methods. So you can use it interchangeably with any code expecting a <code>Table</code>.</p> <p>Like all table expressions in Ibis, <code>ImpalaTable</code> has a <code>schema</code> method you can use to examine its schema:</p> <p>While the client has a <code>drop_table</code> method you can use to drop tables, the table itself has a method <code>drop</code> that you can use:</p> <pre><code>table.drop()\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.base.sql.BaseSQLBackend.table","title":"<code>table(name, database=None)</code>","text":"<p>Construct a table expression.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#expression-execution","title":"Expression execution","text":"<p>Ibis expressions have an <code>execute</code> method with compiles and runs the expressions on Impala or whichever backend is being referenced.</p> <p>For example:</p> <pre><code>&gt;&gt;&gt; fa = db.functional_alltypes\n&gt;&gt;&gt; expr = fa.double_col.sum()\n&gt;&gt;&gt; expr.execute()\n331785.00000000006\n</code></pre> <p>For longer-running queries, Ibis will attempt to cancel the query in progress if an interrupt is received.</p>"},{"location":"backends/Impala/#creating-tables","title":"Creating tables","text":"<p>There are several ways to create new Impala tables:</p> <ul> <li>From an Ibis table expression</li> <li>Empty, from a declared schema</li> <li>Empty and partitioned</li> </ul> <p>In all cases, you should use the <code>create_table</code> method either on the top-level client connection or a database object.</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.create_table","title":"<code>create_table(name, obj=None, *, schema=None, database=None, temp=None, overwrite=False, external=False, format='parquet', location=None, partition=None, like_parquet=None)</code>","text":"<p>Create a new table in Impala using an Ibis table expression.</p> <p>This is currently designed for tables whose data is stored in HDFS.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>obj</code> <code>ir.Table | None</code> <p>If passed, creates table from select statement results</p> <code>None</code> <code>schema</code> <p>Mutually exclusive with obj, creates an empty table with a particular schema</p> <code>None</code> <code>database</code> <p>Database name</p> <code>None</code> <code>temp</code> <code>bool | None</code> <p>Whether a table is temporary</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Do not create table if table with indicated name already exists</p> <code>False</code> <code>external</code> <code>bool</code> <p>Create an external table; Impala will not delete the underlying data when the table is dropped</p> <code>False</code> <code>format</code> <p>File format</p> <code>'parquet'</code> <code>location</code> <p>Specify the directory location where Impala reads and writes files for the table</p> <code>None</code> <code>partition</code> <p>Must pass a schema to use this. Cannot partition from an expression.</p> <code>None</code> <code>like_parquet</code> <p>Can specify instead of a schema</p> <code>None</code>"},{"location":"backends/Impala/#creating-tables-from-a-table-expression","title":"Creating tables from a table expression","text":"<p>If you pass an Ibis expression to <code>create_table</code>, Ibis issues a <code>CREATE TABLE ... AS SELECT</code> (CTAS) statement:</p> <pre><code>&gt;&gt;&gt; table = db.table('functional_alltypes')\n&gt;&gt;&gt; expr = table.group_by('string_col').size()\n&gt;&gt;&gt; db.create_table('string_freqs', expr, format='parquet')\n\n&gt;&gt;&gt; freqs = db.table('string_freqs')\n&gt;&gt;&gt; freqs.execute()\n  string_col  count\n0          9    730\n1          3    730\n2          6    730\n3          4    730\n4          1    730\n5          8    730\n6          2    730\n7          7    730\n8          5    730\n9          0    730\n\n&gt;&gt;&gt; files = freqs.files()\n&gt;&gt;&gt; files\n                                                Path  Size Partition\n0  hdfs://impala:8020/user/hive/warehouse/ibis_te...  584B\n\n&gt;&gt;&gt; freqs.drop()\n</code></pre> <p>You can also choose to create an empty table and use <code>insert</code> (see below).</p>"},{"location":"backends/Impala/#creating-an-empty-table","title":"Creating an empty table","text":"<p>To create an empty table, you must declare an Ibis schema that will be translated to the appopriate Impala schema and data types.</p> <p>As Ibis types are simplified compared with Impala types, this may expand in the future to include a more fine-grained schema declaration.</p> <p>You can use the <code>create_table</code> method either on a database or client object.</p> <pre><code>schema = ibis.schema([('foo', 'string'),\n                      ('year', 'int32'),\n                      ('month', 'int16')])\nname = 'new_table'\ndb.create_table(name, schema=schema)\n</code></pre> <p>By default, this stores the data files in the database default location. You can force a particular path with the <code>location</code> option.</p> <pre><code>from getpass import getuser\nschema = ibis.schema([('foo', 'string'),\n                      ('year', 'int32'),\n                      ('month', 'int16')])\nname = 'new_table'\nlocation = '/home/{}/new-table-data'.format(getuser())\ndb.create_table(name, schema=schema, location=location)\n</code></pre> <p>If the schema matches a known table schema, you can always use the <code>schema</code> method to get a schema object:</p> <pre><code>&gt;&gt;&gt; t = db.table('functional_alltypes')\n&gt;&gt;&gt; t.schema()\nibis.Schema {\n  id               int32\n  bool_col         boolean\n  tinyint_col      int8\n  smallint_col     int16\n  int_col          int32\n  bigint_col       int64\n  float_col        float32\n  double_col       float64\n  date_string_col  string\n  string_col       string\n  timestamp_col    timestamp\n  year             int32\n  month            int32\n}\n</code></pre>"},{"location":"backends/Impala/#creating-a-partitioned-table","title":"Creating a partitioned table","text":"<p>To create an empty partitioned table, include a list of columns to be used as the partition keys.</p> <pre><code>schema = ibis.schema([('foo', 'string'),\n                      ('year', 'int32'),\n                      ('month', 'int16')])\nname = 'new_table'\ndb.create_table(name, schema=schema, partition=['year', 'month'])\n</code></pre>"},{"location":"backends/Impala/#partitioned-tables","title":"Partitioned tables","text":"<p>Ibis enables you to manage partitioned tables in various ways. Since each partition behaves as its own \\\"subtable\\\" sharing a common schema, each partition can have its own file format, directory path, serialization properties, and so forth.</p> <p>There are a handful of table methods for adding and removing partitions and getting information about the partition schema and any existing partition data:</p> <p>To address a specific partition in any method that is partition specific, you can either use a dict with the partition key names and values, or pass a list of the partition values:</p> <pre><code>schema = ibis.schema([('foo', 'string'),\n                      ('year', 'int32'),\n                      ('month', 'int16')])\nname = 'new_table'\ndb.create_table(name, schema=schema, partition=['year', 'month'])\n\ntable = db.table(name)\n\ntable.add_partition({'year': 2007, 'month', 4})\ntable.add_partition([2007, 5])\ntable.add_partition([2007, 6])\n\ntable.drop_partition([2007, 6])\n</code></pre> <p>We'll cover partition metadata management and data loading below.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-attributes","title":"Attributes","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.is_partitioned","title":"<code>is_partitioned</code>  <code>property</code>","text":"<p>True if the table is partitioned.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.add_partition","title":"<code>add_partition(spec, location=None)</code>","text":"<p>Add a new table partition.</p> <p>This API creates any necessary new directories in HDFS.</p> <p>Partition parameters can be set in a single DDL statement or you can use <code>alter_partition</code> to set them after the fact.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.drop_partition","title":"<code>drop_partition(spec)</code>","text":"<p>Drop an existing table partition.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.partition_schema","title":"<code>partition_schema()</code>","text":"<p>Return the schema for the partition columns.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.partitions","title":"<code>partitions()</code>","text":"<p>Return information about the table's partitions.</p> <p>Raises an exception if the table is not partitioned.</p>"},{"location":"backends/Impala/#inserting-data-into-tables","title":"Inserting data into tables","text":"<p>If the schemas are compatible, you can insert into a table directly from an Ibis table expression:</p> <pre><code>&gt;&gt;&gt; t = db.functional_alltypes\n&gt;&gt;&gt; db.create_table('insert_test', schema=t.schema())\n&gt;&gt;&gt; target = db.table('insert_test')\n\n&gt;&gt;&gt; target.insert(t[:3])\n&gt;&gt;&gt; target.insert(t[:3])\n&gt;&gt;&gt; target.insert(t[:3])\n\n&gt;&gt;&gt; target.execute()\n     id  bool_col  tinyint_col  ...           timestamp_col  year  month\n0  5770      True            0  ... 2010-08-01 00:00:00.000  2010      8\n1  5771     False            1  ... 2010-08-01 00:01:00.000  2010      8\n2  5772      True            2  ... 2010-08-01 00:02:00.100  2010      8\n3  5770      True            0  ... 2010-08-01 00:00:00.000  2010      8\n4  5771     False            1  ... 2010-08-01 00:01:00.000  2010      8\n5  5772      True            2  ... 2010-08-01 00:02:00.100  2010      8\n6  5770      True            0  ... 2010-08-01 00:00:00.000  2010      8\n7  5771     False            1  ... 2010-08-01 00:01:00.000  2010      8\n8  5772      True            2  ... 2010-08-01 00:02:00.100  2010      8\n\n[9 rows x 13 columns]\n\n&gt;&gt;&gt; target.drop()\n</code></pre> <p>If the table is partitioned, you must indicate the partition you are inserting into:</p> <pre><code>part = {'year': 2007, 'month': 4}\ntable.insert(expr, partition=part)\n</code></pre>"},{"location":"backends/Impala/#managing-table-metadata","title":"Managing table metadata","text":"<p>Ibis has functions that wrap many of the DDL commands for Impala table metadata.</p>"},{"location":"backends/Impala/#detailed-table-metadata-describe-formatted","title":"Detailed table metadata: <code>DESCRIBE FORMATTED</code>","text":"<p>To get a handy wrangled version of <code>DESCRIBE FORMATTED</code> use the <code>metadata</code> method.</p> <pre><code>&gt;&gt;&gt; t = client.table('ibis_testing.functional_alltypes')\n&gt;&gt;&gt; meta = t.metadata()\n&gt;&gt;&gt; meta\n&lt;class 'ibis.backends.impala.metadata.TableMetadata'&gt;\n{'info': {'CreateTime': datetime.datetime(2021, 1, 14, 21, 23, 8),\n          'Database': 'ibis_testing',\n          'LastAccessTime': 'UNKNOWN',\n          'Location': 'hdfs://impala:8020/__ibis/ibis-testing-data/parquet/functional_alltypes',\n          'Owner': 'root',\n          'Protect Mode': 'None',\n          'Retention': 0,\n          'Table Parameters': {'COLUMN_STATS_ACCURATE': False,\n                               'EXTERNAL': True,\n                               'STATS_GENERATED_VIA_STATS_TASK': True,\n                               'numFiles': 3,\n                               'numRows': 7300,\n                               'rawDataSize': '-1',\n                               'totalSize': 106278,\n                               'transient_lastDdlTime': datetime.datetime(2021, 1, 14, 21, 23, 17)},\n          'Table Type': 'EXTERNAL_TABLE'},\n 'schema': [('id', 'int'),\n            ('bool_col', 'boolean'),\n            ('tinyint_col', 'tinyint'),\n            ('smallint_col', 'smallint'),\n            ('int_col', 'int'),\n            ('bigint_col', 'bigint'),\n            ('float_col', 'float'),\n            ('double_col', 'double'),\n            ('date_string_col', 'string'),\n            ('string_col', 'string'),\n            ('timestamp_col', 'timestamp'),\n            ('year', 'int'),\n            ('month', 'int')],\n 'storage info': {'Bucket Columns': '[]',\n                  'Compressed': False,\n                  'InputFormat': 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat',\n                  'Num Buckets': 0,\n                  'OutputFormat': 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat',\n                  'SerDe Library': 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe',\n                  'Sort Columns': '[]'}}\n\n&gt;&gt;&gt; meta.location\n'hdfs://impala:8020/__ibis/ibis-testing-data/parquet/functional_alltypes'\n\n&gt;&gt;&gt; meta.create_time\ndatetime.datetime(2021, 1, 14, 21, 23, 8)\n</code></pre> <p>The <code>files</code> function is also available to see all of the physical HDFS data files backing a table:</p> <pre><code>&gt;&gt;&gt; ss = c.table('tpcds_parquet.store_sales')\n\n&gt;&gt;&gt; ss.files()[:5]\n                                                path      size  \\\n0  hdfs://localhost:20500/test-warehouse/tpcds.st...  160.61KB\n1  hdfs://localhost:20500/test-warehouse/tpcds.st...  123.88KB\n2  hdfs://localhost:20500/test-warehouse/tpcds.st...  139.28KB\n3  hdfs://localhost:20500/test-warehouse/tpcds.st...  139.60KB\n4  hdfs://localhost:20500/test-warehouse/tpcds.st...   62.84KB\n\n                 partition\n0  ss_sold_date_sk=2451803\n1  ss_sold_date_sk=2451819\n2  ss_sold_date_sk=2451772\n3  ss_sold_date_sk=2451789\n4  ss_sold_date_sk=2451741\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.metadata","title":"<code>metadata()</code>","text":"<p>Return results of <code>DESCRIBE FORMATTED</code> statement.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.files","title":"<code>files()</code>","text":"<p>Return results of SHOW FILES statement.</p>"},{"location":"backends/Impala/#modifying-table-metadata","title":"Modifying table metadata","text":"<p>For unpartitioned tables, you can use the <code>alter</code> method to change its location, file format, and other properties. For partitioned tables, to change partition-specific metadata use <code>alter_partition</code>.</p> <p>For example, if you wanted to \\\"point\\\" an existing table at a directory of CSV files, you could run the following command:</p> <pre><code>from getpass import getuser\n\ncsv_props = {\n    'serialization.format': ',',\n    'field.delim': ',',\n}\ndata_dir = '/home/{}/my-csv-files'.format(getuser())\n\ntable.alter(location=data_dir, format='text', serde_properties=csv_props)\n</code></pre> <p>If the table is partitioned, you can modify only the properties of a particular partition:</p> <pre><code>table.alter_partition(\n    {'year': 2007, 'month': 5},\n    location=data_dir,\n    format='text',\n    serde_properties=csv_props\n)\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.alter","title":"<code>alter(location=None, format=None, tbl_properties=None, serde_properties=None)</code>","text":"<p>Change settings and parameters of the table.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <p>For partitioned tables, you may want the alter_partition function</p> <code>None</code> <code>format</code> <p>Table format</p> <code>None</code> <code>tbl_properties</code> <p>Table properties</p> <code>None</code> <code>serde_properties</code> <p>Serialization/deserialization properties</p> <code>None</code>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.alter_partition","title":"<code>alter_partition(spec, location=None, format=None, tbl_properties=None, serde_properties=None)</code>","text":"<p>Change settings and parameters of an existing partition.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <p>The partition keys for the partition being modified</p> required <code>location</code> <p>Location of the partition</p> <code>None</code> <code>format</code> <p>Table format</p> <code>None</code> <code>tbl_properties</code> <p>Table properties</p> <code>None</code> <code>serde_properties</code> <p>Serialization/deserialization properties</p> <code>None</code>"},{"location":"backends/Impala/#table-statistics","title":"Table statistics","text":""},{"location":"backends/Impala/#computing-table-and-partition-statistics","title":"Computing table and partition statistics","text":"<p>Impala-backed physical tables have a method <code>compute_stats</code> that computes table, column, and partition-level statistics to assist with query planning and optimization. It is standard practice to invoke this after creating a table or loading new data:</p> <pre><code>table.compute_stats()\n</code></pre> <p>If you are using a recent version of Impala, you can also access the <code>COMPUTE INCREMENTAL STATS</code> DDL command:</p> <pre><code>table.compute_stats(incremental=True)\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.compute_stats","title":"<code>compute_stats(incremental=False)</code>","text":"<p>Invoke Impala COMPUTE STATS command on the table.</p>"},{"location":"backends/Impala/#seeing-table-and-column-statistics","title":"Seeing table and column statistics","text":"<p>The <code>compute_stats</code> and <code>stats</code> functions return the results of <code>SHOW COLUMN STATS</code> and <code>SHOW TABLE STATS</code>, respectively, and their output will depend, of course, on the last <code>COMPUTE STATS</code> call.</p> <pre><code>&gt;&gt;&gt; ss = c.table('tpcds_parquet.store_sales')\n&gt;&gt;&gt; ss.compute_stats(incremental=True)\n&gt;&gt;&gt; stats = ss.stats()\n&gt;&gt;&gt; stats[:5]\n  ss_sold_date_sk  #Rows  #Files     Size Bytes Cached Cache Replication  \\\n0         2450829   1071       1  78.34KB   NOT CACHED        NOT CACHED\n1         2450846    839       1  61.83KB   NOT CACHED        NOT CACHED\n2         2450860    747       1  54.86KB   NOT CACHED        NOT CACHED\n3         2450874    922       1  66.74KB   NOT CACHED        NOT CACHED\n4         2450888    856       1  63.33KB   NOT CACHED        NOT CACHED\n\n    Format Incremental stats  \\\n0  PARQUET              true\n1  PARQUET              true\n2  PARQUET              true\n3  PARQUET              true\n4  PARQUET              true\n\n                                            Location\n0  hdfs://localhost:20500/test-warehouse/tpcds.st...\n1  hdfs://localhost:20500/test-warehouse/tpcds.st...\n2  hdfs://localhost:20500/test-warehouse/tpcds.st...\n3  hdfs://localhost:20500/test-warehouse/tpcds.st...\n4  hdfs://localhost:20500/test-warehouse/tpcds.st...\n\n&gt;&gt;&gt; cstats = ss.column_stats()\n&gt;&gt;&gt; cstats\n                   Column          Type  #Distinct Values  #Nulls  Max Size  Avg Size\n0         ss_sold_time_sk        BIGINT             13879      -1       NaN         8\n1              ss_item_sk        BIGINT             17925      -1       NaN         8\n2          ss_customer_sk        BIGINT             15207      -1       NaN         8\n3             ss_cdemo_sk        BIGINT             16968      -1       NaN         8\n4             ss_hdemo_sk        BIGINT              6220      -1       NaN         8\n5              ss_addr_sk        BIGINT             14077      -1       NaN         8\n6             ss_store_sk        BIGINT                 6      -1       NaN         8\n7             ss_promo_sk        BIGINT               298      -1       NaN         8\n8        ss_ticket_number           INT             15006      -1       NaN         4\n9             ss_quantity           INT                99      -1       NaN         4\n10      ss_wholesale_cost  DECIMAL(7,2)             10196      -1       NaN         4\n11          ss_list_price  DECIMAL(7,2)             19393      -1       NaN         4\n12         ss_sales_price  DECIMAL(7,2)             15594      -1       NaN         4\n13    ss_ext_discount_amt  DECIMAL(7,2)             29772      -1       NaN         4\n14     ss_ext_sales_price  DECIMAL(7,2)            102758      -1       NaN         4\n15  ss_ext_wholesale_cost  DECIMAL(7,2)            125448      -1       NaN         4\n16      ss_ext_list_price  DECIMAL(7,2)            141419      -1       NaN         4\n17             ss_ext_tax  DECIMAL(7,2)             33837      -1       NaN         4\n18          ss_coupon_amt  DECIMAL(7,2)             29772      -1       NaN         4\n19            ss_net_paid  DECIMAL(7,2)            109981      -1       NaN         4\n20    ss_net_paid_inc_tax  DECIMAL(7,2)            132286      -1       NaN         4\n21          ss_net_profit  DECIMAL(7,2)            122436      -1       NaN         4\n22        ss_sold_date_sk        BIGINT               120       0       NaN         8\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.column_stats","title":"<code>column_stats()</code>","text":"<p>Return results of <code>SHOW COLUMN STATS</code>.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Column statistics</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.stats","title":"<code>stats()</code>","text":"<p>Return results of <code>SHOW TABLE STATS</code>.</p> <p>If not partitioned, contains only one row.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Table statistics</p>"},{"location":"backends/Impala/#refresh-and-invalidate-metadata","title":"<code>REFRESH</code> and <code>INVALIDATE METADATA</code>","text":"<p>These DDL commands are available as table-level and client-level methods:</p> <p>You can invalidate the cached metadata for a single table or for all tables using <code>invalidate_metadata</code>, and similarly invoke <code>REFRESH db_name.table_name</code> using the <code>refresh</code> method.</p> <pre><code>client.invalidate_metadata()\n\ntable = db.table(table_name)\ntable.invalidate_metadata()\n\ntable.refresh()\n</code></pre> <p>These methods are often used in conjunction with the <code>LOAD DATA</code> commands and <code>COMPUTE STATS</code>. See the Impala documentation for full details.</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.invalidate_metadata","title":"<code>invalidate_metadata(name=None, database=None)</code>","text":"<p>Issue an <code>INVALIDATE METADATA</code> command.</p> <p>Optionally this applies to a specific table. See Impala documentation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Table name. Can be fully qualified (with database)</p> <code>None</code> <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.invalidate_metadata","title":"<code>invalidate_metadata()</code>","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.refresh","title":"<code>refresh()</code>","text":""},{"location":"backends/Impala/#issuing-load-data-commands","title":"Issuing <code>LOAD DATA</code> commands","text":"<p>The <code>LOAD DATA</code> DDL physically moves a single data file or a directory of files into the correct location for a table or table partition. It is especially useful for partitioned tables as you do not have to construct the directory path for a partition by hand, so simpler and less error-prone than manually moving files with low level HDFS commands. It also deals with file name conflicts so data is not lost in such cases.</p> <p>To use these methods, pass the path of a single file or a directory of files you want to load. Afterward, you may want to update the table statistics (see Impala documentation):</p> <pre><code>table.load_data(path)\ntable.refresh()\n</code></pre> <p>Like the other methods with support for partitioned tables, you can load into a particular partition with the <code>partition</code> keyword argument:</p> <pre><code>part = [2007, 5]\ntable.load_data(path, partition=part)\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.load_data","title":"<code>load_data(table_name, path, database=None, overwrite=False, partition=None)</code>","text":"<p>Loads data into an Impala table by physically moving data files.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable","title":"<code>ImpalaTable</code>","text":"<p>         Bases: <code>ir.Table</code></p> <p>A physical table in the Impala-Hive metastore.</p>"},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.client.ImpalaTable.load_data","title":"<code>load_data(path, overwrite=False, partition=None)</code>","text":"<p>Load data into an Impala table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>Data to load</p> required <code>overwrite</code> <p>Overwrite the existing data in the entire table or indicated partition</p> <code>False</code> <code>partition</code> <p>If specified, the partition must already exist</p> <code>None</code>"},{"location":"backends/Impala/#parquet-and-other-session-options","title":"Parquet and other session options","text":"<p>Ibis gives you access to Impala session-level variables that affect query execution:</p> <p>For example:</p> <pre><code>&gt;&gt;&gt; client.get_options()\n{'ABORT_ON_ERROR': '0',\n 'APPX_COUNT_DISTINCT': '0',\n 'BUFFER_POOL_LIMIT': '',\n 'COMPRESSION_CODEC': '',\n 'COMPUTE_STATS_MIN_SAMPLE_SIZE': '1073741824',\n 'DEFAULT_JOIN_DISTRIBUTION_MODE': '0',\n 'DEFAULT_SPILLABLE_BUFFER_SIZE': '2097152',\n 'DISABLE_CODEGEN': '0',\n 'DISABLE_CODEGEN_ROWS_THRESHOLD': '50000',\n 'DISABLE_ROW_RUNTIME_FILTERING': '0',\n 'DISABLE_STREAMING_PREAGGREGATIONS': '0',\n 'DISABLE_UNSAFE_SPILLS': '0',\n 'ENABLE_EXPR_REWRITES': '1',\n 'EXEC_SINGLE_NODE_ROWS_THRESHOLD': '100',\n 'EXEC_TIME_LIMIT_S': '0',\n 'EXPLAIN_LEVEL': '1',\n 'HBASE_CACHE_BLOCKS': '0',\n 'HBASE_CACHING': '0',\n 'IDLE_SESSION_TIMEOUT': '0',\n 'MAX_ERRORS': '100',\n 'MAX_NUM_RUNTIME_FILTERS': '10',\n 'MAX_ROW_SIZE': '524288',\n 'MEM_LIMIT': '0',\n 'MIN_SPILLABLE_BUFFER_SIZE': '65536',\n 'MT_DOP': '',\n 'NUM_SCANNER_THREADS': '0',\n 'OPTIMIZE_PARTITION_KEY_SCANS': '0',\n 'PARQUET_ANNOTATE_STRINGS_UTF8': '0',\n 'PARQUET_ARRAY_RESOLUTION': '2',\n 'PARQUET_DICTIONARY_FILTERING': '1',\n 'PARQUET_FALLBACK_SCHEMA_RESOLUTION': '0',\n 'PARQUET_FILE_SIZE': '0',\n 'PARQUET_READ_STATISTICS': '1',\n 'PREFETCH_MODE': '1',\n 'QUERY_TIMEOUT_S': '0',\n 'REPLICA_PREFERENCE': '0',\n 'REQUEST_POOL': '',\n 'RUNTIME_BLOOM_FILTER_SIZE': '1048576',\n 'RUNTIME_FILTER_MAX_SIZE': '16777216',\n 'RUNTIME_FILTER_MIN_SIZE': '1048576',\n 'RUNTIME_FILTER_MODE': '2',\n 'RUNTIME_FILTER_WAIT_TIME_MS': '0',\n 'S3_SKIP_INSERT_STAGING': '1',\n 'SCHEDULE_RANDOM_REPLICA': '0',\n 'SCRATCH_LIMIT': '-1',\n 'SEQ_COMPRESSION_MODE': '',\n 'SYNC_DDL': '0'}\n</code></pre> <p>To enable Snappy compression for Parquet files, you could do either of:</p> <pre><code>&gt;&gt;&gt; client.set_options({'COMPRESSION_CODEC': 'snappy'})\n&gt;&gt;&gt; client.set_compression_codec('snappy')\n\n&gt;&gt;&gt; client.get_options()['COMPRESSION_CODEC']\n'SNAPPY'\n</code></pre>"},{"location":"backends/Impala/#ibis.backends.impala.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend-functions","title":"Functions","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.disable_codegen","title":"<code>disable_codegen(disabled=True)</code>","text":"<p>Turn off or on LLVM codegen in Impala query execution.</p> <p>Parameters:</p> Name Type Description Default <code>disabled</code> <p>To disable codegen, pass with no argument or True. To enable codegen, pass False.</p> <code>True</code>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.get_options","title":"<code>get_options()</code>","text":"<p>Return current query options for the Impala session.</p>"},{"location":"backends/Impala/#ibis.backends.impala.Backend.set_options","title":"<code>set_options(options)</code>","text":""},{"location":"backends/Impala/#ibis.backends.impala.Backend.set_compression_codec","title":"<code>set_compression_codec(codec)</code>","text":""},{"location":"backends/Impala/#ingesting-data-from-pandas","title":"Ingesting data from pandas","text":"<p>Overall interoperability between the Hadoop / Spark ecosystems and pandas / the PyData stack is poor, but it will improve in time (this is a major part of the Ibis roadmap).</p> <p>Ibis's Impala tools currently interoperate with pandas in these ways:</p> <ul> <li>Ibis expressions return pandas objects (i.e. DataFrame or Series)   for non-scalar expressions when calling their <code>execute</code> method</li> <li>The <code>create_table</code> and <code>insert</code> methods can accept pandas objects.   This includes inserting into partitioned tables. It currently uses   CSV as the ingest route.</li> </ul> <p>For example:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n\n&gt;&gt;&gt; data = pd.DataFrame({'foo': [1, 2, 3, 4], 'bar': ['a', 'b', 'c', 'd']})\n\n&gt;&gt;&gt; db.create_table('pandas_table', data)\n&gt;&gt;&gt; t = db.pandas_table\n&gt;&gt;&gt; t.execute()\n  bar  foo\n0   a    1\n1   b    2\n2   c    3\n3   d    4\n\n&gt;&gt;&gt; t.drop()\n\n&gt;&gt;&gt; db.create_table('empty_for_insert', schema=t.schema())\n\n&gt;&gt;&gt; to_insert = db.empty_for_insert\n&gt;&gt;&gt; to_insert.insert(data)\n&gt;&gt;&gt; to_insert.execute()\n  bar  foo\n0   a    1\n1   b    2\n2   c    3\n3   d    4\n\n&gt;&gt;&gt; to_insert.drop()\n</code></pre> <pre><code>&gt;&gt;&gt; import pandas as pd\n\n&gt;&gt;&gt; data = pd.DataFrame({'foo': [1, 2, 3, 4], 'bar': ['a', 'b', 'c', 'd']})\n\n&gt;&gt;&gt; db.create_table('pandas_table', data)\n&gt;&gt;&gt; t = db.pandas_table\n&gt;&gt;&gt; t.execute()\n   foo bar\n0    1   a\n1    2   b\n2    3   c\n3    4   d\n\n&gt;&gt;&gt; t.drop()\n&gt;&gt;&gt; db.create_table('empty_for_insert', schema=t.schema())\n&gt;&gt;&gt; to_insert = db.empty_for_insert\n&gt;&gt;&gt; to_insert.insert(data)\n&gt;&gt;&gt; to_insert.execute()\n   foo bar\n0    1   a\n1    2   b\n2    3   c\n3    4   d\n\n&gt;&gt;&gt; to_insert.drop()\n</code></pre>"},{"location":"backends/Impala/#uploading-downloading-data-from-hdfs","title":"Uploading / downloading data from HDFS","text":"<p>If you've set up an HDFS connection, you can use the Ibis HDFS interface to look through your data and read and write files to and from HDFS:</p> <pre><code>&gt;&gt;&gt; hdfs = con.hdfs\n&gt;&gt;&gt; hdfs.ls('/__ibis/ibis-testing-data')\n['README.md',\n 'avro',\n 'awards_players.csv',\n 'batting.csv',\n 'csv',\n 'diamonds.csv',\n 'functional_alltypes.csv',\n 'functional_alltypes.parquet',\n 'geo.csv',\n 'ibis_testing.db',\n 'parquet',\n 'struct_table.avro',\n 'udf']\n</code></pre> <pre><code>&gt;&gt;&gt; hdfs.ls('/__ibis/ibis-testing-data/parquet')\n['functional_alltypes',\n 'tpch_customer',\n 'tpch_lineitem',\n 'tpch_nation',\n 'tpch_orders',\n 'tpch_part',\n 'tpch_partsupp',\n 'tpch_region',\n 'tpch_supplier']\n</code></pre> <p>Suppose we wanted to download <code>/__ibis/ibis-testing-data/parquet/functional_alltypes</code>, which is a directory. We need only do:</p> <pre><code>$ rm -rf parquet_dir/\n</code></pre> <pre><code>&gt;&gt;&gt; hdfs.get('/__ibis/ibis-testing-data/parquet/functional_alltypes',\n...          'parquet_dir',\n...           recursive=True)\n'/ibis/docs/source/tutorial/parquet_dir'\n</code></pre> <p>Now we have that directory locally:</p> <pre><code>$ ls parquet_dir/\n9a41de519352ab07-4e76bc4d9fb5a789_1624886651_data.0.parq\n9a41de519352ab07-4e76bc4d9fb5a78a_778826485_data.0.parq\n9a41de519352ab07-4e76bc4d9fb5a78b_1277612014_data.0.parq\n</code></pre> <p>Files and directories can be written to HDFS just as easily using <code>put</code>:</p> <pre><code>&gt;&gt;&gt; path = '/__ibis/dir-write-example'\n&gt;&gt;&gt; hdfs.rm(path, recursive=True)\n&gt;&gt;&gt; hdfs.put(path, 'parquet_dir', recursive=True)\n</code></pre> <pre><code>&gt;&gt;&gt; hdfs.ls('/__ibis/dir-write-example')\n['9a41de519352ab07-4e76bc4d9fb5a789_1624886651_data.0.parq',\n '9a41de519352ab07-4e76bc4d9fb5a78a_778826485_data.0.parq',\n '9a41de519352ab07-4e76bc4d9fb5a78b_1277612014_data.0.parq']\n</code></pre> <p>Delete files and directories with <code>rm</code>:</p> <pre><code>&gt;&gt;&gt; hdfs.rm('/__ibis/dir-write-example', recursive=True)\n</code></pre> <pre><code>rm -rf parquet_dir/\n</code></pre>"},{"location":"backends/Impala/#queries-on-parquet-avro-and-delimited-files-in-hdfs","title":"Queries on Parquet, Avro, and Delimited files in HDFS","text":"<p>Ibis can easily create temporary or persistent Impala tables that reference data in the following formats:</p> <ul> <li>Parquet (<code>parquet_file</code>)</li> <li>Avro (<code>avro_file</code>)</li> <li>Delimited text formats (CSV, TSV, etc.) (<code>delimited_file</code>)</li> </ul> <p>Parquet is the easiest because the schema can be read from the data files:</p> <pre><code>&gt;&gt;&gt; path = '/__ibis/ibis-testing-data/parquet/tpch_lineitem'\n&gt;&gt;&gt; lineitem = con.parquet_file(path)\n&gt;&gt;&gt; lineitem.limit(2)\n   l_orderkey  l_partkey  l_suppkey  l_linenumber l_quantity l_extendedprice  \\\n0           1     155190       7706             1      17.00        21168.23\n1           1      67310       7311             2      36.00        45983.16\n\n  l_discount l_tax l_returnflag l_linestatus  l_shipdate l_commitdate  \\\n0       0.04  0.02            N            O  1996-03-13   1996-02-12\n1       0.09  0.06            N            O  1996-04-12   1996-02-28\n\n  l_receiptdate     l_shipinstruct l_shipmode  \\\n0    1996-03-22  DELIVER IN PERSON      TRUCK\n1    1996-04-20   TAKE BACK RETURN       MAIL\n\n                            l_comment\n0             egular courts above the\n1  ly final dependencies: slyly bold\n</code></pre> <pre><code>&gt;&gt;&gt; lineitem.l_extendedprice.sum()\nDecimal('229577310901.20')\n</code></pre> <p>If you want to query a Parquet file and also create a table in Impala that remains after your session, you can pass more information to <code>parquet_file</code>:</p> <pre><code>&gt;&gt;&gt; table = con.parquet_file(path, name='my_parquet_table',\n...                          database='ibis_testing',\n...                          persist=True)\n&gt;&gt;&gt; table.l_extendedprice.sum()\nDecimal('229577310901.20')\n</code></pre> <pre><code>&gt;&gt;&gt; con.table('my_parquet_table').l_extendedprice.sum()\nDecimal('229577310901.20')\n</code></pre> <pre><code>&gt;&gt;&gt; con.drop_table('my_parquet_table')\n</code></pre> <p>To query delimited files, you need to write down an Ibis schema. At some point we'd like to build some helper tools that will infer the schema for you, all in good time.</p> <p>There's some CSV files in the test folder, so let's use those:</p> <pre><code>&gt;&gt;&gt; hdfs.get('/__ibis/ibis-testing-data/csv', 'csv-files', recursive=True)\n'/ibis/docs/source/tutorial/csv-files'\n</code></pre> <pre><code>$ cat csv-files/0.csv\n63IEbRheTh,0.679388707915,6\nmG4hlqnjeG,2.80710565922,15\nJTPdX9SZH5,-0.155126406372,55\n2jcl6FypOl,1.03787834032,21\nk3TbJLaadQ,-1.40190801103,23\nrP5J4xvinM,-0.442092712869,22\nWniUylixYt,-0.863748033806,27\nznsDuKOB1n,-0.566029637098,47\n4SRP9jlo1M,0.331460412318,88\nKsfjPyDf5e,-0.578930506363,70\n</code></pre> <pre><code>$ rm -rf csv-files/\n</code></pre> <p>The schema here is pretty simple (see <code>ibis.schema</code> for more):</p> <pre><code>&gt;&gt;&gt; schema = ibis.schema([('foo', 'string'),\n...                       ('bar', 'double'),\n...                       ('baz', 'int32')])\n\n&gt;&gt;&gt; table = con.delimited_file('/__ibis/ibis-testing-data/csv',\n...                            schema)\n&gt;&gt;&gt; table.limit(10)\n          foo       bar  baz\n0  63IEbRheTh  0.679389    6\n1  mG4hlqnjeG  2.807106   15\n2  JTPdX9SZH5 -0.155126   55\n3  2jcl6FypOl  1.037878   21\n4  k3TbJLaadQ -1.401908   23\n5  rP5J4xvinM -0.442093   22\n6  WniUylixYt -0.863748   27\n7  znsDuKOB1n -0.566030   47\n8  4SRP9jlo1M  0.331460   88\n9  KsfjPyDf5e -0.578931   70\n</code></pre> <pre><code>&gt;&gt;&gt; table.bar.summary()\n   count  nulls       min       max       sum    mean  approx_nunique\n0    100      0 -1.401908  2.807106  8.479978  0.0848              10\n</code></pre> <p>For functions like <code>parquet_file</code> and <code>delimited_file</code>, an HDFS directory must be passed (we'll add support for S3 and other filesystems later) and the directory must contain files all having the same schema.</p> <p>If you have Avro data, you can query it too if you have the full avro schema:</p> <pre><code>&gt;&gt;&gt; avro_schema = {\n...     \"fields\": [\n...         {\"type\": [\"int\", \"null\"], \"name\": \"R_REGIONKEY\"},\n...         {\"type\": [\"string\", \"null\"], \"name\": \"R_NAME\"},\n...         {\"type\": [\"string\", \"null\"], \"name\": \"R_COMMENT\"}],\n...     \"type\": \"record\",\n...     \"name\": \"a\"\n... }\n\n&gt;&gt;&gt; path = '/__ibis/ibis-testing-data/avro/tpch.region'\n\n&gt;&gt;&gt; hdfs.mkdir(path, create_parents=True)\n&gt;&gt;&gt; table = con.avro_file(path, avro_schema)\n&gt;&gt;&gt; table\nEmpty DataFrame\nColumns: [r_regionkey, r_name, r_comment]\nIndex: []\n</code></pre>"},{"location":"backends/Impala/#other-helper-functions-for-interacting-with-the-database","title":"Other helper functions for interacting with the database","text":"<p>We're adding a growing list of useful utility functions for interacting with an Impala cluster on the client object. The idea is that you should be able to do any database-admin-type work with Ibis and not have to switch over to the Impala SQL shell. Any ways we can make this more pleasant, please let us know.</p> <p>Here's some of the features, which we'll give examples for:</p> <ul> <li>Listing and searching for available databases and tables</li> <li>Creating and dropping databases</li> <li>Getting table schemas</li> </ul> <pre><code>&gt;&gt;&gt; con.list_databases(like='ibis*')\n['ibis_testing', 'ibis_testing_tmp_db']\n</code></pre> <pre><code>&gt;&gt;&gt; con.list_tables(database='ibis_testing', like='tpch*')\n['tpch_customer',\n 'tpch_lineitem',\n 'tpch_nation',\n 'tpch_orders',\n 'tpch_part',\n 'tpch_partsupp',\n 'tpch_region',\n 'tpch_region_avro',\n 'tpch_supplier']\n</code></pre> <pre><code>&gt;&gt;&gt; schema = con.get_schema('functional_alltypes')\n&gt;&gt;&gt; schema\nibis.Schema {\n  id               int32\n  bool_col         boolean\n  tinyint_col      int8\n  smallint_col     int16\n  int_col          int32\n  bigint_col       int64\n  float_col        float32\n  double_col       float64\n  date_string_col  string\n  string_col       string\n  timestamp_col    timestamp\n  year             int32\n  month            int32\n}\n</code></pre> <p>Databases can be created, too, and you can set the storage path in HDFS you want for the data files</p> <pre><code>&gt;&gt;&gt; db = 'ibis_testing2'\n&gt;&gt;&gt; con.create_database(db, path='/__ibis/my-test-database', force=True)\n\n&gt;&gt;&gt; # you may or may not have to give the impala user write and execute permissions to '/__ibis/my-test-database'\n&gt;&gt;&gt; hdfs.chmod('/__ibis/my-test-database', 0o777)\n</code></pre> <pre><code>&gt;&gt;&gt; con.create_table('example_table', con.table('functional_alltypes'),\n...                  database=db, force=True)\n</code></pre> <p>Hopefully, there will be data files in the indicated spot in HDFS:</p> <pre><code>&gt;&gt;&gt; hdfs.ls('/__ibis/my-test-database')\n['example_table']\n</code></pre> <p>To drop a database, including all tables in it, you can use <code>drop_database</code> with <code>force=True</code>:</p> <pre><code>&gt;&gt;&gt; con.drop_database(db, force=True)\n</code></pre>"},{"location":"backends/Impala/#faster-queries-on-small-data-in-impala","title":"Faster queries on small data in Impala","text":"<p>Since Impala internally uses LLVM to compile parts of queries (aka \"codegen\") to make them faster on large data sets there is a certain amount of overhead with running many kinds of queries, even on small datasets. You can disable LLVM code generation when using Ibis, which may significantly speed up queries on smaller datasets:</p> <pre><code>&gt;&gt;&gt; from numpy.random import rand\n&gt;&gt;&gt; con.disable_codegen()\n&gt;&gt;&gt; t = con.table('ibis_testing.functional_alltypes')\n</code></pre> <pre><code>$ time python -c \"(t.double_col + rand()).sum().execute()\"\n27.7 ms \u00b1 996 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n</code></pre> <pre><code># Turn codegen back on\ncon.disable_codegen(False)\n</code></pre> <pre><code>$ time python -c \"(t.double_col + rand()).sum().execute()\"\n27 ms \u00b1 1.62 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n</code></pre> <p>It's important to remember that codegen is a fixed overhead and will significantly speed up queries on big data</p>"},{"location":"backends/Impala/#user-defined-functions-udf","title":"User Defined functions (UDF)","text":"<p>Impala currently supports user-defined scalar functions (known henceforth as UDFs) and aggregate functions (respectively UDAs) via a C++ extension API.</p> <p>Initial support for using C++ UDFs in Ibis came in version 0.4.0.</p>"},{"location":"backends/Impala/#using-scalar-functions-udfs","title":"Using scalar functions (UDFs)","text":"<p>Let's take an example to illustrate how to make a C++ UDF available to Ibis. Here is a function that computes an approximate equality between floating point values:</p> <pre><code>#include \"impala_udf/udf.h\"\n\n#include &lt;cctype&gt;\n#include &lt;cmath&gt;\n\nBooleanVal FuzzyEquals(FunctionContext* ctx, const DoubleVal&amp; x, const DoubleVal&amp; y) {\nconst double EPSILON = 0.000001f;\nif (x.is_null || y.is_null) return BooleanVal::null();\ndouble delta = fabs(x.val - y.val);\nreturn BooleanVal(delta &lt; EPSILON);\n}\n</code></pre> <p>You can compile this to either a shared library (a <code>.so</code> file) or to LLVM bitcode with clang (a <code>.ll</code> file). Skipping that step for now (will add some more detailed instructions here later, promise).</p> <p>To make this function callable, we use <code>ibis.impala.wrap_udf</code>:</p> <pre><code>library = '/ibis/udfs/udftest.ll'\ninputs = ['double', 'double']\noutput = 'boolean'\nsymbol = 'FuzzyEquals'\nudf_db = 'ibis_testing'\nudf_name = 'fuzzy_equals'\n\nfuzzy_equals = ibis.impala.wrap_udf(\n    library, inputs, output, symbol, name=udf_name\n)\n</code></pre> <p>In typical workflows, you will set up a UDF in Impala once then use it thenceforth. So the first time you do this, you need to create the UDF in Impala:</p> <pre><code>client.create_function(fuzzy_equals, database=udf_db)\n</code></pre> <p>Now, we must register this function as a new Impala operation in Ibis. This must take place each time you load your Ibis session.</p> <pre><code>func.register(fuzzy_equals.name, udf_db)\n</code></pre> <p>The object <code>fuzzy_equals</code> is callable and works with Ibis expressions:</p> <pre><code>&gt;&gt;&gt; db = c.database('ibis_testing')\n\n&gt;&gt;&gt; t = db.functional_alltypes\n\n&gt;&gt;&gt; expr = fuzzy_equals(t.float_col, t.double_col / 10)\n\n&gt;&gt;&gt; expr.execute()[:10]\n0     True\n1    False\n2    False\n3    False\n4    False\n5    False\n6    False\n7    False\n8    False\n9    False\nName: tmp, dtype: bool\n</code></pre> <p>Note that the call to <code>register</code> on the UDF object must happen each time you use Ibis. If you have a lot of UDFs, I suggest you create a file with all of your wrapper declarations and user APIs that you load with your Ibis session to plug in all your own functions.</p>"},{"location":"backends/Impala/#working-with-secure-clusters-kerberos","title":"Working with secure clusters (Kerberos)","text":"<p>Ibis is compatible with Hadoop clusters that are secured with Kerberos (as well as SSL and LDAP). Note that to enable this support, you'll also need to install the <code>kerberos</code> package.</p> <pre><code>$ pip install kerberos\n</code></pre> <p>Just like the Impala shell and ODBC/JDBC connectors, Ibis connects to Impala through the HiveServer2 interface (using the impyla client). Therefore, the connection semantics are similar to the other access methods for working with secure clusters.</p> <p>Specifically, after authenticating yourself against Kerberos (e.g., by issuing the appropriate <code>kinit</code> commmand), simply pass <code>auth_mechanism='GSSAPI'</code> or <code>auth_mechanism='LDAP'</code> (and set <code>kerberos_service_name</code> if necessary along with <code>user</code> and <code>password</code> if necessary) to the <code>ibis.impala_connect(...)</code> method when instantiating an <code>ImpalaConnection</code>. This method also takes arguments to configure SSL (<code>use_ssl</code>, <code>ca_cert</code>). See the documentation for the Impala shell for more details.</p> <p>Ibis also includes functionality that communicates directly with HDFS, using the WebHDFS REST API. When calling <code>ibis.impala.hdfs_connect(...)</code>, also pass <code>auth_mechanism='GSSAPI'</code> or <code>auth_mechanism='LDAP'</code>, and ensure that you are connecting to the correct port, which may likely be an SSL-secured WebHDFS port. Also note that you can pass <code>verify=False</code> to avoid verifying SSL certificates (which may be helpful in testing). Ibis will assume <code>https</code> when connecting to a Kerberized cluster. Because some Ibis commands create HDFS directories as well as new Impala databases and/or tables, your user will require the necessary privileges.</p>"},{"location":"backends/Impala/#default-configuation-values-for-cdh-components","title":"Default Configuation Values for CDH Components","text":"<p>Cloudera CDH ships with HDFS, Impala, Hive and many other components. Sometimes it's not obvious what default configuration values these tools are using or should be using.</p> <p>Check out this link to see the default configuration values for every component of CDH.</p>"},{"location":"backends/MSSQL/","title":"MS SQL Server","text":"<p>Introduced in v4.0</p>"},{"location":"backends/MSSQL/#install","title":"Install","text":"<p>Install ibis and dependencies for the MS SQL Server backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[mssql]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-mssql\n</code></pre> <pre><code>mamba install -c conda-forge ibis-mssql\n</code></pre>"},{"location":"backends/MSSQL/#connect","title":"Connect","text":""},{"location":"backends/MSSQL/#api","title":"API","text":"<p>Create a client by passing in connection parameters to <code>ibis.mssql.connect</code>.</p> <p>See <code>ibis.backends.mssql.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.mssql.connect</code> is a thin wrapper around <code>ibis.backends.mssql.Backend.do_connect</code>.</p>"},{"location":"backends/MSSQL/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/MSSQL/#ibis.backends.mssql.Backend.do_connect","title":"<code>do_connect(host='localhost', user=None, password=None, port=1433, database=None, url=None, driver='pymssql')</code>","text":""},{"location":"backends/MSSQL/#backend-api","title":"Backend API","text":""},{"location":"backends/MSSQL/#ibis.backends.mssql.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseAlchemyBackend</code></p>"},{"location":"backends/MySQL/","title":"MySQL","text":""},{"location":"backends/MySQL/#install","title":"Install","text":"<p>Install ibis and dependencies for the MySQL backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[mysql]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-mysql\n</code></pre> <pre><code>mamba install -c conda-forge ibis-mysql\n</code></pre>"},{"location":"backends/MySQL/#connect","title":"Connect","text":""},{"location":"backends/MySQL/#api","title":"API","text":"<p>Create a client by passing in a SQLAlchemy-style URI to <code>ibis.mysql.connect</code>.</p> <p>See <code>ibis.backends.mysql.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.mysql.connect</code> is a thin wrapper around <code>ibis.backends.mysql.Backend.do_connect</code>.</p>"},{"location":"backends/MySQL/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/MySQL/#ibis.backends.mysql.Backend.do_connect","title":"<code>do_connect(host='localhost', user=None, password=None, port=3306, database=None, url=None, driver='pymysql')</code>","text":"<p>Create an Ibis client using the passed connection parameters.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Hostname</p> <code>'localhost'</code> <code>user</code> <code>str | None</code> <p>Username</p> <code>None</code> <code>password</code> <code>str | None</code> <p>Password</p> <code>None</code> <code>port</code> <code>int</code> <p>Port</p> <code>3306</code> <code>database</code> <code>str | None</code> <p>Database to connect to</p> <code>None</code> <code>url</code> <code>str | None</code> <p>Complete SQLAlchemy connection string. If passed, the other connection arguments are ignored.</p> <code>None</code> <code>driver</code> <code>Literal['pymysql']</code> <p>Python MySQL database driver</p> <code>'pymysql'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; import getpass\n&gt;&gt;&gt; host = os.environ.get('IBIS_TEST_MYSQL_HOST', 'localhost')\n&gt;&gt;&gt; user = os.environ.get('IBIS_TEST_MYSQL_USER', getpass.getuser())\n&gt;&gt;&gt; password = os.environ.get('IBIS_TEST_MYSQL_PASSWORD')\n&gt;&gt;&gt; database = os.environ.get('IBIS_TEST_MYSQL_DATABASE',\n...                           'ibis_testing')\n&gt;&gt;&gt; con = connect(\n...     database=database,\n...     host=host,\n...     user=user,\n...     password=password\n... )\n&gt;&gt;&gt; con.list_tables()\n[...]\n&gt;&gt;&gt; t = con.table('functional_alltypes')\n&gt;&gt;&gt; t\nMySQLTable[table]\n  name: functional_alltypes\n  schema:\n    index : int64\n    Unnamed: 0 : int64\n    id : int32\n    bool_col : int8\n    tinyint_col : int8\n    smallint_col : int16\n    int_col : int32\n    bigint_col : int64\n    float_col : float32\n    double_col : float64\n    date_string_col : string\n    string_col : string\n    timestamp_col : timestamp\n    year : int32\n    month : int32\n</code></pre>"},{"location":"backends/MySQL/#backend-api","title":"Backend API","text":""},{"location":"backends/MySQL/#ibis.backends.mysql.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseAlchemyBackend</code></p>"},{"location":"backends/Pandas/","title":"Pandas","text":"<p>Ibis's pandas backend is available in core Ibis.</p>"},{"location":"backends/Pandas/#install","title":"Install","text":"<p>Install ibis and dependencies for the Pandas backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework'\n</code></pre> <pre><code>conda install -c conda-forge ibis-framework\n</code></pre> <pre><code>mamba install -c conda-forge ibis-framework\n</code></pre>"},{"location":"backends/Pandas/#connect","title":"Connect","text":""},{"location":"backends/Pandas/#api","title":"API","text":"<p>Create a client by passing in a dictionary of paths to <code>ibis.pandas.connect</code>.</p> <p>See <code>ibis.backends.pandas.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.pandas.connect</code> is a thin wrapper around <code>ibis.backends.pandas.Backend.do_connect</code>.</p>"},{"location":"backends/Pandas/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/Pandas/#ibis.backends.pandas.BasePandasBackend.do_connect","title":"<code>do_connect(dictionary=None)</code>","text":"<p>Construct a client from a dictionary of pandas DataFrames.</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>MutableMapping[str, pd.DataFrame] | None</code> <p>An optional mapping of string table names to pandas DataFrames.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.pandas.connect({\"t\": pd.DataFrame({\"a\": [1, 2, 3]})})\n&lt;ibis.backends.pandas.Backend at 0x...&gt;\n</code></pre>"},{"location":"backends/Pandas/#backend-api","title":"Backend API","text":""},{"location":"backends/Pandas/#ibis.backends.pandas.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BasePandasBackend</code></p>"},{"location":"backends/Pandas/#user-defined-functions-udf","title":"User Defined functions (UDF)","text":"<p>Ibis supports defining three kinds of user-defined functions for operations on expressions targeting the pandas backend: element-wise, reduction, and analytic.</p>"},{"location":"backends/Pandas/#elementwise-functions","title":"Elementwise Functions","text":"<p>An element-wise function is a function that takes N rows as input and produces N rows of output. <code>log</code>, <code>exp</code>, and <code>floor</code> are examples of element-wise functions.</p> <p>Here's how to define an element-wise function:</p> <pre><code>import ibis.expr.datatypes as dt\nfrom ibis.backends.pandas.udf import udf\n\n@udf.elementwise(input_type=[dt.int64], output_type=dt.double)\ndef add_one(x):\n    return x + 1.0\n</code></pre>"},{"location":"backends/Pandas/#reduction-functions","title":"Reduction Functions","text":"<p>A reduction is a function that takes N rows as input and produces 1 row as output. <code>sum</code>, <code>mean</code> and <code>count</code> are examples of reductions. In the context of a <code>GROUP BY</code>, reductions produce 1 row of output per group.</p> <p>Here's how to define a reduction function:</p> <pre><code>import ibis.expr.datatypes as dt\nfrom ibis.backends.pandas.udf import udf\n\n@udf.reduction(input_type=[dt.double], output_type=dt.double)\ndef double_mean(series):\n    return 2 * series.mean()\n</code></pre>"},{"location":"backends/Pandas/#analytic-functions","title":"Analytic Functions","text":"<p>An analytic function is like an element-wise function in that it takes N rows as input and produces N rows of output. The key difference is that analytic functions can be applied per group using window functions. Z-score is an example of an analytic function.</p> <p>Here's how to define an analytic function:</p> <pre><code>import ibis.expr.datatypes as dt\nfrom ibis.backends.pandas.udf import udf\n\n@udf.analytic(input_type=[dt.double], output_type=dt.double)\ndef zscore(series):\n    return (series - series.mean()) / series.std()\n</code></pre>"},{"location":"backends/Pandas/#details-of-pandas-udfs","title":"Details of Pandas UDFs","text":"<ul> <li>Element-wise provide support   for applying your UDF to any combination of scalar values and columns.</li> <li>Reductions provide support for   whole column aggregations, grouped aggregations, and application of your   function over a window.</li> <li>Analytic functions work in both grouped and non-grouped   settings</li> <li>The objects you receive as input arguments are either <code>pandas.Series</code> or   Python/NumPy scalars.</li> </ul> <p>Keyword arguments must be given a default</p> <p>Any keyword arguments must be given a default value or the function will not work.</p> <p>A common Python convention is to set the default value to <code>None</code> and handle setting it to something not <code>None</code> in the body of the function.</p> <p>Using <code>add_one</code> from above as an example, the following call will receive a <code>pandas.Series</code> for the <code>x</code> argument:</p> <pre><code>import ibis\nimport pandas as pd\ndf = pd.DataFrame({'a': [1, 2, 3]})\ncon = ibis.pandas.connect({'df': df})\nt = con.table('df')\nexpr = add_one(t.a)\nexpr\n</code></pre> <p>And this will receive the <code>int</code> 1:</p> <pre><code>expr = add_one(1)\nexpr\n</code></pre> <p>Since the pandas backend passes around <code>**kwargs</code> you can accept <code>**kwargs</code> in your function:</p> <pre><code>import ibis.expr.datatypes as dt\nfrom ibis.backends.pandas.udf import udf\n\n@udf.elementwise([dt.int64], dt.double)\ndef add_two(x, **kwargs): # do stuff with kwargs\n    return x + 2.0\n</code></pre> <p>Or you can leave them out as we did in the example above. You can also optionally accept specific keyword arguments.</p> <p>For example:</p> <pre><code>import ibis.expr.datatypes as dt\nfrom ibis.backends.pandas.udf import udf\n\n@udf.elementwise([dt.int64], dt.double)\ndef add_two_with_none(x, y=None):\n    if y is None:\n    y = 2.0\n    return x + y\n</code></pre>"},{"location":"backends/Polars/","title":"Polars","text":"<p>Introduced in v4.0</p> <p>The Polars backend is experimental and is subject to backwards incompatible changes.</p>"},{"location":"backends/Polars/#install","title":"Install","text":"<p>Install ibis and dependencies for the Polars backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[polars]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-polars\n</code></pre> <pre><code>mamba install -c conda-forge ibis-polars\n</code></pre>"},{"location":"backends/Polars/#connect","title":"Connect","text":""},{"location":"backends/Polars/#api","title":"API","text":"<p>Create a client by passing in connection parameters to <code>ibis.polars.connect</code>.</p> <p>See <code>ibis.backends.polars.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.polars.connect</code> is a thin wrapper around <code>ibis.backends.polars.Backend.do_connect</code>.</p>"},{"location":"backends/Polars/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/Polars/#ibis.backends.polars.Backend.do_connect","title":"<code>do_connect(tables=None)</code>","text":"<p>Construct a client from a dictionary of <code>polars.LazyFrame</code>s.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>MutableMapping[str, pl.LazyFrame] | None</code> <p>An optional mapping of string table names to polars LazyFrames.</p> <code>None</code>"},{"location":"backends/Polars/#backend-api","title":"Backend API","text":""},{"location":"backends/Polars/#ibis.backends.polars.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseBackend</code></p>"},{"location":"backends/Polars/#ibis.backends.polars.Backend-functions","title":"Functions","text":""},{"location":"backends/Polars/#ibis.backends.polars.Backend.read_csv","title":"<code>read_csv(path, table_name=None, **kwargs)</code>","text":"<p>Register a CSV file as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The data source. A string or Path to the CSV file.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to Polars loading function. See https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.scan_csv.html for more information.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/Polars/#ibis.backends.polars.Backend.read_pandas","title":"<code>read_pandas(source, table_name=None, **kwargs)</code>","text":"<p>Register a Pandas DataFrame or pyarrow Table a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>pd.DataFrame</code> <p>The data source.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to Polars loading function. See https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.from_pandas.html for more information.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/Polars/#ibis.backends.polars.Backend.read_parquet","title":"<code>read_parquet(path, table_name=None, **kwargs)</code>","text":"<p>Register a parquet file as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The data source(s). May be a path to a file or directory of parquet files.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to Polars loading function. See https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.scan_parquet.html for more information.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/Polars/#ibis.backends.polars.Backend.register","title":"<code>register(source, table_name=None, **kwargs)</code>","text":"<p>Register a data source as a table in the current database.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | Path | Any</code> <p>The data source(s). May be a path to a file, a parquet directory, or a pandas dataframe.</p> required <code>table_name</code> <code>str | None</code> <p>An optional name to use for the created table. This defaults to a sequentially generated name.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to Polars loading functions for CSV or parquet. See https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.scan_csv.html and https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.scan_parquet.html for more information</p> <code>{}</code> <p>Returns:</p> Type Description <code>ir.Table</code> <p>The just-registered table</p>"},{"location":"backends/PostgreSQL/","title":"PostgreSQL","text":""},{"location":"backends/PostgreSQL/#install","title":"Install","text":"<p>Install ibis and dependencies for the PostgreSQL backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[postgres]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-postgres\n</code></pre> <pre><code>mamba install -c conda-forge ibis-postgres\n</code></pre>"},{"location":"backends/PostgreSQL/#connect","title":"Connect","text":""},{"location":"backends/PostgreSQL/#api","title":"API","text":"<p>Create a client by passing in a SQLAlchemy-style URI to <code>ibis.postgres.connect</code>.</p> <p>See <code>ibis.backends.postgres.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.postgres.connect</code> is a thin wrapper around <code>ibis.backends.postgres.Backend.do_connect</code>.</p>"},{"location":"backends/PostgreSQL/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/PostgreSQL/#ibis.backends.postgres.Backend.do_connect","title":"<code>do_connect(host='localhost', user=None, password=None, port=5432, database=None, schema=None, url=None, driver='psycopg2')</code>","text":"<p>Create an Ibis client connected to PostgreSQL database.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Hostname</p> <code>'localhost'</code> <code>user</code> <code>str | None</code> <p>Username</p> <code>None</code> <code>password</code> <code>str | None</code> <p>Password</p> <code>None</code> <code>port</code> <code>int</code> <p>Port number</p> <code>5432</code> <code>database</code> <code>str | None</code> <p>Database to connect to</p> <code>None</code> <code>schema</code> <code>str | None</code> <p>PostgreSQL schema to use. If <code>None</code>, use the default <code>search_path</code>.</p> <code>None</code> <code>url</code> <code>str | None</code> <p>SQLAlchemy connection string.</p> <p>If passed, the other connection arguments are ignored.</p> <code>None</code> <code>driver</code> <code>Literal['psycopg2']</code> <p>Database driver</p> <code>'psycopg2'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; import getpass\n&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; host = os.environ.get('IBIS_TEST_POSTGRES_HOST', 'localhost')\n&gt;&gt;&gt; user = os.environ.get('IBIS_TEST_POSTGRES_USER', getpass.getuser())\n&gt;&gt;&gt; password = os.environ.get('IBIS_TEST_POSTGRES_PASSWORD')\n&gt;&gt;&gt; database = os.environ.get('IBIS_TEST_POSTGRES_DATABASE',\n...                           'ibis_testing')\n&gt;&gt;&gt; con = connect(\n...     database=database,\n...     host=host,\n...     user=user,\n...     password=password\n... )\n&gt;&gt;&gt; con.list_tables()\n[...]\n&gt;&gt;&gt; t = con.table('functional_alltypes')\n&gt;&gt;&gt; t\nPostgreSQLTable[table]\n  name: functional_alltypes\n  schema:\n    index : int64\n    Unnamed: 0 : int64\n    id : int32\n    bool_col : boolean\n    tinyint_col : int16\n    smallint_col : int16\n    int_col : int32\n    bigint_col : int64\n    float_col : float32\n    double_col : float64\n    date_string_col : string\n    string_col : string\n    timestamp_col : timestamp\n    year : int32\n    month : int32\n</code></pre>"},{"location":"backends/PostgreSQL/#backend-api","title":"Backend API","text":""},{"location":"backends/PostgreSQL/#ibis.backends.postgres.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseAlchemyBackend</code></p>"},{"location":"backends/PostgreSQL/#ibis.backends.postgres.Backend-functions","title":"Functions","text":""},{"location":"backends/PostgreSQL/#ibis.backends.postgres.Backend.udf","title":"<code>udf(pyfunc, in_types, out_type, schema=None, replace=False, name=None, language='plpythonu')</code>","text":"<p>Decorator that defines a PL/Python UDF in-database.</p> <p>Parameters:</p> Name Type Description Default <code>pyfunc</code> <p>Python function</p> required <code>in_types</code> <p>Input types</p> required <code>out_type</code> <p>Output type</p> required <code>schema</code> <p>The postgres schema in which to define the UDF</p> <code>None</code> <code>replace</code> <p>replace UDF in database if already exists</p> <code>False</code> <code>name</code> <p>name for the UDF to be defined in database</p> <code>None</code> <code>language</code> <p>Language extension to use for PL/Python</p> <code>'plpythonu'</code> <p>Returns:</p> Type Description <code>Callable</code> <p>A callable ibis expression</p> <p>Function that takes in Column arguments and returns an instance inheriting from PostgresUDFNode</p>"},{"location":"backends/PySpark/","title":"PySpark","text":""},{"location":"backends/PySpark/#install","title":"Install","text":"<p>Install ibis and dependencies for the PySpark backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[pyspark]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-pyspark\n</code></pre> <pre><code>mamba install -c conda-forge ibis-pyspark\n</code></pre>"},{"location":"backends/PySpark/#connect","title":"Connect","text":""},{"location":"backends/PySpark/#api","title":"API","text":"<p>Create a client by passing in PySpark things to <code>ibis.pyspark.connect</code>.</p> <p>See <code>ibis.backends.pyspark.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.pyspark.connect</code> is a thin wrapper around <code>ibis.backends.pyspark.Backend.do_connect</code>.</p>"},{"location":"backends/PySpark/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.do_connect","title":"<code>do_connect(session)</code>","text":"<p>Create a PySpark <code>Backend</code> for use with Ibis.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>SparkSession</code> <p>A SparkSession instance</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; from pyspark.sql import SparkSession\n&gt;&gt;&gt; session = SparkSession.builder.getOrCreate()\n&gt;&gt;&gt; ibis.pyspark.connect(session)\n&lt;ibis.backends.pyspark.Backend at 0x...&gt;\n</code></pre>"},{"location":"backends/PySpark/#backend-api","title":"Backend API","text":""},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseSQLBackend</code></p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend-classes","title":"Classes","text":""},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.Options","title":"<code>Options</code>","text":"<p>         Bases: <code>ibis.config.Config</code></p> <p>PySpark options.</p> <p>Attributes:</p> Name Type Description <code>treat_nan_as_null</code> <code>bool</code> <p>Treat NaNs in floating point expressions as NULL.</p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend-functions","title":"Functions","text":""},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.close","title":"<code>close()</code>","text":"<p>Close Spark connection and drop any temporary objects.</p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.compile","title":"<code>compile(expr, timecontext=None, params=None, *args, **kwargs)</code>","text":"<p>Compile an ibis expression to a PySpark DataFrame object.</p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.compute_stats","title":"<code>compute_stats(name, database=None, noscan=False)</code>","text":"<p>Issue a <code>COMPUTE STATISTICS</code> command for a given table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <code>noscan</code> <code>bool</code> <p>If <code>True</code>, collect only basic statistics for the table (number of rows, size in bytes).</p> <code>False</code>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.create_database","title":"<code>create_database(name, path=None, force=False)</code>","text":"<p>Create a new Spark database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Database name</p> required <code>path</code> <code>str | Path | None</code> <p>Path where to store the database data; otherwise uses Spark default</p> <code>None</code> <code>force</code> <code>bool</code> <p>Whether to append <code>IF EXISTS</code> to the database creation SQL</p> <code>False</code>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.create_table","title":"<code>create_table(name, obj=None, *, schema=None, database=None, temp=None, overwrite=False, format='parquet')</code>","text":"<p>Create a new table in Spark.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the new table.</p> required <code>obj</code> <code>ir.Table | pd.DataFrame | None</code> <p>If passed, creates table from <code>SELECT</code> statement results</p> <code>None</code> <code>schema</code> <code>sch.Schema | None</code> <p>Mutually exclusive with <code>obj</code>, creates an empty table with a schema</p> <code>None</code> <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <code>temp</code> <code>bool | None</code> <p>Whether the new table is temporary</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>If <code>True</code>, overwrite existing data</p> <code>False</code> <code>format</code> <code>str</code> <p>Format of the table on disk</p> <code>'parquet'</code> <p>Returns:</p> Type Description <code>Table</code> <p>The newly created table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; con.create_table('new_table_name', table_expr)\n</code></pre>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.create_view","title":"<code>create_view(name, obj, *, database=None, overwrite=False)</code>","text":"<p>Create a Spark view from a table expression.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>View name</p> required <code>obj</code> <code>ir.Table</code> <p>Expression to use for the view</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Replace an existing view of the same name if it exists</p> <code>False</code> <p>Returns:</p> Type Description <code>Table</code> <p>The created view</p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.drop_database","title":"<code>drop_database(name, force=False)</code>","text":"<p>Drop a Spark database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Database name</p> required <code>force</code> <code>bool</code> <p>If False, Spark throws exception if database is not empty or database does not exist</p> <code>False</code>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.drop_table","title":"<code>drop_table(name, *, database=None, force=False)</code>","text":"<p>Drop a table.</p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.drop_table_or_view","title":"<code>drop_table_or_view(name, *, database=None, force=False)</code>","text":"<p>Drop a Spark table or view.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table or view name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code> <code>force</code> <code>bool</code> <p>Database may throw exception if table does not exist</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; table = 'my_table'\n&gt;&gt;&gt; db = 'operations'\n&gt;&gt;&gt; con.drop_table_or_view(table, db, force=True)\n</code></pre>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.drop_view","title":"<code>drop_view(name, *, database=None, force=False)</code>","text":"<p>Drop a view.</p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.execute","title":"<code>execute(expr, **kwargs)</code>","text":"<p>Execute an expression.</p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.insert","title":"<code>insert(table_name, obj=None, database=None, overwrite=False, values=None, validate=True)</code>","text":"<p>Insert data into an existing table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; table = 'my_table'\n&gt;&gt;&gt; con.insert(table, table_expr)\n</code></pre>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.insert--completely-overwrite-contents","title":"Completely overwrite contents","text":"<pre><code>&gt;&gt;&gt; con.insert(table, table_expr, overwrite=True)\n</code></pre>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.table","title":"<code>table(name, database=None)</code>","text":"<p>Return a table expression from a table or view in the database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database in which the table resides</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table named <code>name</code> from <code>database</code></p>"},{"location":"backends/PySpark/#ibis.backends.pyspark.Backend.truncate_table","title":"<code>truncate_table(name, database=None)</code>","text":"<p>Delete all rows from an existing table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Database name</p> <code>None</code>"},{"location":"backends/SQLite/","title":"SQLite","text":""},{"location":"backends/SQLite/#install","title":"Install","text":"<p>Install ibis and dependencies for the SQLite backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[sqlite]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-sqlite\n</code></pre> <pre><code>mamba install -c conda-forge ibis-sqlite\n</code></pre>"},{"location":"backends/SQLite/#connect","title":"Connect","text":""},{"location":"backends/SQLite/#api","title":"API","text":"<p>Create a client by passing in a path to a SQLite database to <code>ibis.sqlite.connect</code>.</p> <p>See <code>ibis.backends.sqlite.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.sqlite.connect</code> is a thin wrapper around <code>ibis.backends.sqlite.Backend.do_connect</code>.</p>"},{"location":"backends/SQLite/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/SQLite/#ibis.backends.sqlite.Backend.do_connect","title":"<code>do_connect(database=None, path=None, type_map=None)</code>","text":"<p>Create an Ibis client connected to a SQLite database.</p> <p>Multiple database files can be accessed using the <code>attach()</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>database</code> <code>str | Path | None</code> <p>File path to the SQLite database file. If <code>None</code>, creates an in-memory transient database and you can use attach() to add more files</p> <code>None</code> <code>path</code> <code>str | Path | None</code> <p>Deprecated, use <code>database</code></p> <code>None</code> <code>type_map</code> <code>dict[str, str | dt.DataType] | None</code> <p>An optional mapping from a string name of a SQLite \"type\" to the corresponding ibis DataType that it represents. This can be used to override schema inference for a given SQLite database.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.sqlite.connect(\"path/to/my/sqlite.db\")\n</code></pre>"},{"location":"backends/SQLite/#backend-api","title":"Backend API","text":""},{"location":"backends/SQLite/#ibis.backends.sqlite.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseAlchemyBackend</code></p>"},{"location":"backends/SQLite/#ibis.backends.sqlite.Backend-functions","title":"Functions","text":""},{"location":"backends/SQLite/#ibis.backends.sqlite.Backend.attach","title":"<code>attach(name, path)</code>","text":"<p>Connect another SQLite database file to the current connection.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Database name within SQLite</p> required <code>path</code> <code>str | Path</code> <p>Path to sqlite3 database files</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; con1 = ibis.sqlite.connect(\"original.db\")\n&gt;&gt;&gt; con2 = ibis.sqlite.connect(\"new.db\")\n&gt;&gt;&gt; con1.attach(\"new\", \"new.db\")\n&gt;&gt;&gt; con1.list_tables(database=\"new\")\n</code></pre>"},{"location":"backends/SQLite/#ibis.backends.sqlite.Backend.table","title":"<code>table(name, database=None, **_)</code>","text":"<p>Create a table expression from a table in the SQLite database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name</p> required <code>database</code> <code>str | None</code> <p>Name of the attached database that the table is located in.</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table expression</p>"},{"location":"backends/Snowflake/","title":"Snowflake","text":"<p>Introduced in v4.0</p> <p>The Snowflake backend is experimental and is subject to backwards incompatible changes.</p>"},{"location":"backends/Snowflake/#install","title":"Install","text":"<p>Install ibis and dependencies for the Snowflake backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[snowflake]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-snowflake\n</code></pre> <pre><code>mamba install -c conda-forge ibis-snowflake\n</code></pre>"},{"location":"backends/Snowflake/#connect","title":"Connect","text":""},{"location":"backends/Snowflake/#api","title":"API","text":"<p>Create a client by passing in a SQLAlchemy connection string to <code>ibis.snowflake.connect</code>.</p> <p>See <code>ibis.backends.snowflake.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.snowflake.connect</code> is a thin wrapper around <code>ibis.backends.snowflake.Backend.do_connect</code>.</p>"},{"location":"backends/Snowflake/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/Snowflake/#ibis.backends.snowflake.Backend.do_connect","title":"<code>do_connect(user, password, account, database, **kwargs)</code>","text":""},{"location":"backends/Snowflake/#backend-api","title":"Backend API","text":""},{"location":"backends/Snowflake/#ibis.backends.snowflake.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseAlchemyBackend</code></p>"},{"location":"backends/Trino/","title":"Trino","text":"<p>Introduced in v4.0</p> <p>The Trino backend is experimental and is subject to backwards incompatible changes.</p>"},{"location":"backends/Trino/#install","title":"Install","text":"<p>Install ibis and dependencies for the Trino backend:</p> pipcondamamba <pre><code>pip install 'ibis-framework[trino]'\n</code></pre> <pre><code>conda install -c conda-forge ibis-trino\n</code></pre> <pre><code>mamba install -c conda-forge ibis-trino\n</code></pre>"},{"location":"backends/Trino/#connect","title":"Connect","text":""},{"location":"backends/Trino/#api","title":"API","text":"<p>Create a client by passing in a SQLAlchemy connection string to <code>ibis.trino.connect</code>.</p> <p>See <code>ibis.backends.trino.Backend.do_connect</code> for connection parameter information.</p> <p><code>ibis.trino.connect</code> is a thin wrapper around <code>ibis.backends.trino.Backend.do_connect</code>.</p>"},{"location":"backends/Trino/#connection-parameters","title":"Connection Parameters","text":""},{"location":"backends/Trino/#ibis.backends.trino.Backend.do_connect","title":"<code>do_connect(user='user', password=None, host='localhost', port=8080, database=None, schema=None, **connect_args)</code>","text":"<p>Create an Ibis client connected to a Trino database.</p>"},{"location":"backends/Trino/#backend-api","title":"Backend API","text":""},{"location":"backends/Trino/#ibis.backends.trino.Backend","title":"<code>Backend</code>","text":"<p>         Bases: <code>BaseAlchemyBackend</code></p>"},{"location":"backends/support_matrix/","title":"Operation Support Matrix","text":"<p>Backends are shown in descending order of the number of supported operations.</p> <p>Backends with low coverage are good places to start contributing!</p> <p>Each backend implements operations differently, but this is usually very similar to other backends. If you want to start contributing to ibis, it's a good idea to start by adding missing operations to backends that have low operation coverage.</p> <p>This app is built using <code>streamlit</code></p> <p>You can develop the app locally by editing <code>docs/backends/app/backend_info_app.py</code> and opening a PR with your changes.</p> <p>Test your changes locally by running</p> <pre><code>$ streamlit run docs/backends/app/backend_info_app.py\n</code></pre> <p>The changes will show up in the dev docs when your PR is merged!</p>"},{"location":"backends/support_matrix/#raw-data","title":"Raw Data","text":"<p>You can also download data from the above tables in CSV format.</p>"},{"location":"blog/Ibis-version-3.0.0-release/","title":"Ibis v3.0.0","text":"<p>by Marlene Mhangami</p> <p>The latest version of Ibis, version 3.0.0, has just been released! This post highlights some of the new features, breaking changes, and performance improvements that come with the new release. 3.0.0 is a major release and includes more changes than those listed in this post. A full list of the changes can be found in the project release notes here.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#new-features","title":"New Features","text":"<p>Aligned to the roadmap and in response to the community\u2019s requests, Ibis 3.0.0 introduces many new features and functionality.</p> <ol> <li>Now query an Ibis table using inline SQL</li> <li>NEW DuckDB backend</li> <li>Explore the NEW backend support matrix tool</li> <li>Improved support for arrays and tuples in ClickHouse</li> <li>Suffixes now supported in join API expressions</li> <li>APIs for creating timestamps and dates from component fields</li> <li>Pretty printing in ipython/ notebooks</li> </ol> <p>Refer to the sections below for more detail on each new feature.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#inline-sql","title":"Inline SQL","text":"<p>The most exciting feature of this release is inline SQL! Many data scientists or developers may be familiar with both Python and SQL. However there may be some queries, transformations that they feel comfortable doing in SQL instead of Python. In the updated version of Ibis users can query an Ibis table using SQL! The new .sql method allows users to mix SQL strings with ibis expressions as well as query ibis table expressions in SQL strings.</p> <p>This functionality currently works for the following backends:</p> <ol> <li>PostgreSQL</li> <li>DuckDB</li> <li>PySpark</li> <li>MySQL</li> </ol> <p>If you're interested in adding .sql support for other backends please open an issue.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#duckdb-backend","title":"DuckDB Backend","text":"<p>Ibis now supports DuckDB as a backend. DuckDB is a high-performance SQL OLAP database management system. It is designed to be fast, reliable and easy to use and can be embedded. Many Ibis use cases start from getting tables from a single-node backend so directly supporting DuckDB offers a lot of value. As mentioned earlier, the DuckDB backend allows for the new .sql method on tables for mixing sql and Ibis expressions.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#backend-support-matrix","title":"Backend Support Matrix","text":"<p>As the number of backends Ibis supports grows, it can be challenging for users to decide which one best fits their needs. One way to make a more informed decision is for users to find the backend that supports the operations they intend to use. The 3.0.0 release comes with a backend support matrix that allows users to do just that. A screenshot of part of the matrix can be seen below and the full version can be found here.</p> <p>In addition to this users can now call <code>ibis.${backend}.has_operation</code> to find out if a specific operation is supported by a backend.</p> <p></p>"},{"location":"blog/Ibis-version-3.0.0-release/#support-of-arrays-and-tuples-for-clickhouse","title":"Support of arrays and tuples for ClickHouse","text":"<p>The 3.0.0 release includes a slew of important improvements for the ClickHouse backend. Most prominently ibis now supports ClickHouse arrays and tuples. Some of the related operations that have been implemented are:</p> <ul> <li>ArrayIndex</li> <li>ArrayConcat</li> <li>ArrayRepeat</li> <li>ArraySlice</li> </ul> <p>Other additional operations now supported for the clickhouse backend are string concat, string slicing, table union, trim, pad and string predicates (LIKE and ILIKE) and all remaining joins.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#suffixes-now-supported-in-join-api-expressions","title":"Suffixes now supported in join API expressions","text":"<p>In previous versions Ibis' join API did not accept suffixes as a parameter, leaving backends to either use some default value or raise an error at execution time when column names overlapped. In 3.0.0 suffixes are now directly supported in the join API itself. Along with the removal of materialize, ibis now automatically adds a default suffix to any overlapping column names.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#creating-timestamp-from-component-fields","title":"Creating timestamp from component fields","text":"<p>It is now possible to create timestamps directly from component fields. This is now possible using the new method <code>ibis.date(y,m,d)</code>. A user can pass in a year, month and day and the result is a datetime object. That is we can assert for example that <code>ibis.date (2022, 2, 4).type() == dt.date</code></p>"},{"location":"blog/Ibis-version-3.0.0-release/#pretty-print-tables-in-ipython-notebooks","title":"Pretty print tables in ipython notebooks","text":"<p>For users that use jupyter notebooks, <code>repr_html</code> has been added for expressions to enable pretty printing tables in the notebook. This is currently only available for interactive mode (currently delegating to pandas implementation) and should help notebooks become more readable. An example of what this looks like can be seen below.</p> <p></p>"},{"location":"blog/Ibis-version-3.0.0-release/#other-changes","title":"Other Changes","text":"<p>3.0.0 is a major release and according to the project's use of semantic versioning, breaking changes are on the table. The full list of these changes can be found here. Some of the important changes include:</p> <ol> <li>Python 3.8 is now the minimum supported version</li> <li>Deprecation of <code>.materialize()</code></li> </ol> <p>Refer to the sections below for more detail on these changes.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#the-minimum-supported-python-version-is-now-python-38","title":"The minimum supported Python version is now Python 3.8","text":"<p>Ibis currently follows NEP 29, a community policy standard that recommends Python and Numpy versions to support. NEP 29 suggests that all projects across the Scientific Python ecosystem adopt a common \u201ctime window-based\u201d policy for support of Python and NumPy versions. Standardizing a recommendation for project support of minimum Python and NumPy versions will improve downstream project planning. As part of the 3.0.0 release, support for Python 3.7 has been dropped and the project has now adopted support for version 3.8 and higher.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#deprecation-of-materialize","title":"Deprecation of .materialize()","text":"<p>This release sees the deprecation of the <code>.materialize()</code> method from TableExpr. In the past, the materialize method has caused a lot of confusion. Doing simple things like <code>t.join(s, t.foo == s.foo).select([\"unambiguous_column\"])</code> raised an exception because of it. It turns out that .materialize() isn't necessary. The materialize method still exists, but is now a no-op and doesn't need to be used.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#performance-improvements","title":"Performance Improvements","text":"<p>The following changes to the Ibis codebase have resulted in performance improvements.</p> <ol> <li>Speeding up <code>__str__</code> and <code>__hash__</code> datatypes</li> <li>Creating a fast path for simple column selection (pandas/dask backends)</li> <li>Global equality cache</li> <li>Removing full tree repr from rule validator error message</li> <li>Speed up attribute access</li> <li>Using assign instead of concat in projections when possible (pandas/dask backends)</li> </ol> <p>Additionally, all TPC-H suite queries can be represented in Ibis. All queries are ready-to-run, using the default substitution parameters as specified by the TPC-H spec. Queries have been added here.</p>"},{"location":"blog/Ibis-version-3.0.0-release/#conclusion","title":"Conclusion","text":"<p>In summary, the 3.0.0 release includes a number of new features including the ability to query an Ibis table using inline SQL, a DuckDB backend, a backend support matrix tool, support for arrays and tuples, suffixes in joins, timestamps from component fields and prettier tables in ipython. Some breaking changes to take note of are the removal of .materialize() and the switch to Python 3.8 as the minimum supported version. A wide range of changes to the code has also led to significant speed ups in 3.0.0 as well.</p> <p>Ibis is a community led, open source project. If you\u2019d like to contribute to the project check out the contribution guide here. If you run into a problem and would like to submit an issue you can do so through Ibis\u2019 Github repository. Finally, Ibis relies on community support to grow and to become successful! You can help promote Ibis by following and sharing the project on Twitter, starring the repo or contributing to the code. Ibis continues to improve with every release. Keep an eye on the blog for updates on the next one!</p>"},{"location":"blog/Ibis-version-3.1.0-release/","title":"Ibis v3.1.0","text":"<p>by Marlene Mhangami</p> <p>25 July 2022</p>"},{"location":"blog/Ibis-version-3.1.0-release/#introduction","title":"Introduction","text":"<p>Ibis 3.1 has officially been released as the latest version of the package. With this release comes new convenience features, increased backend operation coverage and a plethora of bug fixes. As usual, a full list of the changes can be found in the project release notes here Let\u2019s talk about some of the new changes 3.1 brings for Ibis users.</p>"},{"location":"blog/Ibis-version-3.1.0-release/#ibisconnect","title":"<code>ibis.connect</code>","text":"<p>The first significant change to note is that, Ibis now provides a more convenient way to connect to a backend using the <code>ibis.connect</code> method. You can now use this function to connect to an appropriate backend using a connection string.</p> <p>Here are some examples:</p> DuckDBPostgres <p>Initialize a DuckDB instance using <code>'duckdb://:memory:'</code> <pre><code>conn = ibis.connect('duckdb://:memory:')\n</code></pre> And begin registering your tables: <pre><code>conn.register('csv://farm_data/dates.csv', 'dates')\nconn.register('csv://farm_data/farmer_groups.csv', 'farmer_groups')\nconn.register('csv://farm_data/crops.csv', 'crops')\nconn.register('csv://farm_data/farms.csv', 'farms')\nconn.register('csv://farm_data/harvest.csv', 'harvest')\nconn.register('csv://farm_data/farmers.csv', 'farmers')\nconn.register('csv://farm_data/tracts.csv', 'tracts')\nconn.register('csv://farm_data/fields.csv', 'fields')\n</code></pre> You can also do this programmatically: <pre><code>files = glob.glob('farm_data/*.csv')\n\nfor file in files:\n    fname = 'csv://' + file\n    tname = file.replace('farm_data/', '').replace('.csv', '')\n    conn.register(fname, tname)\n</code></pre> This method isn\u2019t limited to <code>csv://</code>.  It works with <code>parquet://</code> and <code>csv.gz://</code> as well. Give it a try!</p> <p><pre><code>conn = ibis.connect('postgres://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;database&gt;')\n</code></pre> Or, using a .pgpass file: <pre><code>conn = ibis.connect('postgres://&lt;username&gt;@&lt;host&gt;:&lt;port&gt;/&lt;database&gt;')\n</code></pre></p>"},{"location":"blog/Ibis-version-3.1.0-release/#unnest-support","title":"Unnest Support","text":"<p>One of the trickier parts about working with data is that it doesn\u2019t usually come organized in neat, predictable rows and columns. Instead data often consists of rows that could contain a single bit of data or arrays of it. When data is organized in layers, as with arrays, it can sometimes be difficult to work with. Ibis 3.1 introduces the <code>unnest</code> function as a way to flatten arrays of data.</p> <p>Unnest takes a column containing an array of values and separates the individual values into rows as shown:</p> <p>Before Unnest:</p> <pre><code>    | col    |\n    | ------ |\n    | [1, 2] |\n</code></pre> <p>After Unnest:</p> <pre><code>    | col |\n    | --- |\n    |  1  |\n    |  2  |\n</code></pre> <p>Here is a self-contained example of creating a dataset with an array and then unnesting it:</p> DuckDBPostgres <pre><code>import ibis\nimport pandas as pd\n\n# Parquet save path\nfname = 'array_data.parquet'\n\n# Mock Data\ndata = [\n    ['array_id', 'array_value']\n    ,[1, [1, 3, 4]]\n    ,[2, [2, 4, 5]]\n    ,[3, [6, 8]]\n    ,[4, [1, 6]]\n]\n\n# Save as parquet\npd.DataFrame(data[1:], columns=data[0]).to_parquet(fname)\n\n# Connect to the file using a DuckDB backend\nconn = ibis.connect(f\"duckdb://{fname}\")\n\n# Create a table expression for your loaded data\narray_data = conn.table(\"array_data\")\n\n# Optionally execute the array data to preview\narray_data.execute()\n\n# select the unnested values with their corresponding IDs\narray_data.select(['array_id', array_data['array_value'].unnest()]).execute()\n</code></pre> <pre><code>import ibis\nimport pandas as pd\n\n# Postgres connection string for user 'ibistutorials' with a valid .pgpass file in ~/\n# See https://www.postgresql.org/docs/9.3/libpq-pgpass.html for details on ~/.pgpass\ncstring = 'postgres://ibistutorials@localhost:5432/pg-ibis'\n\n# Mock Data\ndata = [\n    ['array_id', 'array_value']\n    ,[1, [1, 3, 4]]\n    ,[2, [2, 4, 5]]\n    ,[3, [6, 8]]\n    ,[4, [1, 6]]\n]\n\n# Create a dataframe for easy loading\ndf = pd.DataFrame(data[1:], columns=data[0])\n\n# Postgres backend connection\nconn = ibis.connect(cstring)\n\n# SQLAlchemy Types\n# Integer type\nint_type = ibis.backends.postgres.sa.types.INT()\n# Array type function\narr_f = ibis.backends.postgres.sa.types.ARRAY\n\n# Load data to table using pd.DataFrame.to_sql\ndf.to_sql(\n    name='array_data'\n    ,con=conn.con.connect()\n    ,if_exists='replace'\n    ,index=False\n    ,dtype={\n        'array_id': int_type\n        ,'array_value': arr_f(int_type)\n    }\n)\n\n# Array Data Table Expression\narray_data = conn.table(\"array_data\")\n\n# Optionally execute to preview entire table\n# array_data.execute()\n\n# Unnest\narray_data.select(['array_id', array_data['array_value'].unnest()]).execute()\n</code></pre>"},{"location":"blog/Ibis-version-3.1.0-release/#_-api","title":"<code>_</code> API","text":"<p>There is now a shorthand for lambda functions using underscore (<code>_</code>). This is useful for chaining expressions to one another and helps reduce total line characters and appearances of lambdas.</p> <p>For example, let\u2019s use <code>array_data</code> from above. We will unnest <code>array_value</code>, find the weighted average, and then sum in one expression:</p> <pre><code>from ibis import _\n\n(\n    array_data\n    .select([\n        'array_id'\n        # array_data returns a TableExpr, `_` here is shorthand\n        # for that returned expression\n        ,_['array_value'].unnest().name('arval')\n        # we can use it instead of saying `array_data`\n        ,(_['array_value'].length().cast('float')\n          / _['array_value'].length().sum().cast('float')).name('wgt')\n    ])\n    # Since the above `select` statement returns a TableExpr, we can use\n    # `_` to reference that one as well:\n    .mutate(wgt_prod=_.arval * _.wgt)\n    # And again:\n    .aggregate(vsum=_.wgt_prod.sum(), vcount=_.wgt_prod.count())\n    # And again:\n    .mutate(wgt_mean=_.vsum / _.vcount)\n).execute()\n</code></pre> <p>Note that if you import <code>_</code> directly from <code>ibis</code> (<code>from ibis import _</code>), the default <code>_</code> object will lose its functionality, so be mindful if you have a habit of using it outside of Ibis.</p>"},{"location":"blog/Ibis-version-3.1.0-release/#additional-changes","title":"Additional Changes","text":"<p>Along with these changes, the operation matrix has had a few more holes filled. Contributors should note that backend test data is now loaded dynamically. Most users won\u2019t be exposed to this update, but it should make contribution a bit more streamlined.</p> <p>To see the full patch notes, go to the patch notes page</p> <p>As always, Ibis is free and open source. Contributions are welcome and encouraged\u2013drop into the discussions, raise an issue, or put in a pull request.</p> <p>Download ibis 3.1 today!</p>"},{"location":"blog/ffill-and-bfill-using-ibis/","title":"<code>ffill</code> and <code>bfill</code> using Ibis","text":"<p>by Patrick Clarke</p> <p>Suppose you have a table of data mapping events and dates to values, and that this data contains gaps in values.</p> <p>Suppose you want to forward fill these gaps such that, one-by-one, if a value is null, it is replaced by the non-null value preceeding.</p> <p>For example, you might be measuring the total value of an account over time. Saving the same value until that value changes is an inefficient use of space, so you might only measure the value during certain events, like a change in ownership or value.</p> <p>In that case, to view the value of the account by day, you might want to interpolate dates and then ffill or bfill value to show the account value over time by date.</p> <p>Date interpolation will be covered in a different guide, but if you already have the dates then you can fill in some values.</p> <p>This was heavily inspired by Gil Forsyth's writeup on ffill and bfill on the Ibis GitHub Wiki.</p>"},{"location":"blog/ffill-and-bfill-using-ibis/#setup","title":"Setup","text":"<p>First, we want to make some mock data. To demonstrate this technique in a non-pandas backend, we will use the DuckDB backend.</p> <p>Our data will have measurements by date, and these measurements will be grouped by an event id. We will then save this data to <code>data.parquet</code> so we can register that parquet file as a table in our DuckDB connector.</p> <pre><code>In [1]: import ibis; from datetime import date\nIn [2]: import numpy as np; import pandas as pd\n\nIn [3]: df = pd.DataFrame({\n   ...:     \"event_id\": [0] * 2 + [1] * 3 + [2] * 5 + [3] * 2\n   ...:     ,\"measured_on\": map(\n   ...:         date\n   ...:         ,[2021] * 12, [6] * 4 + [5] * 6 + [7] * 2\n   ...:         ,range(1, 13)\n   ...:     )\n   ...:     ,\"measurement\": np.nan\n   ...: })\n\nIn [4]: df.head()\nOut[4]:\n   event_id measured_on  measurement\n0         0  2021-06-01          NaN\n1         0  2021-06-02          NaN\n2         1  2021-06-03          NaN\n3         1  2021-06-04          NaN\n4         1  2021-05-05          NaN\n\nIn [5]: df.at[1, \"measurement\"] = 5.\nIn [6]: df.at[4, \"measurement\"] = 42.\nIn [7]: df.at[5, \"measurement\"] = 42.\nIn [8]: df.at[7, \"measurement\"] = 11.\n\nIn [9]: df\nOut[9]:\n    event_id measured_on  measurement\n0          0  2021-06-01          NaN\n1          0  2021-06-02          5.0\n2          1  2021-06-03          NaN\n3          1  2021-06-04          NaN\n4          1  2021-05-05         42.0\n5          2  2021-05-06         42.0\n6          2  2021-05-07          NaN\n7          2  2021-05-08         11.0\n8          2  2021-05-09          NaN\n9          2  2021-05-10          NaN\n10         3  2021-07-11          NaN\n11         3  2021-07-12          NaN\n\nIn [10]: df.to_parquet(\"data.parquet\")\n</code></pre> <p>To use the DuckDB backend with our data, we will spin up a DuckDB connection and then register <code>data.parquet</code> as <code>data</code>:</p> <pre><code>In [11]: conn = ibis.connect('duckdb://:memory:')\n\nIn [12]: conn.register('data.parquet', table_name='data')\nOut[12]:\nAlchemyTable: data\n  event_id    int64\n  measured_on date\n  measurement float64\n\nIn [13]: data = conn.table(\"data\")\n\nIn [14]: data.execute()\nOut[14]:\n    event_id measured_on  measurement\n0          0  2021-06-01          NaN\n1          0  2021-06-02          5.0\n2          1  2021-06-03          NaN\n3          1  2021-06-04          NaN\n4          1  2021-05-05         42.0\n5          2  2021-05-06         42.0\n6          2  2021-05-07          NaN\n7          2  2021-05-08         11.0\n8          2  2021-05-09          NaN\n9          2  2021-05-10          NaN\n10         3  2021-07-11          NaN\n11         3  2021-07-12          NaN\n\nIn [15]: data\nOut[15]:\nAlchemyTable: data\n  event_id    int64\n  measured_on date\n  measurement float64\n</code></pre>"},{"location":"blog/ffill-and-bfill-using-ibis/#ffill-strategy","title":"<code>ffill</code> Strategy","text":"<p>To better understand how we can forward-fill our gaps, let's take a minute to explain the strategy and then look at the manual result.</p> <p>We will partition our data by event groups and then sort those groups by date.</p> <p>Our logic for forward fill is then: let <code>j</code> be an event group sorted by date and let <code>i</code> be a date within <code>j</code>. If <code>i</code> is the first date in <code>j</code>, then continue. If <code>i</code> is not the first date in <code>j</code>, then if <code>measurement</code> in <code>i</code> is null then replace it with <code>measurement</code> for <code>i-1</code>. Otherwise, do nothing.</p> <p>Let's take a look at what this means for the first few rows of our data:</p> <pre><code>    event_id measured_on  measurement\n0          0  2021-06-01          NaN # Since this is the first row of the event group (group 0), do nothing\n1          0  2021-06-02          5.0 # Since this is not the first row of the group and is not null: do nothing\n4          1  2021-05-05         42.0 # This is the first row of the event group (group 1): do nothing\n2          1  2021-06-03          NaN # This is not the first row and is null: replace it (NaN \u2192 42.0)\n3          1  2021-06-04          NaN # This is not the first row and is null: replace it (NaN \u2192 42.0)\n5          2  2021-05-06         42.0 # This is the first row of the event group (group 2): do nothing\n6          2  2021-05-07          NaN # This is not the first row and is null: replace it (NaN \u2192 42.0)\n7          2  2021-05-08         11.0 # This is not the first row and is not null: do nothing\n8          2  2021-05-09          NaN # This is not the first row and is null: replace it (NaN \u2192 11.0)\n9          2  2021-05-10          NaN # This is not the first row and is null: replace it (NaN \u2192 11.0)\n10         3  2021-07-11          NaN # This is the first row of the event group (group 3): do nothing\n11         3  2021-07-12          NaN # This is not the first row and is null: replace it (NaN \u2192 NaN)\n</code></pre> <p>Our result should for forward fill should look like this:</p> <pre><code>    event_id measured_on  measurement\n0          0  2021-06-01          NaN\n1          0  2021-06-02          5.0\n2          1  2021-05-05         42.0\n3          1  2021-06-03         42.0\n4          1  2021-06-04         42.0\n5          2  2021-05-06         42.0\n6          2  2021-05-07         42.0\n7          2  2021-05-08         11.0\n8          2  2021-05-09         11.0\n9          2  2021-05-10         11.0\n10         3  2021-07-11          NaN\n11         3  2021-07-12          NaN\n</code></pre> <p>To accomplish this, we will create a window over our <code>event_id</code> to partition our data into groups. We will take these groups and order them by <code>measured_on</code>:</p> <pre><code>In [16]: win = ibis.window(group_by=data.event_id, order_by=data.measured_on, following=0)\n</code></pre> <p>Once we have our window defined, we can flag the first non-null value in an event group using <code>count</code>, as it will count non-null values row-by-row within our group:</p> <pre><code>In [17]: grouped = data.mutate(grouper=data.measurement.count().over(win))\n\nIn [18]: grouped.execute().sort_values(by=['event_id', 'measured_on'])\nOut[18]:\n    event_id measured_on  measurement  grouper\n0          0  2021-06-01          NaN        0\n1          0  2021-06-02          5.0        1\n2          1  2021-05-05         42.0        1\n3          1  2021-06-03          NaN        1\n4          1  2021-06-04          NaN        1\n5          2  2021-05-06         42.0        1\n6          2  2021-05-07          NaN        1\n7          2  2021-05-08         11.0        2\n8          2  2021-05-09          NaN        2\n9          2  2021-05-10          NaN        2\n10         3  2021-07-11          NaN        0\n11         3  2021-07-12          NaN        0\n</code></pre> <p>To see this a bit clearer: look at rows 0, 1, and 2. Row 0 is NaN and is the first row of the group (event_id = 0), so at row 0 we have 0 non-null values (grouper = 0). Row 1 is not null (5.0) and is the second row the group, so our count has increased by 1 (grouper = 1). Row 2 is the first row of its group (event_id = 1) and is not null, so our count is 1 (grouper = 1).</p> <p>Skip down to rows 9, 10, and 11. Row 9 is the sixth row of group 2 and there are three non-null values in group 2 before row 9. Therefore the count at row 9 is 3.</p> <p>Row 10 is the first row of group 3 and is null, therefore its count is 0. Finally: row 11 is the second row of group 3 and is null as well, therefore the count remains 0.</p> <p>Under this design, we now have another partition.</p> <p>Our first partition is by <code>event_id</code>. Within each set in that partition, we have a partition by <code>grouper</code>, where each set has up to one non-null value.</p> <p>Since there less than or equal to one non-null value in each group of <code>['event_id', 'grouper']</code>, we can simply fill values by overwriting all values within the group by the max value in the group.</p> <p>So:</p> <ol> <li>Group by <code>event_id</code> and <code>grouper</code></li> <li>Mutate the data along that grouping by populating a new column <code>ffill</code> with the <code>max</code> value of <code>measurement</code>.</li> </ol> <pre><code>In [19]: result = (\n    ...:     grouped\n    ...:     .group_by([grouped.event_id, grouped.grouper])\n    ...:     .mutate(ffill=grouped.measurement.max())\n    ...:     .execute()\n    ...: ).sort_values(by=['event_id', 'measured_on']).reset_index(drop=True)\n\nIn [20]: result\nOut[20]:\n    event_id measured_on  measurement  grouper  ffill\n0          0  2021-06-01          NaN        0    NaN\n1          0  2021-06-02          5.0        1    5.0\n2          1  2021-05-05         42.0        1   42.0\n3          1  2021-06-03          NaN        1   42.0\n4          1  2021-06-04          NaN        1   42.0\n5          2  2021-05-06         42.0        1   42.0\n6          2  2021-05-07          NaN        1   42.0\n7          2  2021-05-08         11.0        2   11.0\n8          2  2021-05-09          NaN        2   11.0\n9          2  2021-05-10          NaN        2   11.0\n10         3  2021-07-11          NaN        0    NaN\n11         3  2021-07-12          NaN        0    NaN\n</code></pre>"},{"location":"blog/ffill-and-bfill-using-ibis/#bfill-strategy","title":"<code>bfill</code> Strategy","text":"<p>Instead of sorting the dates ascending, we will sort them descending. This is akin to starting at the last row in an event group and going backwards using the same logic outlined above.</p> <p>Let's take a look:</p> <pre><code>    event_id measured_on  measurement  grouper\n0          0  2021-06-01          NaN        1 # null, take the previous row value (NaN \u2192 5.0)\n1          0  2021-06-02          5.0        1 # last row, do nothing\n2          1  2021-05-05         42.0        1 # not null, do nothing\n3          1  2021-06-03          NaN        0 # null, take previous row value (NaN \u2192 NaN)\n4          1  2021-06-04          NaN        0 # last row, do nothing\n5          2  2021-05-06         42.0        2 # not null, do nothing\n6          2  2021-05-07          NaN        1 # null, take previous row value (NaN \u2192 11.0)\n7          2  2021-05-08         11.0        1 # not null, do nothing\n8          2  2021-05-09          NaN        0 # null, take previous row value (NaN \u2192 NaN)\n9          2  2021-05-10          NaN        0 # not null, do nothing\n10         3  2021-07-11          NaN        0 # null, take previous row value (NaN \u2192 NaN)\n11         3  2021-07-12          NaN        0 # last row, do nothing\n</code></pre> <p>Codewise, <code>bfill</code> follows the same strategy as <code>ffill</code>, we need to specify <code>order_by</code> to use <code>ibis.desc</code>. This will flip our dates and our counts (therefore our <code>grouper</code>s) will start backwards.</p> <pre><code>In [21]: win = ibis.window(group_by=data.event_id, order_by=ibis.desc(data.measured_on), following=0)\n\nIn [22]: grouped = data.mutate(grouper=data.measurement.count().over(win))\n\nIn [23]: grouped.execute().sort_values(by=['event_id', 'measured_on']).reset_index(drop=True)\nOut[23]:\n    event_id measured_on  measurement  grouper\n0          0  2021-06-01          NaN        1\n1          0  2021-06-02          5.0        1\n2          1  2021-05-05         42.0        1\n3          1  2021-06-03          NaN        0\n4          1  2021-06-04          NaN        0\n5          2  2021-05-06         42.0        2\n6          2  2021-05-07          NaN        1\n7          2  2021-05-08         11.0        1\n8          2  2021-05-09          NaN        0\n9          2  2021-05-10          NaN        0\n10         3  2021-07-11          NaN        0\n11         3  2021-07-12          NaN        0\n</code></pre> <p>And, again, if we take max of our <code>grouper</code> value, we will get the only non-null value if it exists:</p> <pre><code>In [24]: result = (\n    ...:     grouped\n    ...:     .group_by([grouped.event_id, grouped.grouper])\n    ...:     .mutate(bfill=grouped.measurement.max())\n    ...:     .execute()\n    ...: ).sort_values(by=['event_id', 'measured_on']).reset_index(drop=True)\n\nIn [25]: result\nOut[25]:\n    event_id measured_on  measurement  grouper  bfill\n0          0  2021-06-01          NaN        1    5.0\n1          0  2021-06-02          5.0        1    5.0\n2          1  2021-05-05         42.0        1   42.0\n3          1  2021-06-03          NaN        0    NaN\n4          1  2021-06-04          NaN        0    NaN\n5          2  2021-05-06         42.0        2   42.0\n6          2  2021-05-07          NaN        1   11.0\n7          2  2021-05-08         11.0        1   11.0\n8          2  2021-05-09          NaN        0    NaN\n9          2  2021-05-10          NaN        0    NaN\n10         3  2021-07-11          NaN        0    NaN\n11         3  2021-07-12          NaN        0    NaN\n</code></pre>"},{"location":"blog/ffill-and-bfill-using-ibis/#bfill-and-ffill-without-event-groups","title":"<code>bfill</code> and <code>ffill</code> without Event Groups","text":"<p>You can <code>bfill</code> and <code>ffill</code> without event groups by ignoring that grouping. Remove all references of <code>event_id</code> and you can treat the entire dataset as one event.</p> <p>Your window function will increment whenever a new non-null value is observed, creating that partition where each set has up to one non-null value.</p> <p>For example, reasoning through <code>bfill</code>:</p> <pre><code>In [26]: data.execute().sort_values(by=['measured_on'])\nOut[26]:\n    event_id measured_on  measurement\n4          1  2021-05-05         42.0 # not null, do nothing\n5          2  2021-05-06         42.0 # not null, do nothing\n6          2  2021-05-07          NaN # null, take previous value (NaN \u2192 11.0)\n7          2  2021-05-08         11.0 # not null, do nothing\n8          2  2021-05-09          NaN # null, take previous value (NaN \u2192 5.0)\n9          2  2021-05-10          NaN # null, take previous value (NaN \u2192 5.0)\n0          0  2021-06-01          NaN # null, take previous value (NaN \u2192 5.0)\n1          0  2021-06-02          5.0 # not null, do nothing\n2          1  2021-06-03          NaN # null, take previous value (NaN \u2192 NaN)\n3          1  2021-06-04          NaN # null, take previous value (NaN \u2192 NaN)\n10         3  2021-07-11          NaN # null, take previous value (NaN \u2192 NaN)\n11         3  2021-07-12          NaN # last row, do nothing\n\nIn [27]: win = ibis.window(order_by=ibis.desc(data.measured_on), following=0)\n\nIn [28]: grouped = data.mutate(grouper=data.measurement.count().over(win))\n\nIn [29]: result = (\n    ...:     grouped\n    ...:     .group_by([grouped.grouper])\n    ...:     .mutate(bfill=grouped.measurement.max())\n    ...: )\n\nIn [30]: result.execute().sort_values(by=['measured_on'])\nOut[30]:\n    event_id measured_on  measurement  grouper  bfill\n9          1  2021-05-05         42.0        4   42.0\n4          2  2021-05-06         42.0        3   42.0\n11         2  2021-05-07          NaN        2   11.0\n10         2  2021-05-08         11.0        2   11.0\n8          2  2021-05-09          NaN        1    5.0\n7          2  2021-05-10          NaN        1    5.0\n6          0  2021-06-01          NaN        1    5.0\n5          0  2021-06-02          5.0        1    5.0\n3          1  2021-06-03          NaN        0    NaN\n2          1  2021-06-04          NaN        0    NaN\n1          3  2021-07-11          NaN        0    NaN\n0          3  2021-07-12          NaN        0    NaN\n</code></pre> <p>As an exercise, try to take your time and reason your way through <code>ffill</code>.</p> <p>Happy coding!</p>"},{"location":"blog/ibis-examples/","title":"Ibis Sneak Peek: Examples","text":"<p>by Kae Suarez</p> <p>Ibis has been moving quickly to provide a powerful but easy-to-use interface for interacting with analytical engines. However, as we\u2019re approaching the 5.0 release of Ibis, we\u2019ve realized that moving from not knowing Ibis to writing a first expression is not trivial.</p> <p>As is, in our tutorial structure, work must be done on the user\u2019s part \u2014 though we do provide the commands \u2014 to download a SQLite database onto disk, which can only be used with said backend. We feel that this put too much emphasis on a single backend, and added too much effort into picking the right backend for the first tutorial. We want minimal steps between users and learning the Ibis API.</p> <p>This is why we\u2019ve added the <code>examples</code> module.</p>"},{"location":"blog/ibis-examples/#getting-started-with-examples","title":"Getting Started with Examples","text":"<p>This module offers in-Ibis access to multiple small tables (the largest is around only 30k rows), which are downloaded when requested and immediately read into the backend upon completion. We worked to keep pulling in examples simple, so it looks like this:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import ibis.examples as ex\n\n&gt;&gt;&gt; t = ex.penguins.fetch()\n&gt;&gt;&gt; t.head()\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 int64       \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502        3750 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502        3800 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502        3250 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502           \u2205 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502        3450 \u2502 female \u2502  2007 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Another advantage of this new method is that we were able to register all of them so you can tab-complete, as you can see here:</p> <p></p> <p>Once you\u2019ve retrieved an example table, you can get straight to learning and experimenting, instead of struggling with just getting the data itself.</p> <p>In the future, our tutorials will use the examples module to to help speed up learning of the Ibis framework.</p> <p>Interested in Ibis? Docs are available on this very website, at:</p> <ul> <li>Ibis Docs</li> </ul> <p>and the repo is always at:</p> <ul> <li>Ibis GitHub</li> </ul> <p>Please feel free to reach out on GitHub!</p>"},{"location":"blog/ibis-to-file/","title":"Ibis Sneak Peek: Writing to Files","text":"<p>by Kae Suarez</p> <p>Ibis 5.0 is coming soon and will offer new functionality and fixes to users. To enhance clarity around this process, we\u2019re sharing a sneak peek into what we\u2019re working on.</p> <p>In Ibis 4.0, we added the ability to read CSVs and Parquet via the Ibis interface. We felt this was important because, well, the ability to read files is simply necessary, be it on a local scale, legacy data, data not yet in a database, and so on. However, for a user, the natural next question was \u201ccan I go ahead and write when I\u2019m done?\u201d The answer was no. We didn\u2019t like that, especially since we do care about file-based use cases.</p> <p>So, we\u2019ve gone ahead and fixed that for Ibis 5.0.</p>"},{"location":"blog/ibis-to-file/#files-in-files-out","title":"Files in, Files out","text":"<p>Before we can write a file, we need data \u2014 so let\u2019s read in a file, to start this off:</p> <pre><code>t = ibis.read_csv(\n    \"https://storage.googleapis.com/ibis-examples/data/penguins.csv.gz\"\n)\n</code></pre> <p>Of course, we could just write out, but let\u2019s do an operation first \u2014 how about using selectors, which you can read more about here? Self-promotion aside, here\u2019s an operation:</p> <pre><code>expr = (\n    t.group_by(\"species\")\n     .mutate(s.across(s.numeric() &amp; ~s.c(\"year\"), (_ - _.mean()) / _.std()))\n)\n</code></pre> <p>Now, finally, time to do the exciting part:</p> <pre><code>expr.to_parquet(\"normalized.parquet\")\n</code></pre> <p>Like many things in Ibis, this is as simple and plain-looking as it is important. Being able to create files from Ibis instead of redirecting into other libraries first enables operation at larger scales and fewer steps. Where desired, you can address a backend directly to use its native export functionality \u2014 we want to make sure you have the flexibility to use Ibis or the backend as you see fit.</p>"},{"location":"blog/ibis-to-file/#wrapping-up","title":"Wrapping Up","text":"<p>Ibis is an interface tool for analytical engines that can reach scales far beyond a laptop. Files are important to Ibis because:</p> <ul> <li>Ibis also supports local execution, where files are the standard unit of data \u2014 we want to support all our users.</li> <li>Files are useful for moving between platforms, and long-term storage that isn\u2019t tied to a particular backend.</li> <li>Files can move more easily between our backends than database files, so we think this adds some convenience for the multi-backend use case.</li> </ul> <p>We\u2019re excited to release this functionality in Ibis 5.0.</p> <p>Interested in Ibis? Docs are available on this very website, at:</p> <ul> <li>Ibis Docs</li> </ul> <p>and the repo is always at:</p> <ul> <li>Ibis GitHub</li> </ul> <p>Please feel free to reach out on GitHub!</p>"},{"location":"blog/ibis-version-4.0.0-release/","title":"Ibis v4.0.0","text":"<p>by Patrick Clarke</p> <p>09 January 2023</p>"},{"location":"blog/ibis-version-4.0.0-release/#introduction","title":"Introduction","text":"<p>Ibis 4.0 has officially been released as the latest version of the package. This release includes several new backends, improved functionality, and some major internal refactors. A full list of the changes can be found in the project release notes. Let\u2019s talk about some of the new changes 4.0 brings for Ibis users.</p>"},{"location":"blog/ibis-version-4.0.0-release/#backends","title":"Backends","text":"<p>Ibis 4.0 brings Polars, Snowflake, and Trino into an already-impressive stock of supported backends. The Polars backend adds another way for users to work locally with DataFrames. The Snowflake and Trino backends add a free and familiar python API to popular data warehouses.</p> <p>Alongside these new backends, Google BigQuery and Microsoft SQL have been moved to the main repo, so their release cycle will follow the Ibis core.</p>"},{"location":"blog/ibis-version-4.0.0-release/#functionality","title":"Functionality","text":"<p>There are a lot of improvements incoming, but some notable changes include:</p> <ul> <li>read API: allows users to read various file formats directly into their configured <code>default_backend</code> (default DuckDB) through <code>read_*</code> functions, which makes working with local files easier than ever.</li> <li>to_pyarrow and to_pyarrow_batches: users can now return PyArrow objects (Tables, Arrays, Scalars, RecordBatchReader) and therefore grants all of the functionality that PyArrow provides</li> <li>JSON getitem: users can now run getitem on a JSON field using Ibis expressions with some backends</li> <li>Plotting support through <code>__array__</code>: allows users to plot Ibis expressions out of the box</li> </ul>"},{"location":"blog/ibis-version-4.0.0-release/#refactors","title":"Refactors","text":"<p>This won't be visible to most users, but the project underwent a series of refactors that spans multiple PRs. Notable changes include removing intermediate expressions, improving the testing framework, and UX updates.</p>"},{"location":"blog/ibis-version-4.0.0-release/#additional-changes","title":"Additional Changes","text":"<p>As mentioned previously, additional functionality, bugfixes, and more have been included in the latest 4.0 release. To stay up to date and learn more about recent changes: check out the project's homepage at ibis-project.org, follow @IbisData on Twitter, find the source code and community on GitHub, and join the discussion on Gitter.</p> <p>As always, try Ibis by installing it today.</p>"},{"location":"blog/ibis_substrait_to_duckdb/","title":"Ibis + Substrait + DuckDB","text":"<p>by Gil Forsyth</p> <p>Ibis strives to provide a consistent interface for interacting with a multitude of different analytical execution engines, most of which (but not all) speak some dialect of SQL.</p> <p>Today, Ibis accomplishes this with a lot of help from <code>sqlalchemy</code> and <code>sqlglot</code> to handle differences in dialect, or we interact directly with avalable Python bindings (for instance with the <code>pandas</code>, <code>datafusion</code>, and <code>polars</code> backends).</p> <p>Ibis goes to great lengths to generate sane and consistent SQL for those backends that use it. We are also interested in exploring other means of communicating consistently with those backends.</p> <p>Substrait is a new cross-language serialization format for communicating (among other things) query plans. It's still in its early days, but there is already nascent support for Substrait in Apache Arrow, DuckDB, and Velox.</p> <p>Ibis supports producing Substrait plans from Ibis expressions, with the help of the ibis-substrait library. Let's take a quick peek at how we might use it for query execution.</p>"},{"location":"blog/ibis_substrait_to_duckdb/#getting-started","title":"Getting started","text":"<p>First, we can create a <code>conda</code> environment using the latest versions of <code>duckdb</code>, <code>ibis</code>, and <code>ibis_substrait</code>.</p> <pre><code>mamba create -n ibis_substrait_duckdb ibis-framework==4.1 ibis-substrait==2.19 ipython python-duckdb parsy==2\n</code></pre> <p>Next, we'll need to choose a dataset. For this example, we'll use data from IMDB, available through their dataset portal.</p> <p>For convenience, I used Ready, Set, Data! to grab the data in <code>parquet</code> format and then insert it into a DuckDB database.</p> <pre><code>import duckdb\ncon = duckdb.connect(\"/home/gil/imdb.ddb\")\ncon.execute(\n    \"CREATE TABLE ratings AS SELECT * FROM '/home/gil/data/imdb/imdb_ratings.parquet'\"\n)\ncon.execute(\n    \"CREATE TABLE basics AS SELECT * FROM '/home/gil/data/imdb/imdb_basics.parquet'\"\n)\n</code></pre>"},{"location":"blog/ibis_substrait_to_duckdb/#query-creation","title":"Query Creation","text":"<p>For our example, we'll build up a query using Ibis but without connecting to our execution engine (DuckDB). Once we have an Ibis expression, we'll create a Substrait plan, then execute that plan directly on DuckDB to get results.</p> <p>To do this, all we need is some knowledge of the schema of the tables we want to interact with. We might get these schema from a metadata store, or possibly a coworker, or a friendly mouse.</p> <p>However we arrive at it, if we know the column names and the datatypes, we can build up a query in Ibis, so let's do that.</p> <pre><code>import ibis\nfrom ibis import _\n\nratings = ibis.table(\n    [\n        (\"tconst\", \"str\"),\n        (\"averageRating\", \"str\"),\n        (\"numVotes\", \"str\"),\n    ],\n    name=\"ratings\",\n)\n\nbasics = ibis.table(\n    [\n        (\"tconst\", \"str\"),\n        (\"titleType\", \"str\"),\n        (\"primaryTitle\", \"str\"),\n        (\"originalTitle\", \"str\"),\n        (\"isAdult\", \"str\"),\n        (\"startYear\", \"str\"),\n        (\"endYear\", \"str\"),\n        (\"runtimeMinutes\", \"str\"),\n        (\"genres\", \"str\"),\n    ],\n    name=\"basics\",\n)\n</code></pre> <p>Now that those tables are represented in Ibis, we can start creating our query. We'll try to recreate the top-ten movies on the IMDB leaderboard. For that, we'll need movie titles and their respective ratings.</p> <p>We know that the data we have for <code>ratings</code> looks something like the following:</p> <pre><code>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 tconst    \u2503 averageRating \u2503 numVotes \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 string        \u2502 string   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 tt0000001 \u2502 5.7           \u2502 1919\\n   \u2502\n\u2502 tt0000002 \u2502 5.8           \u2502 260\\n    \u2502\n\u2502 tt0000003 \u2502 6.5           \u2502 1726\\n   \u2502\n\u2502 tt0000004 \u2502 5.6           \u2502 173\\n    \u2502\n\u2502 tt0000005 \u2502 6.2           \u2502 2541\\n   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Based on the column names alone, <code>averageRating</code> is almost certainly supposed to be a <code>float</code>, and <code>numVotes</code> should be an <code>integer</code>. We can cast those so we can make useful comparisons between ratings and vote numbers.</p> <pre><code>ratings = ratings.select(\n    ratings.tconst,\n    avg_rating=ratings.averageRating.cast(\"float\"),\n    num_votes=ratings.numVotes.cast(\"int\"),\n)\n</code></pre> <p>The first few rows of <code>basics</code> looks like this:</p> <pre><code>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 tconst    \u2503 titleType \u2503 primaryTitle           \u2503 originalTitle          \u2503 isAdult \u2503 startYear \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string    \u2502 string    \u2502 string                 \u2502 string                 \u2502 string  \u2502 string    \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 tt0000001 \u2502 short     \u2502 Carmencita             \u2502 Carmencita             \u2502 0       \u2502 1894      \u2502 \u2026 \u2502\n\u2502 tt0000002 \u2502 short     \u2502 Le clown et ses chiens \u2502 Le clown et ses chiens \u2502 0       \u2502 1892      \u2502 \u2026 \u2502\n\u2502 tt0000003 \u2502 short     \u2502 Pauvre Pierrot         \u2502 Pauvre Pierrot         \u2502 0       \u2502 1892      \u2502 \u2026 \u2502\n\u2502 tt0000004 \u2502 short     \u2502 Un bon bock            \u2502 Un bon bock            \u2502 0       \u2502 1892      \u2502 \u2026 \u2502\n\u2502 tt0000005 \u2502 short     \u2502 Blacksmith Scene       \u2502 Blacksmith Scene       \u2502 0       \u2502 1893      \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>In the interest of keeping things family-friendly, we can filter out any adult films. We can filter out any IMDB titles that aren't movies, then select out the columns <code>tconst</code> and <code>primaryTitle</code>. And we'll include <code>startYear</code> just in case it's interesting.</p> <pre><code>basics = basics.filter([basics.titleType == \"movie\", basics.isAdult == \"0\"]).select(\n    \"tconst\",\n    \"primaryTitle\",\n    \"startYear\",\n)\n</code></pre> <p>With the data (lightly) cleaned up, we can construct our query for top films. We want to join the two tables <code>ratings</code> and <code>basics</code>. Then we'll order them by <code>avg_rating</code> and <code>num_votes</code>, and include an additional filter that the movie has to have at least 200,000 votes.</p> <pre><code>topfilms = (\n    ratings.join(basics, \"tconst\")\n    .order_by([_.avg_rating.desc(), _.num_votes.desc()])\n    .filter(_.num_votes &gt; 200_000)\n    .limit(10)\n)\n</code></pre> <p>Now that we have an Ibis expression, it's time for Substrait to enter the scene.</p>"},{"location":"blog/ibis_substrait_to_duckdb/#substrait-serialization","title":"Substrait Serialization","text":"<p>We're going to import <code>ibis_substrait</code> and compile the <code>topfilms</code> expression into a Substrait plan.</p> <pre><code>from ibis_substrait.compiler.core import SubstraitCompiler\n\ncompiler = SubstraitCompiler()\n\nplan = compiler.compile(topfilms)\n\n# type(plan) --&gt; &lt;class 'substrait.ibis.plan_pb2.Plan'&gt;\n</code></pre> <p>Substrait is built using <code>protobuf</code>. If you look at the <code>repr</code> for <code>plan</code>, you'll see a LOOOONG JSON-ish representation of the Substrait plan. This representation is not really meant for human eyes.</p> <p>We'll serialize the Substrait plan to disk and open it up in a separate session, or on another machine, entirely. That's one of the notions of Substrait: plans can be serialized and shuttled around between various systems. It's similar to Ibis in that it allows a separation of plan creation from plan execution.</p> <pre><code>with open(\"topfilms.proto\", \"wb\") as f:\n    f.write(plan.SerializeToString())\n</code></pre>"},{"location":"blog/ibis_substrait_to_duckdb/#substrait-plan-execution","title":"Substrait Plan Execution","text":"<p>Now we can open up the serialized Substrait plan in a new session where we execute it using DuckDB directly. One important point to note here is that our plan refers to two tables, named <code>basics</code> and <code>ratings</code>. If those tables don't exist in our execution engine, then this isn't going to work.</p> <pre><code>import duckdb\n\ncon = duckdb.connect(\"/home/gil/imdb.ddb\")\n\ncon.execute(\"PRAGMA show_tables;\").fetchall()\n</code></pre> basics ratings <p>Luckily, they do exist! Let's install and load the DuckDB Substrait extension, then execute the Substrait plan, and finally grab our results.</p> <pre><code>con.install_extension(\"substrait\")\ncon.load_extension(\"substrait\")\n\nwith open(\"topfilms.proto\", \"rb\") as f:\n    plan_blob = f.read()\n\nresult = con.from_substrait(plan_blob)\n\nresult.fetchall()\n</code></pre> tt0111161 9.3 2651547 The Shawshank Redemption 1994 tt0068646 9.2 1838044 The Godfather 1972 tt0468569 9.0 2623735 The Dark Knight 2008 tt0167260 9.0 1827464 The Lord of the Rings: The Return of the King 2003 tt0108052 9.0 1343647 Schindler's List 1993 tt0071562 9.0 1259465 The Godfather Part II 1974 tt0050083 9.0 782903 12 Angry Men 1957 tt0110912 8.9 2029684 Pulp Fiction 1994 tt1375666 8.8 2325417 Inception 2010 tt0137523 8.8 2096752 Fight Club 1999 <p>That looks about right to me. There may be some small differences with the current Top 10 list on IMDB if our data are a little stale.</p> <p>It's early days still for Substrait, but it's exciting to see how far it's come in the last 18 months!</p>"},{"location":"blog/ibis_substrait_to_duckdb/#why-wouldnt-i-just-use-sql-for-this","title":"Why wouldn't I just use SQL for this?","text":"<p>It's a fair question. SQL is everywhere, after all.</p> <p>There are a few reasons we think you shouldn't ignore Substrait.</p>"},{"location":"blog/ibis_substrait_to_duckdb/#standards","title":"Standards","text":"<p>SQL has a standard, but how closely do engines follow the standard? In our experience, queries don't translate well between engines (this is one reason Ibis exists!)</p>"},{"location":"blog/ibis_substrait_to_duckdb/#extensibility","title":"Extensibility","text":"<p>Substrait is more extensible than SQL. Some DBMS have added in some very cool features, but it usually involves diverging (sometimes widely) from the SQL standard. Substrait has an extension system that allows plan producers and plan consumers to agree on a well-typed and well-defined interaction that exists outside of the core Substrait specification.</p>"},{"location":"blog/ibis_substrait_to_duckdb/#serialization-and-parsing","title":"Serialization and parsing","text":"<p>Parsing SQL can be a big pain (trust us). If you send a big string over the wire, you need the engine on the other side to have a SQL parser to understand what the message is. Now, obviously, SQL engines have those. But here, again, standards (or lack of adherence to standards) can bite you. Extensibility is also difficult here, because now the SQL parser needs to understand some new custom syntax.</p> <p>Protobuf is hardly a dream to work with, but it's a lot easier to consistently define behavior AND to validate that behavior is correct. It's also smaller than raw text.</p>"},{"location":"blog/ibis_substrait_to_duckdb/#wrapping-up","title":"Wrapping Up","text":"<p>That's all for now! To quickly summarize:</p> <p>Substrait is a new standard for representing relational algebra queries with support in Apache Arrow, DuckDB, Velox, and more (and more to come!).</p> <p>Ibis can now generate substrait instead of string SQL, letting it take advantage of this new standard.</p> <p>Interested in substrait or ibis? Docs are available at</p> <ul> <li>Substrait</li> <li>Ibis Docs</li> </ul> <p>and the relevant GitHub repos are</p> <ul> <li>Substrait GitHub</li> <li>Ibis Substrait GitHub</li> <li>Ibis GitHub</li> </ul> <p>Please feel free to reach out on GitHub!</p>"},{"location":"blog/selectors/","title":"Maximizing Productivity with Selectors","text":"<p>Before Ibis 5.0 it's been challenging to concisely express whole-table operations with ibis. Happily this is no longer the case in ibis 5.0.</p> <p>Let's jump right in!</p> <p>We'll look at selectors examples using the <code>palmerpenguins</code> data set with the DuckDB backend.</p>"},{"location":"blog/selectors/#setup","title":"Setup","text":"<pre><code>In [8]: from ibis.interactive import *\n\nIn [11]: t = ex.penguins.fetch()\n\nIn [12]: t\nOut[12]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 int64       \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502        3750 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502        3800 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502        3250 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502           \u2205 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502        3450 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502        3650 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502        3625 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502        4675 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502        3475 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502        4250 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502           \u2026 \u2502 \u2026      \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"blog/selectors/#examples","title":"Examples","text":""},{"location":"blog/selectors/#normalization","title":"Normalization","text":"<p>Let's say you want to compute the z-score of every numeric column and replace the existing data with that normalized value. Here's how you'd do that with selectors:</p> <pre><code>In [13]: t.mutate(s.across(s.numeric(), (_ - _.mean()) / _.std()))\nOut[13]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 float64           \u2502 float64     \u2502 string \u2502 float64   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.883205 \u2502      0.784300 \u2502         -1.416272 \u2502   -0.563317 \u2502 male   \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.809939 \u2502      0.126003 \u2502         -1.060696 \u2502   -0.500969 \u2502 female \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.663408 \u2502      0.429833 \u2502         -0.420660 \u2502   -1.186793 \u2502 female \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502               nan \u2502         nan \u2502 \u2205      \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -1.322799 \u2502      1.088129 \u2502         -0.562890 \u2502   -0.937403 \u2502 female \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.846572 \u2502      1.746426 \u2502         -0.776236 \u2502   -0.688012 \u2502 male   \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.919837 \u2502      0.328556 \u2502         -1.416272 \u2502   -0.719186 \u2502 female \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.864888 \u2502      1.240044 \u2502         -0.420660 \u2502    0.590115 \u2502 male   \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -1.799025 \u2502      0.480471 \u2502         -0.562890 \u2502   -0.906229 \u2502 \u2205      \u2502 -1.257484 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.352029 \u2502      1.543873 \u2502         -0.776236 \u2502    0.060160 \u2502 \u2205      \u2502 -1.257484 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502           \u2026 \u2502 \u2026      \u2502         \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"blog/selectors/#whats-up-with-the-year-column","title":"What's Up With the <code>year</code> Column?","text":"<p>Whoops, looks like we included <code>year</code> in our normalization because it's an <code>int64</code> column (and therefore numeric) but normalizing the year doesn't make sense.</p> <p>We can exclude <code>year</code> from the normalization using another selector:</p> <pre><code>In [14]: t.mutate(s.across(s.numeric() &amp; ~s.c(\"year\"), (_ - _.mean()) / _.std()))\nOut[14]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 float64           \u2502 float64     \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.883205 \u2502      0.784300 \u2502         -1.416272 \u2502   -0.563317 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.809939 \u2502      0.126003 \u2502         -1.060696 \u2502   -0.500969 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.663408 \u2502      0.429833 \u2502         -0.420660 \u2502   -1.186793 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502               nan \u2502         nan \u2502 \u2205      \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -1.322799 \u2502      1.088129 \u2502         -0.562890 \u2502   -0.937403 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.846572 \u2502      1.746426 \u2502         -0.776236 \u2502   -0.688012 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.919837 \u2502      0.328556 \u2502         -1.416272 \u2502   -0.719186 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.864888 \u2502      1.240044 \u2502         -0.420660 \u2502    0.590115 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -1.799025 \u2502      0.480471 \u2502         -0.562890 \u2502   -0.906229 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      -0.352029 \u2502      1.543873 \u2502         -0.776236 \u2502    0.060160 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502           \u2026 \u2502 \u2026      \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p><code>c</code> is short for \"column\" and the <code>~</code> means \"negate\". Combining those we get \"not the year column\"!</p> <p>Pretty neat right?</p>"},{"location":"blog/selectors/#composable-group-by","title":"Composable Group By","text":"<p>The power of this approach comes in when you want the grouped version. Perhaps we think some of these columns vary by species.</p> <p>With selectors, all you need to do is slap a <code>.group_by(\"species\")</code> onto <code>t</code>:</p> <pre><code>In [18]: t.group_by(\"species\").mutate(\n    ...:     s.across(s.numeric() &amp; ~s.c(\"year\"), (_ - _.mean()) / _.std())\n    ...: )\nOut[18]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string \u2502 float64        \u2502 float64       \u2502 float64           \u2502 float64     \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Gentoo  \u2502 Biscoe \u2502      -0.455854 \u2502     -1.816223 \u2502         -0.954050 \u2502   -1.142626 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502      -0.975022 \u2502     -0.287513 \u2502         -0.491442 \u2502   -0.448342 \u2502 female \u2502  2009 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.387793 \u2502     -0.898997 \u2502         -1.108253 \u2502   -1.241809 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.809616 \u2502      0.222056 \u2502          0.125368 \u2502    1.237778 \u2502 male   \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.030865 \u2502     -0.491341 \u2502         -0.337240 \u2502    0.642677 \u2502 male   \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502      -0.326062 \u2502     -1.510481 \u2502         -1.108253 \u2502   -1.043442 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502      -0.682990 \u2502     -0.389427 \u2502         -0.954050 \u2502   -0.547525 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502      -0.261167 \u2502      0.323970 \u2502          0.279571 \u2502    0.245943 \u2502 male   \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502      -1.364397 \u2502     -1.612395 \u2502         -1.262455 \u2502   -1.340993 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502      -0.228719 \u2502      0.425884 \u2502         -0.337240 \u2502    0.146759 \u2502 male   \u2502  2007 \u2502\n\u2502 \u2026       \u2502 \u2026      \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502           \u2026 \u2502 \u2026      \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Since ibis translates this into a run-of-the-mill selection as if you had called <code>select</code> or <code>mutate</code> without selectors, nothing special is needed for a backend to work with these new constructs.</p> <p>Let's look at some more examples.</p>"},{"location":"blog/selectors/#min-max-normalization","title":"Min-max Normalization","text":"<p>Grouped min/max normalization? Easy:</p> <pre><code>In [22]: t.group_by(\"species\").mutate(\n    ...:     s.across(s.numeric() &amp; ~s.c(\"year\"), (_ - _.min()) / (_.max() - _.min()))\n    ...: )\nOut[22]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string \u2502 float64        \u2502 float64       \u2502 float64           \u2502 float64     \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.278075 \u2502      0.023810 \u2502          0.285714 \u2502    0.234043 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.192513 \u2502      0.380952 \u2502          0.392857 \u2502    0.382979 \u2502 female \u2502  2009 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.417112 \u2502      0.238095 \u2502          0.250000 \u2502    0.212766 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.486631 \u2502      0.500000 \u2502          0.535714 \u2502    0.744681 \u2502 male   \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.358289 \u2502      0.333333 \u2502          0.428571 \u2502    0.617021 \u2502 male   \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.299465 \u2502      0.095238 \u2502          0.250000 \u2502    0.255319 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.240642 \u2502      0.357143 \u2502          0.285714 \u2502    0.361702 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.310160 \u2502      0.523810 \u2502          0.571429 \u2502    0.531915 \u2502 male   \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.128342 \u2502      0.071429 \u2502          0.214286 \u2502    0.191489 \u2502 female \u2502  2007 \u2502\n\u2502 Gentoo  \u2502 Biscoe \u2502       0.315508 \u2502      0.547619 \u2502          0.428571 \u2502    0.510638 \u2502 male   \u2502  2007 \u2502\n\u2502 \u2026       \u2502 \u2026      \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502           \u2026 \u2502 \u2026      \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"blog/selectors/#casting-and-munging","title":"Casting and Munging","text":"<p>How about casting every column whose name ends with any of the strings <code>\"mm\"</code> or <code>\"g\"</code> to a <code>float32</code>? No problem!</p> <pre><code>In [23]: t.mutate(s.across(s.endswith((\"mm\", \"g\")), _.cast(\"float32\")))\nOut[23]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float32        \u2502 float32       \u2502 float32           \u2502 float32     \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502 Torgersen \u2502      39.099998 \u2502     18.700001 \u2502             181.0 \u2502      3750.0 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      39.500000 \u2502     17.400000 \u2502             186.0 \u2502      3800.0 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      40.299999 \u2502     18.000000 \u2502             195.0 \u2502      3250.0 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502            nan \u2502           nan \u2502               nan \u2502         nan \u2502 \u2205      \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      36.700001 \u2502     19.299999 \u2502             193.0 \u2502      3450.0 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      39.299999 \u2502     20.600000 \u2502             190.0 \u2502      3650.0 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      38.900002 \u2502     17.799999 \u2502             181.0 \u2502      3625.0 \u2502 female \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      39.200001 \u2502     19.600000 \u2502             195.0 \u2502      4675.0 \u2502 male   \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      34.099998 \u2502     18.100000 \u2502             193.0 \u2502      3475.0 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502      42.000000 \u2502     20.200001 \u2502             190.0 \u2502      4250.0 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502           \u2026 \u2502 \u2026      \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>We can make all string columns have the same case too!</p> <pre><code>In [35]: t.mutate(s.across(s.of_type(\"string\"), _.lower()))\nOut[35]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 year  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 int64       \u2502 string \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 adelie  \u2502 torgersen \u2502           39.1 \u2502          18.7 \u2502               181 \u2502        3750 \u2502 male   \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502           39.5 \u2502          17.4 \u2502               186 \u2502        3800 \u2502 female \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502           40.3 \u2502          18.0 \u2502               195 \u2502        3250 \u2502 female \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502            nan \u2502           nan \u2502                 \u2205 \u2502           \u2205 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502           36.7 \u2502          19.3 \u2502               193 \u2502        3450 \u2502 female \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502           39.3 \u2502          20.6 \u2502               190 \u2502        3650 \u2502 male   \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502           38.9 \u2502          17.8 \u2502               181 \u2502        3625 \u2502 female \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502           39.2 \u2502          19.6 \u2502               195 \u2502        4675 \u2502 male   \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502           34.1 \u2502          18.1 \u2502               193 \u2502        3475 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 adelie  \u2502 torgersen \u2502           42.0 \u2502          20.2 \u2502               190 \u2502        4250 \u2502 \u2205      \u2502  2007 \u2502\n\u2502 \u2026       \u2502 \u2026         \u2502              \u2026 \u2502             \u2026 \u2502                 \u2026 \u2502           \u2026 \u2502 \u2026      \u2502     \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"blog/selectors/#multiple-computations-per-column","title":"Multiple Computations per Column","text":"<p>What if I want to compute multiple things? Heck yeah!</p> <pre><code>In [9]: t.group_by(\"sex\").mutate(\n   ...:     s.across(\n   ...:         s.numeric() &amp; ~s.c(\"year\"),\n   ...:         dict(centered=_ - _.mean(), zscore=(_ - _.mean()) / _.std()),\n   ...:     )\n   ...: ).select(\"sex\", s.endswith((\"_centered\", \"_zscore\")))\nOut[9]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 sex    \u2503 bill_length_mm_centered \u2503 bill_depth_mm_centered \u2503 flipper_length_mm_centered \u2503 body_mass_g_centered \u2503 bill_length_mm_zscore \u2503 bill_depth_mm_zscore \u2503 flipper_length_mm_zscore \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string \u2502 float64                 \u2502 float64                \u2502 float64                    \u2502 float64              \u2502 float64               \u2502 float64              \u2502 float64                  \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 male   \u2502                0.445238 \u2502              -2.091071 \u2502                  10.494048 \u2502           504.315476 \u2502              0.082960 \u2502            -1.122210 \u2502                 0.721346 \u2502 \u2026 \u2502\n\u2502 male   \u2502                2.245238 \u2502              -2.791071 \u2502                   4.494048 \u2502           954.315476 \u2502              0.418349 \u2502            -1.497878 \u2502                 0.308914 \u2502 \u2026 \u2502\n\u2502 male   \u2502               -6.254762 \u2502               0.208929 \u2502                 -18.505952 \u2502           -95.684524 \u2502             -1.165434 \u2502             0.112125 \u2502                -1.272072 \u2502 \u2026 \u2502\n\u2502 male   \u2502               -5.054762 \u2502               1.008929 \u2502                   3.494048 \u2502          -245.684524 \u2502             -0.941841 \u2502             0.541459 \u2502                 0.240176 \u2502 \u2026 \u2502\n\u2502 male   \u2502              -11.254762 \u2502               3.208929 \u2502                  -6.505952 \u2502          -145.684524 \u2502             -2.097071 \u2502             1.722128 \u2502                -0.447210 \u2502 \u2026 \u2502\n\u2502 male   \u2502               -3.354762 \u2502               2.808929 \u2502                  -7.505952 \u2502           -45.684524 \u2502             -0.625084 \u2502             1.507461 \u2502                -0.515948 \u2502 \u2026 \u2502\n\u2502 male   \u2502                0.145238 \u2502               3.608929 \u2502                 -10.505952 \u2502          -345.684524 \u2502              0.027062 \u2502             1.936795 \u2502                -0.722164 \u2502 \u2026 \u2502\n\u2502 male   \u2502               -8.154762 \u2502               0.808929 \u2502                 -24.505952 \u2502          -945.684524 \u2502             -1.519456 \u2502             0.434126 \u2502                -1.684504 \u2502 \u2026 \u2502\n\u2502 male   \u2502               -7.654762 \u2502               0.208929 \u2502                 -19.505952 \u2502          -595.684524 \u2502             -1.426292 \u2502             0.112125 \u2502                -1.340811 \u2502 \u2026 \u2502\n\u2502 male   \u2502               -7.054762 \u2502              -0.691071 \u2502                 -24.505952 \u2502          -745.684524 \u2502             -1.314496 \u2502            -0.370876 \u2502                -1.684504 \u2502 \u2026 \u2502\n\u2502 \u2026      \u2502                       \u2026 \u2502                      \u2026 \u2502                          \u2026 \u2502                    \u2026 \u2502                     \u2026 \u2502                    \u2026 \u2502                        \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</code></pre> <p>Don't like the naming convention?</p> <p>Pass a function to make your own name!</p> <pre><code>In [12]: t.select(s.startswith(\"bill\")).mutate(\n    ...:     s.across(\n    ...:         s.all(),\n    ...:         dict(x=_ - _.mean(), y=_.max()),\n    ...:         names=lambda col, fn: f\"{col}_{fn}_improved\",\n    ...:     )\n    ...: )\nOut[12]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 bill_length_mm \u2503 bill_depth_mm \u2503 bill_length_mm_x_improved \u2503 bill_depth_mm_x_improved \u2503 bill_length_mm_y_improved \u2503 bill_depth_mm_y_improved \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64        \u2502 float64       \u2502 float64                   \u2502 float64                  \u2502 float64                   \u2502 float64                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502           39.1 \u2502          18.7 \u2502                  -4.82193 \u2502                  1.54883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           39.5 \u2502          17.4 \u2502                  -4.42193 \u2502                  0.24883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           40.3 \u2502          18.0 \u2502                  -3.62193 \u2502                  0.84883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502            nan \u2502           nan \u2502                       nan \u2502                      nan \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           36.7 \u2502          19.3 \u2502                  -7.22193 \u2502                  2.14883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           39.3 \u2502          20.6 \u2502                  -4.62193 \u2502                  3.44883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           38.9 \u2502          17.8 \u2502                  -5.02193 \u2502                  0.64883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           39.2 \u2502          19.6 \u2502                  -4.72193 \u2502                  2.44883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           34.1 \u2502          18.1 \u2502                  -9.82193 \u2502                  0.94883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           42.0 \u2502          20.2 \u2502                  -1.92193 \u2502                  3.04883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502              \u2026 \u2502             \u2026 \u2502                         \u2026 \u2502                        \u2026 \u2502                         \u2026 \u2502                        \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Don't like lambda functions? We support a format string too!</p> <pre><code>In [5]: t.select(s.startswith(\"bill\")).mutate(\n   ...:     s.across(\n   ...:         s.all(),\n   ...:         func=dict(x=_ - _.mean(), y=_.max()),\n   ...:         names=\"{col}_{fn}_improved\",\n   ...:     )\n   ...: ).head(2)\nOut[5]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 bill_length_mm \u2503 bill_depth_mm \u2503 bill_length_mm_x_improved \u2503 bill_depth_mm_x_improved \u2503 bill_length_mm_y_improved \u2503 bill_depth_mm_y_improved \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 float64        \u2502 float64       \u2502 float64                   \u2502 float64                  \u2502 float64                   \u2502 float64                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502           39.1 \u2502          18.7 \u2502                  -4.82193 \u2502                  1.54883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2502           39.5 \u2502          17.4 \u2502                  -4.42193 \u2502                  0.24883 \u2502                      59.6 \u2502                     21.5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"blog/selectors/#working-with-other-ibis-apis","title":"Working with other Ibis APIs","text":"<p>We've seen lots of mutate use, but selectors also work with <code>.agg</code>:</p> <pre><code>In [31]: t.group_by(\"year\").agg(s.across(s.numeric() &amp; ~s.c(\"year\"), _.mean())).order_by(\"year\")\nOut[31]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 year  \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 float64        \u2502 float64       \u2502 float64           \u2502 float64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  2007 \u2502      43.740367 \u2502     17.427523 \u2502        196.880734 \u2502 4124.541284 \u2502\n\u2502  2008 \u2502      43.541228 \u2502     16.914035 \u2502        202.798246 \u2502 4266.666667 \u2502\n\u2502  2009 \u2502      44.452941 \u2502     17.125210 \u2502        202.806723 \u2502 4210.294118 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Naturally, selectors work in grouping keys too, for even more convenience:</p> <pre><code>In [12]: t.group_by(~s.numeric() | s.c(\"year\")).mutate(\n    ...:     s.across(s.numeric() &amp; ~s.c(\"year\"), dict(centered=_ - _.mean(), std=_.std()))\n    ...: ).select(\"species\", s.endswith((\"_centered\", \"_std\")))\nOut[12]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 bill_length_mm_centered \u2503 bill_depth_mm_centered \u2503 flipper_length_mm_centered \u2503 body_mass_g_centered \u2503 bill_length_mm_std \u2503 bill_depth_mm_std \u2503 flipper_length_mm_std \u2503 body_mass_g_std \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 float64                 \u2502 float64                \u2502 float64                    \u2502 float64              \u2502 float64            \u2502 float64           \u2502 float64               \u2502 float64         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Adelie  \u2502                1.187500 \u2502               1.412500 \u2502                       -1.0 \u2502          -550.000000 \u2502           2.087676 \u2502          0.756755 \u2502              7.764388 \u2502      311.677489 \u2502\n\u2502 Adelie  \u2502               -3.812500 \u2502               0.612500 \u2502                       -5.0 \u2502          -300.000000 \u2502           2.087676 \u2502          0.756755 \u2502              7.764388 \u2502      311.677489 \u2502\n\u2502 Adelie  \u2502               -1.812500 \u2502               0.312500 \u2502                       -6.0 \u2502          -150.000000 \u2502           2.087676 \u2502          0.756755 \u2502              7.764388 \u2502      311.677489 \u2502\n\u2502 Adelie  \u2502                0.987500 \u2502              -0.787500 \u2502                       10.0 \u2502           200.000000 \u2502           2.087676 \u2502          0.756755 \u2502              7.764388 \u2502      311.677489 \u2502\n\u2502 Adelie  \u2502               -0.512500 \u2502              -0.787500 \u2502                       -9.0 \u2502           350.000000 \u2502           2.087676 \u2502          0.756755 \u2502              7.764388 \u2502      311.677489 \u2502\n\u2502 Adelie  \u2502                0.687500 \u2502               0.012500 \u2502                       13.0 \u2502           200.000000 \u2502           2.087676 \u2502          0.756755 \u2502              7.764388 \u2502      311.677489 \u2502\n\u2502 Adelie  \u2502                0.187500 \u2502              -0.387500 \u2502                        1.0 \u2502           250.000000 \u2502           2.087676 \u2502          0.756755 \u2502              7.764388 \u2502      311.677489 \u2502\n\u2502 Adelie  \u2502                3.087500 \u2502              -0.387500 \u2502                       -3.0 \u2502             0.000000 \u2502           2.087676 \u2502          0.756755 \u2502              7.764388 \u2502      311.677489 \u2502\n\u2502 Adelie  \u2502                1.644444 \u2502              -1.144444 \u2502                       -7.0 \u2502           -19.444444 \u2502           2.119028 \u2502          0.860394 \u2502              5.408327 \u2502      170.375403 \u2502\n\u2502 Adelie  \u2502                1.644444 \u2502              -0.044444 \u2502                        3.0 \u2502            30.555556 \u2502           2.119028 \u2502          0.860394 \u2502              5.408327 \u2502      170.375403 \u2502\n\u2502 \u2026       \u2502                       \u2026 \u2502                      \u2026 \u2502                          \u2026 \u2502                    \u2026 \u2502                  \u2026 \u2502                 \u2026 \u2502                     \u2026 \u2502               \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"blog/selectors/#filtering-selectors","title":"Filtering Selectors","text":"<p>You can also express complex filters more concisely.</p> <p>Let's say we only want to keep rows where all the bill size z-score related columns' absolute values are greater than 2.</p> <pre><code>In [78]: t.drop(\"year\").group_by(\"species\").mutate(\n    ...:     s.across(s.numeric(), dict(zscore=(_ - _.mean()) / _.std()))\n    ...: ).filter(s.if_all(s.startswith(\"bill\") &amp; s.endswith(\"_zscore\"), _.abs() &gt; 2))\nOut[78]:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 species \u2503 island    \u2503 bill_length_mm \u2503 bill_depth_mm \u2503 flipper_length_mm \u2503 body_mass_g \u2503 sex    \u2503 bill_length_mm_zscore \u2503 bill_depth_mm_zscore \u2503 flipper_length_mm_zscore \u2503 body_mass_g_zscore \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 string  \u2502 string    \u2502 float64        \u2502 float64       \u2502 int64             \u2502 int64       \u2502 string \u2502 float64               \u2502 float64              \u2502 float64                  \u2502 float64            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Gentoo  \u2502 Biscoe    \u2502           59.6 \u2502          17.0 \u2502               230 \u2502        6050 \u2502 male   \u2502              3.924621 \u2502             2.056508 \u2502                 1.975799 \u2502           1.932062 \u2502\n\u2502 Gentoo  \u2502 Biscoe    \u2502           55.9 \u2502          17.0 \u2502               228 \u2502        5600 \u2502 male   \u2502              2.724046 \u2502             2.056508 \u2502                 1.667394 \u2502           1.039411 \u2502\n\u2502 Adelie  \u2502 Torgersen \u2502           46.0 \u2502          21.5 \u2502               194 \u2502        4200 \u2502 male   \u2502              2.706539 \u2502             2.592071 \u2502                 0.618760 \u2502           1.088911 \u2502\n\u2502 Adelie  \u2502 Dream     \u2502           32.1 \u2502          15.5 \u2502               188 \u2502        3050 \u2502 female \u2502             -2.512345 \u2502            -2.339505 \u2502                -0.298747 \u2502          -1.418906 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518```\n</code></pre>"},{"location":"blog/selectors/#bonus-generated-sql","title":"Bonus: Generated SQL","text":"<p>The SQL for that last expression is pretty gnarly:</p> <pre><code>In [79]: ibis.show_sql(\n    ...:     t.drop(\"year\")\n    ...:     .group_by(\"species\")\n    ...:     .mutate(s.across(s.numeric(), dict(zscore=(_ - _.mean()) / _.std())))\n    ...:     .filter(s.if_all(s.startswith(\"bill\") &amp; s.endswith(\"_zscore\"), _.abs() &gt; 2))\n    ...: )\n</code></pre> <pre><code>WITH t0 AS (\nSELECT\nt2.species AS species,\nt2.island AS island,\nt2.bill_length_mm AS bill_length_mm,\nt2.bill_depth_mm AS bill_depth_mm,\nt2.flipper_length_mm AS flipper_length_mm,\nt2.body_mass_g AS body_mass_g,\nt2.sex AS sex\nFROM ibis_read_csv_3 AS t2\n), t1 AS (\nSELECT\nt0.species AS species,\nt0.island AS island,\nt0.bill_length_mm AS bill_length_mm,\nt0.bill_depth_mm AS bill_depth_mm,\nt0.flipper_length_mm AS flipper_length_mm,\nt0.body_mass_g AS body_mass_g,\nt0.sex AS sex,\n(\nt0.bill_length_mm - AVG(t0.bill_length_mm) OVER (PARTITION BY t0.species ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)\n) / STDDEV_SAMP(t0.bill_length_mm) OVER (PARTITION BY t0.species ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS bill_length_mm_zscore,\n(\nt0.bill_depth_mm - AVG(t0.bill_depth_mm) OVER (PARTITION BY t0.species ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)\n) / STDDEV_SAMP(t0.bill_depth_mm) OVER (PARTITION BY t0.species ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS bill_depth_mm_zscore,\n(\nt0.flipper_length_mm - AVG(t0.flipper_length_mm) OVER (PARTITION BY t0.species ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)\n) / STDDEV_SAMP(t0.flipper_length_mm) OVER (PARTITION BY t0.species ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS flipper_length_mm_zscore,\n(\nt0.body_mass_g - AVG(t0.body_mass_g) OVER (PARTITION BY t0.species ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)\n) / STDDEV_SAMP(t0.body_mass_g) OVER (PARTITION BY t0.species ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS body_mass_g_zscore\nFROM t0\n)\nSELECT\nt1.species,\nt1.island,\nt1.bill_length_mm,\nt1.bill_depth_mm,\nt1.flipper_length_mm,\nt1.body_mass_g,\nt1.sex,\nt1.bill_length_mm_zscore,\nt1.bill_depth_mm_zscore,\nt1.flipper_length_mm_zscore,\nt1.body_mass_g_zscore\nFROM t1\nWHERE\nABS(t1.bill_length_mm_zscore) &gt; CAST(2 AS SMALLINT)\nAND ABS(t1.bill_depth_mm_zscore) &gt; CAST(2 AS SMALLINT)\n</code></pre> <p>Good thing you didn't have to write that by hand!</p>"},{"location":"blog/selectors/#summary","title":"Summary","text":"<p>This blog post illustrates the ability to apply computations to many columns at once and the power of ibis as a composable, expressive library for analytics.</p> <ul> <li>Get involved!</li> <li>Report issues!</li> </ul>"},{"location":"blog/rendered/ci-analysis/","title":"Analysis of Ibis's CI Performance","text":"In\u00a0[2]: Copied! <pre>import ibis\nfrom ibis import _\n\nibis.options.interactive = True\n</pre> import ibis from ibis import _  ibis.options.interactive = True In\u00a0[3]: Copied! <pre>url = \"bigquery://ibis-gbq/workflows\"\ncon = ibis.connect(url)\n</pre> url = \"bigquery://ibis-gbq/workflows\" con = ibis.connect(url) <p>Let's see what tables are available.</p> In\u00a0[4]: Copied! <pre>con.list_tables()\n</pre> con.list_tables() Out[4]: <pre>['analysis', 'jobs', 'workflows']</pre> In\u00a0[5]: Copied! <pre>jobs = con.tables.jobs\n</pre> jobs = con.tables.jobs In\u00a0[6]: Copied! <pre>jobs\n</pre> jobs Out[6]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 url                       \u2503 steps                     \u2503 status    \u2503 started_at          \u2503 runner_group_name \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502                           \u2502 array&lt;struct&lt;status:      \u2502           \u2502                     \u2502                   \u2502   \u2502\n\u2502 string                    \u2502 string, conclusion:       \u2502 string    \u2502 timestamp           \u2502 string            \u2502 \u2026 \u2502\n\u2502                           \u2502 string, started_at:       \u2502           \u2502                     \u2502                   \u2502   \u2502\n\u2502                           \u2502 timestamp, number:\u2026       \u2502           \u2502                     \u2502                   \u2502   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +12]   \u2502 completed \u2502 2020-08-04 23:54:37 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +5]    \u2502 completed \u2502 2020-08-04 23:54:37 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +5]    \u2502 completed \u2502 2020-08-04 23:51:54 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +12]   \u2502 completed \u2502 2020-08-04 23:51:53 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +11]   \u2502 completed \u2502 2020-08-04 23:50:19 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +5]    \u2502 completed \u2502 2020-08-04 23:50:20 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +5]    \u2502 completed \u2502 2020-08-04 23:39:58 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +9]    \u2502 completed \u2502 2020-08-04 23:39:57 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +9]    \u2502 completed \u2502 2020-08-04 23:34:19 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502 [{...}, {...}, ... +5]    \u2502 completed \u2502 2020-08-04 23:34:19 \u2502 \u2205                 \u2502 \u2026 \u2502\n\u2502 \u2026                         \u2502 \u2026                         \u2502 \u2026         \u2502 \u2026                   \u2502 \u2026                 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</pre> <p>These first few columns in the <code>jobs</code> table aren't that interesting so we should look at what else is there</p> In\u00a0[7]: Copied! <pre>jobs.columns\n</pre> jobs.columns Out[7]: <pre>['url',\n 'steps',\n 'status',\n 'started_at',\n 'runner_group_name',\n 'run_attempt',\n 'name',\n 'labels',\n 'node_id',\n 'id',\n 'runner_id',\n 'run_url',\n 'run_id',\n 'check_run_url',\n 'html_url',\n 'runner_name',\n 'runner_group_id',\n 'head_sha',\n 'conclusion',\n 'completed_at']</pre> <p>A bunch of these aren't that useful for our purposes. However, <code>run_id</code>, <code>started_at</code>, <code>completed_at</code> are useful for us. The GitHub documentation for job information provides useful detail about the meaning of these fields.</p> <ul> <li><code>run_id</code>: the workflow run associated with this job run</li> <li><code>started_at</code>: when the job started</li> <li><code>completed_at</code>: when the job completed</li> </ul> <p>What we're interested in to a first degree is the job duration, so let's compute that.</p> <p>We also need to compute when the last job for a given <code>run_id</code> started and when it completed. We'll use the former to compute the queueing duration, and the latter to compute the total time it took for a given workflow run to complete.</p> In\u00a0[8]: Copied! <pre>run_id_win = ibis.window(group_by=_.run_id)\njobs = jobs.select(\n    _.run_id,\n    job_duration=_.completed_at.cast(\"int\") - _.started_at.cast(\"int\"),\n    last_job_started_at=_.started_at.max().over(run_id_win),\n    last_job_completed_at=_.completed_at.max().over(run_id_win),\n)\njobs\n</pre> run_id_win = ibis.window(group_by=_.run_id) jobs = jobs.select(     _.run_id,     job_duration=_.completed_at.cast(\"int\") - _.started_at.cast(\"int\"),     last_job_started_at=_.started_at.max().over(run_id_win),     last_job_completed_at=_.completed_at.max().over(run_id_win), ) jobs Out[8]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 run_id    \u2503 job_duration \u2503 last_job_started_at \u2503 last_job_completed_at \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64     \u2502 int64        \u2502 timestamp           \u2502 timestamp             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 199092057 \u2502   3148000000 \u2502 2020-08-07 11:24:05 \u2502 2020-08-07 12:16:33   \u2502\n\u2502 202720732 \u2502     68000000 \u2502 2020-08-10 15:42:13 \u2502 2020-08-10 16:31:20   \u2502\n\u2502 202720732 \u2502   2947000000 \u2502 2020-08-10 15:42:13 \u2502 2020-08-10 16:31:20   \u2502\n\u2502 240931982 \u2502    943000000 \u2502 2020-09-05 20:52:43 \u2502 2020-09-05 20:52:43   \u2502\n\u2502 240931982 \u2502    648000000 \u2502 2020-09-05 20:52:43 \u2502 2020-09-05 20:52:43   \u2502\n\u2502 240931982 \u2502    562000000 \u2502 2020-09-05 20:52:43 \u2502 2020-09-05 20:52:43   \u2502\n\u2502 240931982 \u2502    421000000 \u2502 2020-09-05 20:52:43 \u2502 2020-09-05 20:52:43   \u2502\n\u2502 240931982 \u2502    469000000 \u2502 2020-09-05 20:52:43 \u2502 2020-09-05 20:52:43   \u2502\n\u2502 240931982 \u2502   3244000000 \u2502 2020-09-05 20:52:43 \u2502 2020-09-05 20:52:43   \u2502\n\u2502 240931982 \u2502            0 \u2502 2020-09-05 20:52:43 \u2502 2020-09-05 20:52:43   \u2502\n\u2502         \u2026 \u2502            \u2026 \u2502 \u2026                   \u2502 \u2026                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Let's take a look at <code>workflows</code></p> In\u00a0[9]: Copied! <pre>workflows = con.tables.workflows\n</pre> workflows = con.tables.workflows In\u00a0[10]: Copied! <pre>workflows\n</pre> workflows Out[10]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 workflow_url              \u2503 workflow_id \u2503 triggering_actor \u2503 run_number \u2503 run_attempt \u2503 updated_at          \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 string                    \u2502 int64       \u2502 struct&lt;subscrip\u2026 \u2502 int64      \u2502 int64       \u2502 timestamp           \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502         13 \u2502           1 \u2502 2020-08-04 23:57:03 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502         12 \u2502           1 \u2502 2020-08-04 23:55:08 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502         11 \u2502           1 \u2502 2020-08-04 23:52:58 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502         10 \u2502           1 \u2502 2020-08-04 23:42:41 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502          9 \u2502           1 \u2502 2020-08-04 23:36:32 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502          8 \u2502           1 \u2502 2020-08-04 23:31:43 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502          7 \u2502           1 \u2502 2020-08-04 23:19:50 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502          6 \u2502           1 \u2502 2020-08-04 23:14:16 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502          5 \u2502           1 \u2502 2020-08-04 23:05:14 \u2502 \u2026 \u2502\n\u2502 https://api.github.com/r\u2026 \u2502     2100986 \u2502 \u2205                \u2502          4 \u2502           1 \u2502 2020-08-04 23:01:32 \u2502 \u2026 \u2502\n\u2502 \u2026                         \u2502           \u2026 \u2502 \u2026                \u2502          \u2026 \u2502           \u2026 \u2502 \u2026                   \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</pre> <p>Again we have a bunch of columns that aren't so useful to us, so let's see what else is there.</p> In\u00a0[11]: Copied! <pre>workflows.columns\n</pre> workflows.columns Out[11]: <pre>['workflow_url',\n 'workflow_id',\n 'triggering_actor',\n 'run_number',\n 'run_attempt',\n 'updated_at',\n 'cancel_url',\n 'rerun_url',\n 'check_suite_node_id',\n 'pull_requests',\n 'id',\n 'node_id',\n 'status',\n 'repository',\n 'jobs_url',\n 'previous_attempt_url',\n 'artifacts_url',\n 'html_url',\n 'head_sha',\n 'head_repository',\n 'run_started_at',\n 'head_branch',\n 'url',\n 'event',\n 'name',\n 'actor',\n 'created_at',\n 'check_suite_url',\n 'check_suite_id',\n 'conclusion',\n 'head_commit',\n 'logs_url']</pre> <p>We don't care about many of these for the purposes of this analysis, however we need the <code>id</code> and a few values derived from the <code>run_started_at</code> column.</p> <ul> <li><code>id</code>: the unique identifier of the workflow run</li> <li><code>run_started_at</code>: the time the workflow run started</li> </ul> <p>We compute the date the run started at so we can later compare it to the dates where we added poetry and switched to the team plan.</p> In\u00a0[12]: Copied! <pre>workflows = workflows.select(\n    _.id, _.run_started_at, started_date=_.run_started_at.date()\n)\nworkflows\n</pre> workflows = workflows.select(     _.id, _.run_started_at, started_date=_.run_started_at.date() ) workflows Out[12]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 id        \u2503 run_started_at      \u2503 started_date \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64     \u2502 timestamp           \u2502 date         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 195478382 \u2502 2020-08-04 23:54:29 \u2502 2020-08-04   \u2502\n\u2502 195476517 \u2502 2020-08-04 23:51:44 \u2502 2020-08-04   \u2502\n\u2502 195475525 \u2502 2020-08-04 23:50:11 \u2502 2020-08-04   \u2502\n\u2502 195468677 \u2502 2020-08-04 23:39:51 \u2502 2020-08-04   \u2502\n\u2502 195465343 \u2502 2020-08-04 23:34:11 \u2502 2020-08-04   \u2502\n\u2502 195460611 \u2502 2020-08-04 23:29:07 \u2502 2020-08-04   \u2502\n\u2502 195452505 \u2502 2020-08-04 23:17:29 \u2502 2020-08-04   \u2502\n\u2502 195447886 \u2502 2020-08-04 23:11:35 \u2502 2020-08-04   \u2502\n\u2502 195435521 \u2502 2020-08-04 23:02:34 \u2502 2020-08-04   \u2502\n\u2502 195433385 \u2502 2020-08-04 23:01:00 \u2502 2020-08-04   \u2502\n\u2502         \u2026 \u2502 \u2026                   \u2502 \u2026            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>We need to associate jobs and workflows somehow, so let's join them on the relevant key fields.</p> In\u00a0[13]: Copied! <pre>joined = jobs.join(workflows, jobs.run_id == workflows.id)\njoined\n</pre> joined = jobs.join(workflows, jobs.run_id == workflows.id) joined Out[13]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 run_id    \u2503 job_duration \u2503 last_job_started_at \u2503 last_job_completed_at \u2503 id        \u2503 run_started_at      \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 int64     \u2502 int64        \u2502 timestamp           \u2502 timestamp             \u2502 int64     \u2502 timestamp           \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 637414690 \u2502            0 \u2502 2021-03-09 23:40:16 \u2502 2021-03-09 23:40:16   \u2502 637414690 \u2502 2021-03-09 22:59:31 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502   2146000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502   1329000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502   2979000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502   1527000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502   1585000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502    985000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502   2455000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502   1305000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502 637412930 \u2502   1015000000 \u2502 2021-03-09 23:38:33 \u2502 2021-03-10 00:17:30   \u2502 637412930 \u2502 2021-03-09 22:58:27 \u2502 \u2026 \u2502\n\u2502         \u2026 \u2502            \u2026 \u2502 \u2026                   \u2502 \u2026                     \u2502         \u2026 \u2502 \u2026                   \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</pre> <p>Sweet! Now we have workflow runs and job runs together in the same table, let's start exploring summarization.</p> <p>Let's encode our knowledge about when the poetry move happened and also when we moved to the team plan.</p> In\u00a0[14]: Copied! <pre>from datetime import date\n\nPOETRY_MERGED_DATE = date(2021, 10, 15)\nTEAMIZATION_DATE = date(2022, 11, 28)\n</pre> from datetime import date  POETRY_MERGED_DATE = date(2021, 10, 15) TEAMIZATION_DATE = date(2022, 11, 28) <p>Let's compute some indicator variables indicating whether a given row contains data after poetry changes occurred, and do the same for the team plan.</p> <p>Let's also compute queueing time and workflow duration.</p> In\u00a0[15]: Copied! <pre>stats = joined.select(\n    _.started_date,\n    _.job_duration,\n    has_poetry=_.started_date &gt; POETRY_MERGED_DATE,\n    has_team=_.started_date &gt; TEAMIZATION_DATE,\n    queueing_time=_.last_job_started_at.cast(\"int\")\n    - _.run_started_at.cast(\"int\"),\n    workflow_duration=_.last_job_completed_at.cast(\"int\")\n    - _.run_started_at.cast(\"int\"),\n)\nstats\n</pre> stats = joined.select(     _.started_date,     _.job_duration,     has_poetry=_.started_date &gt; POETRY_MERGED_DATE,     has_team=_.started_date &gt; TEAMIZATION_DATE,     queueing_time=_.last_job_started_at.cast(\"int\")     - _.run_started_at.cast(\"int\"),     workflow_duration=_.last_job_completed_at.cast(\"int\")     - _.run_started_at.cast(\"int\"), ) stats Out[15]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 started_date \u2503 job_duration \u2503 has_poetry \u2503 has_team \u2503 queueing_time \u2503 workflow_duration \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 date         \u2502 int64        \u2502 boolean    \u2502 boolean  \u2502 int64         \u2502 int64             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2021-08-02   \u2502    286000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    274000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    397000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    394000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    709000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    760000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    717000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    419000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    503000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 2021-08-02   \u2502    811000000 \u2502 False      \u2502 False    \u2502      12000000 \u2502         823000000 \u2502\n\u2502 \u2026            \u2502            \u2026 \u2502 \u2026          \u2502 \u2026        \u2502             \u2026 \u2502                 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Let's create a column ranging from 0 to 2 inclusive where:</p> <ul> <li>0: no improvements</li> <li>1: just poetry</li> <li>2: poetry and the team plan</li> </ul> <p>Let's also give them some names that'll look nice on our plots.</p> In\u00a0[16]: Copied! <pre>stats = stats.mutate(\n    raw_improvements=_.has_poetry.cast(\"int\") + _.has_team.cast(\"int\")\n).mutate(\n    improvements=(\n        _.raw_improvements.case()\n        .when(0, \"None\")\n        .when(1, \"Poetry\")\n        .when(2, \"Poetry + Team Plan\")\n        .else_(\"NA\")\n        .end()\n    ),\n    team_plan=ibis.where(_.raw_improvements &gt; 1, \"Poetry + Team Plan\", \"None\"),\n)\nstats\n</pre> stats = stats.mutate(     raw_improvements=_.has_poetry.cast(\"int\") + _.has_team.cast(\"int\") ).mutate(     improvements=(         _.raw_improvements.case()         .when(0, \"None\")         .when(1, \"Poetry\")         .when(2, \"Poetry + Team Plan\")         .else_(\"NA\")         .end()     ),     team_plan=ibis.where(_.raw_improvements &gt; 1, \"Poetry + Team Plan\", \"None\"), ) stats Out[16]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2513\n\u2503 started_date \u2503 job_duration \u2503 has_poetry \u2503 has_team \u2503 queueing_time \u2503 workflow_duration \u2503 raw_improvements \u2503 \u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2529\n\u2502 date         \u2502 int64        \u2502 boolean    \u2502 boolean  \u2502 int64         \u2502 int64             \u2502 int64            \u2502 \u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502 2021-08-22   \u2502    388000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    392000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    502000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    515000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    392000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    341000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    743000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    630000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    750000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 2021-08-22   \u2502    777000000 \u2502 False      \u2502 False    \u2502      21000000 \u2502         850000000 \u2502                0 \u2502 \u2026 \u2502\n\u2502 \u2026            \u2502            \u2026 \u2502 \u2026          \u2502 \u2026        \u2502             \u2026 \u2502                 \u2026 \u2502                \u2026 \u2502 \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\n</pre> <p>Finally, we can summarize by averaging the different durations, grouping on the variables of interest.</p> In\u00a0[17]: Copied! <pre>USECS_PER_MIN = 60_000_000\n\nagged = stats.group_by([_.started_date, _.improvements, _.team_plan]).agg(\n    job=_.job_duration.div(USECS_PER_MIN).mean(),\n    workflow=_.workflow_duration.div(USECS_PER_MIN).mean(),\n    queueing_time=_.queueing_time.div(USECS_PER_MIN).mean(),\n)\nagged\n</pre> USECS_PER_MIN = 60_000_000  agged = stats.group_by([_.started_date, _.improvements, _.team_plan]).agg(     job=_.job_duration.div(USECS_PER_MIN).mean(),     workflow=_.workflow_duration.div(USECS_PER_MIN).mean(),     queueing_time=_.queueing_time.div(USECS_PER_MIN).mean(), ) agged Out[17]: <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 started_date \u2503 improvements \u2503 team_plan \u2503 job       \u2503 workflow  \u2503 queueing_time \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 date         \u2502 string       \u2502 string    \u2502 float64   \u2502 float64   \u2502 float64       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2021-11-08   \u2502 Poetry       \u2502 None      \u2502  5.076520 \u2502 25.813687 \u2502     17.095093 \u2502\n\u2502 2022-05-09   \u2502 Poetry       \u2502 None      \u2502  3.645870 \u2502 17.563438 \u2502     15.305701 \u2502\n\u2502 2022-06-04   \u2502 Poetry       \u2502 None      \u2502  3.641251 \u2502 12.041645 \u2502     10.759055 \u2502\n\u2502 2022-07-21   \u2502 Poetry       \u2502 None      \u2502  3.236880 \u2502 13.001932 \u2502     12.147463 \u2502\n\u2502 2020-12-15   \u2502 None         \u2502 None      \u2502 13.788721 \u2502 59.767340 \u2502     59.767340 \u2502\n\u2502 2021-08-17   \u2502 None         \u2502 None      \u2502  8.777027 \u2502 22.233333 \u2502      7.607057 \u2502\n\u2502 2021-09-23   \u2502 None         \u2502 None      \u2502 11.531302 \u2502 93.434379 \u2502     93.059946 \u2502\n\u2502 2020-09-01   \u2502 None         \u2502 None      \u2502 15.639095 \u2502 59.154527 \u2502     58.680453 \u2502\n\u2502 2021-06-24   \u2502 None         \u2502 None      \u2502  8.442157 \u2502 13.697059 \u2502      0.197059 \u2502\n\u2502 2021-01-07   \u2502 None         \u2502 None      \u2502 12.555856 \u2502 48.162613 \u2502     47.651351 \u2502\n\u2502 \u2026            \u2502 \u2026            \u2502 \u2026         \u2502         \u2026 \u2502         \u2026 \u2502             \u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>If at any point you want to inspect the SQL you'll be running, ibis has you covered with <code>ibis.to_sql</code>.</p> In\u00a0[18]: Copied! <pre>sql = ibis.to_sql(agged)\nsql\n</pre> sql = ibis.to_sql(agged) sql Out[18]: <pre>SELECT\nt0.`started_date`,\nt0.`improvements`,\nt0.`team_plan`,\nAVG(IEEE_DIVIDE(t0.`job_duration`, 60000000)) AS `job`,\nAVG(IEEE_DIVIDE(t0.`workflow_duration`, 60000000)) AS `workflow`,\nAVG(IEEE_DIVIDE(t0.`queueing_time`, 60000000)) AS `queueing_time`\nFROM (\nSELECT\nt1.*,\nCASE t1.`raw_improvements`\nWHEN 0\nTHEN 'None'\nWHEN 1\nTHEN 'Poetry'\nWHEN 2\nTHEN 'Poetry + Team Plan'\nELSE 'NA'\nEND AS `improvements`,\nCASE WHEN t1.`raw_improvements` &gt; 1 THEN 'Poetry + Team Plan' ELSE 'None' END AS `team_plan`\nFROM (\nSELECT\nt2.*,\nCAST(t2.`has_poetry` AS INT64) + CAST(t2.`has_team` AS INT64) AS `raw_improvements`\nFROM (\nSELECT\n`started_date`,\n`job_duration`,\n`started_date` &gt; CAST('2021-10-15' AS DATE) AS `has_poetry`,\n`started_date` &gt; CAST('2022-11-28' AS DATE) AS `has_team`,\nUNIX_MICROS(`last_job_started_at`) - UNIX_MICROS(`run_started_at`) AS `queueing_time`,\nUNIX_MICROS(`last_job_completed_at`) - UNIX_MICROS(`run_started_at`) AS `workflow_duration`\nFROM (\nSELECT\nt5.`run_id`,\nUNIX_MICROS(t5.`completed_at`) - UNIX_MICROS(t5.`started_at`) AS `job_duration`,\nMAX(t5.`started_at`) OVER (PARTITION BY t5.`run_id`) AS `last_job_started_at`,\nMAX(t5.`completed_at`) OVER (PARTITION BY t5.`run_id`) AS `last_job_completed_at`\nFROM `ibis-gbq.workflows.jobs` AS t5\n) AS t3\nINNER JOIN (\nSELECT\nt5.`id`,\nt5.`run_started_at`,\nDATE(t5.`run_started_at`) AS `started_date`\nFROM `ibis-gbq.workflows.workflows` AS t5\n) AS t4\nON t3.`run_id` = t4.`id`\n) AS t2\n) AS t1\n) AS t0\nGROUP BY\n1,\n2,\n3\n</pre> In\u00a0[19]: Copied! <pre>raw_df = agged.execute()\n</pre> raw_df = agged.execute() In\u00a0[20]: Copied! <pre>raw_df\n</pre> raw_df Out[20]: started_date improvements team_plan job workflow queueing_time 0 2020-10-24 None None 12.366667 54.710606 54.709091 1 2021-03-09 None None 28.335816 52.688830 10.635284 2 2022-01-04 Poetry None 3.288468 20.827914 20.684298 3 2021-09-30 None None 7.993065 52.552629 51.354530 4 2022-09-14 Poetry None 3.855526 29.760230 27.029778 ... ... ... ... ... ... ... 801 2020-11-17 None None 12.460078 40.966512 30.366744 802 2022-11-06 Poetry None 3.937369 19.095751 16.830617 803 2020-09-23 None None 12.086594 44.403986 43.983152 804 2020-08-28 None None 15.834127 60.183333 60.183333 805 2021-09-05 None None 6.944340 18.912736 12.630189 <p>806 rows \u00d7 6 columns</p> <p>Generally, <code>plotnine</code> works with long, tidy data so let's use <code>pandas.melt</code> to get there.</p> In\u00a0[21]: Copied! <pre>import pandas as pd\n\ndf = pd.melt(\n    raw_df,\n    id_vars=[\"started_date\", \"improvements\", \"team_plan\"],\n    var_name=\"entity\",\n    value_name=\"duration\",\n)\ndf.head()\n</pre> import pandas as pd  df = pd.melt(     raw_df,     id_vars=[\"started_date\", \"improvements\", \"team_plan\"],     var_name=\"entity\",     value_name=\"duration\", ) df.head() Out[21]: started_date improvements team_plan entity duration 0 2020-10-24 None None job 12.366667 1 2021-03-09 None None job 28.335816 2 2022-01-04 Poetry None job 3.288468 3 2021-09-30 None None job 7.993065 4 2022-09-14 Poetry None job 3.855526 <p>Let's make our theme lighthearted by using <code>xkcd</code>-style plots.</p> In\u00a0[22]: Copied! <pre>from plotnine import *\n</pre> from plotnine import * In\u00a0[23]: Copied! <pre>theme_set(theme_xkcd())\n</pre> theme_set(theme_xkcd()) <p>Create a few labels for our plot.</p> In\u00a0[24]: Copied! <pre>poetry_label = f\"Poetry\\n{POETRY_MERGED_DATE}\"\nteam_label = f\"Team Plan\\n{TEAMIZATION_DATE}\"\n</pre> poetry_label = f\"Poetry\\n{POETRY_MERGED_DATE}\" team_label = f\"Team Plan\\n{TEAMIZATION_DATE}\" <p>Without the following line you may see large amount of inconsequential warnings that make the notebook unusable.</p> In\u00a0[25]: Copied! <pre>import logging\n\n# without this, findfont logging spams the notebook making it unusable\nlogging.getLogger('matplotlib.font_manager').disabled = True\n</pre> import logging  # without this, findfont logging spams the notebook making it unusable logging.getLogger('matplotlib.font_manager').disabled = True <p>Here we show job durations, coloring the points differently depending on whether they have no improvements, poetry, or poetry + team plan.</p> In\u00a0[26]: Copied! <pre>(\n    ggplot(\n        df.loc[df.entity == \"job\"].reset_index(drop=True),\n        aes(x=\"started_date\", y=\"duration\", color=\"factor(improvements)\"),\n    )\n    + geom_point()\n    + geom_vline(\n        xintercept=[TEAMIZATION_DATE, POETRY_MERGED_DATE],\n        colour=[\"blue\", \"green\"],\n        linetype=\"dashed\",\n    )\n    + scale_color_brewer(\n        palette=7,\n        type='qual',\n        limits=[\"None\", \"Poetry\", \"Poetry + Team Plan\"],\n    )\n    + geom_text(x=POETRY_MERGED_DATE, label=poetry_label, y=15, color=\"blue\")\n    + geom_text(x=TEAMIZATION_DATE, label=team_label, y=10, color=\"blue\")\n    + stat_smooth(method=\"lm\")\n    + labs(x=\"Date\", y=\"Duration (minutes)\")\n    + ggtitle(\"Job Duration\")\n    + theme(\n        figure_size=(22, 6),\n        legend_position=(0.67, 0.65),\n        legend_direction=\"vertical\",\n    )\n)\n</pre> (     ggplot(         df.loc[df.entity == \"job\"].reset_index(drop=True),         aes(x=\"started_date\", y=\"duration\", color=\"factor(improvements)\"),     )     + geom_point()     + geom_vline(         xintercept=[TEAMIZATION_DATE, POETRY_MERGED_DATE],         colour=[\"blue\", \"green\"],         linetype=\"dashed\",     )     + scale_color_brewer(         palette=7,         type='qual',         limits=[\"None\", \"Poetry\", \"Poetry + Team Plan\"],     )     + geom_text(x=POETRY_MERGED_DATE, label=poetry_label, y=15, color=\"blue\")     + geom_text(x=TEAMIZATION_DATE, label=team_label, y=10, color=\"blue\")     + stat_smooth(method=\"lm\")     + labs(x=\"Date\", y=\"Duration (minutes)\")     + ggtitle(\"Job Duration\")     + theme(         figure_size=(22, 6),         legend_position=(0.67, 0.65),         legend_direction=\"vertical\",     ) ) Out[26]: <pre>&lt;ggplot: (8787848799950)&gt;</pre> In\u00a0[27]: Copied! <pre>(\n    ggplot(\n        df.loc[df.entity != \"job\"].reset_index(drop=True),\n        aes(x=\"started_date\", y=\"duration\", color=\"factor(improvements)\"),\n    )\n    + facet_wrap(\"entity\", ncol=1)\n    + geom_point()\n    + geom_vline(\n        xintercept=[TEAMIZATION_DATE, POETRY_MERGED_DATE],\n        linetype=\"dashed\",\n    )\n    + scale_color_brewer(\n        palette=7,\n        type='qual',\n        limits=[\"None\", \"Poetry\", \"Poetry + Team Plan\"],\n    )\n    + geom_text(x=POETRY_MERGED_DATE, label=poetry_label, y=75, color=\"blue\")\n    + geom_text(x=TEAMIZATION_DATE, label=team_label, y=50, color=\"blue\")\n    + stat_smooth(method=\"lm\")\n    + labs(x=\"Date\", y=\"Duration (minutes)\")\n    + ggtitle(\"Workflow Duration\")\n    + theme(\n        figure_size=(22, 13),\n        legend_position=(0.68, 0.75),\n        legend_direction=\"vertical\",\n    )\n)\n</pre> (     ggplot(         df.loc[df.entity != \"job\"].reset_index(drop=True),         aes(x=\"started_date\", y=\"duration\", color=\"factor(improvements)\"),     )     + facet_wrap(\"entity\", ncol=1)     + geom_point()     + geom_vline(         xintercept=[TEAMIZATION_DATE, POETRY_MERGED_DATE],         linetype=\"dashed\",     )     + scale_color_brewer(         palette=7,         type='qual',         limits=[\"None\", \"Poetry\", \"Poetry + Team Plan\"],     )     + geom_text(x=POETRY_MERGED_DATE, label=poetry_label, y=75, color=\"blue\")     + geom_text(x=TEAMIZATION_DATE, label=team_label, y=50, color=\"blue\")     + stat_smooth(method=\"lm\")     + labs(x=\"Date\", y=\"Duration (minutes)\")     + ggtitle(\"Workflow Duration\")     + theme(         figure_size=(22, 13),         legend_position=(0.68, 0.75),         legend_direction=\"vertical\",     ) ) Out[27]: <pre>&lt;ggplot: (8787517291848)&gt;</pre> In\u00a0[28]: Copied! <pre>(\n    ggplot(raw_df, aes(x=\"workflow\", y=\"queueing_time\"))\n    + geom_point()\n    + geom_rug()\n    + facet_grid(\". ~ team_plan\")\n    + labs(x=\"Workflow Duration (minutes)\", y=\"Queueing Time (minutes)\")\n    + ggtitle(\"Workflow Duration vs. Queueing Time\")\n    + theme(figure_size=(22, 6))\n)\n</pre> (     ggplot(raw_df, aes(x=\"workflow\", y=\"queueing_time\"))     + geom_point()     + geom_rug()     + facet_grid(\". ~ team_plan\")     + labs(x=\"Workflow Duration (minutes)\", y=\"Queueing Time (minutes)\")     + ggtitle(\"Workflow Duration vs. Queueing Time\")     + theme(figure_size=(22, 6)) ) Out[28]: <pre>&lt;ggplot: (8787487205632)&gt;</pre>"},{"location":"blog/rendered/ci-analysis/#Analysis-of-Ibis's-CI-Performance","title":"Analysis of Ibis's CI Performance\u00b6","text":""},{"location":"blog/rendered/ci-analysis/#Summary","title":"Summary\u00b6","text":"<p>This notebook takes you through an analysis of Ibis's CI data using ibis on top of Google BigQuery.</p> <ul> <li>First, we load some data and poke around at it to see what's what.</li> <li>Second, we figure out some useful things to calculate based on our poking.</li> <li>Third, we'll visualize the results of calculations to showcase what changed and how.</li> </ul>"},{"location":"blog/rendered/ci-analysis/#Imports","title":"Imports\u00b6","text":"<p>Let's start out by importing ibis and turning on interactive mode.</p>"},{"location":"blog/rendered/ci-analysis/#Connect-to-BigQuery","title":"Connect to BigQuery\u00b6","text":"<p>We connect to BigQuery using the <code>ibis.connect</code> API, which accepts a URL string indicating the backend and various bit of information needed to connect to the backend. Here we're using BigQuery, so we need the project id (<code>ibis-gbq</code>) and the dataset id (<code>workflows</code>).</p> <p>Datasets are analogous to schemas in other systems.</p>"},{"location":"blog/rendered/ci-analysis/#Analysis","title":"Analysis\u00b6","text":"<p>Here we've got our first bit of interesting information: the <code>jobs</code> and <code>workflows</code> tables.</p>"},{"location":"blog/rendered/ci-analysis/#Terminology","title":"Terminology\u00b6","text":"<p>Before we jump in, it helps to lay down some terminology.</p> <ul> <li>A workflow corresponds to an individual GitHub Actions YAML file in a GitHub repository under the <code>.github/workflows</code> directory.</li> <li>A job is a named set of steps to run inside a workflow file.</li> </ul>"},{"location":"blog/rendered/ci-analysis/#What's-in-the-workflows-table?","title":"What's in the <code>workflows</code> table?\u00b6","text":"<p>Each row in the <code>workflows</code> table corresponds to a workflow run.</p> <ul> <li>A workflow run is an instance of a workflow that was triggered by some entity: a GitHub user, bot, or other entity. Each row of the <code>workflows</code> table is a workflow run.</li> </ul>"},{"location":"blog/rendered/ci-analysis/#What's-in-the-jobs-table?","title":"What's in the <code>jobs</code> table?\u00b6","text":"<p>Similarly, each row in the <code>jobs</code> table is a job run. That is, for a given workflow run there are a set of jobs run with it.</p> <ul> <li>A job run is an instance of a job in a workflow. It is associated with a single workflow run.</li> </ul>"},{"location":"blog/rendered/ci-analysis/#Rationale","title":"Rationale\u00b6","text":"<p>The goal of this analysis is to try to understand ibis's CI performance, and whether the amount of time we spent waiting on CI has decreased, stayed the same or increased. Ideally, we can understand the pieces that contribute to the change or lack thereof.</p>"},{"location":"blog/rendered/ci-analysis/#Metrics","title":"Metrics\u00b6","text":"<p>To that end there are a few interesting metrics to look at:</p> <ul> <li>job run duration: this is the amount of time it takes for a given job to complete</li> <li>workflow run duration: the amount of time it takes for all job runs in a workflow run to complete.</li> <li>queueing duration: the amount time time spent waiting for the first job run to commence.</li> </ul>"},{"location":"blog/rendered/ci-analysis/#Mitigating-Factors","title":"Mitigating Factors\u00b6","text":"<ul> <li>Around October 2021, we changed our CI infrastructure to use Poetry instead of Conda. The goal there was to see if we could cache dependencies using the lock file generated by poetry. We should see whether that had any effect.</li> <li>At the end of November 2022, we switch to the Team Plan (a paid GitHub plan) for the Ibis organzation. This tripled the amount of job runs that could execute in parallel. We should see if that helped anything.</li> </ul> <p>Alright, let's jump into some data!</p>"},{"location":"blog/rendered/ci-analysis/#Plot-the-Results","title":"Plot the Results\u00b6","text":"<p>Ibis doesn't have builtin plotting support, so we need to pull our results into pandas.</p> <p>Here I'm using <code>plotnine</code> (a Python port of <code>ggplot2</code>), which has great integration with pandas DataFrames.</p>"},{"location":"blog/rendered/ci-analysis/#Result-%231:-Job-Duration","title":"Result #1: Job Duration\u00b6","text":"<p>This result is pretty interesting.</p> <p>A few things pop out to me right away:</p> <ul> <li>The move to poetry decreased the average job run duration by quite a bit. No, I'm not going to do any statistical tests.</li> <li>The variability of job run durations also decreased by quite a bit after introducing poetry.</li> <li>Moving to the team plan had little to no effect on job run duration.</li> </ul>"},{"location":"blog/rendered/ci-analysis/#Result-%232:-Workflow-Duration-and-Queueing-Time","title":"Result #2: Workflow Duration and Queueing Time\u00b6","text":"<p>Another interesting result.</p>"},{"location":"blog/rendered/ci-analysis/#Queueing-Time","title":"Queueing Time\u00b6","text":"<ul> <li>It almost looks like moving to poetry made average queueing time worse. This is probably due to our perception that faster jobs means faster ci. As we see here that isn't the case</li> <li>Moving to the team plan cut down the queueing time by quite a bit</li> </ul>"},{"location":"blog/rendered/ci-analysis/#Workflow-Duration","title":"Workflow Duration\u00b6","text":"<ul> <li>Overall workflow duration appears to be strongly influenced by moving to the team plan, which is almost certainly due to the drop in queueing time since we are no longer limited by slow job durations.</li> <li>Perhaps it's obvious, but queueing time and workflow duration appear to be highly correlated.</li> </ul> <p>In the next plot we'll look at that correlation.</p>"},{"location":"blog/rendered/ci-analysis/#Result-%233:-Workflow-Duration-and-Queueing-Duration-are-correlated","title":"Result #3: Workflow Duration and Queueing Duration are correlated\u00b6","text":"<p>It also seems that moving to the team plan (though also the move to poetry might be related here) reduced the variability of both metrics.</p> <p>We're lacking data compared to the past so we should wait for more to come in.</p>"},{"location":"blog/rendered/ci-analysis/#Conclusions","title":"Conclusions\u00b6","text":"<p>It appears that you need both a short queue time and fast individual jobs to minimize time spent in CI.</p> <p>If you have a short queue time, but long job runs then you'll be bottlenecked on individual jobs, and if you have more jobs than queue slots then you'll be blocked on queueing time.</p> <p>I think we can sum this up nicely:</p> <ul> <li>slow jobs, slow queue: \ud83e\udd37 blocked by jobs or queue</li> <li>slow jobs, fast queue: \u2753 blocked by jobs, if jobs are slow enough</li> <li>fast jobs, slow queue: \u2757 blocked by queue, with enough jobs</li> <li>fast jobs, fast queue: \u2705</li> </ul>"},{"location":"community/","title":"Community","text":"<p>Ibis aims to be a welcoming, friendly, diverse and inclusive community. Everybody is welcome, regardless of gender, sexual orientation, gender identity, and expression, disability, physical appearance, body size, race, or religion.</p>"},{"location":"community/contribute/","title":"Contribute to Ibis","text":"<p>ibis is developed and maintained by a community of volunteer contributors.</p>"},{"location":"community/contribute/#maintainers","title":"Maintainers","text":"<ul> <li> <p>@cpcloud</p> </li> <li> <p>@kszucs</p> </li> <li> <p>@jreback</p> </li> <li> <p>@gforsyth</p> </li> <li> <p>@jcrist</p> </li> <li> <p>@saulpw</p> </li> </ul>"},{"location":"community/contribute/01_environment/","title":"Setting Up a Development Environment","text":""},{"location":"community/contribute/01_environment/#required-dependencies","title":"Required Dependencies","text":"<ul> <li><code>git</code></li> </ul> NixCondapip <p>Some optional dependencies for Windows are not available through <code>conda</code>/<code>mamba</code></p> <ol> <li><code>clickhouse-cityhash</code>. Required for compression support in the ClickHouse backend.</li> </ol> <p><code>pip</code> will not handle installation of system dependencies</p> <p><code>pip</code> will not install system dependencies needed for some packages such as <code>psycopg2</code> and <code>kerberos</code>.</p> <p>For a better development experience see the <code>conda</code> or <code>nix</code> setup instructions.</p> <ol> <li> <p>Install <code>gh</code></p> </li> <li> <p>Fork and clone the ibis repository:</p> <pre><code>gh repo fork --clone --remote ibis-project/ibis\n</code></pre> </li> <li> <p>Change directory into <code>ibis</code>:</p> <pre><code>cd ibis\n</code></pre> </li> <li> <p>Install development dependencies</p> <pre><code>pip install 'poetry&gt;=1.2'\npip install -r requirements.txt\n</code></pre> </li> <li> <p>Install ibis in development mode</p> <pre><code>pip install -e .\n</code></pre> </li> </ol>"},{"location":"community/contribute/01_environment/#support-matrix","title":"Support Matrix","text":"Python Version  Python 3.8 Python 3.9 Python 3.10 Operating System Linux 1 macOS (x86_64) Windows 3 <ol> <li>Install <code>nix</code></li> <li> <p>Install <code>gh</code>:</p> <code>nix-shell</code><code>nix-env</code> <pre><code>nix-shell -p gh\n</code></pre> <pre><code>nix-env -iA gh\n</code></pre> </li> <li> <p>Fork and clone the ibis repository:</p> <pre><code>gh repo fork --clone --remote ibis-project/ibis\n</code></pre> </li> <li> <p>Set up the public <code>ibis</code> Cachix cache to pull pre-built dependencies:</p> <pre><code>nix-shell -p cachix --run 'cachix use ibis'\n</code></pre> </li> <li> <p>Run <code>nix-shell</code> in the checkout directory:</p> <pre><code>cd ibis\nnix-shell\n</code></pre> <p>This may take a while due to artifact download from the cache.</p> </li> </ol>"},{"location":"community/contribute/01_environment/#support-matrix_1","title":"Support Matrix","text":"Python Version  Python 3.8 Python 3.9 Python 3.10 Operating System Linux 1 macOS Windows <code>conda</code><code>mamba</code> <ol> <li> <p>Install Miniconda</p> </li> <li> <p>Install <code>gh</code></p> <pre><code>conda install -c conda-forge gh\n</code></pre> </li> <li> <p>Fork and clone the ibis repository:</p> <pre><code>gh repo fork --clone --remote ibis-project/ibis\n</code></pre> </li> <li> <p>Create a Conda environment from a lock file in the repo:</p> LinuxMacOSWindows <pre><code>cd ibis\nconda create -n ibis-dev --file=conda-lock/linux-64-3.9.lock\n</code></pre> <pre><code>cd ibis\nconda create -n ibis-dev --file=conda-lock/osx-64-3.9.lock\n</code></pre> <pre><code>cd ibis\nconda create -n ibis-dev --file=conda-lock/win-64-3.9.lock\n</code></pre> </li> <li> <p>Activate the environment</p> <pre><code>conda activate ibis-dev\n</code></pre> </li> <li> <p>Install your local copy of <code>ibis</code> into the Conda environment.</p> <pre><code>cd ibis\npip install -e .\n</code></pre> </li> <li> <p>If you want to run the backend test suite you'll need to install <code>docker-compose</code>:</p> <pre><code>conda install docker-compose -c conda-forge\n</code></pre> </li> </ol> <ol> <li> <p>Install Mamba</p> </li> <li> <p>Install <code>gh</code></p> <pre><code>mamba install -c conda-forge gh\n</code></pre> </li> <li> <p>Fork and clone the ibis repository:</p> <pre><code>gh repo fork --clone --remote ibis-project/ibis\n</code></pre> </li> <li> <p>Create a Conda environment from a lock file in the repo:</p> LinuxMacOSWindows <pre><code>cd ibis\nmamba create -n ibis-dev --file=conda-lock/linux-64-3.9.lock\n</code></pre> <pre><code>cd ibis\nmamba create -n ibis-dev --file=conda-lock/osx-64-3.9.lock\n</code></pre> <pre><code>cd ibis\nmamba create -n ibis-dev --file=conda-lock/win-64-3.9.lock\n</code></pre> </li> <li> <p>Activate the environment</p> <pre><code>mamba activate ibis-dev\n</code></pre> </li> <li> <p>Install your local copy of <code>ibis</code> into the Conda environment.</p> <pre><code>cd ibis\npip install -e .\n</code></pre> </li> <li> <p>If you want to run the backend test suite you'll need to install <code>docker-compose</code>:</p> <pre><code>mamba install docker-compose -c conda-forge\n</code></pre> </li> </ol>"},{"location":"community/contribute/01_environment/#building-the-docs","title":"Building the Docs","text":"<p>You must set up an environment with Nix as above to build the website and docs.</p> <p>Then, run:</p> <pre><code>mkdocs serve\n</code></pre> <ol> <li> <p>Tested in CI. If this doesn't work for you, please file an issue.\u00a0\u21a9\u21a9</p> </li> <li> <p>Should work but doesn't because upstream is broken. Supported on a best-effort basis.\u00a0\u21a9</p> </li> <li> <p>Unlikely to ever be supported or no upstream support.\u00a0\u21a9</p> </li> </ol>"},{"location":"community/contribute/02_workflow/","title":"Contribute to the Ibis Codebase","text":""},{"location":"community/contribute/02_workflow/#getting-started","title":"Getting started","text":"<p>First, set up a development environment.</p>"},{"location":"community/contribute/02_workflow/#taking-issues","title":"Taking Issues","text":"<p>If you find an issue you want to work on, write a comment with the text <code>/take</code> on the issue. GitHub will then assign the issue to you.</p>"},{"location":"community/contribute/02_workflow/#running-the-test-suite","title":"Running the test suite","text":"<p>To run tests that do not require a backend:</p> <pre><code>pytest -m core\n</code></pre>"},{"location":"community/contribute/02_workflow/#backend-test-suites","title":"Backend Test Suites","text":"<p>You may be able to skip this section</p> <p>If you haven't made changes to the core of ibis (e.g., <code>ibis/expr</code>) or any specific backends (<code>ibis/backends</code>) this material isn't necessary to follow to make a pull request.</p> <p>First, we need to download example data to run the tests successfully:</p> <pre><code>just download-data\n</code></pre> <p>To run the tests for a specific backend (e.g. sqlite):</p> <pre><code>pytest -m sqlite\n</code></pre>"},{"location":"community/contribute/02_workflow/#setting-up-non-trivial-backends","title":"Setting up non-trivial backends","text":"<p>These client-server backends need to be started before testing them. They can be started with <code>docker-compose</code> directly, or using the <code>just</code> tool.</p> <ul> <li>ClickHouse: <code>just up clickhouse</code></li> <li>PostgreSQL: <code>just up postgres</code></li> <li>MySQL: <code>just up mysql</code></li> <li>impala: <code>just up impala</code></li> </ul>"},{"location":"community/contribute/02_workflow/#test-the-backend-locally","title":"Test the backend locally","text":"<p>If anything seems amiss with a backend, you can of course test it locally:</p> <pre><code>export PGPASSWORD=postgres\npsql -t -A -h localhost -U postgres -d ibis_testing -c \"select 'success'\"\n</code></pre>"},{"location":"community/contribute/02_workflow/#writing-the-commit","title":"Writing the commit","text":"<p>Ibis follows the Conventional Commits structure. In brief, the commit summary should look like:</p> <pre><code>fix(types): make all floats doubles\n</code></pre> <p>The type (e.g. <code>fix</code>) can be:</p> <ul> <li><code>fix</code>: A bug fix. Correlates with PATCH in SemVer</li> <li><code>feat</code>: A new feature. Correlates with MINOR in SemVer</li> <li><code>docs</code>: Documentation only changes</li> <li> <p><code>style</code>: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc)   `   If the commit fixes a Github issue, add something like this to the bottom of the description:</p> <p>fixes #4242</p> </li> </ul>"},{"location":"community/contribute/02_workflow/#submit-a-pr","title":"Submit a PR","text":"<p>Ibis follows the standard Git Pull Request process. The team will review the PR and merge when it's ready.</p>"},{"location":"community/contribute/03_style/","title":"Style and Formatting","text":""},{"location":"community/contribute/03_style/#code-style","title":"Code Style","text":"<ul> <li><code>black</code>: Formatting Python code</li> <li><code>ruff</code>: Formatting and sorting <code>import</code> statements</li> <li><code>shellcheck</code>: Linting shell scripts</li> <li><code>shfmt</code>: Formatting shell scripts</li> <li><code>statix</code>: Linting nix files</li> <li><code>nixpkgs-fmt</code>: Formatting nix files</li> </ul> <p>Tip</p> <p>If you use <code>nix-shell</code>, all of these are already setup for you and ready to use, and you don't need to do anything to install these tools.</p> <p>We use numpydoc as our standard format for docstrings.</p>"},{"location":"community/contribute/05_maintainers_guide/","title":"Maintaining the Codebase","text":"<p>Ibis maintainers are expected to handle the following tasks as they arise:</p> <ul> <li>Reviewing and merging pull requests</li> <li>Triaging new issues</li> </ul>"},{"location":"community/contribute/05_maintainers_guide/#dependencies","title":"Dependencies","text":"<p>A number of tasks that are typically associated with maintenance are partially or fully automated.</p> <ul> <li>WhiteSource Renovate (Python library dependencies and GitHub Actions)</li> <li>Custom GitHub Action (Nix dependencies)</li> </ul>"},{"location":"community/contribute/05_maintainers_guide/#poetry","title":"poetry","text":"<p>Occasionally you may need to lock <code>poetry</code> dependencies. Edit <code>pyproject.toml</code> as needed, then run:</p> <pre><code>poetry lock --no-update\n</code></pre>"},{"location":"community/contribute/05_maintainers_guide/#adding-examples","title":"Adding Examples","text":"<p>If you're not a maintainer, please open an issue asking us to add your example.</p>"},{"location":"community/contribute/05_maintainers_guide/#requirements","title":"Requirements","text":"<p>You need the ability to write to the <code>gs://ibis-examples</code> GCS bucket to add an example.</p>"},{"location":"community/contribute/05_maintainers_guide/#instructions","title":"Instructions","text":"<p>Make sure you're in the root of the ibis git repository.</p> <p>Assuming your file is called <code>example.csv</code>:</p> <ol> <li>Add a gzip-compressed CSV file with the path <code>ibis/examples/data/example.csv.gz</code>.</li> <li>Add a file named <code>ibis/examples/descriptions/example</code> that contains a    description of your example. One line is best, but not necessary.</li> <li>Run one of the following from the git root of an ibis clone:</li> <li><code>python ibis/examples/gen_registry.py</code> (doesn't include R dependenices)</li> <li><code>nix run '.#gen-examples'</code> (includes R dependenices)</li> </ol>"},{"location":"community/contribute/05_maintainers_guide/#release","title":"Release","text":"<p>Ibis is released on PyPI and Conda Forge.</p> PyPI<code>conda-forge</code> <p>Releases to PyPI are handled automatically using semantic release.</p> <p>To trigger a release use the Release GitHub Action.</p> <p>The conda-forge package is maintained as a conda-forge feedstock.</p> <p>After a release to PyPI, the conda-forge bot automatically updates the ibis package.</p>"},{"location":"docs/","title":"Ibis Documentation","text":"<p>Welcome to the ibis documentation!</p> <ul> <li>Coming from Pandas?: Check out ibis for pandas users!</li> <li>Coming from SQL?: Take a look at ibis for SQL programmers!</li> <li>Want to see some more examples?: We've got a set of tutorial notebooks for that!</li> <li>Looking for API docs?: Start here!</li> <li>Interested in contributing?: Our contribution section has what you need!</li> </ul>"},{"location":"how_to/chain-expressions/","title":"How to Chain Expressions with Underscore","text":"<p>Expressions can easily be chained using the deferred expression API, also known as the Underscore (<code>_</code>) API.</p> <p>In this guide, we use the <code>_</code> API to concisely create column expressions and then chain table expressions.</p>"},{"location":"how_to/chain-expressions/#setup","title":"Setup","text":"<p>To get started, import <code>_</code> from ibis:</p> <pre><code>import ibis\nfrom ibis import _\n\nimport pandas as pd\n</code></pre> <p>Let's create two in-memory tables using <code>ibis.memtable</code>, an API introduced in 3.2:</p> <pre><code>t1 = ibis.memtable(pd.DataFrame({'x': range(5), 'y': list('ab')*2 + list('e')}))\nt2 = ibis.memtable(pd.DataFrame({'x': range(10), 'z': list(reversed(list('ab')*2 + list('e')))*2}))\n</code></pre>"},{"location":"how_to/chain-expressions/#creating-columnexpressions","title":"Creating ColumnExpressions","text":"<p>We can use <code>_</code> to create new column expressions without explicit reference to the previous table expression:</p> <pre><code># We can pass a deferred expression into a function:\ndef modf(t):\n    return t.x % 3\n\nxmod = modf(_)\n\n# We can create ColumnExprs like aggregate expressions:\nymax = _.y.max()\nzmax = _.z.max()\nzct = _.z.count()\n</code></pre>"},{"location":"how_to/chain-expressions/#chaining-ibis-expressions","title":"Chaining Ibis Expressions","text":"<p>We can also use it to chain Ibis expressions in one Python expression:</p> <pre><code>join = (\n    t1\n    # _ is t1\n    .join(t2, _.x == t2.x)\n    # _ is the join result:\n    .mutate(xmod=xmod)\n    # _ is the TableExpression after mutate:\n    .group_by(_.xmod)\n    # `ct` is a ColumnExpression derived from a deferred expression:\n    .aggregate(ymax=ymax, zmax=zmax)\n    # _ is the aggregation result:\n    .filter(_.ymax == _.zmax)\n    # _ is the filtered result, and re-create xmod in t2 using modf:\n    .join(t2, _.xmod == modf(t2))\n    # _ is the second join result:\n    .join(t1, _.xmod == modf(t1), suffixes=('', '_x'))\n    # _ is the third join result:\n    .select(_.x, _.y, _.z)\n    # Finally, _ is the selection result:\n    .order_by(_.x)\n)\n</code></pre>"},{"location":"how_to/duckdb_register/","title":"How to Use <code>register</code> to load external data files with the DuckDB backend","text":"<p>Here we use the <code>register</code> method to load external data files and join them.</p> <p>We're going to download one month of NYC Taxi data in <code>parquet</code> format and also download the \"Taxi Zone Lookup Table\" which is a <code>csv</code></p> <p>https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-01.parquet https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv</p> <p>Create an in-memory DuckDB connection via <code>ibis</code></p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; con = ibis.duckdb.connect()  # in-memory database\n&gt;&gt;&gt; con.list_tables()\n[]\n</code></pre> <p>Now we call <code>register</code> with the filepath (the <code>table_name</code> argument is optional, if it isn't specified, Ibis will use the filename minus the extension)</p> <pre><code>&gt;&gt;&gt; con.register(\"taxi+_zone_lookup.csv\", table_name=\"taxi_zone_lookup\")\nAlchemyTable: taxi+_zone_lookup\n  LocationID   int32\n  Borough      string\n  Zone         string\n  service_zone string\n\n&gt;&gt;&gt; con.register(\"green_tripdata_2022-01.parquet\", table_name=\"tripdata\")\nAlchemyTable: green_tripdata_2022_01\n  VendorID              int64\n  lpep_pickup_datetime  timestamp\n  lpep_dropoff_datetime timestamp\n  store_and_fwd_flag    string\n  RatecodeID            float64\n  PULocationID          int64\n  DOLocationID          int64\n  passenger_count       float64\n  trip_distance         float64\n  fare_amount           float64\n  extra                 float64\n  mta_tax               float64\n  tip_amount            float64\n  tolls_amount          float64\n  ehail_fee             int32\n  improvement_surcharge float64\n  total_amount          float64\n  payment_type          float64\n  trip_type             float64\n  congestion_surcharge  float64\n&gt;&gt;&gt; con.list_tables()\n['tripdata, 'taxi_zone_lookup']\n</code></pre> <p>We now have a schema parsed from the files and corresponding tables (they are actually <code>views</code> that are lazily-loaded) are available.</p> <p>Now we can interact with these tables just like a table or view in any backend connection:</p> <pre><code>&gt;&gt;&gt; lookup = con.table(\"taxi_zone_lookup\")\n&gt;&gt;&gt; tripdata = con.table(\"tripdata\")\n\n&gt;&gt;&gt; tripdata.columns\n['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime', 'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge', 'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge']\n\n&gt;&gt;&gt; lookup.columns\n['LocationID', 'Borough', 'Zone', 'service_zone']\n</code></pre> <p>We can grab a small subset of the <code>tripdata</code> columns and then join them to the <code>lookup</code> table to get human-readable values for the pickup locations:</p> <pre><code>&gt;&gt;&gt; ibis.options.interactive = True\n\n&gt;&gt;&gt; tripdata = tripdata[[\"lpep_pickup_datetime\", \"PULocationID\"]]\n\n&gt;&gt;&gt; tripdata.head()\n  lpep_pickup_datetime  PULocationID\n0  2022-01-01 00:14:21            42\n1  2022-01-01 00:20:55           116\n2  2022-01-01 00:57:02            41\n3  2022-01-01 00:07:42           181\n4  2022-01-01 00:07:50            33\n\n&gt;&gt;&gt; tripdata.join(lookup, tripdata.PULocationID == lookup.LocationID).head()\n  lpep_pickup_datetime  PULocationID  LocationID    Borough                  Zone service_zone\n0  2022-01-01 00:14:21            42          42  Manhattan  Central Harlem North    Boro Zone\n1  2022-01-01 00:20:55           116         116  Manhattan      Hamilton Heights    Boro Zone\n2  2022-01-01 00:57:02            41          41  Manhattan        Central Harlem    Boro Zone\n3  2022-01-01 00:07:42           181         181   Brooklyn            Park Slope    Boro Zone\n4  2022-01-01 00:07:50            33          33   Brooklyn      Brooklyn Heights    Boro Zone\n</code></pre> <p>That's it!</p> <p>Ibis+duckdb currently supports registering <code>parquet</code>, <code>csv</code>, and <code>csv.gz</code>.</p> <p>You can pass in the filename and the filetype will be inferred from the extension, or you can pass it explicitly using a file URI, e.g.</p> <pre><code>con.register(\"csv://some_csv_file_without_an_extension\")\ncon.register(\"csv.gz://a_compressed_csv_file.csv\")\ncon.register(\"parquet://a_parquet_file_with_truncated_extension.parq\")\n</code></pre>"},{"location":"how_to/ffill_bfill_w_window/","title":"How to <code>ffill</code> and <code>bfill</code> using Window Functions","text":"<p>If you have gaps in your data and need to fill them in using a simple forward fill (given an order, null values are replaced by the value preceeding) or backward fill (given an order, null values are replaced by the value following), then you can do this in Ibis:</p> <code>ffill</code><code>bfill</code> <pre><code># Create a window that orders your series, default ascending\nwin = ibis.window(order_by=data.measured_on, following=0)\n# Create a grouping that is a rolling count of non-null values\n# This creates a partition where each set has no more than one non-null value\ngrouped = data.mutate(grouper=data.measurement.count().over(win))\n# Group by your newly-created grouping and, in each set,\n# set all values to the one non-null value in that set (if it exists)\nresult = (\n    grouped\n    .group_by([grouped.grouper])\n    .mutate(ffill=grouped.measurement.max())\n)\n# execute to get a pandas dataframe, sort values in case your backend shuffles\nresult.execute().sort_values(by=['measured_on'])\n</code></pre> <pre><code># Create a window that orders your series (use ibis.desc to get descending order)\nwin = ibis.window(order_by=ibis.desc(data.measured_on), following=0)\n# Create a grouping that is a rolling count of non-null values\n# This creates a partition where each set has no more than one non-null value\ngrouped = data.mutate(grouper=data.measurement.count().over(win))\n# Group by your newly-created grouping and, in each set,\n# set all values to the one non-null value in that set (if it exists)\nresult = (\n    grouped\n    .group_by([grouped.grouper])\n    .mutate(ffill=grouped.measurement.max())\n)\n# execute to get a pandas dataframe, sort values in case your backend shuffles\nresult.execute().sort_values(by=['measured_on'])\n</code></pre> <p>If you have an event partition, which means there's another segment you need to consider for your ffill or bfill operations, you can do this as well:</p> <code>ffill</code> with event partition<code>bfill</code> with event partition <pre><code># Group your data by your event partition and then order your series (default ascending)\nwin = ibis.window(group_by=data.event_id, order_by=data.measured_on, following=0)\n# Create a grouping that is a rolling count of non-null values within each event\n# This creates a partition where each set has no more than one non-null value\ngrouped = data.mutate(grouper=data.measurement.count().over(win))\n# Group by your newly-created grouping and, in each set,\n# set all values to the one non-null value in that set (if it exists)\nresult = (\n    grouped\n    .group_by([grouped.event_id, grouped.grouper])\n    .mutate(ffill=grouped.measurement.max())\n)\n# execute to get a pandas dataframe, sort values in case your backend shuffles\nresult.execute().sort_values(by=['event_id', 'measured_on'])\n</code></pre> <pre><code># Group your data by your event partition and then order your series (use ibis.desc for desc)\nwin = ibis.window(group_by=data.event_id, order_by=ibis.desc(data.measured_on), following=0)\n# Create a grouping that is a rolling count of non-null values within each event\n# This creates a partition where each set has no more than one non-null value\ngrouped = data.mutate(grouper=data.measurement.count().over(win))\n# Group by your newly-created grouping and, in each set,\n# set all values to the one non-null value in that set (if it exists)\nresult = (\n    grouped\n    .group_by([grouped.event_id, grouped.grouper])\n    .mutate(ffill=grouped.measurement.max())\n)\n# execute to get a pandas dataframe, sort values in case your backend shuffles\nresult.execute().sort_values(by=['event_id', 'measured_on'])\n</code></pre> <p>We wrote a deeper dive into how this works on the ibis-project blog here.</p>"},{"location":"how_to/memtable-join/","title":"How to join an in-memory DataFrame to a TableExpression","text":"<p>You might have an in-memory DataFrame that you want to join to a TableExpression. For example, you might have a file on your local machine that you don't want to upload to your backend, but you need to join it to a table in that backend.</p> <p>You can perform joins on local data to TableExpressions from your backend easily with Ibis MemTables.</p> <p>In this guide, you will learn how to join a pandas DataFrame to a TableExpression.</p>"},{"location":"how_to/memtable-join/#data-setup","title":"Data Setup:","text":"<p>In this example, we will create two DataFrames: one containing events and one containing event names. We will save the events to a parquet file and read that as a TableExpression in the DuckDB backend. We will then convert the event names DataFrame to a PandasInMemoryTable (MemTable), which is a pandas DataFrame as a TableExpression and join the two expressions together as we would two TableExpressions in a backend.</p> <pre><code>    In [1]: import ibis\n\n    In [2]: import pandas as pd\n       ...: from datetime import date\n\n    In [3]: # create a pandas DataFrame that we will convert to a\n       ...: # PandasInMemoryTable (Ibis MemTable)\n       ...: events = pd.DataFrame(\n       ...:     {\n       ...:         'event_id': range(4),\n       ...:         'event_name': [f'e{k}' for k in range(4)],\n       ...:     }\n       ...: )\n\n    In [4]: # Create a parquet file that we will read in using the DuckDB backend\n       ...: # as a TableExpression\n       ...: measures = pd.DataFrame({\n       ...:     \"event_id\": [0] * 2 + [1] * 3 + [2] * 5 + [3] * 2\n       ...:     ,\"measured_on\": map(\n       ...:         date\n       ...:         ,[2021] * 12, [6] * 4 + [5] * 6 + [7] * 2\n       ...:         ,range(1, 13)\n       ...:     )\n       ...:     ,\"measurement\": None\n       ...: })\n\n    In [5]: measures.at[1, \"measurement\"] = 5.\n       ...: measures.at[4, \"measurement\"] = 42.\n       ...: measures.at[5, \"measurement\"] = 42.\n       ...: measures.at[7, \"measurement\"] = 11.\n\n    In [6]: # Save measures to parquet:\n       ...: measures.to_parquet('measures.parquet')\n\n    In [7]: # connect to a DuckDB backend\n       ...: conn = ibis.connect('duckdb://:memory:')\n       ...: measures = conn.register('measures.parquet', 'measures')\n\n    In [8]: # `measures` is a TableExpression in a DuckDB backend connection:\n       ...: measures\n    Out[8]:\n    AlchemyTable: measures\n      event_id    int64\n      measured_on date\n      measurement float64\n</code></pre> <p>Converting a pandas DataFrame to a MemTable is as simple as feeding it to <code>ibis.memtable</code>:</p> <pre><code>    In [9]: # To join, convert your DataFrame to a memtable\n       ...: mem_events = ibis.memtable(events)\n\n    In [10]: mem_events\n    Out[10]:\n    PandasInMemoryTable\n      data:\n        DataFrameProxy:\n             event_id event_name\n          0         0         e0\n          1         1         e1\n          2         2         e2\n          3         3         e3\n</code></pre> <p>and joining is the same as joining any two TableExpressions:</p> <pre><code>    In [11]: # Join as you would two table expressions\n        ...: measures.join(\n        ...:     mem_events\n        ...:     ,measures['event_id'] == mem_events['event_id']\n        ...:     ,suffixes=('', '__x')\n        ...: ).execute()\n    Out[11]:\n        event_id measured_on  measurement  event_id__x event_name\n    0          0  2021-06-01          NaN            0         e0\n    1          0  2021-06-02          5.0            0         e0\n    2          1  2021-06-03          NaN            1         e1\n    3          1  2021-06-04          NaN            1         e1\n    4          1  2021-05-05         42.0            1         e1\n    5          2  2021-05-06         42.0            2         e2\n    6          2  2021-05-07          NaN            2         e2\n    7          2  2021-05-08         11.0            2         e2\n    8          2  2021-05-09          NaN            2         e2\n    9          2  2021-05-10          NaN            2         e2\n    10         3  2021-07-11          NaN            3         e3\n    11         3  2021-07-12          NaN            3         e3\n</code></pre> <p>Note that the return result of the <code>join</code> is a TableExpression and that <code>execute</code> returns a pandas DataFrame.</p>"},{"location":"how_to/sessionize/","title":"How to Sessionize a Log of Events","text":"<p>Suppose you have entities (users, objects, actions, etc) that have event logs through polling or event triggers.</p> <p>You might be interested in partitioning these logs by something called sessions, which can be defined as groups of consecutive event records without long interruptions for a given entity.</p> <p>In the case of a user portal, it might be grouping the navigation events that result in completing a task or buying a product. For online games, it might be a the grouping of activity events of a given user playing the game while remaining logged in.</p> <p>Sessionization can also be useful on longer time scales, for instance to reconstruct active subscription data from a raw payment or activity log, so as to model customer churn.</p> <p>This guide on sessionization is inspired by The Expressions API in Polars is Amazing, a blog post in the Polars community demonstrating the strength of Polars expressions.</p>"},{"location":"how_to/sessionize/#sessionizing-logs-on-a-cadence","title":"Sessionizing Logs on a Cadence","text":"<p>For this example, we use an activity log from the online game \"World of Warcraft\" with more than 10 million records for 37,354 unique players made available under the CC0 / Public Domain license. A copy of the data can be found at <code>https://storage.googleapis.com/ibis-tutorial-data/wowah_data/wowah_data_raw.parquet</code> (75 MB) under the parquet format to reduce load times. You can use <code>ibis.read_parquet</code> to quickly get it into a table expression via the default <code>DuckDB</code> backend.</p> <p>This data contains the following fields:</p> <ul> <li><code>char</code> : a unique identifier for a character (or a player). This is our entity column.</li> <li><code>timestamp</code>: a timestamp denoting when a <code>char</code> was polled. This occurs every ~10 minutes.</li> </ul> <p>We can take this information, along with a definition of what separates two sessions for an entity, and break our dataset up into sessions without using any joins:</p> <pre><code># Imports\nimport ibis\nfrom ibis import deferred as c\n\n# Read files into table expressions with ibis.read_parquet:\ndata = ibis.read_parquet(\n    \"https://storage.googleapis.com/ibis-tutorial-data/wowah_data/wowah_data_raw.parquet\"\n)\n\n# Integer delay in seconds noting if a row should be included in the previous\n# session for an entity.\nsession_boundary_threshold = 30 * 60\n\n# Window for finding session ids per character\nentity_window = ibis.cumulative_window(group_by=c.char, order_by=c.timestamp)\n\n# Take the previous timestamp within a window (by character ordered by timestamp):\n# Note: the first value in a window will be null.\nts_lag = c.timestamp.lag().over(entity_window)\n\n# Subtract the lag from the current timestamp to get a timedelta.\nts_delta = c.timestamp - ts_lag\n\n# Compare timedelta to our session delay in seconds to determine if the\n# current timestamp falls outside of the session.\n# Cast as int for aggregation.\nis_new_session = (ts_delta &gt; ibis.interval(seconds=session_boundary_threshold))\n\n# Window to compute session min/max and duration.\nsession_window = ibis.window(group_by=[c.char, c.session_id])\n\n# Generate all of the data we need to analyze sessions:\nsessionized = (\n    data\n    # Create a session id for each character by using a cumulative sum\n    # over the `new_session` column.\n    .mutate(new_session=is_new_session.fillna(True))\n    # Create a session id for each character by using a cumulative sum\n    # over the `new_session` column.\n    .mutate(session_id=c.new_session.sum().over(entity_window))\n    # Drop `new_session` because it is no longer needed.\n    .drop(\"new_session\")\n    .mutate(\n        # Get session duration using max(timestamp) - min(timestamp) over our window.\n        session_duration=c.timestamp.max().over(session_window) - c.timestamp.min().over(session_window)\n    )\n    # Sort for convenience.\n    .order_by([c.char, c.timestamp])\n)\n</code></pre> <p>Calling <code>ibis.show_sql(sessionized)</code> displays the SQL query and can be used to confirm that this Ibis expression does not rely on any join operations.</p> <p>Calling <code>sessionized.execute()</code> should complete in less than a minute, depending on the speed of the internet connection to download the data and the number of CPU cores available to parallelize the processing of this nested query.</p>"},{"location":"how_to/topk/","title":"How to Compute the Top K Records","text":"<p>Here we use the <code>topk</code> method to compute the top 5 customers for some generated TPC-H data by:</p> <ul> <li>count (the default)</li> <li>sum of order totals</li> </ul> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; con = ibis.duckdb.connect()  # in-memory duckdb\n&gt;&gt;&gt; con.raw_sql(\"CALL dbgen(sf=0.1)\")\n&gt;&gt;&gt; orders = con.table(\"orders\")\n&gt;&gt;&gt; orders.o_custkey.topk(5)  # top 5 most frequent customers\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 o_custkey \u2503 count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 !int32    \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      8761 \u2502    36 \u2502\n\u2502     11998 \u2502    36 \u2502\n\u2502      3151 \u2502    35 \u2502\n\u2502      8362 \u2502    35 \u2502\n\u2502       388 \u2502    35 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; topk = orders.o_custkey.topk(5, by=orders.o_totalprice.sum())  # top 5 largest spending customers\n&gt;&gt;&gt; topk\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 o_custkey \u2503 sum            \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 !int32    \u2502 decimal(38, 2) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      8362 \u2502     5793605.05 \u2502\n\u2502      6958 \u2502     5370682.19 \u2502\n\u2502      9454 \u2502     5354381.81 \u2502\n\u2502       346 \u2502     5323350.43 \u2502\n\u2502     10354 \u2502     5227957.24 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can also use <code>topk</code> to retrieve the rows from the original table that match the key used, in this case <code>o_custkey</code>. This is done with a left semi join:</p> <pre><code>&gt;&gt;&gt; orders.semi_join(topk, \"o_custkey\")\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 o_orderkey \u2503 o_custkey \u2503 o_orderstatus \u2503 o_totalprice    \u2503 o_orderdate \u2503 o_orderpriority \u2503 o_clerk         \u2503 o_shippriority \u2503 o_comment                                                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 !int32     \u2502 !int32    \u2502 !string       \u2502 !decimal(15, 2) \u2502 !date       \u2502 !string         \u2502 !string         \u2502 !int32         \u2502 !string                                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502       4000 \u2502      6958 \u2502 F             \u2502       115722.85 \u2502 1992-01-04  \u2502 5-LOW           \u2502 Clerk#000000339 \u2502              0 \u2502 le carefully closely even pinto beans. regular, ironic foxe\u2026 \u2502\n\u2502      14402 \u2502      8362 \u2502 F             \u2502       131557.79 \u2502 1993-10-15  \u2502 3-MEDIUM        \u2502 Clerk#000000672 \u2502              0 \u2502 azzle slyly. carefully regular instructions affix carefully\u2026 \u2502\n\u2502      14784 \u2502     10354 \u2502 F             \u2502       216307.34 \u2502 1992-03-15  \u2502 3-MEDIUM        \u2502 Clerk#000000479 \u2502              0 \u2502 lyly final theodoli                                          \u2502\n\u2502      17415 \u2502     10354 \u2502 O             \u2502       110427.40 \u2502 1996-09-18  \u2502 2-HIGH          \u2502 Clerk#000000148 \u2502              0 \u2502 . furiously even asymptotes wake carefully according to t    \u2502\n\u2502      17760 \u2502      9454 \u2502 F             \u2502       167249.60 \u2502 1992-06-05  \u2502 4-NOT SPECIFIED \u2502 Clerk#000000093 \u2502              0 \u2502 uriously final pinto beans wake furiously                    \u2502\n\u2502      18853 \u2502      9454 \u2502 F             \u2502       163677.19 \u2502 1993-01-18  \u2502 1-URGENT        \u2502 Clerk#000000046 \u2502              0 \u2502 sts. courts haggle furiously. even, enticing depo            \u2502\n\u2502      21317 \u2502      8362 \u2502 P             \u2502       267386.98 \u2502 1995-04-10  \u2502 5-LOW           \u2502 Clerk#000000737 \u2502              0 \u2502 Tiresias. accounts a                                         \u2502\n\u2502      23138 \u2502      8362 \u2502 O             \u2502       174882.01 \u2502 1997-07-23  \u2502 1-URGENT        \u2502 Clerk#000000253 \u2502              0 \u2502 uctions integrate carefully regular pinto beans. silent acc\u2026 \u2502\n\u2502      23972 \u2502     10354 \u2502 F             \u2502       129646.66 \u2502 1993-08-17  \u2502 4-NOT SPECIFIED \u2502 Clerk#000001000 \u2502              0 \u2502 s. blithely final packages sleep quickly idle pearls. even,\u2026 \u2502\n\u2502      24064 \u2502       346 \u2502 F             \u2502       147095.22 \u2502 1993-07-26  \u2502 3-MEDIUM        \u2502 Clerk#000000020 \u2502              0 \u2502 ithely final foxes. furiously final instructi                \u2502\n\u2502          \u2026 \u2502         \u2026 \u2502 \u2026             \u2502               \u2026 \u2502 \u2026           \u2502 \u2026               \u2502 \u2026               \u2502              \u2026 \u2502 \u2026                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user_guide/configuration/","title":"Configuring Ibis","text":"<p>Ibis configuration happens through the <code>ibis.options</code> attribute. Attributes can be get and set like class attributes.</p>"},{"location":"user_guide/configuration/#interactive-mode","title":"Interactive mode","text":"<p>Ibis out of the box is in developer mode. Expressions display their internal details when printed to the console. For a better interactive experience, set the <code>interactive</code> option:</p> <pre><code>ibis.options.interactive = True\n</code></pre> <p>This will cause expressions to be executed immediately when printed to the console.</p>"},{"location":"user_guide/configuration/#sql-query-execution","title":"SQL Query Execution","text":"<p>If an Ibis table expression has no row limit set using the <code>limit</code> API, a default one is applied to prevent too much data from being retrieved from the query engine. The default is currently 10000 rows, but this can be configured with the <code>sql.default_limit</code> option:</p> <pre><code>ibis.options.sql.default_limit = 100\n</code></pre> <p>Set this to <code>None</code> to retrieve all rows in all queries</p> <p>Be careful with <code>None</code></p> <p>Setting the default limit to <code>None</code> will result in all rows from a query coming back to the client from the backend.</p> <pre><code>ibis.options.sql.default_limit = None\n</code></pre>"},{"location":"user_guide/configuration/#verbose-option-and-logging","title":"Verbose option and Logging","text":"<p>To see all internal Ibis activity (like queries being executed) set <code>ibis.options.verbose</code>:</p> <pre><code>ibis.options.verbose = True\n</code></pre> <p>By default this information is sent to <code>sys.stdout</code>, but you can set some other logging function:</p> <pre><code>def cowsay(msg):\n    print(f\"Cow says: {msg}\")\n\n\nibis.options.verbose_log = cowsay\n</code></pre>"},{"location":"user_guide/configuration/#default-backend","title":"Default backend","text":"<p><code>ibis.options.default_backend</code> controls which backend is used by table expressions returned by top-level functions such as <code>ibis.memtable</code>, <code>ibis.read_csv</code> or <code>ibis.read_parquet</code>.</p> <p>By default, it points to an instance of DuckDB backend. Assuming the backend dependencies have been installed, it can be updated by passing the name of the backend to <code>ibis.set_backend</code> as follows:</p> <pre><code>import ibis\n\nexpr = ibis.memtable({\"column\": [0, 1, 2, 3, 4]})\nibis.get_backend(expr)\n# &lt;ibis.backends.duckdb.Backend at 0x12fa0fb50&gt;\n\nibis.set_backend(\"sqlite\")\nibis.get_backend(expr)\n# &lt;ibis.backends.sqlite.Backend at 0x158411d10&gt;\n</code></pre>"},{"location":"user_guide/design/","title":"Design","text":""},{"location":"user_guide/design/#primary-goals","title":"Primary Goals","text":"<ol> <li>Type safety</li> <li>Expressiveness</li> <li>Composability</li> <li>Familiarity</li> </ol>"},{"location":"user_guide/design/#flow-of-execution","title":"Flow of Execution","text":"<ol> <li>User writes expression</li> <li>Each method or function call builds a new expression</li> <li>Expressions are type checked as you create them</li> <li>Expressions have some optimizations that happen as the user builds them</li> <li>Backend specific rewrites</li> <li>Expressions are compiled</li> <li>The SQL string that generated by the compiler is sent to the database and    executed (this step is skipped for the pandas backend)</li> <li>The database returns some data that is then turned into a pandas DataFrame    by ibis</li> </ol>"},{"location":"user_guide/design/#expressions","title":"Expressions","text":"<p>The main user-facing component of ibis is expressions. The base class of all expressions in ibis is the ibis.expr.types.Expr class.</p> <p>Expressions provide the user facing API, most of which is defined in <code>ibis/expr/api.py</code>.</p>"},{"location":"user_guide/design/#type-system","title":"Type System","text":"<p>Ibis's type system consists of a set of rules for specifying the types of inputs to <code>ibis.expr.types.Node</code> subclasses. Upon construction of a <code>Node</code> subclass, ibis performs validation of every input to the node based on the rule that was used to declare the input.</p> <p>Rules are defined in <code>ibis.expr.rules</code></p>"},{"location":"user_guide/design/#the-expr-class","title":"The <code>Expr</code> class","text":"<p>Expressions are a thin but important abstraction over operations, containing only type information and shape information, i.e., whether they are tables, columns, or scalars.</p> <p>Examples of expression types include <code>StringValue</code> and <code>Table</code>.</p>"},{"location":"user_guide/design/#the-ibisexprtypesnode-class","title":"The <code>ibis.expr.types.Node</code> Class","text":"<p><code>Node</code> subclasses make up the core set of operations of ibis. Each node corresponds to a particular operation.</p> <p>Most nodes are defined in the <code>ibis.expr.operations</code> module.</p> <p>Examples of nodes include <code>ibis.expr.operations.Add</code> and <code>ibis.expr.operations.Sum</code>.</p> <p>Nodes (transitively) inherit from a class that allows node authors to define their node's input arguments directly in the class body.</p> <p>Additionally the <code>output_type</code> member of the class is a rule or method that defines the shape (scalar or column) and element type of the operation.</p> <p>An example of usage is a node that representats a logarithm operation:</p> <pre><code>import ibis.expr.rules as rlz\nfrom ibis.expr.operations import Value\n\nclass Log(Value):\n   # A double scalar or column\n   arg = rlz.double\n   # Optional argument, defaults to None\n   base = rlz.optional(rlz.double)\n   # Output expression's datatype will correspond to arg's datatype\n   output_dtype = rlz.dtype_like('arg')\n   # Output expression will be scalar if arg is scalar, column otherwise\n   output_shape = rlz.shape_like('arg')\n</code></pre> <p>This class describes an operation called <code>Log</code> that takes one required argument: a double scalar or column, and one optional argument: a double scalar or column named <code>base</code> that defaults to nothing if not provided. The <code>base</code> argument is <code>None</code> by default so that the expression will behave as the underlying database does.</p> <p>Similar objects are instantiated when you use ibis APIs:</p> <pre><code>import ibis\nt = ibis.table([('a', 'float')], name='t')\nlog_1p = (1 + t.a).log()  # an Add and a Log are instantiated here\n</code></pre>"},{"location":"user_guide/design/#expressions-vs-operations-why-are-they-different","title":"Expressions vs Operations: Why are they different?","text":"<p>Separating expressions from their underlying operations makes it easy to generically describe and validate the inputs to particular nodes. In the log example, it doesn't matter what operation (node) the double-valued arguments are coming from, they must only satisfy the requirement denoted by the rule.</p> <p>Separation of the <code>ibis.expr.types.Node</code> and <code>ibis.expr.types.Expr</code> classes also allows the API to be tied to the physical type of the expression rather than the particular operation, making it easy to define the API in terms of types rather than specific operations.</p> <p>Furthermore, operations often have an output type that depends on the input type. An example of this is the <code>greatest</code> function, which takes the maximum of all of its arguments. Another example is <code>CASE</code> statements, whose <code>THEN</code> expressions determine the output type of the expression.</p> <p>This allows ibis to provide only the APIs that make sense for a particular type, even when an operation yields a different output type depending on its input. Concretely, this means that you cannot perform operations that don't make sense, like computing the average of a string column.</p>"},{"location":"user_guide/design/#compilation","title":"Compilation","text":"<p>The next major component of ibis is the compilers.</p> <p>The first few versions of ibis directly generated strings, but the compiler infrastructure was generalized to support compilation of SQLAlchemy based expressions.</p> <p>The compiler works by translating the different pieces of SQL expression into a string or SQLAlchemy expression.</p> <p>The main pieces of a <code>SELECT</code> statement are:</p> <p>!. The set of column expressions (<code>select_set</code>) !. <code>WHERE</code> clauses (<code>where</code>) !. <code>GROUP BY</code> clauses (<code>group_by</code>) !. <code>HAVING</code> clauses (<code>having</code>) !. <code>LIMIT</code> clauses (<code>limit</code>) !. <code>ORDER BY</code> clauses (<code>order_by</code>) !. <code>DISTINCT</code> clauses (<code>distinct</code>)</p> <p>Each of these pieces is translated into a SQL string and finally assembled by the instance of the <code>ibis.sql.compiler.ExprTranslator</code> subclass specific to the backend being compiled. For example, the <code>ibis.impala.compiler.ImpalaExprTranslator</code> is one of the subclasses that will perform this translation.</p> <p>Ibis can target other systems besides SQL</p> <p>While ibis was designed with an explicit goal of first-class SQL support, ibis can target other systems such as pandas.</p>"},{"location":"user_guide/design/#execution","title":"Execution","text":"<p>Presumably we want to do something with our compiled expressions. This is where execution comes in.</p> <p>This is least complex part of ibis, mostly only requiring ibis to correctly handle whatever the database hands back.</p> <p>By and large, the execution of compiled SQL is handled by the database to which SQL is sent from ibis.</p> <p>However, once the data arrives from the database we need to convert that data to a pandas DataFrame.</p> <p>The Query class, with its <code>ibis.sql.client.Query._fetch</code> method, provides a way for ibis <code>ibis.sql.client.SQLClient</code> objects to do any additional processing necessary after the database returns results to the client.</p>"},{"location":"user_guide/self_joins/","title":"Self Joins","text":"<p>If you\u2019re a relational data guru, you may have wondered how it\u2019s possible to join tables with themselves, because joins clauses involve column references back to the original table.</p> <p>Consider the SQL</p> <pre><code>SELECT t1.key, sum(t1.value - t2.value) AS metric\nFROM my_table t1\nJOIN my_table t2\nON t1.key = t2.subkey\nGROUP BY 1\n</code></pre> <p>Here, we have an unambiguous way to refer to each of the tables through aliasing.</p> <p>Let\u2019s consider the TPC-H database, and support we want to compute year-over-year change in total order amounts by region using joins.</p> <pre><code>&gt;&gt;&gt; region = con.table('tpch_region')\n&gt;&gt;&gt; nation = con.table('tpch_nation')\n&gt;&gt;&gt; customer = con.table('tpch_customer')\n&gt;&gt;&gt; orders = con.table('tpch_orders')\n&gt;&gt;&gt; orders.limit(5)\n   o_orderkey  o_custkey o_orderstatus o_totalprice o_orderdate  \\\n0           1      36901             O    173665.47  1996-01-02\n1           2      78002             O     46929.18  1996-12-01\n2           3     123314             F    193846.25  1993-10-14\n3           4     136777             O     32151.78  1995-10-11\n4           5      44485             F    144659.20  1994-07-30\n\n  o_orderpriority          o_clerk  o_shippriority  \\\n0           5-LOW  Clerk#000000951               0\n1        1-URGENT  Clerk#000000880               0\n2           5-LOW  Clerk#000000955               0\n3           5-LOW  Clerk#000000124               0\n4           5-LOW  Clerk#000000925               0\n\n                                           o_comment\n0                 nstructions sleep furiously among\n1   foxes. pending accounts at the pending, silen...\n2  sly final accounts boost. carefully regular id...\n3  sits. slyly regular warthogs cajole. regular, ...\n4  quickly. bold deposits sleep slyly. packages u...\n</code></pre> <p>First, let\u2019s join all the things and select the fields we care about:</p> <pre><code>&gt;&gt;&gt; fields_of_interest = [region.r_name.name('region'),\n...                       nation.n_name.name('nation'),\n...                       orders.o_totalprice.name('amount'),\n...                       orders.o_orderdate.cast('timestamp').name('odate') # these are strings\n...                       ]\n&gt;&gt;&gt; joined_all = (region.join(nation, region.r_regionkey == nation.n_regionkey)\n...               .join(customer, customer.c_nationkey == nation.n_nationkey)\n...               .join(orders, orders.o_custkey == customer.c_custkey)\n...               [fields_of_interest])\n</code></pre> <p>Okay, great, let\u2019s have a look:</p> <pre><code>&gt;&gt;&gt; joined_all.limit(5)\n        region         nation     amount      odate\n0      AMERICA  UNITED STATES  160843.35 1992-06-22\n1  MIDDLE EAST           IRAN   78307.91 1996-04-19\n2       EUROPE         FRANCE  103237.90 1994-10-12\n3       EUROPE         FRANCE  201463.59 1997-09-12\n4         ASIA          JAPAN  166098.86 1995-09-12\n</code></pre> <p>Sweet, now let\u2019s aggregate by year and region:</p> <pre><code>&gt;&gt;&gt; year = joined_all.odate.year().name('year')\n&gt;&gt;&gt; total = joined_all.amount.sum().cast('float').name('total')\n&gt;&gt;&gt; annual_amounts = (joined_all\n...                   .group_by(['region', year])\n...                   .aggregate(total))\n    &gt;&gt;&gt; annual_amounts.limit(5)\n         region  year         total\n0        EUROPE  1994  6.979473e+09\n1        EUROPE  1996  7.015421e+09\n2          ASIA  1997  6.910663e+09\n3          ASIA  1998  4.058824e+09\n4        EUROPE  1992  6.926705e+09\n</code></pre> <p>Looking good so far. Now, we need to join this table on itself, by subtracting 1 from one of the year columns.</p> <p>We do this by creating a \u201cjoinable\u201d view of a table that is considered a distinct object within Ibis. To do this, use the <code>view</code> function:</p> <pre><code>&gt;&gt;&gt; current = annual_amounts\n&gt;&gt;&gt; prior = annual_amounts.view()\n&gt;&gt;&gt; yoy_change = (current.total - prior.total).name('yoy_change')\n&gt;&gt;&gt; results = (current.join(prior, ((current.region == prior.region) &amp;\n...                                 (current.year == (prior.year - 1))))\n...            [current.region, current.year, yoy_change])\n&gt;&gt;&gt; df = results.execute()\n</code></pre> <pre><code>&gt;&gt;&gt; df['yoy_pretty'] = df.yoy_change.map(lambda x: '$%.2fmm' % (x / 1000000.))\n</code></pre> <p>If you\u2019re being fastidious and want to consider the first year occurring in the dataset for each region to have 0 for the prior year, you will instead need to do an outer join and treat nulls in the prior side of the join as zero:</p> <pre><code>&gt;&gt;&gt; yoy_change = (current.total - prior.total.zeroifnull()).name('yoy_change')\n&gt;&gt;&gt; results = (current.outer_join(prior, ((current.region == prior.region) &amp;\n...                                       (current.year == (prior.year - 1))))\n...            [current.region, current.year, current.total,\n...             prior.total.zeroifnull().name('prior_total'),\n...             yoy_change])\n&gt;&gt;&gt; results.limit(5)\n        region  year         total   prior_total    yoy_change\n0         ASIA  1998  4.058824e+09  0.000000e+00  4.058824e+09\n1       AFRICA  1994  6.837587e+09  6.908429e+09 -7.084172e+07\n2      AMERICA  1996  6.883057e+09  6.922465e+09 -3.940791e+07\n3       AFRICA  1996  6.878112e+09  6.848983e+09  2.912979e+07\n4       AFRICA  1992  6.873319e+09  6.859733e+09  1.358699e+07\n</code></pre>"},{"location":"user_guide/extending/elementwise/","title":"Adding an Elementwise Operation","text":"<p>This notebook will show you how to add a new elementwise operation to an existing backend.</p> <p>We are going to add <code>julianday</code>, a function supported by the SQLite database, to the SQLite Ibis backend.</p> <p>The Julian day of a date, is the number of days since January 1st, 4713 BC. For more information check the Julian day wikipedia page.</p> <p>Let's define the <code>julianday</code> operation as a function that takes one string input argument and returns a float.</p> <pre>def julianday(date: str) -&gt; float:\n\"\"\"Julian date\"\"\"\n</pre> In\u00a0[1]: Copied! <pre>import ibis.expr.datatypes as dt\nimport ibis.expr.rules as rlz\nfrom ibis.expr.operations import ValueOp\n\n\nclass JulianDay(ValueOp):\n    arg = rlz.string\n\n    output_dtype = dt.float32\n    output_shape = rlz.shape_like('arg')\n</pre> import ibis.expr.datatypes as dt import ibis.expr.rules as rlz from ibis.expr.operations import ValueOp   class JulianDay(ValueOp):     arg = rlz.string      output_dtype = dt.float32     output_shape = rlz.shape_like('arg') <p>We just defined a <code>JulianDay</code> class that takes one argument of type string or binary, and returns a float.</p> <p>Because we know the output type of the operation, to make an expression out of <code>JulianDay</code> we simply need to construct it and call its <code>ibis.expr.types.Node.to_expr</code> method.</p> <p>We still need to add a method to <code>StringValue</code> and <code>BinaryValue</code> (this needs to work on both scalars and columns).</p> <p>When you add a method to any of the expression classes whose name matches <code>*Value</code> both the scalar and column child classes will pick it up, making it easy to define operations for both scalars and columns in one place.</p> <p>We can do this by defining a function and assigning it to the appropriate class of expressions.</p> In\u00a0[2]: Copied! <pre>from ibis.expr.types import BinaryValue, StringValue\n\n\ndef julianday(string_value):\n    return JulianDay(string_value).to_expr()\n\n\nStringValue.julianday = julianday\n</pre> from ibis.expr.types import BinaryValue, StringValue   def julianday(string_value):     return JulianDay(string_value).to_expr()   StringValue.julianday = julianday In\u00a0[3]: Copied! <pre>import ibis\n\nt = ibis.table([('string_col', 'string')], name='t')\n\nt.string_col.julianday()\n</pre> import ibis  t = ibis.table([('string_col', 'string')], name='t')  t.string_col.julianday() Out[3]: <pre>r0 := UnboundTable: t\n  string_col string\n\nSelection[r0]\n  selections:\n    JulianDay(string_col): JulianDay(r0.string_col)\n</pre> In\u00a0[4]: Copied! <pre>import sqlalchemy as sa\n\n\n@ibis.sqlite.add_operation(JulianDay)\ndef _julianday(translator, expr):\n    # pull out the arguments to the expression\n    (arg,) = expr.args\n\n    # compile the argument\n    compiled_arg = translator.translate(arg)\n\n    # return a SQLAlchemy expression that calls into the SQLite julianday function\n    return sa.func.julianday(compiled_arg)\n</pre> import sqlalchemy as sa   @ibis.sqlite.add_operation(JulianDay) def _julianday(translator, expr):     # pull out the arguments to the expression     (arg,) = expr.args      # compile the argument     compiled_arg = translator.translate(arg)      # return a SQLAlchemy expression that calls into the SQLite julianday function     return sa.func.julianday(compiled_arg) In\u00a0[5]: Copied! <pre>!curl -LsS -o geography.db 'https://storage.googleapis.com/ibis-tutorial-data/geography.db'\n</pre> !curl -LsS -o geography.db 'https://storage.googleapis.com/ibis-tutorial-data/geography.db' In\u00a0[6]: Copied! <pre>import os\nimport tempfile\n\nimport ibis\n\ndb_fname = 'geography.db'\n\ncon = ibis.sqlite.connect(db_fname)\n</pre> import os import tempfile  import ibis  db_fname = 'geography.db'  con = ibis.sqlite.connect(db_fname) In\u00a0[7]: Copied! <pre>independence = con.table('independence')\nindependence\n</pre> independence = con.table('independence') independence Out[7]: <pre>AlchemyTable: independence\n  country_code      string\n  independence_date date\n  independence_from string\n</pre> In\u00a0[8]: Copied! <pre>day = independence.independence_date.cast('string')\nday\n</pre> day = independence.independence_date.cast('string') day Out[8]: <pre>r0 := AlchemyTable: independence\n  country_code      string\n  independence_date date\n  independence_from string\n\nSelection[r0]\n  selections:\n    Cast(independence_date, string): Cast(r0.independence_date, to=string)\n</pre> In\u00a0[9]: Copied! <pre>julianday_expr = day.julianday().name(\"jday\")\njulianday_expr\n</pre> julianday_expr = day.julianday().name(\"jday\") julianday_expr Out[9]: <pre>r0 := AlchemyTable: independence\n  country_code      string\n  independence_date date\n  independence_from string\n\nSelection[r0]\n  selections:\n    jday: JulianDay(Cast(r0.independence_date, to=string))\n</pre> In\u00a0[10]: Copied! <pre>sql_expr = julianday_expr.compile()\nprint(sql_expr)\n</pre> sql_expr = julianday_expr.compile() print(sql_expr) <pre>SELECT julianday(CAST(t0.independence_date AS TEXT)) AS jday \nFROM main.independence AS t0\n</pre> In\u00a0[11]: Copied! <pre>result = julianday_expr.execute()\nresult.head()\n</pre> result = julianday_expr.execute() result.head() Out[11]: <pre>0    2422189.5\n1    2419734.5\n2    2437850.5\n3    2442727.5\n4    2444909.5\nName: jday, dtype: float32</pre> <p>Because we've defined our operation on <code>StringValue</code>, and not just on <code>StringColumn</code> we get operations on both string scalars and string columns for free</p> In\u00a0[12]: Copied! <pre>scalar = ibis.literal('2010-03-14')\nscalar\n</pre> scalar = ibis.literal('2010-03-14') scalar Out[12]: <pre>'2010-03-14'</pre> In\u00a0[13]: Copied! <pre>julianday_scalar = scalar.julianday()\n</pre> julianday_scalar = scalar.julianday() In\u00a0[14]: Copied! <pre>con.execute(julianday_scalar)\n</pre> con.execute(julianday_scalar) Out[14]: <pre>2455269.5</pre>"},{"location":"user_guide/extending/elementwise/#Adding-an-Elementwise-Operation","title":"Adding an Elementwise Operation\u00b6","text":""},{"location":"user_guide/extending/elementwise/#Step-1:-Define-the-Operation","title":"Step 1: Define the Operation\u00b6","text":""},{"location":"user_guide/extending/elementwise/#Step-2:-Define-the-API","title":"Step 2: Define the API\u00b6","text":""},{"location":"user_guide/extending/elementwise/#Interlude:-Create-some-expressions-with-sha1","title":"Interlude: Create some expressions with <code>sha1</code>\u00b6","text":""},{"location":"user_guide/extending/elementwise/#Step-3:-Turn-the-Expression-into-SQL","title":"Step 3: Turn the Expression into SQL\u00b6","text":""},{"location":"user_guide/extending/elementwise/#Step-4:-Putting-it-all-Together","title":"Step 4: Putting it all Together\u00b6","text":""},{"location":"user_guide/extending/elementwise/#Create-and-execute-a-julianday-expression","title":"Create and execute a <code>julianday</code> expression\u00b6","text":""},{"location":"user_guide/extending/reduction/","title":"Adding a Reduction Operation","text":"<p>This notebook will show you how to add a new reduction operation <code>last_date</code> to the existing backend SQLite.</p> <p>A reduction operation is a function that maps $N$ rows to 1 row, for example the <code>sum</code> function.</p> <p>Let's define the <code>last_date</code> operation as a function that takes any date column as input and returns a date:</p> <pre>import datetime\nimport typing\n\ndef last_date(dates: typing.List[datetime.date]) -&gt; datetime.date:\n\"\"\"Latest date\"\"\"\n</pre> In\u00a0[1]: Copied! <pre>import ibis.expr.datatypes as dt\nimport ibis.expr.rules as rlz\nfrom ibis.expr.operations import Reduction\n\n\nclass LastDate(Reduction):\n    arg = rlz.column(rlz.date)\n    where = rlz.optional(rlz.boolean)\n\n    output_dtype = rlz.dtype_like('arg')\n    output_shape = rlz.Shape.SCALAR\n</pre> import ibis.expr.datatypes as dt import ibis.expr.rules as rlz from ibis.expr.operations import Reduction   class LastDate(Reduction):     arg = rlz.column(rlz.date)     where = rlz.optional(rlz.boolean)      output_dtype = rlz.dtype_like('arg')     output_shape = rlz.Shape.SCALAR <p>We just defined a <code>LastDate</code> class that takes one date column as input, and returns a scalar output of the same type as the input. This matches both the requirements of a reduction and the spepcifics of the function that we want to implement.</p> <p>Note: It is very important that you write the correct argument rules and output type here. The expression will not work otherwise.</p> <p>Because every reduction in ibis has the ability to filter out values during aggregation (a typical feature in databases and analytics tools), to make an expression out of <code>LastDate</code> we need to pass an additional argument: <code>where</code> to our <code>LastDate</code> constructor.</p> In\u00a0[2]: Copied! <pre>from ibis.expr.types import (\n    DateColumn,  # not DateValue! reductions are only valid on columns\n)\n\n\ndef last_date(date_column, where=None):\n    return LastDate(date_column, where=where).to_expr()\n\n\nDateColumn.last_date = last_date\n</pre> from ibis.expr.types import (     DateColumn,  # not DateValue! reductions are only valid on columns )   def last_date(date_column, where=None):     return LastDate(date_column, where=where).to_expr()   DateColumn.last_date = last_date In\u00a0[3]: Copied! <pre>import ibis\n</pre> import ibis In\u00a0[4]: Copied! <pre>people = ibis.table(\n    dict(name='string', country='string', date_of_birth='date'), name='people'\n)\n</pre> people = ibis.table(     dict(name='string', country='string', date_of_birth='date'), name='people' ) In\u00a0[5]: Copied! <pre>people.date_of_birth.last_date()\n</pre> people.date_of_birth.last_date() Out[5]: <pre>r0 := UnboundTable: people\n  name          string\n  country       string\n  date_of_birth date\n\nLastDate(date_of_birth): LastDate(r0.date_of_birth)</pre> In\u00a0[6]: Copied! <pre>people.date_of_birth.last_date(people.country == 'Indonesia')\n</pre> people.date_of_birth.last_date(people.country == 'Indonesia') Out[6]: <pre>r0 := UnboundTable: people\n  name          string\n  country       string\n  date_of_birth date\n\nLastDate(date_of_birth, Equals(country, 'Indonesia')): LastDate(r0.date_of_birth, where=r0.country == 'Indonesia')</pre> In\u00a0[7]: Copied! <pre>import sqlalchemy as sa\n\n\n@ibis.sqlite.add_operation(LastDate)\ndef _last_date(translator, expr):\n    # pull out the arguments to the expression\n    arg, where = expr.op().args\n\n    # compile the argument\n    compiled_arg = translator.translate(arg)\n\n    # call the appropriate SQLite function (`max` for the latest/maximum date)\n    agg = sa.func.max(compiled_arg)\n\n    # handle a non-None filter clause\n    if where is not None:\n        return agg.filter(translator.translate(where))\n    return agg\n</pre> import sqlalchemy as sa   @ibis.sqlite.add_operation(LastDate) def _last_date(translator, expr):     # pull out the arguments to the expression     arg, where = expr.op().args      # compile the argument     compiled_arg = translator.translate(arg)      # call the appropriate SQLite function (`max` for the latest/maximum date)     agg = sa.func.max(compiled_arg)      # handle a non-None filter clause     if where is not None:         return agg.filter(translator.translate(where))     return agg In\u00a0[8]: Copied! <pre>!curl -LsS -o geography.db 'https://storage.googleapis.com/ibis-tutorial-data/geography.db'\n</pre> !curl -LsS -o geography.db 'https://storage.googleapis.com/ibis-tutorial-data/geography.db' In\u00a0[9]: Copied! <pre>import os\nimport tempfile\n\nimport ibis\n\ndb_fname = 'geography.db'\n\ncon = ibis.sqlite.connect(db_fname)\n</pre> import os import tempfile  import ibis  db_fname = 'geography.db'  con = ibis.sqlite.connect(db_fname) In\u00a0[10]: Copied! <pre>independence = con.table('independence')\nindependence\n</pre> independence = con.table('independence') independence Out[10]: <pre>AlchemyTable: independence\n  country_code      string\n  independence_date date\n  independence_from string\n</pre> <p>Last country to gain independence in our database:</p> In\u00a0[11]: Copied! <pre>expr = independence.independence_date.last_date()\nexpr\n</pre> expr = independence.independence_date.last_date() expr Out[11]: <pre>r0 := AlchemyTable: independence\n  country_code      string\n  independence_date date\n  independence_from string\n\nLastDate(independence_date): LastDate(r0.independence_date)</pre> In\u00a0[12]: Copied! <pre>sql_expr = expr.compile()\nprint(sql_expr)\n</pre> sql_expr = expr.compile() print(sql_expr) <pre>SELECT max(t0.independence_date) AS \"LastDate(independence_date)\" \nFROM main.independence AS t0\n</pre> <pre>/tmp/nix-shell.dHqke1/ipykernel_1902206/3120781585.py:7: FutureWarning: `Node.op` is deprecated as of v4.0; remove intermediate .op() calls\n  arg, where = expr.op().args\n</pre> In\u00a0[13]: Copied! <pre>expr.execute()\n</pre> expr.execute() <pre>/tmp/nix-shell.dHqke1/ipykernel_1902206/3120781585.py:7: FutureWarning: `Node.op` is deprecated as of v4.0; remove intermediate .op() calls\n  arg, where = expr.op().args\n</pre> Out[13]: <pre>Timestamp('2011-07-09 00:00:00')</pre> <p>Last country to gain independence from the Spanish Empire, using the <code>where</code> parameter:</p> In\u00a0[14]: Copied! <pre>expr = independence.independence_date.last_date(\n    where=independence.independence_from == 'Spanish Empire'\n)\nexpr\n</pre> expr = independence.independence_date.last_date(     where=independence.independence_from == 'Spanish Empire' ) expr Out[14]: <pre>r0 := AlchemyTable: independence\n  country_code      string\n  independence_date date\n  independence_from string\n\nLastDate(independence_date, Equals(independence_from, 'Spanish Empire')): LastDate(r0.independence_date, where=r0.independence_from == 'Spanish Empire')</pre> In\u00a0[15]: Copied! <pre>result = expr.execute()\nresult\n</pre> result = expr.execute() result <pre>/tmp/nix-shell.dHqke1/ipykernel_1902206/3120781585.py:7: FutureWarning: `Node.op` is deprecated as of v4.0; remove intermediate .op() calls\n  arg, where = expr.op().args\n</pre> Out[15]: <pre>Timestamp('1898-06-12 00:00:00')</pre>"},{"location":"user_guide/extending/reduction/#Adding-a-Reduction-Operation","title":"Adding a Reduction Operation\u00b6","text":""},{"location":"user_guide/extending/reduction/#Description","title":"Description\u00b6","text":"<p>We're going to add a <code>last_date</code> function to ibis. <code>last_date</code> simply returns the latest date of a list of dates.</p>"},{"location":"user_guide/extending/reduction/#Step-1:-Define-the-Operation","title":"Step 1: Define the Operation\u00b6","text":""},{"location":"user_guide/extending/reduction/#Step-2:-Define-the-API","title":"Step 2: Define the API\u00b6","text":""},{"location":"user_guide/extending/reduction/#Interlude:-Create-some-expressions-using-last_date","title":"Interlude: Create some expressions using <code>last_date</code>\u00b6","text":""},{"location":"user_guide/extending/reduction/#Step-3:-Turn-the-Expression-into-SQL","title":"Step 3: Turn the Expression into SQL\u00b6","text":""},{"location":"user_guide/extending/reduction/#Step-4:-Putting-it-all-Together","title":"Step 4: Putting it all Together\u00b6","text":""},{"location":"user_guide/extending/reduction/#Create-and-execute-a-bitwise_and-expression","title":"Create and execute a <code>bitwise_and</code> expression\u00b6","text":""}]}