---
title: "Ibis"
description: "the portable Python dataframe library"
css: index.scss
repo-actions: false
code-annotations: hover
twitter-card:
  image: logo.png
format:
  html:
    toc: false
    include-in-header:
      text: |
        <script data-goatcounter="https://ibis.goatcounter.com/count"
                async src="//gc.zgo.at/count.js"></script>
about:
  id: about
  template: jolla
  image: logo.svg
  links:
    - icon: info-circle
      href: why.qmd
    - icon: download
      href: install.qmd
    - icon: book
      href: tutorials/getting_started.qmd
    - icon: postcard
      text: Blog
      href: posts.qmd
    - icon: github
      text: GitHub
      href: https://github.com/ibis-project
    - icon: zulip
      href: https://ibis-project.zulipchat.com
      text: Chat
    - icon: rss
      text: RSS
      href: https://ibis-project.org/posts.xml
---

::: {#about}
:::

{{< pagebreak >}}

::: {.column-page}

### An open source dataframe library that works with any data system

- Fast local dataframes (via DuckDB by default)
- Compose Python dataframe and SQL code
- Use the same API for 20+ backends
- Iterate locally and deploy remotely by changing a single line of code

```{python}
#| code-fold: true
#| echo: false

import ibis

t = ibis.examples.penguins.fetch()
t.to_parquet("penguins.parquet")
```

## Fast local dataframes

Ibis offers a familiar local dataframe experience with outstanding performance,
using [DuckDB](https://duckdb.org) by default.

```{python}
import ibis  # <1>

ibis.options.interactive = True  # <2>

t = ibis.read_parquet("penguins.parquet", table_name="penguins")  # <3>
t.head(3)  # <4>
```

1. Import Ibis.
2. Enable interactive mode for exploratory data analysis (EDA) or demos.
3. Read a Parquet file and specify a table name (optional).
4. Display the first few rows of the table.

Iterate and explore data locally:

```{python}
grouped = t.group_by("species", "island").agg(count=t.count()).order_by("count")  # <1>
grouped  # <2>
```

1. Transform the table.
2. Display the transformed table.

## Python + SQL: better together

Ibis works by decoupling the dataframe API from the backend execution. Most
backends support a SQL dialect, which Ibis compiles its expressions into using
[SQLGlot](https://github.com/tobymao/sqlglot). You can inspect the SQL that Ibis
generates for any SQL backend:

```{python}
ibis.to_sql(grouped)  # <1>
```

1. Display the SQL generated from the table expression.

And use SQL strings directly, mixing and matching with Python dataframe code:

```{python}
t.sql(  # <1>
    "SELECT species, island, COUNT(*) AS count FROM penguins GROUP BY species, island"  # <1>
).order_by("count")  # <2>
```

1. Transform the table using SQL.
2. Then, transform the table using Python dataframe code.

This allows you to combine the flexibility of Python with the scale and
performance of modern SQL.

## 20+ backends

Use the same dataframe API for 20+ backends:

```{python}
#| code-fold: true
#| echo: false

from backends_sankey import fig
fig.show()
```

For example:

::: {.panel-tabset}

## DuckDB

```{python}
backend = "duckdb"
con = ibis.connect(f"{backend}://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## Polars

```{python}
backend = "polars"
con = ibis.connect(f"{backend}://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## DataFusion

```{python}
backend = "datafusion"
con = ibis.connect(f"{backend}://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## PySpark

```{python}
backend = "pyspark"
con = ibis.connect(f"{backend}://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

:::

## Development to production

Iterate locally and deploy remotely by changing a single line of code. For
instance, switch between DuckDB and BigQuery:

```python
local_con = ibis.duckdb.connect()
remote_con = ibis.bigquery.connect()
```

```{python}
#| code-fold: true
#| echo: false

local_con = ibis.duckdb.connect()
remote_con = ibis.duckdb.connect()
penguins = ibis.examples.penguins.fetch()
_ = remote_con.create_table("penguins", penguins.to_pyarrow())
```

Get the table from the remote backend:
```{python}
remote_penguins = remote_con.table("penguins")
remote_penguins.head(3)
```

And downsample the data to work locally:

```{python}
sampled_penguins = remote_penguins.sample(0.1)  # <1>
local_con.create_table("penguins", sampled_penguins.to_pyarrow())  # <2>
local_penguins = local_con.table("penguins")  # <3>
local_penguins.head(3)  # <4>
```

1. Create a sample from the remote table.
2. Transfer the sampled data to the local backend via Apache Arrow.
3. Load the sampled data into a local table.
4. Display the first few rows of the local table.

Then, just write Python code to encapsulate your logic:

```{python}
def transform_penguins(table):
    """Logic to transform the penguins table."""
    transformed = (
        table.group_by("species", "island")
        .agg(
            min_body_mass=table["body_mass_g"].min(),
            mean_body_mass=table["body_mass_g"].mean(),
            max_body_mass=table["body_mass_g"].max(),
            std_body_mass=table["body_mass_g"].std(),
        )
        .order_by("species", "island")
    )

    return transformed
```

And run on DuckDB locally with the sampled data:

```{python}
transform_penguins(local_penguins)
```

Then once you're done iterating, run the same code on BigQuery remotely with the
full dataset:

::: {.callout-note}
Results differ due to the downsampling earlier -- the same logic is executed.
:::

```{python}
transform_penguins(remote_penguins)
```

## Users say...

::: {.grid}

::: {.g-col-4}
::: {.figure .text-center}
::: {.blockquote}
"Ibis is amazing, we have so much bikeshedding at my job that I feel this is
going to significantly improve upon. Big thanks to those who have contributed!
Currently using it to power a dashboard using Druid under the hood without
needing to remember the nuances of Druid SQL."
:::
[Nick Shook]{.blockquote-footer}
:::
:::

::: {.g-col-4}
::: {.figure .text-center}
::: {.blockquote}
"I now have Ibis code that runs PySpark in my Databricks environment and Polars
on my laptop which is pretty slick ðŸ”¥"
:::
[Mark Druffle]{.blockquote-footer}
:::
:::

::: {.g-col-4}
::: {.figure .text-center}
::: {.blockquote}
"I love that with Ibis, I can use SQL for the heavy lifting or aggregations and
then switch to a dataframe-like API for the type of dynamic transformations that
would otherwise be tedious to do in pure SQL."
:::
[Daniel Kim]{.blockquote-footer}
:::
:::

:::

## Quickstart

Below is a quick introduction to Ibis using DuckDB. See [the getting started
tutorial](tutorials/getting_started.qmd) for a more in-depth introduction.

### Install

We recommend starting with the default backend (DuckDB) and some built-in
example data.

::: {.callout-tip}
See the [full installation guide](install.qmd) for the list of available
backends and more installation options.
:::

```bash
pip install 'ibis-framework[duckdb,examples]' # <1>
```

1. Install Ibis with the DuckDB backend along with examples.

### Imports and example data

```{python}
import ibis  # <1>

ibis.options.interactive = True  # <2>

t = ibis.examples.penguins.fetch()  # <3>
t.head(3)  # <4>
```

1. Import Ibis.
2. Use interactive mode for exploratory data analysis (EDA) or demos.
3. Load a dataset from the built-in examples.
4. Display the table.

Ibis is a dataframe library with familiar syntax.

```{python}
t[10:15]  # <1>
```

1. Display a slice of the table.

### Analytics

Ibis is built for easy analytics at scale in Python.

```{python}
(  # <1>
    t.filter(t["body_mass_g"] != None)  # <1>
    .group_by("species", "island")  # <1>
    .aggregate(count=ibis._.count())  # <1>
    .order_by(ibis.desc("count"))  # <1>
)  # <1>
```

1. Group by species and island, and compute the number of rows in each group.

### Exploratory data analysis (EDA) and visualization

#### Exploratory data analysis

Ibis has built-in methods for exploration and [visualization](#visualization).

```{python}
t["species"].value_counts()  # <1>
```

1. Display the top species by count.

Describe the table:

```{python}
t.describe()  # <1>
```

1. Display summary statistics.

#### Visualization

Ibis works with any Python plotting library that supports the [dataframe
interchange
protocol](https://data-apis.org/dataframe-protocol/latest/index.html).
Otherwise, you can always call `to_pandas()` or `to_polars()` to convert the
table to a format that your plotting library supports.

```{python}
grouped = (  # <1>
    t.group_by("species")  # <1>
    .aggregate(count=ibis._.count())  # <1>
    .order_by(ibis.desc("count"))  # <1>
)  # <1>
grouped  # <2>
```

1. Setup data to plot.
2. Display the table.

::: {.panel-tabset}

## Altair

```{.bash}
pip install altair
```

```{python}
import altair as alt

chart = (
    alt.Chart(grouped)
    .mark_bar()
    .encode(
        x="species",
        y="count",
        tooltip=["species", "count"],
    )
    .properties(width=600, height=400)
    .interactive()
)
chart
```

## matplotlib

```{.bash}
pip install matplotlib
```

```{python}
import matplotlib.pyplot as plt

plt.figure(figsize=(600 / 100, 400 / 100))
plt.bar(
    data=grouped.to_pandas(),
    x="species",
    height="count",
)
plt.show()
```

## Plotly

```{.bash}
pip install plotly
```

```{python}
import plotly.express as px

chart = px.bar(
    grouped,
    x="species",
    y="count",
    width=600,
    height=400,
)
chart
```

## plotnine

```{.bash}
pip install plotnine
```
```{python}
from plotnine import ggplot, aes, geom_bar, theme

chart = (
    ggplot(
        grouped,
        aes(x="species", y="count"),
    )
    + geom_bar(stat="identity")
    + theme(figure_size=(600 / 100, 400 / 100))
)
chart
```

## seaborn

```{.bash}
pip install seaborn
```

```{python}
import seaborn as sns

chart = sns.barplot(
    data=grouped.to_pandas(),
    x="species",
    y="count",
)
chart.figure.set_size_inches(600 / 100, 400 / 100)
```

:::

### Data science

Use Ibis with your favorite data science libraries for concise and efficient
workflows.

```{python}
import ibis.selectors as s  # <1>


def transform(t):  # <2>
    t = t.mutate(  # <2>
        s.across(s.numeric(), {"zscore": lambda x: (x - x.mean()) / x.std()})  # <2>
    ).dropna()  # <2>
    return t  # <2>


f = transform(t.drop("year"))  # <3>
f.select("species", "island", s.contains("zscore"))  # <4>
```

1. Import the selectors module.
2. Define a function to transform the table for code reuse (compute z-scores on
 numeric columns).
3. Apply the function to the table and assign it to a new variable.
4. Display the transformed table.

```bash
pip install scikit-learn
```

```{python}
import plotly.express as px  # <1>
from sklearn.decomposition import PCA  # <1>

X = f.select(s.contains("zscore"))  # <2>

n_components = 3  # <3>
pca = PCA(n_components=n_components).fit(X)  # <3>

t_pca = ibis.memtable(pca.transform(X)).rename(  # <4>
    {"pc1": "col0", "pc2": "col1", "pc3": "col2"}
)  # <4>

f = f.mutate(row_number=ibis.row_number().over()).join(  # <5>
    t_pca.mutate(row_number=ibis.row_number().over()),
    "row_number",
)  # <5>

px.scatter_3d(  # <6>
    f,
    x="pc1",
    y="pc2",
    z="pc3",
    color="species",
    symbol="island",
    template="plotly_dark",
)  # <6>
```

1. Import data science libraries
2. Select "features" (numeric columns) as X
3. Compute PCA
4. Create a table from the PCA results
5. Join the PCA results to the original table
6. Plot the results

### Input and output

Ibis supports a variety of input and output options.

#### Data platforms

You can connect Ibis to any supported backend to read and write data in
backend-native tables.

```{python}
#| code-fold: true
#| code-summary: "Setup code"

import os
import ibis

if os.path.exists("penguins.ddb"):
    os.remove("penguins.ddb")

t = ibis.examples.penguins.fetch()
con = ibis.duckdb.connect("penguins.ddb")
con.create_table("penguins", t.to_pyarrow(), overwrite=True)
con.disconnect()
```

```{python}
con = ibis.duckdb.connect("penguins.ddb")  # <1>
con.list_tables() # <2>
```

1. Connect to a backend with existing data.
2. List tables in the backend.

```{python}
t = con.table("penguins")  # <1>
t.head(3)  # <2>
```

1. Load a table from the backend.
2. Display the table.

```{python}
grouped = (  # <1>
    t.group_by(["species", "island"])  # <1>
    .aggregate(count=ibis._.count())  # <1>
    .order_by(ibis.desc("count"))  # <1>
)  # <1>
con.create_table("penguins_grouped", grouped, overwrite=True)  # <2>
```

1. Create a lazily evaluated Ibis expression.
2. Write to a table.

```{python}
con.list_tables()  # <1>
```

1. List tables in the backend.

#### File formats

Depending on the backend, you can read and write data in several file formats.

::: {.panel-tabset}

## CSV

```{.bash}
pip install 'ibis-framework[duckdb]'
```

```{python}
t.to_csv("penguins.csv")  # <1>
ibis.read_csv("penguins.csv").head(3)  # <2>
```

1. Write the table to a CSV file. Dependent on backend.
2. Read the CSV file into a table. Dependent on backend.

## Delta Lake

```{.bash}
pip install 'ibis-framework[duckdb,deltalake]'
```

```{python}
t.to_delta("penguins.delta", mode="overwrite")  # <1>
ibis.read_delta("penguins.delta").head(3)  # <2>
```

1. Write the table to a Delta Lake table. Dependent on backend.
2. Read the Delta Lake table into a table. Dependent on backend.

## Parquet

```{.bash}
pip install 'ibis-framework[duckdb]'
```

```{python}
t.to_parquet("penguins.parquet")  # <1>
ibis.read_parquet("penguins.parquet").head(3)  # <2>
```

1. Write the table to a Parquet file. Dependent on backend.
2. Read the Parquet file into a table. Dependent on backend.

:::

#### With other Python libraries

Ibis uses [Apache Arrow](https://arrow.apache.org/) for efficient data transfer
to and from other libraries. Ibis tables implement the `__dataframe__` and
`__array__` protocols, so you can pass them to any library that supports these
protocols.

::: {.panel-tabset}

## pandas

You can convert Ibis tables to pandas dataframes.

```bash
pip install pandas
```

```{python}
df = t.to_pandas()  # <1>
df.head(3)
```

1. Returns a pandas dataframe.

Or you can convert pandas dataframes to Ibis tables.

```{python}
t = ibis.memtable(df)  # <1>
t.head(3)
```

1. Returns an Ibis table.

## Polars

You can convert Ibis tables to Polars dataframes.

```bash
pip install polars
```

```{python}
df = t.to_polars()
df.head(3)
```

Or Polars dataframes to Ibis tables.

```{python}
t = ibis.memtable(df)
t.head(3)
```

## PyArrow

You can convert Ibis tables to PyArrow tables.

```bash
pip install pyarrow
```

```{python}
t.to_pyarrow()
```

Or PyArrow batches:

```{python}
t.to_pyarrow_batches()
```

And you can convert PyArrow tables to Ibis tables.

```{python}
ibis.memtable(t.to_pyarrow()).head(3)
```

## PyTorch

You can convert Ibis tables to torch tensors.

```bash
pip install torch
```

```python
t.select(s.numeric()).limit(3).to_torch()
```

```
{'col2': tensor([39.1000, 39.5000, 40.3000], dtype=torch.float64),
 'col3': tensor([18.7000, 17.4000, 18.0000], dtype=torch.float64),
 'col4': tensor([181., 186., 195.], dtype=torch.float64),
 'col5': tensor([3750., 3800., 3250.], dtype=torch.float64),
 'col7': tensor([2007, 2007, 2007], dtype=torch.int16)}
```

## `__dataframe__`

You can directly call the `__dataframe__` protocol on Ibis tables, though this
is typically handled by the library you're using.

```{python}
t.__dataframe__()
```

## `__array__`

You can directly call the `__array__` protocol on Ibis tables, though this is
typically handled by the library you're using.

```{python}
t.__array__()
```

:::

### SQL + Python

Ibis has the `ibis.to_sql` to generate SQL strings.

In a Jupyter notebook or IPython shell session, the output of `ibis.to_sql` will
be syntax highlighted. In a plain Python REPL use `print(ibis.to_sql(...))` to
pretty print SQL.

Ibis uses [SQLGlot](https://sqlglot.com) under the hood to allow passing a
`dialect` parameter to SQL methods.

::: {.panel-tabset}

## BigQuery

```{python}
dialect = "bigquery"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain `.sql` (specifying a `dialect` as input) and Ibis expressions together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## ClickHouse

```{python}
dialect = "clickhouse"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## DataFusion

```{python}
dialect = "datafusion"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## DuckDB

```{python}
dialect = "duckdb"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## Druid

```{python}
dialect = "druid"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## Flink

```{python}
dialect = "flink"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## MSSQL

```{python}
dialect = "mssql"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## MySQL

```{python}
dialect = "mysql"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## Oracle

```{python}
dialect = "oracle"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## PostgreSQL

```{python}
dialect = "postgres"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## PySpark

```{python}
dialect = "pyspark"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## Snowflake

```{python}
dialect = "snowflake"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## SQLite

```{python}
dialect = "sqlite"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

## Trino

```{python}
dialect = "trino"  # <1>
sql = ibis.to_sql(  # <2>
    grouped,  # <2>
    dialect=dialect,  # <2>
)  # <2>
sql  # <3>
```

1. Set the dialect.
2. Convert the table to a SQL string.
3. Display the SQL string.

You can chain Ibis expressions and `.sql` together.

```{python}
con.sql(sql, dialect=dialect).filter(ibis._["species"] == "Adelie")  # <1>
```

1. Chain `.sql` calls and Ibis expressions together.

:::

:::
