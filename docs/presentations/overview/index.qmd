---
title: "Ibis: an overview"
author:
  - Cody Peterson
date: "2024-07-24"
execute:
  echo: true
format:
  revealjs:
    footer: <https://ibis-project.org>
    # preview-links: true
    chalkboard: true
    incremental: false
    # https://quarto.org/docs/presentations/revealjs/themes.html#using-themes
    theme: dark
    scrollable: true
    # smaller: true
---

# composable data systems

## A Python perspective

["The Road to Composable Data Systems: Thoughts on the Last 15 Years and the Future"](https://wesmckinney.com/blog/looking-back-15-years) by Wes McKinney:

> **pandas solved many problems that database systems also solve**, but almost no one in the data science ecosystem had the expertise to build a data frame library using database techniques. Eagerly-evaluated APIs (as opposed to “lazy” ones) make it more difficult to do efficient “query” planning and execution. **Data interoperability with other systems is always going to be painful**...

## A Python perspective

["The Road to Composable Data Systems: Thoughts on the Last 15 Years and the Future"](https://wesmckinney.com/blog/looking-back-15-years) by Wes McKinney:

> ...**unless faster, more efficient “standards” for interoperability are created**.

## Layers

["The Composable Codex"](https://voltrondata.com/codex) by Voltron Data:

![layers](img/layers.png)

## Future

["The Composable Codex"](https://voltrondata.com/codex) by Voltron Data:

![future](img/future2.png)

## Why composable data systems?

Efficiency:

- time
- money
- data mesh
- engineering productivity
- avoid vendor lock-in

## How can you implement it? {.smaller}

Choose your stack:

:::: {.columns}

::: {.column width="33%"}
**UI**:

- Ibis (Python)
- dplyr (R)
- SQL
- ...
:::

::: {.column width="33%"}
**Execution engine**:

- DuckDB
- DataFusion
- Polars
- Spark
- Trino
- ClickHouse
- Snowflake
- Databricks
- Theseus
- ...
:::

::: {.column width="33%"}
**Storage**:

- Iceberg
- Delta Lake
- Hudi
- Hive-partitioned Parquet files
- ...
:::

::::

## Choose your stack (there's more) {.smaller}

Additionally, choose tools for:

**Orchestration**:

- Airflow
- Prefect
- Dagster
- Kedro
- SQLMesh
- dbt
- ...

**Ingestion**:

- dlt
- Airbyte
- requests
- Ibis
- ...

**Visualization**:

- Altair
- plotnine
- Plotly
- seaborn
- matplotlib
- ...

**Dashboarding**:

- Streamlit
- Quarto dashboards
- Shiny for Python
- Dash
- marimo
- ...

**Testing**:

- Great Expectations
- Pandera
- Pytest
- assert statements
- ...

**CLI**:

- Click
- Typer
- argparse
- ...

# what is Ibis?

## Ibis is a Python library for:

- exploratory data analysis (EDA)
- analytics
- data engineering
- machine learning
- building your own library
- ...

::: {.fragment}
::: {.r-fit-text}
***development to production with the same API***
:::
:::

## Getting started...

```{python}
#| code-fold: true
#| echo: false

import ibis

t = ibis.examples.penguins.fetch()
t.to_parquet("penguins.parquet")
```

```{python}
import ibis

ibis.options.interactive = True
```

```{python}
t = ibis.read_parquet("penguins.parquet")
t.head(3)
```

## One API, 20+ backends {.smaller}

::: {.panel-tabset}

## DuckDB

```{python}
con = ibis.connect("duckdb://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## Polars

```{python}
con = ibis.connect("polars://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## DataFusion

```{python}
con = ibis.connect("datafusion://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## PySpark

```{python}
con = ibis.connect("pyspark://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

:::

## How it works

Ibis compiles down to SQL or dataframe code:

```{python}
#| echo: false
import os
import sys

sys.path.append(os.path.abspath("../.."))

from backends_sankey import fig

fig.show()
```

## SQL + Python: better together

```{python}
#| code-fold: true
#| echo: false

import ibis

t = ibis.read_parquet("penguins.parquet", table_name="penguins")
```

For SQL backends, inspect the SQL generated by Ibis:

```{python}
g = t.group_by("species", "island").agg(count=t.count()).order_by(ibis.desc("count"))
ibis.to_sql(g)
```

## SQL + Python: better together

For SQL backends, mix SQL and Python:

```{python}
sql = """
SELECT
  species,
  island,
  count(*) as count
FROM penguins
GROUP BY 1, 2
"""
t.sql(sql)
```

## SQL + Python: better together

For SQL backends, mix SQL and Python:

```{python}
sql = """
SELECT
  species,
  island,
  count(*) as count
FROM penguins
GROUP BY 1, 2
"""
t.sql(sql).order_by(ibis.desc("count"))
```

# demo

## `ibis-analytics`

Analyzing 10M+ rows from 4+ data sources.

```{=html}
<iframe class="streamlit-app-inner" width="100%" height="75%" src="https://ibis-analytics.streamlit.app/?embedded=true"></iframe>
```

# why

## Dataframe lore {.smaller}

::: {.fragment .fade-in-then-semi-out}
Dataframes first appeared in the `S` programming language (*in 1991!*), then evolved into the `R` programming language.
:::

::: {.fragment .fade-in-then-semi-out}
Then `pandas` perfected the dataframe in Python...or did it?
:::

::: {.fragment .fade-in-then-semi-out}
Since, dozens of Python dataframes libraries have come and gone...
:::

::: {.fragment .fade-in-then-semi-out}
The pandas API remains the de facto standard for dataframes in Python (alongside PySpark), but it doesn't scale.
:::

::: {.fragment .fade-in-then-semi-out}
This leads to data scientists frequently "throwing their work over the wall" to data engineers and ML engineers.
:::

::: {.fragment .fade-in-then-semi-out}
But what if there were a new [standard](https://xkcd.com/927/)?
:::

## Ibis origins {.smaller}

::: {.fragment .fade-left}
from [Apache Arrow and the "10 Things I Hate About pandas"](https://wesmckinney.com/blog/apache-arrow-pandas-internals/) by Wes McKinney
:::

::: {.fragment .fade-left}
> ...in 2015, I started the Ibis project...to create a pandas-friendly deferred expression system for static analysis and compilation [of] these types of [query planned, multicore execution] operations. Since an efficient multithreaded in-memory engine for pandas was not available when I started Ibis, I instead focused on building compilers for SQL engines (Impala, PostgreSQL, SQLite), similar to the R dplyr package. Phillip Cloud from the pandas core team has been actively working on Ibis with me for quite a long time.
:::

## Two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:
:::

::: {.column}
Python:
:::

::::
:::

## Two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:

- databases & tables
:::

::: {.column}
Python:

- files & dataframes
:::

::::
:::

## Two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:

- databases & tables
- analytics
:::

::: {.column}
Python:

- files & dataframes
- data science
:::

::::
:::

## Two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:

- databases & tables
- analytics
- metrics
:::

::: {.column}
Python:

- files & dataframes
- data science
- statistics
:::

::::
:::

## Two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:

- databases & tables
- analytics
- metrics
- dashboards
:::

::: {.column}
Python:

- files & dataframes
- data science
- statistics
- notebooks
:::

::::
:::

## Two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
Python:

- files & dataframes
- data science
- statistics
- notebooks
:::

::: {.column}
SQL:

- databases & tables
- analytics
- metrics
- dashboards
:::

::::
:::

::: {.r-fit-text}
***Ibis bridges the gap.***
:::

## Python dataframe history {.smaller}

::: {.incremental}

- **pandas** (2008): dataframes in Python
- **Spark** (2009): distributed dataframes with PySpark
- **Dask** (2014): distributed pandas dataframes
- **Vaex** (2014): multicore dataframes in Python via C++
- [**Ibis**]{style="color:#7C65A0"} (2015): backend-agnostic dataframes in Python
- **cuDF** (2017): pandas API on GPUs
- **Modin** (2018): pandas API on Ray/Dask
- **Koalas** (2019): pandas API on Spark, later renamed "pandas API on Spark"
- **Polars** (2020): multicore dataframes in Python via Rust
- [**Ibis**]{style="color:#7C65A0"} (2022): Ibis invested in heavily by Voltron Data
- **Snowpark Python** (2022): PySpark-like dataframes on Snowflake
- **Daft** (2022): distributed dataframes in Python via Rust
- **BigQuery DataFrames** (2023): pandas API on Google BigQuery (via [Ibis]{style="color:#7C65A0"}!)
- **Snowpark pandas API** (2024): pandas API on Snowflake
- [**SQLFrame**]{style="color:#7C65A0"} (2024): backend-agnostic dataframes in Python (PySpark API)
- **DataFusion dataframes** (2024): multicore dataframes in Python via Rust

:::

## Obligatory standards xkcd

![standards](https://imgs.xkcd.com/comics/standards.png)

## Standards and composability

All Python dataframe libraries that are not Ibis (or SQLFrame) **lock you into an execution engine**.

::: {.fragment}
::: {.r-fit-text}
***Good [standards are composable]{style="color:#7C65A0"} and adopted by competitors.***
:::
:::

## Python dataframe history (aside) {.smaller}

We see three approaches:

::: {.nonincremental}
:::: {.columns}

::: {.column width=33%}
pandas clones:

- Modin
- pandas API on Spark
  - formerly known as Koalas
- cuDF
- Dask (sort of)
- BigQuery DataFrames
- Snowpark pandas API
:::

::: {.column width=33%}
PySpark clones:

- [SQLFrame]{style="color:#7C65A0"}
- Snowpark Python (sort of)
- DuckDB Spark API
- SQLGlot Spark API
:::

::: {.column width=33%}
something else:

- [Ibis]{style="color:#7C65A0"}
- Polars
- Daft
- DataFusion
:::

::::
:::

## Database history

- they got faster

::: {.fragment}
::: {.r-fit-text}
***Ibis brings the best of [databases]{style="color:#6A9BC9"} to [dataframes]{style="color:#D58273"}.***
:::
:::

## DuckDB {auto-animate="true"}

```python
import ibis

con = ibis.duckdb.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

An embeddable, zero-dependency, C++ SQL database engine.

## DataFusion {auto-animate="true"}

```python
import ibis

con = ibis.datafusion.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A Rust SQL query engine.

## ClickHouse {auto-animate="true"}

```python
import ibis

con = ibis.clickhouse.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A C++ column-oriented database management system.

## Polars {auto-animate="true"}

```python
import ibis

con = ibis.polars.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A Rust DataFrame library.

## BigQuery {auto-animate="true"}

```python
import ibis

con = ibis.bigquery.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A serverless, highly scalable, and cost-effective cloud data warehouse.

## Snowflake {auto-animate="true"}

```python
import ibis

con = ibis.snowflake.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A cloud data platform.

## Oracle {auto-animate="true"}

```python
import ibis

con = ibis.oracle.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A relational database management system.

## Spark {auto-animate="true"}

```python
import ibis

con = ibis.pyspark.connect(session)
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A unified analytics engine for large-scale data processing.

## Trino {auto-animate="true"}

```python
import ibis

con = ibis.trino.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A distributed SQL query engine.

## ...and more!

:::: {.columns}

::: {.column}
::: {.nonincremental}
- SQLite
- PostgreSQL
- MySQL
- MSSQL
:::
:::

::: {.column}
::: {.nonincremental}
- Druid
- pandas
- Impala
- Dask
:::
:::

::::

::: {.fragment .fade-left}
New backends are easy to add!^\*^
:::

::: {.fragment .fade-up}
^\*^usually
:::

# how

## Try it out now!

Install:

```bash
pip install 'ibis-framework[duckdb,examples]'
```

::: {.fragment .fade-left}
Then run:

```{python}
import ibis

ibis.options.interactive = True

t = ibis.examples.penguins.fetch()
t
```
:::

# questions?

# the end
