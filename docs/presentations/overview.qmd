---
title: "Ibis: an overview"
author:
  - Cody Peterson
execute:
  echo: true
format:
  revealjs:
    footer: <https://ibis-project.org>
    # preview-links: true
    chalkboard: true
    incremental: true
    # https://quarto.org/docs/presentations/revealjs/themes.html#using-themes
    theme: dark
    scrollable: true
    # smaller: true
---

# what

## Ibis is a Python library for:

- exploratory data analysis (EDA)
- analytics
- data engineering
- machine learning
- building your own library (e.g. [Google BigFrames](https://github.com/googleapis/python-bigquery-dataframes))
- ...

::: {.fragment}
::: {.r-fit-text}
development to production with the same API
:::
:::

## Getting started...

```{python}
#| code-fold: true
#| echo: false

import ibis

t = ibis.examples.penguins.fetch()
t.to_parquet("penguins.parquet")
```

```{python}
import ibis

ibis.options.interactive = True
```

```{python}
t = ibis.read_parquet("penguins.parquet")
t.head(3)
```

## One API, 20+ backends {.smaller}

::: {.panel-tabset}

## DuckDB

```{python}
con = ibis.connect("duckdb://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## Polars

```{python}
con = ibis.connect("polars://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## DataFusion

```{python}
con = ibis.connect("datafusion://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

## PySpark

```{python}
con = ibis.connect("pyspark://")
```

```{python}
t = con.read_parquet("penguins.parquet")
t.head(3)
```

```{python}
t.group_by("species", "island").agg(count=t.count()).order_by("count")
```

:::

## how it works

Ibis compiles down to SQL or dataframe code:

```{python}
#| echo: false

import os
import sys
sys.path.append(os.path.abspath(".."))

from backends_sankey import fig
fig.show()
```

## SQL + Python: better together

```{python}
#| code-fold: true
#| echo: false

import ibis

t = ibis.read_parquet("penguins.parquet", table_name="penguins")
```

For SQL backends, inspect the SQL generated by Ibis:

```{python}
g = t.group_by("species", "island").agg(count=t.count()).order_by(ibis.desc("count"))
ibis.to_sql(g)
```

## SQL + Python: better together

For SQL backends, mix SQL and Python:

```{python}
sql = """
SELECT
  species,
  island,
  count(*) as count
FROM penguins
GROUP BY 1, 2
"""
t.sql(sql)
```

## SQL + Python: better together

For SQL backends, mix SQL and Python:

```{python}
sql = """
SELECT
  species,
  island,
  count(*) as count
FROM penguins
GROUP BY 1, 2
"""
t.sql(sql).order_by(ibis.desc("count"))
```

# demo

## `ibis-analytics`

Analyzing 10M+ rows from 4+ data sources.

```{=html}
<iframe class="streamlit-app-inner" width="100%" height="75%" src="https://ibis-analytics.streamlit.app/?embedded=true"></iframe>
```

# why

## dataframe lore

::: {.fragment .fade-in-then-semi-out}
Dataframes first appeared in the `S` programming language (*in 1991!*), then evolved into the `R` programming language.
:::

::: {.fragment .fade-in-then-semi-out}
Then `pandas` perfected the dataframe in Python...or did it?
:::

::: {.fragment .fade-in-then-semi-out}
Since, dozens of Python dataframes libraries have come and gone...
:::

::: {.fragment .fade-in-then-semi-out}
The pandas API remains the de facto standard for dataframes in Python (alongside PySpark), but it doesn't scale.
:::

::: {.fragment .fade-in-then-semi-out}
This leads to data scientists frequently "throwing their work over the wall" to data engineers and ML engineers.
:::

::: {.fragment .fade-in-then-semi-out}
But what if there were a new [standard](https://xkcd.com/927/)?
:::

## Ibis origins

::: {.fragment .fade-left}
from [Apache Arrow and the "10 Things I Hate About pandas"](https://wesmckinney.com/blog/apache-arrow-pandas-internals/) by Wes McKinney
:::

::: {.fragment .fade-left}
> ...in 2015, I started the Ibis project...to create a pandas-friendly deferred expression system for static analysis and compilation [of] these types of [query planned, multicore execution] operations. Since an efficient multithreaded in-memory engine for pandas was not available when I started Ibis, I instead focused on building compilers for SQL engines (Impala, PostgreSQL, SQLite), similar to the R dplyr package. Phillip Cloud from the pandas core team has been actively working on Ibis with me for quite a long time.
:::

## two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:
:::

::: {.column}
Python:
:::

::::
:::

## two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:

- databases & tables
:::

::: {.column}
Python:

- files & dataframes
:::

::::
:::

## two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:

- databases & tables
- analytics
:::

::: {.column}
Python:

- files & dataframes
- data science
:::

::::
:::

## two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:

- databases & tables
- analytics
- metrics
:::

::: {.column}
Python:

- files & dataframes
- data science
- statistics
:::

::::
:::

## two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
SQL:

- databases & tables
- analytics
- metrics
- dashboards
:::

::: {.column}
Python:

- files & dataframes
- data science
- statistics
- notebooks
:::

::::
:::

## two world problem {auto-animate="true"}

::: {.nonincremental}
:::: {.columns}

::: {.column}
Python:

- files & dataframes
- data science
- statistics
- notebooks
:::

::: {.column}
SQL:

- databases & tables
- analytics
- metrics
- dashboards
:::

::::
:::

::: {.r-fit-text}
***Ibis bridges the gap.***
:::

## Python dataframe history {.smaller}

- **pandas** (2008): dataframes in Python
- **Spark** (2009): distributed dataframes with PySpark
- **Dask** (2014): distributed pandas dataframes
- **Vaex** (2014): multicore dataframes in Python via C++
- [**Ibis**]{style="color:#7C65A0"} (2015): dataframes in Python with SQL-like syntax
- **cuDF** (2017): pandas API on GPUs
- **Modin** (2018): pandas API on Ray/Dask
- **Koalas** (2019): pandas API on Spark, later renamed "pandas API on Spark"
- **Polars** (2020): multicore dataframes in Python via Rust
- [**Ibis**]{style="color:#7C65A0"} (2022): Ibis invested in heavily by Voltron Data
- **Snowpark Python** (2022): PySpark-like dataframes on Snowflake
- **BigQuery DataFrames** (2023): pandas API on Google BigQuery (via [Ibis]{style="color:#7C65A0"}!)
- **Snowpark pandas API** (2024): pandas API on Snowflake

## Python dataframe history (aside) {.smaller}

We see three approaches:

::: {.nonincremental}
:::: {.columns}

::: {.column width=33%}
pandas clones:

- Modin
- pandas API on Spark
  - formerly known as Koalas
- cuDF
- Dask (sort of)
- BigQuery DataFrames
- Snowpark pandas API
:::

::: {.column width=33%}
PySpark clones:

- Snowpark Python (sort of)
- DuckDB Spark API
- SQLGlot Spark API
:::

::: {.column width=33%}
something else:

- Ibis
- Polars
:::

::::
:::

## database history

- they got faster

::: {.fragment}
::: {.r-fit-text}
***Ibis brings the best of [databases]{style="color:#6A9BC9"} to [dataframes]{style="color:#D58273"}.***
:::
:::

## DuckDB {auto-animate="true"}

```python
import ibis

con = ibis.duckdb.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

An embeddable, zero-dependency, C++ SQL database engine.

## DataFusion {auto-animate="true"}

```python
import ibis

con = ibis.datafusion.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A Rust SQL query engine.

## ClickHouse {auto-animate="true"}

```python
import ibis

con = ibis.clickhouse.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A C++ column-oriented database management system.

## Polars {auto-animate="true"}

```python
import ibis

con = ibis.polars.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A Rust DataFrame library.

## BigQuery {auto-animate="true"}

```python
import ibis

con = ibis.bigquery.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A serverless, highly scalable, and cost-effective cloud data warehouse.

## Snowflake {auto-animate="true"}

```python
import ibis

con = ibis.snowflake.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A cloud data platform.

## Oracle {auto-animate="true"}

```python
import ibis

con = ibis.oracle.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A relational database management system.

## Spark {auto-animate="true"}

```python
import ibis

con = ibis.pyspark.connect(session)
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A unified analytics engine for large-scale data processing.

## Trino {auto-animate="true"}

```python
import ibis

con = ibis.trino.connect()
penguins = con.table("penguins")
penguins.group_by(["species", "island"]).agg(penguins.count().name("count"))
```

A distributed SQL query engine.

## and more!

:::: {.columns}

::: {.column}
::: {.nonincremental}
- SQLite
- PostgreSQL
- MySQL
- MSSQL
:::
:::

::: {.column}
::: {.nonincremental}
- Druid
- pandas
- Impala
- Dask
:::
:::

::::

::: {.fragment .fade-left}
New backends are easy to add!^\*^
:::

::: {.fragment .fade-up}
^\*^usually
:::


# how

## try it out now

Install:

```bash
pip install 'ibis-framework[duckdb,examples]'
```

::: {.fragment .fade-left}
Then run:

```{python}
import ibis

ibis.options.interactive = True

t = ibis.examples.penguins.fetch()
t
```
:::

# questions?

# the end
