## Data platforms

You can connect Ibis to any supported backend to read and write data in backend-native tables.

```{python}
# | code-fold: true

con = ibis.duckdb.connect("penguins.ddb")
t = con.create_table("penguins", t.to_pyarrow(), overwrite=True)
```

```{python}
con = ibis.duckdb.connect("penguins.ddb")  # <1>
t = con.table("penguins")  # <2>
t.head(3)  # <3>
```

1. Connect to a backend.
2. Load a table.
3. Display the table.

```{python}
grouped = (  # <1>
    t.group_by(["species", "island"])  # <1>
    .aggregate(count=ibis._.count())  # <1>
    .order_by(ibis.desc("count"))  # <1>
)  # <1>
con.create_table("penguins_grouped", grouped.to_pyarrow(), overwrite=True)  # <2>
```

1. Create a lazily evaluated Ibis expression.
2. Write to a table.

## File formats

Depending on the backend, you can read and write data in several file formats.

::: {.panel-tabset}

## CSV

```{.bash}
pip install 'ibis-framework[duckdb]'
```

```{python}
t.to_csv("penguins.csv")  # <1>
ibis.read_csv("penguins.csv").head(3)  # <2>
```
1. Write the table to a CSV file. Dependent on backend.
2. Read the CSV file into a table. Dependent on backend.

## Delta Lake

```{.bash}
pip install 'ibis-framework[duckdb,deltalake]'
```

```{python}
t.to_delta("penguins.delta", mode="overwrite")  # <1>
ibis.read_delta("penguins.delta").head(3)  # <2>
```

1. Write the table to a Delta Lake table. Dependent on backend.
2. Read the Delta Lake table into a table. Dependent on backend.

## Parquet

```{.bash}
pip install 'ibis-framework[duckdb]'
```

```{python}
t.to_parquet("penguins.parquet")  # <1>
ibis.read_parquet("penguins.parquet").head(3)  # <2>
```

1. Write the table to a Parquet file. Dependent on backend.
2. Read the Parquet file into a table. Dependent on backend.

:::

## With other Python libraries

Ibis uses [Apache Arrow](https://arrow.apache.org/) for efficient data transfer
to and from other libraries. Ibis tables implement the `__dataframe__` and
`__array__` protocols, so you can pass them to any library that supports these
protocols.

::: {.panel-tabset}

## `pandas`

You can convert Ibis tables to pandas dataframes.

```bash
pip install pandas
```

```{python}
df = t.to_pandas()  # <1>
df.head(3)
```

1. Returns a pandas dataframe.

Or you can convert pandas dataframes to Ibis tables.

```{python}
t = ibis.memtable(df)  # <1>
t.head(3)
```

1. Returns an Ibis table.

## `polars`

You can convert Ibis tables to Polars dataframes.

```bash
pip install polars
```

```{python}
import polars as pl

df = pl.from_arrow(t.to_pyarrow())
df.head(3)
```

Or Polars dataframes to Ibis tables.

```{python}
t = ibis.memtable(df)
t.head(3)
```

## `pyarrow`

You can convert Ibis tables to PyArrow tables.

```bash
pip install pyarrow
```

```{python}
t.to_pyarrow()
```

Or PyArrow batches:

```{python}
t.to_pyarrow_batches()
```

And you can convert PyArrow tables to Ibis tables.

```{python}
ibis.memtable(t.to_pyarrow()).head(3)
```

## `torch`

You can convert Ibis tables to torch tensors.

```bash
pip install torch
```

```python
t.select(s.numeric()).limit(3).to_torch()
```

```
{'col2': tensor([39.1000, 39.5000, 40.3000], dtype=torch.float64),
 'col3': tensor([18.7000, 17.4000, 18.0000], dtype=torch.float64),
 'col4': tensor([181., 186., 195.], dtype=torch.float64),
 'col5': tensor([3750., 3800., 3250.], dtype=torch.float64),
 'col7': tensor([2007, 2007, 2007], dtype=torch.int16)}
```

## `__dataframe__`

You can directly call the `__dataframe__` protocol on Ibis tables, though this is typically handled by the library you're using.

```{python}
t.__dataframe__()
```

## `__array__`

You can directly call the `__array__` protocol on Ibis tables, though this is typically handled by the library you're using.

```{python}
t.__array__()
```

:::
