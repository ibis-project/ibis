---
title: "Analysis of Ibis's CI performance"
author: "Phillip Cloud"
date: "2023-01-09"
categories:
    - blog
    - bigquery
    - continuous integration
    - data engineering
    - dogfood
---

## Summary

This notebook takes you through an analysis of Ibis's CI data using ibis on top of [Google BigQuery](https://cloud.google.com/bigquery).

- First, we load some data and poke around at it to see what's what.
- Second, we figure out some useful things to calculate based on our poking.
- Third, we'll visualize the results of calculations to showcase what changed and how.

## Imports

Let's start out by importing ibis and turning on interactive mode.


```{python}
import ibis
from ibis import _

ibis.options.interactive = True
```

## Connect to BigQuery

We connect to BigQuery using the `ibis.connect` API, which accepts a URL string indicating the backend and various bit of information needed to connect to the backend. Here we're using BigQuery, so we need the project id (`ibis-gbq`) and the dataset id (`workflows`).

Datasets are analogous to schemas in other systems.


```{python}
url = "bigquery://ibis-gbq/workflows"
con = ibis.connect(url)
```

Let's see what tables are available.


```{python}
con.list_tables()
```

## Analysis

Here we've got our first bit of interesting information: the `jobs` and `workflows` tables.

### Terminology

Before we jump in, it helps to lay down some terminology.

- A **workflow** corresponds to an individual GitHub Actions YAML file in a GitHub repository under the `.github/workflows` directory.
- A **job** is a named set of steps to run inside a **workflow** file.

### What's in the `workflows` table?

Each row in the `workflows` table corresponds to a **workflow run**.

- A **workflow run** is an instance of a workflow that was triggered by some entity: a GitHub user, bot, or other entity. Each row of the `workflows` table is a **workflow run**.

### What's in the `jobs` table?

Similarly, each row in the `jobs` table is a **job run**. That is, for a given **workflow run** there are a set of jobs run with it.

- A **job run** is an instance of a job *in a workflow*. It is associated with a single **workflow run**.

## Rationale

The goal of this analysis is to try to understand ibis's CI performance, and whether the amount of time we spent waiting on CI has decreased, stayed the same or increased. Ideally, we can understand the pieces that contribute to the change or lack thereof.

### Metrics

To that end there are a few interesting metrics to look at:

- **job run** *duration*: this is the amount of time it takes for a given job to complete
- **workflow run** *duration*: the amount of time it takes for *all* job runs in a workflow run to complete.
- **queueing** *duration*: the amount time time spent waiting for the *first* job run to commence.

### Mitigating Factors

- Around October 2021, we changed our CI infrastructure to use [Poetry](https://python-poetry.org/) instead of [Conda](https://docs.conda.io/en/latest/). The goal there was to see if we could cache dependencies using the lock file generated by poetry. We should see whether that had any effect.
- At the end of November 2022, we switch to the Team Plan (a paid GitHub plan) for the Ibis organzation. This tripled the amount of **job runs** that could execute in parallel. We should see if that helped anything.

Alright, let's jump into some data!


```{python}
jobs = con.tables.jobs[_.started_at < "2023-01-09"]
jobs
```

These first few columns in the `jobs` table aren't that interesting so we should look at what else is there


```{python}
jobs.columns
```

A bunch of these aren't that useful for our purposes. However, `run_id`, `started_at`, `completed_at` are useful for us. The [GitHub documentation for job information](https://docs.github.com/en/rest/actions/workflow-jobs?apiVersion=2022-11-28#get-a-job-for-a-workflow-run) provides useful detail about the meaning of these fields.

- `run_id`: the workflow run associated with this job run
- `started_at`: when the job started
- `completed_at`: when the job completed

What we're interested in to a first degree is the job duration, so let's compute that.

We also need to compute when the last job for a given `run_id` started and when it completed. We'll use the former to compute the queueing duration, and the latter to compute the total time it took for a given workflow run to complete.


```{python}
run_id_win = ibis.window(group_by=_.run_id)
jobs = jobs.select(
    _.run_id,
    job_duration=_.completed_at.cast("int") - _.started_at.cast("int"),
    last_job_started_at=_.started_at.max().over(run_id_win),
    last_job_completed_at=_.completed_at.max().over(run_id_win),
)
jobs
```

Let's take a look at `workflows`

```{python}
workflows = con.tables.workflows
workflows
```

Again we have a bunch of columns that aren't so useful to us, so let's see what else is there.


```{python}
workflows.columns
```

We don't care about many of these for the purposes of this analysis, however we need the `id` and a few values derived from the `run_started_at` column.

- `id`: the unique identifier of the **workflow run**
- `run_started_at`: the time the workflow run started

We compute the date the run started at so we can later compare it to the dates where we added poetry and switched to the team plan.

```{python}
workflows = workflows.select(
    _.id, _.run_started_at, started_date=_.run_started_at.date()
)
workflows
```

We need to associate jobs and workflows somehow, so let's join them on the relevant key fields.

```{python}
joined = jobs.join(workflows, jobs.run_id == workflows.id)
joined
```

Sweet! Now we have workflow runs and job runs together in the same table, let's start exploring summarization.

Let's encode our knowledge about when the poetry move happened and also when we moved to the team plan.


```{python}
from datetime import date

POETRY_MERGED_DATE = date(2021, 10, 15)
TEAMIZATION_DATE = date(2022, 11, 28)
```

Let's compute some indicator variables indicating whether a given row contains data after poetry changes occurred, and do the same for the team plan.

Let's also compute queueing time and workflow duration.


```{python}
stats = joined.select(
    _.started_date,
    _.job_duration,
    has_poetry=_.started_date > POETRY_MERGED_DATE,
    has_team=_.started_date > TEAMIZATION_DATE,
    queueing_time=_.last_job_started_at.cast("int")
    - _.run_started_at.cast("int"),
    workflow_duration=_.last_job_completed_at.cast("int")
    - _.run_started_at.cast("int"),
)
stats
```

Let's create a column ranging from 0 to 2 inclusive where:

- 0: no improvements
- 1: just poetry
- 2: poetry and the team plan

Let's also give them some names that'll look nice on our plots.


```{python}
stats = stats.mutate(
    raw_improvements=_.has_poetry.cast("int") + _.has_team.cast("int")
).mutate(
    improvements=(
        _.raw_improvements.case()
        .when(0, "None")
        .when(1, "Poetry")
        .when(2, "Poetry + Team Plan")
        .else_("NA")
        .end()
    ),
    team_plan=ibis.where(_.raw_improvements > 1, "Poetry + Team Plan", "None"),
)
stats
```

Finally, we can summarize by averaging the different durations, grouping on the variables of interest.

```{python}
USECS_PER_MIN = 60_000_000

agged = stats.group_by([_.started_date, _.improvements, _.team_plan]).agg(
    job=_.job_duration.div(USECS_PER_MIN).mean(),
    workflow=_.workflow_duration.div(USECS_PER_MIN).mean(),
    queueing_time=_.queueing_time.div(USECS_PER_MIN).mean(),
)
agged
```

If at any point you want to inspect the SQL you'll be running, ibis has you covered with `ibis.to_sql`.


```{python}
ibis.to_sql(agged)
```

# Plot the Results

Ibis doesn't have builtin plotting support, so we need to pull our results into pandas.

Here I'm using `plotnine` (a Python port of `ggplot2`), which has great integration with pandas DataFrames.

```{python}
raw_df = agged.execute()
raw_df
```

Generally, `plotnine` works with long, tidy data so let's use `pandas.melt` to get there.


```{python}
import pandas as pd

df = pd.melt(
    raw_df,
    id_vars=["started_date", "improvements", "team_plan"],
    var_name="entity",
    value_name="duration",
)
df.head()
```

Let's make our theme lighthearted by using `xkcd`-style plots.


```{python}
from plotnine import *

theme_set(theme_xkcd())
```

Create a few labels for our plot.


```{python}
poetry_label = f"Poetry\n{POETRY_MERGED_DATE}"
team_label = f"Team Plan\n{TEAMIZATION_DATE}"
```

Without the following line you may see large amount of inconsequential warnings that make the notebook unusable.

```{python}
import logging

# without this, findfont logging spams the notebook making it unusable
logging.getLogger('matplotlib.font_manager').disabled = True
```

Here we show job durations, coloring the points differently depending on whether they have no improvements, poetry, or poetry + team plan.

```{python}
(
    ggplot(
        df.loc[df.entity == "job"].reset_index(drop=True),
        aes(x="started_date", y="duration", color="factor(improvements)"),
    )
    + geom_point()
    + geom_vline(
        xintercept=[TEAMIZATION_DATE, POETRY_MERGED_DATE],
        colour=["blue", "green"],
        linetype="dashed",
    )
    + scale_color_brewer(
        palette=7,
        type='qual',
        limits=["None", "Poetry", "Poetry + Team Plan"],
    )
    + geom_text(x=POETRY_MERGED_DATE, label=poetry_label, y=15, color="blue")
    + geom_text(x=TEAMIZATION_DATE, label=team_label, y=10, color="blue")
    + stat_smooth(method="lm")
    + labs(x="Date", y="Duration (minutes)")
    + ggtitle("Job Duration")
    + theme(
        figure_size=(22, 6),
        legend_position=(0.67, 0.65),
        legend_direction="vertical",
    )
)
```

## Result #1: Job Duration

This result is pretty interesting.

A few things pop out to me right away:

- The move to poetry decreased the average job run duration by quite a bit. No, I'm not going to do any statistical tests.
- The variability of job run durations also decreased by quite a bit after introducing poetry.
- Moving to the team plan had little to no effect on job run duration.

```{python}
(
    ggplot(
        df.loc[df.entity != "job"].reset_index(drop=True),
        aes(x="started_date", y="duration", color="factor(improvements)"),
    )
    + facet_wrap("entity", ncol=1)
    + geom_point()
    + geom_vline(
        xintercept=[TEAMIZATION_DATE, POETRY_MERGED_DATE],
        linetype="dashed",
    )
    + scale_color_brewer(
        palette=7,
        type='qual',
        limits=["None", "Poetry", "Poetry + Team Plan"],
    )
    + geom_text(x=POETRY_MERGED_DATE, label=poetry_label, y=75, color="blue")
    + geom_text(x=TEAMIZATION_DATE, label=team_label, y=50, color="blue")
    + stat_smooth(method="lm")
    + labs(x="Date", y="Duration (minutes)")
    + ggtitle("Workflow Duration")
    + theme(
        figure_size=(22, 13),
        legend_position=(0.68, 0.75),
        legend_direction="vertical",
    )
)
```

## Result #2: Workflow Duration and Queueing Time

Another interesting result.

### Queueing Time

- It almost looks like moving to poetry made average queueing time worse. This is probably due to our perception that faster jobs means faster ci. As we see here that isn't the case
- Moving to the team plan cut down the queueing time by quite a bit

### Workflow Duration

- Overall workflow duration appears to be strongly influenced by moving to the team plan, which is almost certainly due to the drop in queueing time since we are no longer limited by slow job durations.
- Perhaps it's obvious, but queueing time and workflow duration appear to be highly correlated.

In the next plot we'll look at that correlation.

```{python}
(
    ggplot(raw_df, aes(x="workflow", y="queueing_time"))
    + geom_point()
    + geom_rug()
    + facet_grid(". ~ team_plan")
    + labs(x="Workflow Duration (minutes)", y="Queueing Time (minutes)")
    + ggtitle("Workflow Duration vs. Queueing Time")
    + theme(figure_size=(22, 6))
)
```

## Result #3: Workflow Duration and Queueing Duration are correlated

It also seems that moving to the team plan (though also the move to poetry might be related here) reduced the variability of both metrics.

We're lacking data compared to the past so we should wait for more to come in.

## Conclusions

It appears that you need both a short queue time **and** fast individual jobs to minimize time spent in CI.

If you have a short queue time, but long job runs then you'll be bottlenecked on individual jobs, and if you have more jobs than queue slots then you'll be blocked on queueing time.

I think we can sum this up nicely:

- slow jobs, slow queue: 🤷 blocked by jobs or queue
- slow jobs, fast queue: ❓ blocked by jobs, if jobs are slow enough
- fast jobs, slow queue: ❗ blocked by queue, with enough jobs
- fast jobs, fast queue: ✅
